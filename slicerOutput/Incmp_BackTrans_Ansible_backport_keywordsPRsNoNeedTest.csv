"VERSION = '2.10'
"
-------------------------------------------------------------------------
"from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

"
-------------------------------------------------------------------------
"from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

"
-------------------------------------------------------------------------
"Recom
PRs: 73616, 73637"
-------------------------------------------------------------------------
=========================================================================
"# -*- coding: utf-8 -*-
#
# documentation build configuration file, created by
# sphinx-quickstart on Sat Sep 27 13:23:22 2008-2009.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# The contents of this file are pickled, so don't put values in the namespace
# that aren't pickleable (module imports are okay, they're removed
# automatically).
#
# All configuration values have a default value; values that are commented out
# serve to show the default value.

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import sys
import os

# pip install sphinx_rtd_theme
# import sphinx_rtd_theme
# html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]

# If your extensions are in another directory, add it here. If the directory
# is relative to the documentation root, use os.path.abspath to make it
# absolute, like shown here.
# sys.path.append(os.path.abspath('some/directory'))
#
sys.path.insert(0, os.path.join('ansible', 'lib'))
sys.path.append(os.path.abspath(os.path.join('..', '_extensions')))

# We want sphinx to document the ansible modules contained in this repository,
# not those that may happen to be installed in the version
# of Python used to run sphinx.  When sphinx loads in order to document,
# the repository version needs to be the one that is loaded:
sys.path.insert(0, os.path.abspath(os.path.join('..', '..', '..', 'lib')))

VERSION = 'devel'
AUTHOR = 'Ansible, Inc'


# General configuration
# ---------------------

# Add any Sphinx extension module names here, as strings.
# They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
# TEST: 'sphinxcontrib.fulltoc'
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.intersphinx', 'pygments_lexer', 'notfound.extension']

# Later on, add 'sphinx.ext.viewcode' to the list if you want to have
# colorized code generated too for references.


# Add any paths that contain templates here, relative to this directory.
templates_path = ['.templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The master toctree document.
master_doc = 'index'

# General substitutions.
project = 'Ansible'
copyright = ""2021 Red Hat, Inc.""

# The default replacements for |version| and |release|, also used in various
# other places throughout the built documents.
#
# The short X.Y version.
version = VERSION
# The full version, including alpha/beta/rc tags.
release = VERSION

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
# today = ''
# Else, today_fmt is used as the format for a strftime call.
today_fmt = '%B %d, %Y'

# List of documents that shouldn't be included in the build.
# unused_docs = []

# List of directories, relative to source directories, that shouldn't be
# searched for source files.
# exclude_dirs = []

# A list of glob-style patterns that should be excluded when looking
# for source files.
exclude_patterns = [
'2.10_index.rst',
'ansible_index.rst',
'core_index.rst',
'porting_guides/core_porting_guides.rst',
'porting_guides/porting_guide_base_2.10.rst',
'porting_guides/porting_guide_core_2.11.rst',
'roadmap/index.rst',
'roadmap/ansible_base_roadmap_index.rst',
'roadmap/ROADMAP_2_10.rst',
'roadmap/ROADMAP_2_11.rst'


e reST default role (used for this markup: `text`) to use for all
cuments.
fault_role = None

 true, '()' will be appended to :func: etc. cross-reference text.
d_function_parentheses = True

 true, the current module name will be prepended to all description
it titles (such as .. function::).
d_module_names = True

 true, sectionauthor and moduleauthor directives will be shown in the
tput. They are ignored by default.
ow_authors = False

e name of the Pygments (syntax highlighting) style to use.
ents_style = 'sphinx'

light_language = 'YAMLJinja'

bstitutions, variables, entities, & shortcuts for text which do not need to link to anything.
r titles which should be a link, use the intersphinx anchors set at the index, chapter, and section levels, such as  qi_start_:
r| is useful for formatting fields inside of tables
| is a nonbreaking space; similarly useful inside of tables
epilog = """"""
br| raw:: html

br>
_| unicode:: 0xA0
:trim:



tions for HTML output
---------------------

_theme_path = ['../_themes']
_theme = 'sphinx_rtd_theme'
_short_title = 'Ansible Documentation'
_show_sphinx = False

_theme_options = {
'canonical_url': ""https://docs.ansible.com/ansible/latest/"",
'vcs_pageview_mode': 'edit'


_context = {
'display_github': 'True',
'github_user': 'ansible',
'github_repo': 'ansible',
'github_version': 'devel/docs/docsite/rst/',
'github_module_version': 'devel/lib/ansible/modules/',
'github_root_dir': 'devel/lib/ansible',
'github_cli_version': 'devel/lib/ansible/cli/',
'current_version': version,
'latest_version': '2.10',
# list specifically out of order to make latest work
'available_versions': ('latest', '2.9', '2.9_ja', '2.8', 'devel'),
'css_files': ('_static/ansible.css',  # overrides to the standard theme
              ),


e style sheet to use for HTML and HTML Help pages. A file of that name
st exist either in Sphinx' static/ path, or in one of the custom paths
ven in html_static_path.
ml_style = 'solar.css'

e name for this set of Sphinx documents.  If None, it defaults to
project> v<release> documentation"".
_title = 'Ansible Documentation'

shorter title for the navigation bar.  Default is the same as html_title.
ml_short_title = None

e name of an image file (within the static path) to place at the top of
e sidebar.
ml_logo =

e name of an image file (within the static path) to use as favicon of the
cs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
xels large.
ml_favicon = 'favicon.ico'

d any paths that contain custom static files (such as style sheets) here,
lative to this directory. They are copied after the builtin static files,
 a file named ""default.css"" will overwrite the builtin ""default.css"".
_static_path = ['../_static']

 not '', a 'Last updated on:' timestamp is inserted at every page bottom,
ing the given strftime format.
_last_updated_fmt = '%b %d, %Y'

 true, SmartyPants will be used to convert quotes and dashes to
pographically correct entities.
ml_use_smartypants = True

stom sidebar templates, maps document names to template names.
ml_sidebars = {}

ditional templates that should be rendered to pages, maps page names to
mplate names.
ml_additional_pages = {}

 false, no module index is generated.
ml_use_modindex = True

 false, no index is generated.
ml_use_index = True

 true, the index is split into individual pages for each letter.
ml_split_index = False

 true, the reST sources are included in the HTML build as _sources/<name>.
_copy_source = False

 true, an OpenSearch description file will be output, and all pages will
ntain a <link> tag referring to it.  The value of this option must be the
se URL from which the finished HTML is served.
ml_use_opensearch = 'https://docs.ansible.com/ansible/latest'

 nonempty, this is the file name suffix for HTML files (e.g. "".xhtml"").
ml_file_suffix = ''

tput file base name for HTML help builder.
help_basename = 'Poseidodoc'

nfiguration for sphinx-notfound-pages
th no 'notfound_template' and no 'notfound_context' set,
e extension builds 404.rst into a location-agnostic 404 page

fault is `en` - using this for the sub-site:
ound_default_language = ""ansible""
fault is `latest`:
tting explicitly - docsite serves up /ansible/latest/404.html
 keep this set to `latest` even on the `devel` branch
en no maintenance is needed when we branch a new stable_x.x
ound_default_version = ""latest""
kes default setting explicit:
ound_no_urls_prefix = False

tions for LaTeX output
----------------------

e paper size ('letter' or 'a4').
tex_paper_size = 'letter'

e font size ('10pt', '11pt' or '12pt').
tex_font_size = '10pt'

ouping the document tree into LaTeX files. List of tuples
ource start file, target name, title, author, document class
owto/manual]).
x_documents = [
('index', 'ansible.tex', 'Ansible 2.2 Documentation', AUTHOR, 'manual'),


e name of an image file (relative to this directory) to place at the top of
e title page.
tex_logo = None

r ""manual"" documents, if this is true, then toplevel headings are parts,
t chapters.
tex_use_parts = False

ditional stuff for the LaTeX preamble.
tex_preamble = ''

cuments to append as an appendix to all manuals.
tex_appendices = []

 false, no module index is generated.
tex_use_modindex = True

class_content = 'both'

te:  Our strategy for intersphinx mappings is to have the upstream build location as the
nonical source and then cached copies of the mapping stored locally in case someone is building
en disconnected from the internet.  We then have a script to update the cached copies.

cause of that, each entry in this mapping should have this format:
name: ('http://UPSTREAM_URL', (None, 'path/to/local/cache.inv'))

e update script depends on this format so deviating from this (for instance, adding a third
cation for the mappning to live) will confuse it.
rsphinx_mapping = {'python': ('https://docs.python.org/2/', (None, '../python2.inv')),
                   'python3': ('https://docs.python.org/3/', (None, '../python3.inv')),
                   'jinja2': ('http://jinja.palletsprojects.com/', (None, '../jinja2.inv')),
                   'ansible_2_10': ('https://docs.ansible.com/ansible/2.10/', (None, '../ansible_2_10.inv')),
                   'ansible_2_9': ('https://docs.ansible.com/ansible/2.9/', (None, '../ansible_2_9.inv')),
                   'ansible_2_8': ('https://docs.ansible.com/ansible/2.8/', (None, '../ansible_2_8.inv')),
                   'ansible_2_7': ('https://docs.ansible.com/ansible/2.7/', (None, '../ansible_2_7.inv')),
                   'ansible_2_6': ('https://docs.ansible.com/ansible/2.6/', (None, '../ansible_2_6.inv')),
                   'ansible_2_5': ('https://docs.ansible.com/ansible/2.5/', (None, '../ansible_2_5.inv')),
                   }

nckchecker settings
check_ignore = [
r'http://irc\.freenode\.net',

check_workers = 25
nkcheck_anchors = False
"
-------------------------------------------------------------------------
"# -*- coding: utf-8 -*-
#
# documentation build configuration file, created by
# sphinx-quickstart on Sat Sep 27 13:23:22 2008-2009.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# The contents of this file are pickled, so don't put values in the namespace
# that aren't pickleable (module imports are okay, they're removed
# automatically).
#
# All configuration values have a default value; values that are commented out
# serve to show the default value.

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import sys
import os

# pip install sphinx_rtd_theme
# import sphinx_rtd_theme
# html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]

# If your extensions are in another directory, add it here. If the directory
# is relative to the documentation root, use os.path.abspath to make it
# absolute, like shown here.
# sys.path.append(os.path.abspath('some/directory'))
#
sys.path.insert(0, os.path.join('ansible', 'lib'))
sys.path.append(os.path.abspath(os.path.join('..', '_extensions')))

# We want sphinx to document the ansible modules contained in this repository,
# not those that may happen to be installed in the version
# of Python used to run sphinx.  When sphinx loads in order to document,
# the repository version needs to be the one that is loaded:
sys.path.insert(0, os.path.abspath(os.path.join('..', '..', '..', 'lib')))

VERSION = '3'
AUTHOR = 'Ansible, Inc'


# General configuration
# ---------------------

# Add any Sphinx extension module names here, as strings.
# They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
# TEST: 'sphinxcontrib.fulltoc'
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.intersphinx', 'pygments_lexer', 'notfound.extension']

# Later on, add 'sphinx.ext.viewcode' to the list if you want to have
# colorized code generated too for references.


# Add any paths that contain templates here, relative to this directory.
templates_path = ['.templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The master toctree document.
master_doc = 'index'

# General substitutions.
project = 'Ansible'
copyright = ""2021 Red Hat, Inc.""

# The default replacements for |version| and |release|, also used in various
# other places throughout the built documents.
#
# The short X.Y version.
version = VERSION
# The full version, including alpha/beta/rc tags.
release = VERSION

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
# today = ''
# Else, today_fmt is used as the format for a strftime call.
today_fmt = '%B %d, %Y'

# List of documents that shouldn't be included in the build.
# unused_docs = []

# List of directories, relative to source directories, that shouldn't be
# searched for source files.
# exclude_dirs = []

# A list of glob-style patterns that should be excluded when looking
# for source files.
exclude_patterns = [
'2.10_index.rst',
'ansible_index.rst',
'core_index.rst',
'porting_guides/core_porting_guides.rst',
'porting_guides/porting_guide_base_2.10.rst',
'porting_guides/porting_guide_core_2.11.rst',
'roadmap/index.rst',
'roadmap/ansible_base_roadmap_index.rst',
'roadmap/ROADMAP_2_10.rst',
'roadmap/ROADMAP_2_11.rst'


e reST default role (used for this markup: `text`) to use for all
cuments.
fault_role = None

 true, '()' will be appended to :func: etc. cross-reference text.
d_function_parentheses = True

 true, the current module name will be prepended to all description
it titles (such as .. function::).
d_module_names = True

 true, sectionauthor and moduleauthor directives will be shown in the
tput. They are ignored by default.
ow_authors = False

e name of the Pygments (syntax highlighting) style to use.
ents_style = 'sphinx'

light_language = 'YAMLJinja'

bstitutions, variables, entities, & shortcuts for text which do not need to link to anything.
r titles which should be a link, use the intersphinx anchors set at the index, chapter, and section levels, such as  qi_start_:
r| is useful for formatting fields inside of tables
| is a nonbreaking space; similarly useful inside of tables
epilog = """"""
br| raw:: html

br>
_| unicode:: 0xA0
:trim:



tions for HTML output
---------------------

_theme_path = ['../_themes']
_theme = 'sphinx_rtd_theme'
_short_title = 'Ansible Documentation'
_show_sphinx = False

_theme_options = {
'canonical_url': ""https://docs.ansible.com/ansible/latest/"",
'vcs_pageview_mode': 'edit'


_context = {
'display_github': 'True',
'github_user': 'ansible',
'github_repo': 'ansible',
'github_version': 'devel/docs/docsite/rst/',
'github_module_version': 'devel/lib/ansible/modules/',
'github_root_dir': 'devel/lib/ansible',
'github_cli_version': 'devel/lib/ansible/cli/',
'current_version': version,
'latest_version': '3',
# list specifically out of order to make latest work
'available_versions': ('latest', '2.10', '2.9', '2.9_ja', '2.8', 'devel'),
'css_files': ('_static/ansible.css',  # overrides to the standard theme
              ),


e style sheet to use for HTML and HTML Help pages. A file of that name
st exist either in Sphinx' static/ path, or in one of the custom paths
ven in html_static_path.
ml_style = 'solar.css'

e name for this set of Sphinx documents.  If None, it defaults to
project> v<release> documentation"".
_title = 'Ansible Documentation'

shorter title for the navigation bar.  Default is the same as html_title.
ml_short_title = None

e name of an image file (within the static path) to place at the top of
e sidebar.
ml_logo =

e name of an image file (within the static path) to use as favicon of the
cs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
xels large.
ml_favicon = 'favicon.ico'

d any paths that contain custom static files (such as style sheets) here,
lative to this directory. They are copied after the builtin static files,
 a file named ""default.css"" will overwrite the builtin ""default.css"".
_static_path = ['../_static']

 not '', a 'Last updated on:' timestamp is inserted at every page bottom,
ing the given strftime format.
_last_updated_fmt = '%b %d, %Y'

 true, SmartyPants will be used to convert quotes and dashes to
pographically correct entities.
ml_use_smartypants = True

stom sidebar templates, maps document names to template names.
ml_sidebars = {}

ditional templates that should be rendered to pages, maps page names to
mplate names.
ml_additional_pages = {}

 false, no module index is generated.
ml_use_modindex = True

 false, no index is generated.
ml_use_index = True

 true, the index is split into individual pages for each letter.
ml_split_index = False

 true, the reST sources are included in the HTML build as _sources/<name>.
_copy_source = False

 true, an OpenSearch description file will be output, and all pages will
ntain a <link> tag referring to it.  The value of this option must be the
se URL from which the finished HTML is served.
ml_use_opensearch = 'https://docs.ansible.com/ansible/latest'

 nonempty, this is the file name suffix for HTML files (e.g. "".xhtml"").
ml_file_suffix = ''

tput file base name for HTML help builder.
help_basename = 'Poseidodoc'

nfiguration for sphinx-notfound-pages
th no 'notfound_template' and no 'notfound_context' set,
e extension builds 404.rst into a location-agnostic 404 page

fault is `en` - using this for the sub-site:
ound_default_language = ""ansible""
fault is `latest`:
tting explicitly - docsite serves up /ansible/latest/404.html
 keep this set to `latest` even on the `devel` branch
en no maintenance is needed when we branch a new stable_x.x
ound_default_version = ""latest""
kes default setting explicit:
ound_no_urls_prefix = False

tions for LaTeX output
----------------------

e paper size ('letter' or 'a4').
tex_paper_size = 'letter'

e font size ('10pt', '11pt' or '12pt').
tex_font_size = '10pt'

ouping the document tree into LaTeX files. List of tuples
ource start file, target name, title, author, document class
owto/manual]).
x_documents = [
('index', 'ansible.tex', 'Ansible 2.2 Documentation', AUTHOR, 'manual'),


e name of an image file (relative to this directory) to place at the top of
e title page.
tex_logo = None

r ""manual"" documents, if this is true, then toplevel headings are parts,
t chapters.
tex_use_parts = False

ditional stuff for the LaTeX preamble.
tex_preamble = ''

cuments to append as an appendix to all manuals.
tex_appendices = []

 false, no module index is generated.
tex_use_modindex = True

class_content = 'both'

te:  Our strategy for intersphinx mappings is to have the upstream build location as the
nonical source and then cached copies of the mapping stored locally in case someone is building
en disconnected from the internet.  We then have a script to update the cached copies.

cause of that, each entry in this mapping should have this format:
name: ('http://UPSTREAM_URL', (None, 'path/to/local/cache.inv'))

e update script depends on this format so deviating from this (for instance, adding a third
cation for the mappning to live) will confuse it.
rsphinx_mapping = {'python': ('https://docs.python.org/2/', (None, '../python2.inv')),
                   'python3': ('https://docs.python.org/3/', (None, '../python3.inv')),
                   'jinja2': ('http://jinja.palletsprojects.com/', (None, '../jinja2.inv')),
                   'ansible_2_10': ('https://docs.ansible.com/ansible/2.10/', (None, '../ansible_2_10.inv')),
                   'ansible_2_9': ('https://docs.ansible.com/ansible/2.9/', (None, '../ansible_2_9.inv')),
                   'ansible_2_8': ('https://docs.ansible.com/ansible/2.8/', (None, '../ansible_2_8.inv')),
                   'ansible_2_7': ('https://docs.ansible.com/ansible/2.7/', (None, '../ansible_2_7.inv')),
                   'ansible_2_6': ('https://docs.ansible.com/ansible/2.6/', (None, '../ansible_2_6.inv')),
                   'ansible_2_5': ('https://docs.ansible.com/ansible/2.5/', (None, '../ansible_2_5.inv')),
                   }

nckchecker settings
check_ignore = [
r'http://irc\.freenode\.net',

check_workers = 25
nkcheck_anchors = False
"
-------------------------------------------------------------------------
"# -*- coding: utf-8 -*-
#
# documentation build configuration file, created by
# sphinx-quickstart on Sat Sep 27 13:23:22 2008-2009.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# The contents of this file are pickled, so don't put values in the namespace
# that aren't pickleable (module imports are okay, they're removed
# automatically).
#
# All configuration values have a default value; values that are commented out
# serve to show the default value.

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import sys
import os

# pip install sphinx_rtd_theme
# import sphinx_rtd_theme
# html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]

# If your extensions are in another directory, add it here. If the directory
# is relative to the documentation root, use os.path.abspath to make it
# absolute, like shown here.
# sys.path.append(os.path.abspath('some/directory'))
#
sys.path.insert(0, os.path.join('ansible', 'lib'))
sys.path.append(os.path.abspath(os.path.join('..', '_extensions')))

# We want sphinx to document the ansible modules contained in this repository,
# not those that may happen to be installed in the version
# of Python used to run sphinx.  When sphinx loads in order to document,
# the repository version needs to be the one that is loaded:
sys.path.insert(0, os.path.abspath(os.path.join('..', '..', '..', 'lib')))

VERSION = '3'
AUTHOR = 'Ansible, Inc'


# General configuration
# ---------------------

# Add any Sphinx extension module names here, as strings.
# They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
# TEST: 'sphinxcontrib.fulltoc'
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.intersphinx', 'pygments_lexer', 'notfound.extension']

# Later on, add 'sphinx.ext.viewcode' to the list if you want to have
# colorized code generated too for references.


# Add any paths that contain templates here, relative to this directory.
templates_path = ['.templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The master toctree document.
master_doc = 'index'

# General substitutions.
project = 'Ansible'
copyright = ""2021 Red Hat, Inc.""

# The default replacements for |version| and |release|, also used in various
# other places throughout the built documents.
#
# The short X.Y version.
version = VERSION
# The full version, including alpha/beta/rc tags.
release = VERSION

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
# today = ''
# Else, today_fmt is used as the format for a strftime call.
today_fmt = '%B %d, %Y'

# List of documents that shouldn't be included in the build.
# unused_docs = []

# List of directories, relative to source directories, that shouldn't be
# searched for source files.
# exclude_dirs = []

# A list of glob-style patterns that should be excluded when looking
# for source files.
exclude_patterns = [
'2.10_index.rst',
'ansible_index.rst',
'core_index.rst',
'porting_guides/core_porting_guides.rst',
'porting_guides/porting_guide_base_2.10.rst',
'porting_guides/porting_guide_core_2.11.rst',
'roadmap/index.rst',
'roadmap/ansible_base_roadmap_index.rst',
'roadmap/ROADMAP_2_10.rst',
'roadmap/ROADMAP_2_11.rst'


e reST default role (used for this markup: `text`) to use for all
cuments.
fault_role = None

 true, '()' will be appended to :func: etc. cross-reference text.
d_function_parentheses = True

 true, the current module name will be prepended to all description
it titles (such as .. function::).
d_module_names = True

 true, sectionauthor and moduleauthor directives will be shown in the
tput. They are ignored by default.
ow_authors = False

e name of the Pygments (syntax highlighting) style to use.
ents_style = 'sphinx'

light_language = 'YAMLJinja'

bstitutions, variables, entities, & shortcuts for text which do not need to link to anything.
r titles which should be a link, use the intersphinx anchors set at the index, chapter, and section levels, such as  qi_start_:
r| is useful for formatting fields inside of tables
| is a nonbreaking space; similarly useful inside of tables
epilog = """"""
br| raw:: html

br>
_| unicode:: 0xA0
:trim:



tions for HTML output
---------------------

_theme_path = ['../_themes']
_theme = 'sphinx_rtd_theme'
_short_title = 'Ansible Documentation'
_show_sphinx = False

_theme_options = {
'canonical_url': ""https://docs.ansible.com/ansible/latest/"",
'vcs_pageview_mode': 'edit'


_context = {
'display_github': 'True',
'github_user': 'ansible',
'github_repo': 'ansible',
'github_version': 'devel/docs/docsite/rst/',
'github_module_version': 'devel/lib/ansible/modules/',
'github_root_dir': 'devel/lib/ansible',
'github_cli_version': 'devel/lib/ansible/cli/',
'current_version': version,
'latest_version': '3',
# list specifically out of order to make latest work
'available_versions': ('latest', '2.10', '2.9', '2.9_ja', '2.8', 'devel'),
'css_files': ('_static/ansible.css',  # overrides to the standard theme
              ),


e style sheet to use for HTML and HTML Help pages. A file of that name
st exist either in Sphinx' static/ path, or in one of the custom paths
ven in html_static_path.
ml_style = 'solar.css'

e name for this set of Sphinx documents.  If None, it defaults to
project> v<release> documentation"".
_title = 'Ansible Documentation'

shorter title for the navigation bar.  Default is the same as html_title.
ml_short_title = None

e name of an image file (within the static path) to place at the top of
e sidebar.
ml_logo =

e name of an image file (within the static path) to use as favicon of the
cs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
xels large.
ml_favicon = 'favicon.ico'

d any paths that contain custom static files (such as style sheets) here,
lative to this directory. They are copied after the builtin static files,
 a file named ""default.css"" will overwrite the builtin ""default.css"".
_static_path = ['../_static']

 not '', a 'Last updated on:' timestamp is inserted at every page bottom,
ing the given strftime format.
_last_updated_fmt = '%b %d, %Y'

 true, SmartyPants will be used to convert quotes and dashes to
pographically correct entities.
ml_use_smartypants = True

stom sidebar templates, maps document names to template names.
ml_sidebars = {}

ditional templates that should be rendered to pages, maps page names to
mplate names.
ml_additional_pages = {}

 false, no module index is generated.
ml_use_modindex = True

 false, no index is generated.
ml_use_index = True

 true, the index is split into individual pages for each letter.
ml_split_index = False

 true, the reST sources are included in the HTML build as _sources/<name>.
_copy_source = False

 true, an OpenSearch description file will be output, and all pages will
ntain a <link> tag referring to it.  The value of this option must be the
se URL from which the finished HTML is served.
ml_use_opensearch = 'https://docs.ansible.com/ansible/latest'

 nonempty, this is the file name suffix for HTML files (e.g. "".xhtml"").
ml_file_suffix = ''

tput file base name for HTML help builder.
help_basename = 'Poseidodoc'

nfiguration for sphinx-notfound-pages
th no 'notfound_template' and no 'notfound_context' set,
e extension builds 404.rst into a location-agnostic 404 page

fault is `en` - using this for the sub-site:
ound_default_language = ""ansible""
fault is `latest`:
tting explicitly - docsite serves up /ansible/latest/404.html
 keep this set to `latest` even on the `devel` branch
en no maintenance is needed when we branch a new stable_x.x
ound_default_version = ""latest""
kes default setting explicit:
ound_no_urls_prefix = False

tions for LaTeX output
----------------------

e paper size ('letter' or 'a4').
tex_paper_size = 'letter'

e font size ('10pt', '11pt' or '12pt').
tex_font_size = '10pt'

ouping the document tree into LaTeX files. List of tuples
ource start file, target name, title, author, document class
owto/manual]).
x_documents = [
('index', 'ansible.tex', 'Ansible 2.2 Documentation', AUTHOR, 'manual'),


e name of an image file (relative to this directory) to place at the top of
e title page.
tex_logo = None

r ""manual"" documents, if this is true, then toplevel headings are parts,
t chapters.
tex_use_parts = False

ditional stuff for the LaTeX preamble.
tex_preamble = ''

cuments to append as an appendix to all manuals.
tex_appendices = []

 false, no module index is generated.
tex_use_modindex = True

class_content = 'both'

te:  Our strategy for intersphinx mappings is to have the upstream build location as the
nonical source and then cached copies of the mapping stored locally in case someone is building
en disconnected from the internet.  We then have a script to update the cached copies.

cause of that, each entry in this mapping should have this format:
name: ('http://UPSTREAM_URL', (None, 'path/to/local/cache.inv'))

e update script depends on this format so deviating from this (for instance, adding a third
cation for the mappning to live) will confuse it.
rsphinx_mapping = {'python': ('https://docs.python.org/2/', (None, '../python2.inv')),
                   'python3': ('https://docs.python.org/3/', (None, '../python3.inv')),
                   'jinja2': ('http://jinja.palletsprojects.com/', (None, '../jinja2.inv')),
                   'ansible_2_10': ('https://docs.ansible.com/ansible/2.10/', (None, '../ansible_2_10.inv')),
                   'ansible_2_9': ('https://docs.ansible.com/ansible/2.9/', (None, '../ansible_2_9.inv')),
                   'ansible_2_8': ('https://docs.ansible.com/ansible/2.8/', (None, '../ansible_2_8.inv')),
                   'ansible_2_7': ('https://docs.ansible.com/ansible/2.7/', (None, '../ansible_2_7.inv')),
                   'ansible_2_6': ('https://docs.ansible.com/ansible/2.6/', (None, '../ansible_2_6.inv')),
                   'ansible_2_5': ('https://docs.ansible.com/ansible/2.5/', (None, '../ansible_2_5.inv')),
                   }

nckchecker settings
check_ignore = [
r'http://irc\.freenode\.net',

check_workers = 25
nkcheck_anchors = False
"
-------------------------------------------------------------------------
"Recom
PRs: 73616, 73637"
-------------------------------------------------------------------------
=========================================================================
"'EulerOS', 'openEuler', 'AlmaLinux'],
"
-------------------------------------------------------------------------
"'OEL', 'Amazon', 'Virtuozzo', 'XenServer', 'Alibaba',
'AlmaLinux'],
"
-------------------------------------------------------------------------
"'OEL', 'Amazon', 'Virtuozzo', 'XenServer', 'Alibaba',
'AlmaLinux'],
"
-------------------------------------------------------------------------
"Recom
PRs: 73541, 73544"
-------------------------------------------------------------------------
=========================================================================
"if 'BHYVE' in out:
    guest_tech.add('bhyve')
    if not found_virt:
        virtual_facts['virtualization_type'] = 'bhyve'
        virtual_facts['virtualization_role'] = 'guest'
        found_virt = True

"
-------------------------------------------------------------------------
"if 'BHYVE' in out:
    virtual_facts['virtualization_type'] = 'bhyve'
    virtual_facts['virtualization_role'] = 'guest'
    return virtual_facts

"
-------------------------------------------------------------------------
"if 'BHYVE' in out:
    virtual_facts['virtualization_type'] = 'bhyve'
    virtual_facts['virtualization_role'] = 'guest'
    return virtual_facts

"
-------------------------------------------------------------------------
"Recom
PRs: 73204, 73234"
-------------------------------------------------------------------------
=========================================================================
"if 'BHYVE' in out:
    guest_tech.add('bhyve')
    if not found_virt:
        virtual_facts['virtualization_type'] = 'bhyve'
        virtual_facts['virtualization_role'] = 'guest'
        found_virt = True

"
-------------------------------------------------------------------------
"if 'BHYVE' in out:
    virtual_facts['virtualization_type'] = 'bhyve'
    virtual_facts['virtualization_role'] = 'guest'
    return virtual_facts

"
-------------------------------------------------------------------------
"if 'BHYVE' in out:
    virtual_facts['virtualization_type'] = 'bhyve'
    virtual_facts['virtualization_role'] = 'guest'
    return virtual_facts

"
-------------------------------------------------------------------------
"Recom
PRs: 73204, 73233"
-------------------------------------------------------------------------
=========================================================================
"to_text,
"
-------------------------------------------------------------------------
"yield DirectoryTarget(to_text(sorted(matched_directories, key=len)[0]), target.modules)
"
-------------------------------------------------------------------------
"yield DirectoryTarget(to_text(sorted(matched_directories, key=len)[0]), target.modules)
"
-------------------------------------------------------------------------
"Recom
PRs: 72623, 72866"
-------------------------------------------------------------------------
=========================================================================
"yield IntegrationTarget(to_text(path), modules, prefixes)
"
-------------------------------------------------------------------------
"yield TestTarget(to_text(file_path), module_path, prefix, path, symlink)
"
-------------------------------------------------------------------------
"yield TestTarget(to_text(file_path), module_path, prefix, path, symlink)
"
-------------------------------------------------------------------------
"Recom
PRs: 72623, 72866"
-------------------------------------------------------------------------
=========================================================================
"import sys
"
-------------------------------------------------------------------------
"import sys
import time
"
-------------------------------------------------------------------------
"import sys
import time
"
-------------------------------------------------------------------------
"Recom
PRs: 72604, 72610"
-------------------------------------------------------------------------
=========================================================================
"import sys
"
-------------------------------------------------------------------------
"import sys
import time
"
-------------------------------------------------------------------------
"import sys
import time
"
-------------------------------------------------------------------------
"Recom
PRs: 72604, 72609"
-------------------------------------------------------------------------
=========================================================================
"@staticmethod
def _combine_plugin_doc(plugin, plugin_type, doc, plainexamples, returndocs, metadata):
    # generate extra data
    if plugin_type == 'module':
        # is there corresponding action plugin?
        if plugin in action_loader:
            doc['has_action'] = True
        else:
            doc['has_action'] = False

    # return everything as one dictionary
    return {'doc': doc, 'examples': plainexamples, 'return': returndocs, 'metadata': metadata}

"
-------------------------------------------------------------------------
"def _combine_plugin_doc(plugin, plugin_type, doc, plainexamples, returndocs, metadata):
            doc['has_action'] = True
            doc['has_action'] = False

    # return everything as one dictionary
    return {'doc': doc, 'examples': plainexamples, 'return': returndocs, 'metadata': metadata}
@staticmethod
def format_plugin_doc(plugin, plugin_type, doc, plainexamples, returndocs, metadata):
    # assign from other sections
    doc['plainexamples'] = plainexamples
    doc['returndocs'] = returndocs
    doc['metadata'] = metadata
"
-------------------------------------------------------------------------
"def _combine_plugin_doc(plugin, plugin_type, doc, plainexamples, returndocs, metadata):
            doc['has_action'] = True
            doc['has_action'] = False

    # return everything as one dictionary
    return {'doc': doc, 'examples': plainexamples, 'return': returndocs, 'metadata': metadata}
@staticmethod
def format_plugin_doc(plugin, plugin_type, doc, plainexamples, returndocs, metadata):
    # assign from other sections
    doc['plainexamples'] = plainexamples
    doc['returndocs'] = returndocs
    doc['metadata'] = metadata
"
-------------------------------------------------------------------------
"Recom
PRs: 72359, 72416"
-------------------------------------------------------------------------
=========================================================================
"
# Workaround for https://github.com/ansible/ansible/issues/71528
elif err and rc == 1 and 'Failed to parse bus message' in err:
    result['status'] = parse_systemctl_show(to_native(out).split('\n'))

    (rc, out, err) = module.run_command(""{systemctl} list-units '{unit}*'"".format(systemctl=systemctl, unit=unit))
    is_systemd = unit in out

    (rc, out, err) = module.run_command(""{systemctl} is-active '{unit}'"".format(systemctl=systemctl, unit=unit))
    result['status']['ActiveState'] = out.rstrip('\n')

"
-------------------------------------------------------------------------
"
# Workaround for https://github.com/ansible/ansible/issues/71528
elif err and rc == 1 and 'Failed to parse bus message' in err:
    result['status'] = parse_systemctl_show(to_native(out).split('\n'))

    unit, sep, suffix = unit.partition('@')
    unit_search = '{unit}{sep}*'.format(unit=unit, sep=sep)
    (rc, out, err) = module.run_command(""{systemctl} list-unit-files '{unit_search}'"".format(systemctl=systemctl, unit_search=unit_search))
    is_systemd = unit in out

    (rc, out, err) = module.run_command(""{systemctl} is-active '{unit}'"".format(systemctl=systemctl, unit=unit))
    result['status']['ActiveState'] = out.rstrip('\n')

"
-------------------------------------------------------------------------
"
# Workaround for https://github.com/ansible/ansible/issues/71528
elif err and rc == 1 and 'Failed to parse bus message' in err:
    result['status'] = parse_systemctl_show(to_native(out).split('\n'))

    unit, sep, suffix = unit.partition('@')
    unit_search = '{unit}{sep}*'.format(unit=unit, sep=sep)
    (rc, out, err) = module.run_command(""{systemctl} list-unit-files '{unit_search}'"".format(systemctl=systemctl, unit_search=unit_search))
    is_systemd = unit in out

    (rc, out, err) = module.run_command(""{systemctl} is-active '{unit}'"".format(systemctl=systemctl, unit=unit))
    result['status']['ActiveState'] = out.rstrip('\n')

"
-------------------------------------------------------------------------
"Recom
PRs: 72337, 72348"
-------------------------------------------------------------------------
=========================================================================
"
# Workaround for https://github.com/ansible/ansible/issues/71528
elif err and rc == 1 and 'Failed to parse bus message' in err:
    result['status'] = parse_systemctl_show(to_native(out).split('\n'))

    (rc, out, err) = module.run_command(""{systemctl} list-units '{unit}*'"".format(systemctl=systemctl, unit=unit))
    is_systemd = unit in out

    (rc, out, err) = module.run_command(""{systemctl} is-active '{unit}'"".format(systemctl=systemctl, unit=unit))
    result['status']['ActiveState'] = out.rstrip('\n')

"
-------------------------------------------------------------------------
"
# Workaround for https://github.com/ansible/ansible/issues/71528
elif err and rc == 1 and 'Failed to parse bus message' in err:
    result['status'] = parse_systemctl_show(to_native(out).split('\n'))

    unit, sep, suffix = unit.partition('@')
    unit_search = '{unit}{sep}*'.format(unit=unit, sep=sep)
    (rc, out, err) = module.run_command(""{systemctl} list-unit-files '{unit_search}'"".format(systemctl=systemctl, unit_search=unit_search))
    is_systemd = unit in out

    (rc, out, err) = module.run_command(""{systemctl} is-active '{unit}'"".format(systemctl=systemctl, unit=unit))
    result['status']['ActiveState'] = out.rstrip('\n')

"
-------------------------------------------------------------------------
"
# Workaround for https://github.com/ansible/ansible/issues/71528
elif err and rc == 1 and 'Failed to parse bus message' in err:
    result['status'] = parse_systemctl_show(to_native(out).split('\n'))

    unit, sep, suffix = unit.partition('@')
    unit_search = '{unit}{sep}*'.format(unit=unit, sep=sep)
    (rc, out, err) = module.run_command(""{systemctl} list-unit-files '{unit_search}'"".format(systemctl=systemctl, unit_search=unit_search))
    is_systemd = unit in out

    (rc, out, err) = module.run_command(""{systemctl} is-active '{unit}'"".format(systemctl=systemctl, unit=unit))
    result['status']['ActiveState'] = out.rstrip('\n')

"
-------------------------------------------------------------------------
"Recom
PRs: 72337, 72347"
-------------------------------------------------------------------------
=========================================================================
"(rc, _out, _err) = self.execute_command([lchage_cmd, '-E', to_native(lexpires), self.name])
return (rc, out, err)
(rc, _out, _err) = self.execute_command([lgroupmod_cmd, '-M', self.name, add_group])
"
-------------------------------------------------------------------------
"(rc, _out, _err) = self.execute_command([lchage_cmd, '-E', to_native(lexpires), self.name])
"
-------------------------------------------------------------------------
"(rc, _out, _err) = self.execute_command([lchage_cmd, '-E', to_native(lexpires), self.name])
"
-------------------------------------------------------------------------
"Recom
PRs: 72088, 72340"
-------------------------------------------------------------------------
=========================================================================
"(rc, out, err) = (None, '', '')
    (rc, out, err) = self.execute_command(cmd)
    return (rc, out, err)
    (rc, _out, _err) = self.execute_command([lchage_cmd, '-E', to_native(lexpires), self.name])
    return (rc, out, err)
    (rc, _out, _err) = self.execute_command([lgroupmod_cmd, '-M', self.name, add_group])
    (rc, _out, _err) = self.execute_command([lgroupmod_cmd, '-m', self.name, del_group])
"
-------------------------------------------------------------------------
"(rc, out, err) = (None, '', '')
    (rc, out, err) = self.execute_command(cmd)
    return (rc, out, err)
    (rc, _out, _err) = self.execute_command([lchage_cmd, '-E', to_native(lexpires), self.name])
"
-------------------------------------------------------------------------
"(rc, out, err) = (None, '', '')
    (rc, out, err) = self.execute_command(cmd)
    return (rc, out, err)
    (rc, _out, _err) = self.execute_command([lchage_cmd, '-E', to_native(lexpires), self.name])
"
-------------------------------------------------------------------------
"Recom
PRs: 72088, 72340"
-------------------------------------------------------------------------
=========================================================================
"def post_process_whens(result, task, templar):

cond = None
if task.changed_when:
    cond = Conditional(loader=templar._loader)
    cond.when = task.changed_when
    result['changed'] = cond.evaluate_conditional(templar, templar.available_variables)

if task.failed_when:
    if cond is None:
        cond = Conditional(loader=templar._loader)
    cond.when = task.failed_when
    failed_when_result = cond.evaluate_conditional(templar, templar.available_variables)
    result['failed_when_result'] = result['failed'] = failed_when_result


"
-------------------------------------------------------------------------
"_sentinel = StrategySentinel()


"
-------------------------------------------------------------------------
"_sentinel = StrategySentinel()


"
-------------------------------------------------------------------------
"Recom
PRs: 70919, 72118"
-------------------------------------------------------------------------
=========================================================================
"post_process_whens(result_item, original_task, handler_templar)
post_process_whens(result_item, original_task, handler_templar)
"
-------------------------------------------------------------------------
"def post_process_whens(result, task, templar):
cond = None
if task.changed_when:
    cond = Conditional(loader=templar._loader)
    cond.when = task.changed_when
    result['changed'] = cond.evaluate_conditional(templar, templar.available_variables)

if task.failed_when:
    if cond is None:
        cond = Conditional(loader=templar._loader)
    cond.when = task.failed_when
    failed_when_result = cond.evaluate_conditional(templar, templar.available_variables)
    result['failed_when_result'] = result['failed'] = failed_when_result
"
-------------------------------------------------------------------------
"def post_process_whens(result, task, templar):
cond = None
if task.changed_when:
    cond = Conditional(loader=templar._loader)
    cond.when = task.changed_when
    result['changed'] = cond.evaluate_conditional(templar, templar.available_variables)

if task.failed_when:
    if cond is None:
        cond = Conditional(loader=templar._loader)
    cond.when = task.failed_when
    failed_when_result = cond.evaluate_conditional(templar, templar.available_variables)
    result['failed_when_result'] = result['failed'] = failed_when_result
"
-------------------------------------------------------------------------
"Recom
PRs: 70919, 72118"
-------------------------------------------------------------------------
=========================================================================
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
                self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
                fail = True
        else:  # fatal error
            fail = True

        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg)

"
-------------------------------------------------------------------------
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
                self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
                fail = True
        else:  # fatal error
            fail = True

        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg=msg)

"
-------------------------------------------------------------------------
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
                self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
                fail = True
        else:  # fatal error
            fail = True

        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg=msg)

"
-------------------------------------------------------------------------
"Recom
PRs: 71537, 71541"
-------------------------------------------------------------------------
=========================================================================
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
                self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
                fail = True
        else:  # fatal error
            fail = True

        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg)

"
-------------------------------------------------------------------------
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
                self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
                fail = True
        else:  # fatal error
            fail = True

        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg=msg)

"
-------------------------------------------------------------------------
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
                self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
                fail = True
        else:  # fatal error
            fail = True

        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg=msg)

"
-------------------------------------------------------------------------
"Recom
PRs: 71537, 71540"
-------------------------------------------------------------------------
=========================================================================
"self._created_files = set()

    self._uses_common_file_args = True
"
-------------------------------------------------------------------------
"if mode is None:
    return changed

"
-------------------------------------------------------------------------
"if mode is None:
    return changed

"
-------------------------------------------------------------------------
"Recom
PRs: 71260, 71514"
-------------------------------------------------------------------------
=========================================================================
"# Remove paths so we do not warn about creating with default permissions
# since we are calling this method on the path and setting the specified mode.
try:
    self._created_files.remove(path)
except KeyError:
    pass

"
-------------------------------------------------------------------------
"_DEFAULT_PERM = 0o0666       # default file permission bits
"
-------------------------------------------------------------------------
"_DEFAULT_PERM = 0o0666       # default file permission bits
"
-------------------------------------------------------------------------
"Recom
PRs: 71260, 71514"
-------------------------------------------------------------------------
=========================================================================
"_DEFAULT_PERM = 0o0600       # default file permission bits
"
-------------------------------------------------------------------------
"stat1.st_mode = 0o0644
"
-------------------------------------------------------------------------
"stat1.st_mode = 0o0644
"
-------------------------------------------------------------------------
"Recom
PRs: 71260, 71514"
-------------------------------------------------------------------------
=========================================================================
"- module: ansible.builtin.blockinfile
- module: ansible.builtin.copy
- module: ansible.builtin.file
- module: ansible.builtin.replace
- module: ansible.builtin.template
- module: ansible.windows.win_lineinfile
"
-------------------------------------------------------------------------
"- module: ansible.builtin.blockinfile
- module: ansible.builtin.copy
- module: ansible.builtin.file
- module: ansible.builtin.replace
- module: ansible.builtin.template
- module: community.windows.win_lineinfile
"
-------------------------------------------------------------------------
"- module: ansible.builtin.blockinfile
- module: ansible.builtin.copy
- module: ansible.builtin.file
- module: ansible.builtin.replace
- module: ansible.builtin.template
- module: community.windows.win_lineinfile
"
-------------------------------------------------------------------------
"Recom
PRs: 70530, 71380"
-------------------------------------------------------------------------
=========================================================================
"- module: ansible.builtin.copy
- module: ansible.windows.win_copy
- module: ansible.windows.win_template
"
-------------------------------------------------------------------------
"- For Windows you can use M(ansible.windows.win_template) which uses '\\r\\n' as C(newline_sequence) by default.
- module: ansible.builtin.copy
- module: ansible.windows.win_copy
- module: ansible.windows.win_template
"
-------------------------------------------------------------------------
"- For Windows you can use M(ansible.windows.win_template) which uses '\\r\\n' as C(newline_sequence) by default.
- module: ansible.builtin.copy
- module: ansible.windows.win_copy
- module: ansible.windows.win_template
"
-------------------------------------------------------------------------
"Recom
PRs: 70530, 71380"
-------------------------------------------------------------------------
=========================================================================
"- module: ansible.builtin.authorized_key
- module: ansible.builtin.group
- module: ansible.windows.win_user
"
-------------------------------------------------------------------------
"- module: ansible.posix.authorized_key
- module: ansible.builtin.group
- module: ansible.windows.win_user
"
-------------------------------------------------------------------------
"- module: ansible.posix.authorized_key
- module: ansible.builtin.group
- module: ansible.windows.win_user
"
-------------------------------------------------------------------------
"Recom
PRs: 70530, 71380"
-------------------------------------------------------------------------
=========================================================================
"- module: ansible.builtin.wait_for
- module: ansible.windows.win_wait_for
- module: ansible.windows.win_wait_for_process
"
-------------------------------------------------------------------------
"- module: ansible.builtin.wait_for
- module: ansible.windows.win_wait_for
- module: community.windows.win_wait_for_process
"
-------------------------------------------------------------------------
"- module: ansible.builtin.wait_for
- module: ansible.windows.win_wait_for
- module: community.windows.win_wait_for_process
"
-------------------------------------------------------------------------
"Recom
PRs: 70530, 71380"
-------------------------------------------------------------------------
=========================================================================
"- If you wish to update an existing repository definition use M(ansible.builtin.ini_file) instead.
"
-------------------------------------------------------------------------
"- If you wish to update an existing repository definition use M(community.general.ini_file) instead.
"
-------------------------------------------------------------------------
"- If you wish to update an existing repository definition use M(community.general.ini_file) instead.
"
-------------------------------------------------------------------------
"Recom
PRs: 70530, 71380"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils.common.collections import is_sequence, Mapping
def _fail_on_undefined(data):
""""""Recursively find an undefined value in a nested data structure
and properly raise the undefined exception.
""""""
if isinstance(data, Mapping):
    for value in data.values():
        _fail_on_undefined(value)
elif is_sequence(data):
    for item in data:
        _fail_on_undefined(item)
else:
    if isinstance(data, StrictUndefined):
        # To actually raise the undefined exception we need to
        # access the undefined object otherwise the exception would
        # be raised on the next access which might not be properly
        # handled.
        # See https://github.com/ansible/ansible/issues/52158
        # and StrictUndefined implementation in upstream Jinja2.
        str(data)

return data


https://github.com/pallets/jinja/blob/master/src/jinja2/nativetypes.py
""""""
    out = _fail_on_undefined(head[0])
    out = u''.join([to_text(_fail_on_undefined(v)) for v in nodes])
"
-------------------------------------------------------------------------
"from ansible.module_utils.common.collections import is_sequence, Mapping
"
-------------------------------------------------------------------------
"from ansible.module_utils.common.collections import is_sequence, Mapping
"
-------------------------------------------------------------------------
"Recom
PRs: 68432, 71105"
-------------------------------------------------------------------------
=========================================================================
"# Instantiate our ResultsCollector for handling results as
# they come in. Ansible expects this to be one of its main
# display outlets.
callback = ResultsCollector()

# Instantiate task queue manager, which takes care of forking
# and setting up all objects to iterate over host list and tasks.
# IMPORTANT: This also adds library dirs paths to the module loader
# IMPORTANT: and so it must be initialized before calling `Play.load()`.
tqm = TaskQueueManager(
    inventory=inventory,
    variable_manager=variable_manager,
    loader=loader,
    passwords=passwords,
    stdout_callback=callback,
)

"
-------------------------------------------------------------------------
"loader = DataLoader()  # Takes care of finding and reading yaml, json and ini files
passwords = dict(vault_pass='secret')
# Instantiate our ResultsCollectorJSONCallback for handling results as they come in. Ansible expects this to be one of its main display outlets
results_callback = ResultsCollectorJSONCallback()
# create inventory, use path to host config file as source or hosts in a comma separated string

# variable manager takes care of merging all the different sources to give you a unified view of variables available in each context
# instantiate task queue manager, which takes care of forking and setting up all objects to iterate over host list and tasks
"
-------------------------------------------------------------------------
"loader = DataLoader()  # Takes care of finding and reading yaml, json and ini files
passwords = dict(vault_pass='secret')
# Instantiate our ResultsCollectorJSONCallback for handling results as they come in. Ansible expects this to be one of its main display outlets
results_callback = ResultsCollectorJSONCallback()
# create inventory, use path to host config file as source or hosts in a comma separated string

# variable manager takes care of merging all the different sources to give you a unified view of variables available in each context
# instantiate task queue manager, which takes care of forking and setting up all objects to iterate over host list and tasks
"
-------------------------------------------------------------------------
"Recom
PRs: 70842, 70851"
-------------------------------------------------------------------------
=========================================================================
"# Instantiate our ResultsCollector for handling results as
# they come in. Ansible expects this to be one of its main
# display outlets.
callback = ResultsCollector()

# Instantiate task queue manager, which takes care of forking
# and setting up all objects to iterate over host list and tasks.
# IMPORTANT: This also adds library dirs paths to the module loader
# IMPORTANT: and so it must be initialized before calling `Play.load()`.
tqm = TaskQueueManager(
    inventory=inventory,
    variable_manager=variable_manager,
    loader=loader,
    passwords=passwords,
    stdout_callback=callback,
)

"
-------------------------------------------------------------------------
"loader = DataLoader()  # Takes care of finding and reading yaml, json and ini files
passwords = dict(vault_pass='secret')
# Instantiate our ResultsCollectorJSONCallback for handling results as they come in. Ansible expects this to be one of its main display outlets
results_callback = ResultsCollectorJSONCallback()
# create inventory, use path to host config file as source or hosts in a comma separated string

# variable manager takes care of merging all the different sources to give you a unified view of variables available in each context
# instantiate task queue manager, which takes care of forking and setting up all objects to iterate over host list and tasks
"
-------------------------------------------------------------------------
"loader = DataLoader()  # Takes care of finding and reading yaml, json and ini files
passwords = dict(vault_pass='secret')
# Instantiate our ResultsCollectorJSONCallback for handling results as they come in. Ansible expects this to be one of its main display outlets
results_callback = ResultsCollectorJSONCallback()
# create inventory, use path to host config file as source or hosts in a comma separated string

# variable manager takes care of merging all the different sources to give you a unified view of variables available in each context
# instantiate task queue manager, which takes care of forking and setting up all objects to iterate over host list and tasks
"
-------------------------------------------------------------------------
"Recom
PRs: 70445, 70850"
-------------------------------------------------------------------------
=========================================================================
"# `distutils` must be imported after `setuptools` or it will cause explosions
# with `setuptools >=48.0.0, <49.1`.
# Refs:
# * https://github.com/ansible/ansible/issues/70456
# * https://github.com/pypa/setuptools/issues/2230
# * https://github.com/pypa/setuptools/commit/bd110264
from distutils.command.build_scripts import build_scripts as BuildScripts
from distutils.command.sdist import sdist as SDist

"
-------------------------------------------------------------------------
"# `distutils` must be imported after `setuptools` or it will cause explosions
# with `setuptools >=48.0.0, <49.1`.
# Refs:
# * https://github.com/ansible/ansible/issues/70456
# * https://github.com/pypa/setuptools/issues/2230
# * https://github.com/pypa/setuptools/commit/bd110264
from distutils.command.build_scripts import build_scripts as BuildScripts
from distutils.command.sdist import sdist as SDist


def find_package_info(*file_paths):
try:
    with open(os.path.join(*file_paths), 'r') as f:
        info_file = f.read()
except Exception:
    raise RuntimeError(""Unable to find package info."")

# The version line must have the form
# __version__ = 'ver'
version_match = re.search(r""^__version__ = ['\""]([^'\""]*)['\""]"",
                          info_file, re.M)
author_match = re.search(r""^__author__ = ['\""]([^'\""]*)['\""]"",
                         info_file, re.M)

if version_match and author_match:
    return version_match.group(1), author_match.group(1)
raise RuntimeError(""Unable to find package info."")


_validate_install_ansible_base():
""""""Validate that we can install ansible-base. Currently this only
cares about upgrading to ansible-base from ansible<2.10
""""""
if os.getenv('ANSIBLE_SKIP_CONFLICT_CHECK', '') not in ('', '0'):
    return

# Save these for later restoring things to pre invocation
sys_modules = sys.modules.copy()
sys_modules_keys = set(sys_modules)

# Make sure `lib` isn't in `sys.path` that could confuse this
sys_path = sys.path[:]
abspath = os.path.abspath
sys.path[:] = [p for p in sys.path if abspath(p) != abspath('lib')]

try:
    from ansible.release import __version__
except ImportError:
    pass
else:
    version_tuple = tuple(int(v) for v in __version__.split('.')[:2])
    if version_tuple < (2, 10):
        stars = '*' * 76
        raise RuntimeError(
            '''

%s

Cannot install ansible-base with a pre-existing ansible==%s
installation.

Installing ansible-base with ansible-2.9 or older currently installed with
pip is known to cause problems. Please uninstall ansible and install the new
version:

    pip uninstall ansible
    pip install ansible-base

If you want to skip the conflict checks and manually resolve any issues
afterwards, set the ANSIBLE_SKIP_CONFLICT_CHECK environment variable:

    ANSIBLE_SKIP_CONFLICT_CHECK=1 pip install ansible-base

%s
            ''' % (stars, __version__, stars)
        )
finally:
    sys.path[:] = sys_path
    for key in sys_modules_keys.symmetric_difference(sys.modules):
        sys.modules.pop(key, None)
    sys.modules.update(sys_modules)


idate_install_ansible_base()
"
-------------------------------------------------------------------------
"# `distutils` must be imported after `setuptools` or it will cause explosions
# with `setuptools >=48.0.0, <49.1`.
# Refs:
# * https://github.com/ansible/ansible/issues/70456
# * https://github.com/pypa/setuptools/issues/2230
# * https://github.com/pypa/setuptools/commit/bd110264
from distutils.command.build_scripts import build_scripts as BuildScripts
from distutils.command.sdist import sdist as SDist


def find_package_info(*file_paths):
try:
    with open(os.path.join(*file_paths), 'r') as f:
        info_file = f.read()
except Exception:
    raise RuntimeError(""Unable to find package info."")

# The version line must have the form
# __version__ = 'ver'
version_match = re.search(r""^__version__ = ['\""]([^'\""]*)['\""]"",
                          info_file, re.M)
author_match = re.search(r""^__author__ = ['\""]([^'\""]*)['\""]"",
                         info_file, re.M)

if version_match and author_match:
    return version_match.group(1), author_match.group(1)
raise RuntimeError(""Unable to find package info."")


_validate_install_ansible_base():
""""""Validate that we can install ansible-base. Currently this only
cares about upgrading to ansible-base from ansible<2.10
""""""
if os.getenv('ANSIBLE_SKIP_CONFLICT_CHECK', '') not in ('', '0'):
    return

# Save these for later restoring things to pre invocation
sys_modules = sys.modules.copy()
sys_modules_keys = set(sys_modules)

# Make sure `lib` isn't in `sys.path` that could confuse this
sys_path = sys.path[:]
abspath = os.path.abspath
sys.path[:] = [p for p in sys.path if abspath(p) != abspath('lib')]

try:
    from ansible.release import __version__
except ImportError:
    pass
else:
    version_tuple = tuple(int(v) for v in __version__.split('.')[:2])
    if version_tuple < (2, 10):
        stars = '*' * 76
        raise RuntimeError(
            '''

%s

Cannot install ansible-base with a pre-existing ansible==%s
installation.

Installing ansible-base with ansible-2.9 or older currently installed with
pip is known to cause problems. Please uninstall ansible and install the new
version:

    pip uninstall ansible
    pip install ansible-base

If you want to skip the conflict checks and manually resolve any issues
afterwards, set the ANSIBLE_SKIP_CONFLICT_CHECK environment variable:

    ANSIBLE_SKIP_CONFLICT_CHECK=1 pip install ansible-base

%s
            ''' % (stars, __version__, stars)
        )
finally:
    sys.path[:] = sys_path
    for key in sys_modules_keys.symmetric_difference(sys.modules):
        sys.modules.pop(key, None)
    sys.modules.update(sys_modules)


idate_install_ansible_base()
"
-------------------------------------------------------------------------
"Recom
PRs: 70525, 70760"
-------------------------------------------------------------------------
=========================================================================
"# -*- coding: utf-8 -*-
# Copyright (c) 2019 Ansible Project
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)

from __future__ import absolute_import, division, print_function
__metaclass__ = type

import os
import pytest

from ansible.module_utils.facts.system.distribution import DistributionFiles


@pytest.fixture
def test_input():
return {
    'name': 'Clearlinux',
    'path': '/usr/lib/os-release',
    'collected_facts': None,
}


test_parse_distribution_file_clear_linux(mock_module, test_input):
test_input['data'] = open(os.path.join(os.path.dirname(__file__), '../../fixtures/distribution_files/ClearLinux')).read()

result = (
    True,
    {
        'distribution': 'Clear Linux OS',
        'distribution_major_version': '28120',
        'distribution_release': 'clear-linux-os',
        'distribution_version': '28120'
    }
)

distribution = DistributionFiles(module=mock_module())
assert result == distribution.parse_distribution_file_ClearLinux(**test_input)


est.mark.parametrize('distro_file', ('CoreOS', 'LinuxMint'))
test_parse_distribution_file_clear_linux_no_match(mock_module, distro_file, test_input):
""""""
Test against data from Linux Mint and CoreOS to ensure we do not get a reported
match from parse_distribution_file_ClearLinux()
""""""
test_input['data'] = open(os.path.join(os.path.dirname(__file__), '../../fixtures/distribution_files', distro_file)).read()

result = (False, {})

distribution = DistributionFiles(module=mock_module())
assert result == distribution.parse_distribution_file_ClearLinux(**test_input)
"
-------------------------------------------------------------------------
"import os
import pytest
@pytest.fixture
def test_input():
return {

test_parse_distribution_file_clear_linux(mock_module, test_input):
test_input['data'] = open(os.path.join(os.path.dirname(__file__), '../../fixtures/distribution_files/ClearLinux')).read()

"
-------------------------------------------------------------------------
"import os
import pytest
@pytest.fixture
def test_input():
return {

test_parse_distribution_file_clear_linux(mock_module, test_input):
test_input['data'] = open(os.path.join(os.path.dirname(__file__), '../../fixtures/distribution_files/ClearLinux')).read()

"
-------------------------------------------------------------------------
"Recom
PRs: 68142, 70718"
-------------------------------------------------------------------------
=========================================================================
"if 'stderr' in fail_mode:
    print('printed to stderr', file=sys.stderr)

"
-------------------------------------------------------------------------
"from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

"
-------------------------------------------------------------------------
"from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

"
-------------------------------------------------------------------------
"Recom
PRs: 70593, 70630"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils.common.text.converters import container_to_text, to_native
from ansible.module_utils.six import string_types, PY2
"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_native
from ansible.module_utils.common.text.converters import container_to_text
from ansible.module_utils.six import string_types, PY2
"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_native
from ansible.module_utils.common.text.converters import container_to_text
from ansible.module_utils.six import string_types, PY2
"
-------------------------------------------------------------------------
"Recom
PRs: 68576, 69626"
-------------------------------------------------------------------------
=========================================================================
"- The file name of the destination archive. The parent directory must exists on the remote host.
"
-------------------------------------------------------------------------
"try:
    if fmt == 'zip':
        arcfile.write(n_fullpath, n_arcname)
    else:
        arcfile.add(n_fullpath, n_arcname, recursive=False)

    b_successes.append(b_fullpath)
except Exception as e:
    errors.append('Adding %s: %s' % (to_native(b_path), to_native(e)))
"
-------------------------------------------------------------------------
"try:
    if fmt == 'zip':
        arcfile.write(n_fullpath, n_arcname)
    else:
        arcfile.add(n_fullpath, n_arcname, recursive=False)

    b_successes.append(b_fullpath)
except Exception as e:
    errors.append('Adding %s: %s' % (to_native(b_path), to_native(e)))
"
-------------------------------------------------------------------------
"Recom
PRs: 64895, 69420"
-------------------------------------------------------------------------
=========================================================================
"stdin_data = None
    if self.has_option_password_from_stdin():
        bits.append(""--password-from-stdin"")
        stdin_data = self.password
    else:
        self.module.warn(""The authentication provided will be used on the svn command line and is not secure. ""
                         ""To securely pass credentials, upgrade svn to version 1.10.0 or greater."")
        bits.extend([""--password"", self.password])
rc, out, err = self.module.run_command(bits, check_rc, data=stdin_data)
"
-------------------------------------------------------------------------
"stdin_data = None
    if self.has_option_password_from_stdin():
        bits.append(""--password-from-stdin"")
        stdin_data = self.password
    else:
        self.module.warn(""The authentication provided will be used on the svn command line and is not secure. ""
                         ""To securely pass credentials, upgrade svn to version 1.10.0 or greater."")
        bits.extend([""--password"", self.password])
rc, out, err = self.module.run_command(bits, check_rc, data=stdin_data)

"
-------------------------------------------------------------------------
"stdin_data = None
    if self.has_option_password_from_stdin():
        bits.append(""--password-from-stdin"")
        stdin_data = self.password
    else:
        self.module.warn(""The authentication provided will be used on the svn command line and is not secure. ""
                         ""To securely pass credentials, upgrade svn to version 1.10.0 or greater."")
        bits.extend([""--password"", self.password])
rc, out, err = self.module.run_command(bits, check_rc, data=stdin_data)

"
-------------------------------------------------------------------------
"Recom
PRs: 67829, 68913"
-------------------------------------------------------------------------
=========================================================================
"# Write config; make sure it has permissions 0x600
content = json.dumps(self._config, indent=4, sort_keys=True).encode('utf-8')
f = os.open(self._config_path, os.O_WRONLY | os.O_CREAT | os.O_TRUNC, 0o600)
try:
    os.write(f, content)
finally:
    os.close(f)
"
-------------------------------------------------------------------------
"# Write config; make sure it has permissions 0x600
content = json.dumps(config, indent=5, sort_keys=True).encode('utf-8')
f = os.open(path, os.O_WRONLY | os.O_CREAT | os.O_TRUNC, 0o600)
try:
    os.write(f, content)
finally:
    os.close(f)
"
-------------------------------------------------------------------------
"# Write config; make sure it has permissions 0x600
content = json.dumps(config, indent=5, sort_keys=True).encode('utf-8')
f = os.open(path, os.O_WRONLY | os.O_CREAT | os.O_TRUNC, 0o600)
try:
    os.write(f, content)
finally:
    os.close(f)
"
-------------------------------------------------------------------------
"Recom
PRs: 67353, 67441"
-------------------------------------------------------------------------
=========================================================================
"vlan_id=10,
name=""tenreplaced"",
 = ['vlan 10', 'name tenreplaced', 'state suspend']
"
-------------------------------------------------------------------------
"#
# (c) 2019, Ansible by Red Hat, inc
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
#

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

from units.compat.mock import patch
from ansible.modules.network.eos import eos_vlans
from units.modules.utils import set_module_args
from .eos_module import TestEosModule, load_fixture


class TestEosVlansModule(TestEosModule):
module = eos_vlans

def setUp(self):
    super(TestEosVlansModule, self).setUp()

    self.mock_get_config = patch('ansible.module_utils.network.common.network.Config.get_config')
    self.get_config = self.mock_get_config.start()

    self.mock_load_config = patch('ansible.module_utils.network.common.network.Config.load_config')
    self.load_config = self.mock_load_config.start()

    self.mock_get_resource_connection_config = patch('ansible.module_utils.network.common.cfg.base.get_resource_connection')
    self.get_resource_connection_config = self.mock_get_resource_connection_config.start()

    self.mock_get_resource_connection_facts = patch('ansible.module_utils.network.common.facts.facts.get_resource_connection')
    self.get_resource_connection_facts = self.mock_get_resource_connection_facts.start()

    self.mock_edit_config = patch('ansible.module_utils.network.eos.providers.providers.CliProvider.edit_config')
    self.edit_config = self.mock_edit_config.start()

    self.mock_execute_show_command = patch('ansible.module_utils.network.eos.config.vlans.vlans.Vlans.get_vlans_facts')
    self.execute_show_command = self.mock_execute_show_command.start()

def tearDown(self):
    super(TestEosVlansModule, self).tearDown()
    self.mock_get_resource_connection_config.stop()
    self.mock_get_resource_connection_facts.stop()
    self.mock_edit_config.stop()
    self.mock_get_config.stop()
    self.mock_load_config.stop()
    self.mock_execute_show_command.stop()

def load_fixtures(self, commands=None, transport='cli'):
    file_cmd = load_fixture('eos_vlan_config.cfg').split()
    file_cmd_dict = {}
    for i in range(0, len(file_cmd), 2):
        if file_cmd[i] == 'vlan_id':
            y = int(file_cmd[i  1])
        else:
            y = file_cmd[i  1]
        file_cmd_dict.update({file_cmd[i]: y})
    self.execute_show_command.return_value = [file_cmd_dict]

def test_eos_vlan_default(self):
    self.execute_show_command.return_value = []
    set_module_args(dict(
        config=[dict(
            vlan_id=30,
            name=""thirty""
        )]
    ))
    commands = ['vlan 30', 'name thirty']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_default_idempotent(self):
    self.execute_show_command.return_value = load_fixture('eos_vlan_config.cfg')
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten""
        )]
    ))
    self.execute_module(changed=False, commands=[])

def test_eos_vlan_merged(self):
    self.execute_show_command.return_value = []
    set_module_args(dict(
        config=[dict(
            vlan_id=30,
            name=""thirty""
        )], state=""merged""
    ))
    commands = ['vlan 30', 'name thirty']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_merged_idempotent(self):
    self.execute_show_command.return_value = load_fixture('eos_vlan_config.cfg')
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten""
        )], state=""merged""
    ))
    self.execute_module(changed=False, commands=[])

def test_eos_vlan_replaced(self):
    self.execute_show_command.return_value = []
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""tenreplaced"",
            state=""suspend""
        )], state=""replaced""
    ))
    commands = ['vlan 10', 'name tenreplaced', 'state suspend']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_replaced_idempotent(self):
    self.execute_show_command.return_value = load_fixture('eos_vlan_config.cfg')
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten""
        )], state=""replaced""
    ))
    self.execute_module(changed=False, commands=[])

def test_eos_vlan_overridden(self):
    self.execute_show_command.return_value = []
    set_module_args(dict(
        config=[dict(
            vlan_id=30,
            name=""thirty"",
            state=""suspend""
        )], state=""overridden""
    ))
    commands = ['no vlan 10', 'vlan 30', 'name thirty', 'state suspend']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_overridden_idempotent(self):
    self.execute_show_command.return_value = load_fixture('eos_vlan_config.cfg')
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten""
        )], state=""overridden""
    ))
    self.execute_module(changed=False, commands=[])

def test_eos_vlan_deleted(self):
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten"",
        )], state=""deleted""
    ))
    commands = ['no vlan 10']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_id_datatype(self):
    set_module_args(dict(
        config=[dict(
            vlan_id=""thirty""
        )]
    ))
    result = self.execute_module(failed=True)
    self.assertIn(""we were unable to convert to int"", result['msg'])

def test_eos_vlan_state_datatype(self):
    set_module_args(dict(
        config=[dict(
            vlan_id=30,
            state=10
        )]
    ))
    result = self.execute_module(failed=True)
    self.assertIn(""value of state must be one of: active, suspend"", result['msg'])
"
-------------------------------------------------------------------------
"#
# (c) 2019, Ansible by Red Hat, inc
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
#

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

from units.compat.mock import patch
from ansible.modules.network.eos import eos_vlans
from units.modules.utils import set_module_args
from .eos_module import TestEosModule, load_fixture


class TestEosVlansModule(TestEosModule):
module = eos_vlans

def setUp(self):
    super(TestEosVlansModule, self).setUp()

    self.mock_get_config = patch('ansible.module_utils.network.common.network.Config.get_config')
    self.get_config = self.mock_get_config.start()

    self.mock_load_config = patch('ansible.module_utils.network.common.network.Config.load_config')
    self.load_config = self.mock_load_config.start()

    self.mock_get_resource_connection_config = patch('ansible.module_utils.network.common.cfg.base.get_resource_connection')
    self.get_resource_connection_config = self.mock_get_resource_connection_config.start()

    self.mock_get_resource_connection_facts = patch('ansible.module_utils.network.common.facts.facts.get_resource_connection')
    self.get_resource_connection_facts = self.mock_get_resource_connection_facts.start()

    self.mock_edit_config = patch('ansible.module_utils.network.eos.providers.providers.CliProvider.edit_config')
    self.edit_config = self.mock_edit_config.start()

    self.mock_execute_show_command = patch('ansible.module_utils.network.eos.config.vlans.vlans.Vlans.get_vlans_facts')
    self.execute_show_command = self.mock_execute_show_command.start()

def tearDown(self):
    super(TestEosVlansModule, self).tearDown()
    self.mock_get_resource_connection_config.stop()
    self.mock_get_resource_connection_facts.stop()
    self.mock_edit_config.stop()
    self.mock_get_config.stop()
    self.mock_load_config.stop()
    self.mock_execute_show_command.stop()

def load_fixtures(self, commands=None, transport='cli'):
    file_cmd = load_fixture('eos_vlan_config.cfg').split()
    file_cmd_dict = {}
    for i in range(0, len(file_cmd), 2):
        if file_cmd[i] == 'vlan_id':
            y = int(file_cmd[i  1])
        else:
            y = file_cmd[i  1]
        file_cmd_dict.update({file_cmd[i]: y})
    self.execute_show_command.return_value = [file_cmd_dict]

def test_eos_vlan_default(self):
    self.execute_show_command.return_value = []
    set_module_args(dict(
        config=[dict(
            vlan_id=30,
            name=""thirty""
        )]
    ))
    commands = ['vlan 30', 'name thirty']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_default_idempotent(self):
    self.execute_show_command.return_value = load_fixture('eos_vlan_config.cfg')
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten""
        )]
    ))
    self.execute_module(changed=False, commands=[])

def test_eos_vlan_merged(self):
    self.execute_show_command.return_value = []
    set_module_args(dict(
        config=[dict(
            vlan_id=30,
            name=""thirty""
        )], state=""merged""
    ))
    commands = ['vlan 30', 'name thirty']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_merged_idempotent(self):
    self.execute_show_command.return_value = load_fixture('eos_vlan_config.cfg')
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten""
        )], state=""merged""
    ))
    self.execute_module(changed=False, commands=[])

def test_eos_vlan_replaced(self):
    self.execute_show_command.return_value = []
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""tenreplaced"",
            state=""suspend""
        )], state=""replaced""
    ))
    commands = ['vlan 10', 'name tenreplaced', 'state suspend']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_replaced_idempotent(self):
    self.execute_show_command.return_value = load_fixture('eos_vlan_config.cfg')
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten""
        )], state=""replaced""
    ))
    self.execute_module(changed=False, commands=[])

def test_eos_vlan_overridden(self):
    self.execute_show_command.return_value = []
    set_module_args(dict(
        config=[dict(
            vlan_id=30,
            name=""thirty"",
            state=""suspend""
        )], state=""overridden""
    ))
    commands = ['no vlan 10', 'vlan 30', 'name thirty', 'state suspend']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_overridden_idempotent(self):
    self.execute_show_command.return_value = load_fixture('eos_vlan_config.cfg')
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten""
        )], state=""overridden""
    ))
    self.execute_module(changed=False, commands=[])

def test_eos_vlan_deleted(self):
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten"",
        )], state=""deleted""
    ))
    commands = ['no vlan 10']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_id_datatype(self):
    set_module_args(dict(
        config=[dict(
            vlan_id=""thirty""
        )]
    ))
    result = self.execute_module(failed=True)
    self.assertIn(""we were unable to convert to int"", result['msg'])

def test_eos_vlan_state_datatype(self):
    set_module_args(dict(
        config=[dict(
            vlan_id=30,
            state=10
        )]
    ))
    result = self.execute_module(failed=True)
    self.assertIn(""value of state must be one of: active, suspend"", result['msg'])
"
-------------------------------------------------------------------------
"Recom
PRs: 67318, 67346"
-------------------------------------------------------------------------
=========================================================================
"def get_fingerprint(path, passphrase=None, content=None, backend='pyopenssl'):
privatekey = load_privatekey(path, passphrase=passphrase, content=content, check_passphrase=False, backend=backend)

if backend == 'pyopenssl':
        publickey = crypto.dump_publickey(crypto.FILETYPE_ASN1, privatekey)
        # If PyOpenSSL < 16.0 crypto.dump_publickey() will fail.
        try:
            bio = crypto._new_mem_buf()
            rc = crypto._lib.i2d_PUBKEY_bio(bio, privatekey._pkey)
            if rc != 1:
                crypto._raise_current_error()
            publickey = crypto._bio_to_string(bio)
        except AttributeError:
            # By doing this we prevent the code from raising an error
            # yet we return no value in the fingerprint hash.
            return None
elif backend == 'cryptography':
    publickey = privatekey.public_key().public_bytes(
        serialization.Encoding.DER,
        serialization.PublicFormat.SubjectPublicKeyInfo
    )

"
-------------------------------------------------------------------------
"def get_fingerprint(path, passphrase=None, backend='pyopenssl'):
privatekey = load_privatekey(path, passphrase, check_passphrase=False, backend=backend)

if backend == 'pyopenssl':
        publickey = crypto.dump_publickey(crypto.FILETYPE_ASN1, privatekey)
        # If PyOpenSSL < 16.0 crypto.dump_publickey() will fail.
        try:
            bio = crypto._new_mem_buf()
            rc = crypto._lib.i2d_PUBKEY_bio(bio, privatekey._pkey)
            if rc != 1:
                crypto._raise_current_error()
            publickey = crypto._bio_to_string(bio)
        except AttributeError:
            # By doing this we prevent the code from raising an error
            # yet we return no value in the fingerprint hash.
            return None
elif backend == 'cryptography':
    publickey = privatekey.public_key().public_bytes(
        serialization.Encoding.DER,
        serialization.PublicFormat.SubjectPublicKeyInfo
    )

"
-------------------------------------------------------------------------
"def get_fingerprint(path, passphrase=None, backend='pyopenssl'):
privatekey = load_privatekey(path, passphrase, check_passphrase=False, backend=backend)

if backend == 'pyopenssl':
        publickey = crypto.dump_publickey(crypto.FILETYPE_ASN1, privatekey)
        # If PyOpenSSL < 16.0 crypto.dump_publickey() will fail.
        try:
            bio = crypto._new_mem_buf()
            rc = crypto._lib.i2d_PUBKEY_bio(bio, privatekey._pkey)
            if rc != 1:
                crypto._raise_current_error()
            publickey = crypto._bio_to_string(bio)
        except AttributeError:
            # By doing this we prevent the code from raising an error
            # yet we return no value in the fingerprint hash.
            return None
elif backend == 'cryptography':
    publickey = privatekey.public_key().public_bytes(
        serialization.Encoding.DER,
        serialization.PublicFormat.SubjectPublicKeyInfo
    )

"
-------------------------------------------------------------------------
"Recom
PRs: 67036, 67039"
-------------------------------------------------------------------------
=========================================================================
"'CREATE ROLE', 'DROP ROLE', 'APPLICATION_PASSWORD_ADMIN',
'AUDIT_ADMIN', 'BACKUP_ADMIN', 'BINLOG_ADMIN',
'BINLOG_ENCRYPTION_ADMIN', 'CLONE_ADMIN', 'CONNECTION_ADMIN',
'ENCRYPTION_KEY_ADMIN', 'FIREWALL_ADMIN', 'FIREWALL_USER',
'GROUP_REPLICATION_ADMIN', 'INNODB_REDO_LOG_ARCHIVE',
'NDB_STORED_USER', 'PERSIST_RO_VARIABLES_ADMIN',
'REPLICATION_APPLIER', 'REPLICATION_SLAVE_ADMIN',
'RESOURCE_GROUP_ADMIN', 'RESOURCE_GROUP_USER',
'ROLE_ADMIN', 'SESSION_VARIABLES_ADMIN', 'SET_USER_ID',
'SYSTEM_USER', 'SYSTEM_VARIABLES_ADMIN', 'SYSTEM_USER',
'TABLE_ENCRYPTION_ADMIN', 'VERSION_TOKEN_ADMIN',
'XA_RECOVER_ADMIN', 'LOAD FROM S3', 'SELECT INTO S3'))
"
-------------------------------------------------------------------------
"'CREATE ROLE', 'DROP ROLE', 'APPLICATION_PASSWORD_ADMIN',
'AUDIT_ADMIN', 'BACKUP_ADMIN', 'BINLOG_ADMIN',
'BINLOG_ENCRYPTION_ADMIN', 'CONNECTION_ADMIN',
'ENCRYPTION_KEY_ADMIN', 'FIREWALL_ADMIN', 'FIREWALL_USER',
'GROUP_REPLICATION_ADMIN', 'PERSIST_RO_VARIABLES_ADMIN',
'REPLICATION_SLAVE_ADMIN', 'RESOURCE_GROUP_ADMIN', 'RESOURCE_GROUP_USER',
'ROLE_ADMIN', 'SESSION_VARIABLES_ADMIN', 'SET_USER_ID',
'SYSTEM_VARIABLES_ADMIN', 'VERSION_TOKEN_ADMIN', 'XA_RECOVER_ADMIN'))
"
-------------------------------------------------------------------------
"'CREATE ROLE', 'DROP ROLE', 'APPLICATION_PASSWORD_ADMIN',
'AUDIT_ADMIN', 'BACKUP_ADMIN', 'BINLOG_ADMIN',
'BINLOG_ENCRYPTION_ADMIN', 'CONNECTION_ADMIN',
'ENCRYPTION_KEY_ADMIN', 'FIREWALL_ADMIN', 'FIREWALL_USER',
'GROUP_REPLICATION_ADMIN', 'PERSIST_RO_VARIABLES_ADMIN',
'REPLICATION_SLAVE_ADMIN', 'RESOURCE_GROUP_ADMIN', 'RESOURCE_GROUP_USER',
'ROLE_ADMIN', 'SESSION_VARIABLES_ADMIN', 'SET_USER_ID',
'SYSTEM_VARIABLES_ADMIN', 'VERSION_TOKEN_ADMIN', 'XA_RECOVER_ADMIN'))
"
-------------------------------------------------------------------------
"Recom
PRs: 66995, 66999"
-------------------------------------------------------------------------
=========================================================================
"if not container.exists or container.removing:
    if container.removing:
        self.log('Found container in removal phase')
    else:
        self.log('No container found')
    if container.removing:
        # Wait for container to be removed before trying to create it
        self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"if not container.exists or container.removing:
    if container.removing:
        self.log('Found container in removal phase')
    else:
        self.log('No container found')
    if container.removing and not self.check_mode:
        # Wait for container to be removed before trying to create it
        self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"if not container.exists or container.removing:
    if container.removing:
        self.log('Found container in removal phase')
    else:
        self.log('No container found')
    if container.removing and not self.check_mode:
        # Wait for container to be removed before trying to create it
        self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"Recom
PRs: 65854, 66118"
-------------------------------------------------------------------------
=========================================================================
"self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"if not self.check_mode:
    self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"if not self.check_mode:
    self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"Recom
PRs: 65854, 66118"
-------------------------------------------------------------------------
=========================================================================
"if not container.exists or container.removing:
    if container.removing:
        self.log('Found container in removal phase')
    else:
        self.log('No container found')
    if container.removing:
        # Wait for container to be removed before trying to create it
        self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"if not container.exists or container.removing:
    if container.removing:
        self.log('Found container in removal phase')
    else:
        self.log('No container found')
    if container.removing and not self.check_mode:
        # Wait for container to be removed before trying to create it
        self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"if not container.exists or container.removing:
    if container.removing:
        self.log('Found container in removal phase')
    else:
        self.log('No container found')
    if container.removing and not self.check_mode:
        # Wait for container to be removed before trying to create it
        self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"Recom
PRs: 65854, 66117"
-------------------------------------------------------------------------
=========================================================================
"self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"if not self.check_mode:
    self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"if not self.check_mode:
    self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"Recom
PRs: 65854, 66117"
-------------------------------------------------------------------------
=========================================================================
"@property
    if self._yum_base:
        return self._yum_base
    else:
        # Only init once
        self._yum_base = yum.YumBase()
        self._yum_base.preconf.debuglevel = 0
        self._yum_base.preconf.errorlevel = 0
        self._yum_base.preconf.plugins = True
        self._yum_base.preconf.enabled_plugins = self.enable_plugin
        self._yum_base.preconf.disabled_plugins = self.disable_plugin
        if self.releasever:
            self._yum_base.preconf.releasever = self.releasever
        if self.installroot != '/':
            # do not setup installroot by default, because of error
            # CRITICAL:yum.cli:Config Error: Error accessing file for config file:////etc/yum.conf
            # in old yum version (like in CentOS 6.6)
            self._yum_base.preconf.root = self.installroot
            self._yum_base.conf.installroot = self.installroot
        if self.conf_file and os.path.exists(self.conf_file):
            self._yum_base.preconf.fn = self.conf_file
        if os.geteuid() != 0:
            if hasattr(self._yum_base, 'setCacheDir'):
                self._yum_base.setCacheDir()
            else:
                cachedir = yum.misc.getCacheDir()
                self._yum_base.repos.setCacheDir(cachedir)
                self._yum_base.conf.cache = 0
        if self.disable_excludes:
            self._yum_base.conf.disable_excludes = self.disable_excludes
        # A sideeffect of accessing conf is that the configuration is
        # loaded and plugins are discovered
        self.yum_base.conf

        try:
            self._enablerepos_with_error_checking(self._yum_base)

            for rid in self.disablerepo:
                self.yum_base.repos.disableRepo(rid)
        except Exception as e:
            self.module.fail_json(msg=""Failure talking to yum: %s"" % to_native(e))

    return self._yum_base
"
-------------------------------------------------------------------------
"self._yum_base = None
"
-------------------------------------------------------------------------
"self._yum_base = None
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"groups_list = self.yum_base.doGroupLists(return_evgrps=True)
groups_list = self.yum_base.doGroupLists()
"
-------------------------------------------------------------------------
"def _enablerepos_with_error_checking(self, yumbase):
    # NOTE: This seems unintuitive, but it mirrors yum's CLI bahavior
    if len(self.enablerepo) == 1:
        try:
            yumbase.repos.enableRepo(self.enablerepo[0])
        except yum.Errors.YumBaseError as e:
            if u'repository not found' in to_text(e):
                self.module.fail_json(msg=""Repository %s not found."" % self.enablerepo[0])
            else:
                raise e
    else:
        for rid in self.enablerepo:
            try:
                yumbase.repos.enableRepo(rid)
            except yum.Errors.YumBaseError as e:
                if u'repository not found' in to_text(e):
                    self.module.warn(""Repository %s not found."" % rid)
                else:
                    raise e

@property
    if self._yum_base:
        return self._yum_base
    else:
        # Only init once
        self._yum_base = yum.YumBase()
        self._yum_base.preconf.debuglevel = 0
        self._yum_base.preconf.errorlevel = 0
        self._yum_base.preconf.plugins = True
        self._yum_base.preconf.enabled_plugins = self.enable_plugin
        self._yum_base.preconf.disabled_plugins = self.disable_plugin
        if self.releasever:
            self._yum_base.preconf.releasever = self.releasever
        if self.installroot != '/':
            # do not setup installroot by default, because of error
            # CRITICAL:yum.cli:Config Error: Error accessing file for config file:////etc/yum.conf
            # in old yum version (like in CentOS 6.6)
            self._yum_base.preconf.root = self.installroot
            self._yum_base.conf.installroot = self.installroot
        if self.conf_file and os.path.exists(self.conf_file):
            self._yum_base.preconf.fn = self.conf_file
        if os.geteuid() != 0:
            if hasattr(self._yum_base, 'setCacheDir'):
                self._yum_base.setCacheDir()
            else:
                cachedir = yum.misc.getCacheDir()
                self._yum_base.repos.setCacheDir(cachedir)
                self._yum_base.conf.cache = 0
        if self.disable_excludes:
            self._yum_base.conf.disable_excludes = self.disable_excludes

        # A sideeffect of accessing conf is that the configuration is
        # loaded and plugins are discovered
        self.yum_base.conf
        try:
            self._enablerepos_with_error_checking(self._yum_base)

            for rid in self.disablerepo:
                self.yum_base.repos.disableRepo(rid)
        except Exception as e:
            self.module.fail_json(msg=""Failure talking to yum: %s"" % to_native(e))

    return self._yum_base
"
-------------------------------------------------------------------------
"def _enablerepos_with_error_checking(self, yumbase):
    # NOTE: This seems unintuitive, but it mirrors yum's CLI bahavior
    if len(self.enablerepo) == 1:
        try:
            yumbase.repos.enableRepo(self.enablerepo[0])
        except yum.Errors.YumBaseError as e:
            if u'repository not found' in to_text(e):
                self.module.fail_json(msg=""Repository %s not found."" % self.enablerepo[0])
            else:
                raise e
    else:
        for rid in self.enablerepo:
            try:
                yumbase.repos.enableRepo(rid)
            except yum.Errors.YumBaseError as e:
                if u'repository not found' in to_text(e):
                    self.module.warn(""Repository %s not found."" % rid)
                else:
                    raise e

@property
    if self._yum_base:
        return self._yum_base
    else:
        # Only init once
        self._yum_base = yum.YumBase()
        self._yum_base.preconf.debuglevel = 0
        self._yum_base.preconf.errorlevel = 0
        self._yum_base.preconf.plugins = True
        self._yum_base.preconf.enabled_plugins = self.enable_plugin
        self._yum_base.preconf.disabled_plugins = self.disable_plugin
        if self.releasever:
            self._yum_base.preconf.releasever = self.releasever
        if self.installroot != '/':
            # do not setup installroot by default, because of error
            # CRITICAL:yum.cli:Config Error: Error accessing file for config file:////etc/yum.conf
            # in old yum version (like in CentOS 6.6)
            self._yum_base.preconf.root = self.installroot
            self._yum_base.conf.installroot = self.installroot
        if self.conf_file and os.path.exists(self.conf_file):
            self._yum_base.preconf.fn = self.conf_file
        if os.geteuid() != 0:
            if hasattr(self._yum_base, 'setCacheDir'):
                self._yum_base.setCacheDir()
            else:
                cachedir = yum.misc.getCacheDir()
                self._yum_base.repos.setCacheDir(cachedir)
                self._yum_base.conf.cache = 0
        if self.disable_excludes:
            self._yum_base.conf.disable_excludes = self.disable_excludes

        # A sideeffect of accessing conf is that the configuration is
        # loaded and plugins are discovered
        self.yum_base.conf
        try:
            self._enablerepos_with_error_checking(self._yum_base)

            for rid in self.disablerepo:
                self.yum_base.repos.disableRepo(rid)
        except Exception as e:
            self.module.fail_json(msg=""Failure talking to yum: %s"" % to_native(e))

    return self._yum_base
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"e, m, _ = self.yum_base.rpmdb.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnInstalledPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"groups_list = self.yum_base.doGroupLists(return_evgrps=True)
groups_list = self.yum_base.doGroupLists()
"
-------------------------------------------------------------------------
"groups_list = self.yum_base.doGroupLists(return_evgrps=True)
groups_list = self.yum_base.doGroupLists()
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"e, m, _ = self.yum_base.rpmdb.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnInstalledPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"e, m, _ = self.yum_base.rpmdb.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnInstalledPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"pkgs = self.yum_base.returnPackagesByDep(pkgspec)  \
    self.yum_base.returnInstalledPackagesByDep(pkgspec)
    e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
updates = self.yum_base.doPackageLists(pkgnarrow='updates').updates
"
-------------------------------------------------------------------------
"e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"pkgs = self.yum_base.returnPackagesByDep(req_spec)  \
    self.yum_base.returnInstalledPackagesByDep(req_spec)
"
-------------------------------------------------------------------------
"pkgs = self.yum_base.returnPackagesByDep(pkgspec)  \
    self.yum_base.returnInstalledPackagesByDep(pkgspec)
    e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
updates = self.yum_base.doPackageLists(pkgnarrow='updates').updates
"
-------------------------------------------------------------------------
"pkgs = self.yum_base.returnPackagesByDep(pkgspec)  \
    self.yum_base.returnInstalledPackagesByDep(pkgspec)
    e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
updates = self.yum_base.doPackageLists(pkgnarrow='updates').updates
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"pkgs = self.yum_base.returnPackagesByDep(req_spec)  \
    self.yum_base.returnInstalledPackagesByDep(req_spec)
, _ = self.yum_base.pkgSack.matchPackageNames([req_spec])
, _ = self.yum_base.rpmdb.matchPackageNames([req_spec])
"
-------------------------------------------------------------------------
"pkgs = self.yum_base.returnPackagesByDep(req_spec)  \
    self.yum_base.returnInstalledPackagesByDep(req_spec)
"
-------------------------------------------------------------------------
"pkgs = self.yum_base.returnPackagesByDep(req_spec)  \
    self.yum_base.returnInstalledPackagesByDep(req_spec)
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"if self.yum_base.conf.proxy and self.yum_base.conf.proxy not in (""_none_"",):
    if self.yum_base.conf.proxy_username:
        namepass = namepass  self.yum_base.conf.proxy_username
        proxy_url = self.yum_base.conf.proxy
        if self.yum_base.conf.proxy_password:
            namepass = namepass  "":""  self.yum_base.conf.proxy_password
    elif '@' in self.yum_base.conf.proxy:
        namepass = self.yum_base.conf.proxy.split('@')[0].split('//')[-1]
        proxy_url = self.yum_base.conf.proxy.replace(""{0}@"".format(namepass), """")
"
-------------------------------------------------------------------------
"pkgs = self.yum_base.returnPackagesByDep(req_spec)  \
    self.yum_base.returnInstalledPackagesByDep(req_spec)
, _ = self.yum_base.pkgSack.matchPackageNames([req_spec])
, _ = self.yum_base.rpmdb.matchPackageNames([req_spec])
"
-------------------------------------------------------------------------
"pkgs = self.yum_base.returnPackagesByDep(req_spec)  \
    self.yum_base.returnInstalledPackagesByDep(req_spec)
, _ = self.yum_base.pkgSack.matchPackageNames([req_spec])
, _ = self.yum_base.rpmdb.matchPackageNames([req_spec])
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"os.environ[item  ""_proxy""] = self.yum_base.conf.proxy
"
-------------------------------------------------------------------------
"if self.yum_base.conf.proxy and self.yum_base.conf.proxy not in (""_none_"",):
    if self.yum_base.conf.proxy_username:
        namepass = namepass  self.yum_base.conf.proxy_username
        proxy_url = self.yum_base.conf.proxy
        if self.yum_base.conf.proxy_password:
            namepass = namepass  "":""  self.yum_base.conf.proxy_password
    elif '@' in self.yum_base.conf.proxy:
        namepass = self.yum_base.conf.proxy.split('@')[0].split('//')[-1]
        proxy_url = self.yum_base.conf.proxy.replace(""{0}@"".format(namepass), """")
"
-------------------------------------------------------------------------
"if self.yum_base.conf.proxy and self.yum_base.conf.proxy not in (""_none_"",):
    if self.yum_base.conf.proxy_username:
        namepass = namepass  self.yum_base.conf.proxy_username
        proxy_url = self.yum_base.conf.proxy
        if self.yum_base.conf.proxy_password:
            namepass = namepass  "":""  self.yum_base.conf.proxy_password
    elif '@' in self.yum_base.conf.proxy:
        namepass = self.yum_base.conf.proxy.split('@')[0].split('//')[-1]
        proxy_url = self.yum_base.conf.proxy.replace(""{0}@"".format(namepass), """")
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"self._yum_base = None  # previous YumBase package index is now invalid
"
-------------------------------------------------------------------------
"os.environ[item  ""_proxy""] = self.yum_base.conf.proxy
"
-------------------------------------------------------------------------
"os.environ[item  ""_proxy""] = self.yum_base.conf.proxy
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"try: self.yum_base.repos.disableRepo(disablerepo)
try: self.yum_base.repos.enableRepo(enablerepo)
"
-------------------------------------------------------------------------
"self._yum_base = None  # previous YumBase package index is now invalid
"
-------------------------------------------------------------------------
"self._yum_base = None  # previous YumBase package index is now invalid
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"current_repos = self.yum_base.repos.repos.keys()
        new_repos = self.yum_base.repos.repos.keys()
                rid = self.yum_base.repos.getRepo(i)
"
-------------------------------------------------------------------------
"try: self.yum_base.repos.disableRepo(disablerepo)
try: self.yum_base.repos.enableRepo(enablerepo)
"
-------------------------------------------------------------------------
"try: self.yum_base.repos.disableRepo(disablerepo)
try: self.yum_base.repos.enableRepo(enablerepo)
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"yum_plugins = self.yum_base.plugins._plugins
"
-------------------------------------------------------------------------
"current_repos = self.yum_base.repos.repos.keys()
        new_repos = self.yum_base.repos.repos.keys()
                rid = self.yum_base.repos.getRepo(i)
"
-------------------------------------------------------------------------
"current_repos = self.yum_base.repos.repos.keys()
        new_repos = self.yum_base.repos.repos.keys()
                rid = self.yum_base.repos.getRepo(i)
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"elif current_condition['Field'] == condition['Field'] and current_condition['Values'] == condition['Values']:
"
-------------------------------------------------------------------------
"elif current_condition['Field'] == condition['Field'] and sorted(current_condition['Values']) == sorted(condition['Values']):
"
-------------------------------------------------------------------------
"elif current_condition['Field'] == condition['Field'] and sorted(current_condition['Values']) == sorted(condition['Values']):
"
-------------------------------------------------------------------------
"Recom
PRs: 65021, 65212"
-------------------------------------------------------------------------
=========================================================================
"""WHERE indexrelname = %(name)s ""
""AND schemaname = %(schema)s"")
exec_sql(self, query, query_params={'name': self.name, 'schema': self.schema},
         add_to_executed=False)
"
-------------------------------------------------------------------------
"""WHERE i.indexname = %(name)s"")
c_sql(self, query, query_params={'name': self.name}, add_to_executed=False)
"
-------------------------------------------------------------------------
"""WHERE i.indexname = %(name)s"")
c_sql(self, query, query_params={'name': self.name}, add_to_executed=False)
"
-------------------------------------------------------------------------
"Recom
PRs: 64661, 65034"
-------------------------------------------------------------------------
=========================================================================
"feed_ca_cert:
      The ca_cert alias will be removed in Ansible 2.14.
  aliases: [ importer_ssl_ca_cert, ca_cert ]
feed_client_cert:
  version_added: ""2.10""
"
-------------------------------------------------------------------------
"feed_ca_cert:
      The ca_cert alias will be removed in Ansible 2.14.
  aliases: [ importer_ssl_ca_cert, ca_cert ]
feed_client_cert:
  version_added: ""2.9.2""
"
-------------------------------------------------------------------------
"feed_ca_cert:
      The ca_cert alias will be removed in Ansible 2.14.
  aliases: [ importer_ssl_ca_cert, ca_cert ]
feed_client_cert:
  version_added: ""2.9.2""
"
-------------------------------------------------------------------------
"Recom
PRs: 59522, 65014"
-------------------------------------------------------------------------
=========================================================================
"- If not specified the default value will come from client_cert. Which will
  change in Ansible 2.14.
_client_key:
rsion_added: ""2.10""
- If not specified the default value will come from client_key. Which will
  change in Ansible 2.14.
"
-------------------------------------------------------------------------
"- If not specified the default value will come from client_cert. Which will
  change in Ansible 2.14.
_client_key:
rsion_added: ""2.9.2""
- If not specified the default value will come from client_key. Which will
  change in Ansible 2.14.
"
-------------------------------------------------------------------------
"- If not specified the default value will come from client_cert. Which will
  change in Ansible 2.14.
_client_key:
rsion_added: ""2.9.2""
- If not specified the default value will come from client_key. Which will
  change in Ansible 2.14.
"
-------------------------------------------------------------------------
"Recom
PRs: 59522, 65014"
-------------------------------------------------------------------------
=========================================================================
"importer_ssl_ca_cert = module.params['feed_ca_cert']
importer_ssl_client_cert = module.params['feed_client_cert']
if importer_ssl_client_cert is None and module.params['client_cert'] is not None:
    importer_ssl_client_cert = module.params['client_cert']
    module.deprecate((""To specify client certificates to be used with the repo to sync, and not for communication with pulp.io, use the new options ""
                      ""`feed_client_cert` and `feed_client_key` (available since Ansible 2.10). Until Ansible 2.14, the default value for ""
                      ""`feed_client_cert` will be taken from `client_cert` if only the latter is specified""), version=""2.14"")
importer_ssl_client_key = module.params['feed_client_key']
if importer_ssl_client_key is None and module.params['client_key'] is not None:
    importer_ssl_client_key = module.params['client_key']
    module.deprecate(""In Ansible 2.10 `feed_client_key` option was added. Until 2.14 the default value will come from client_key option"", version=""2.14"")
"
-------------------------------------------------------------------------
"importer_ssl_ca_cert = module.params['feed_ca_cert']
importer_ssl_client_cert = module.params['feed_client_cert']
if importer_ssl_client_cert is None and module.params['client_cert'] is not None:
    importer_ssl_client_cert = module.params['client_cert']
    module.deprecate(""To specify client certificates to be used with the repo to sync, and not for communication with the ""
                     ""Pulp instance, use the new options `feed_client_cert` and `feed_client_key` (available since ""
                     ""Ansible 2.9.2). Until Ansible 2.14, the default value for `feed_client_cert` will be taken from ""
                     ""`client_cert` if only the latter is specified"", version=""2.14"")
importer_ssl_client_key = module.params['feed_client_key']
if importer_ssl_client_key is None and module.params['client_key'] is not None:
    importer_ssl_client_key = module.params['client_key']
    module.deprecate(""In Ansible 2.9.2 `feed_client_key` option was added. Until 2.14 the default value will come from client_key option"", version=""2.14"")
"
-------------------------------------------------------------------------
"importer_ssl_ca_cert = module.params['feed_ca_cert']
importer_ssl_client_cert = module.params['feed_client_cert']
if importer_ssl_client_cert is None and module.params['client_cert'] is not None:
    importer_ssl_client_cert = module.params['client_cert']
    module.deprecate(""To specify client certificates to be used with the repo to sync, and not for communication with the ""
                     ""Pulp instance, use the new options `feed_client_cert` and `feed_client_key` (available since ""
                     ""Ansible 2.9.2). Until Ansible 2.14, the default value for `feed_client_cert` will be taken from ""
                     ""`client_cert` if only the latter is specified"", version=""2.14"")
importer_ssl_client_key = module.params['feed_client_key']
if importer_ssl_client_key is None and module.params['client_key'] is not None:
    importer_ssl_client_key = module.params['client_key']
    module.deprecate(""In Ansible 2.9.2 `feed_client_key` option was added. Until 2.14 the default value will come from client_key option"", version=""2.14"")
"
-------------------------------------------------------------------------
"Recom
PRs: 59522, 65014"
-------------------------------------------------------------------------
=========================================================================
"
notes:
- Return values I(out) and I(err) have been deprecated and will be removed in Ansible 2.14. Use I(stdout) and I(stderr) instead.
"
-------------------------------------------------------------------------
"rc=rc,
out=out, err=err,
stdout=out, stderr=err)
"
-------------------------------------------------------------------------
"rc=rc,
out=out, err=err,
stdout=out, stderr=err)
"
-------------------------------------------------------------------------
"Recom
PRs: 63467, 64120"
-------------------------------------------------------------------------
=========================================================================
"rc=rc,
out=out, err=err,  # Deprecated
stdout=out, stderr=err)
"
-------------------------------------------------------------------------
"module.exit_json(
    changed=False,
    rc=rc,
    stdout=out,
    stderr=err)
    rc=rc,
    stdout=out,
    stderr=err,
"
-------------------------------------------------------------------------
"module.exit_json(
    changed=False,
    rc=rc,
    stdout=out,
    stderr=err)
    rc=rc,
    stdout=out,
    stderr=err,
"
-------------------------------------------------------------------------
"Recom
PRs: 63467, 64120"
-------------------------------------------------------------------------
=========================================================================
"module.exit_json(
    changed=False,
    rc=rc,
    stdout=out,
    stderr=err)
    rc=rc,
    stdout=out,
    stderr=err,
"
-------------------------------------------------------------------------
"out=out, err=err,
stdout=out, stderr=err)
changed=True,
msg=out, rc=rc,
err=err,
stdout=out, stderr=err)
"
-------------------------------------------------------------------------
"out=out, err=err,
stdout=out, stderr=err)
changed=True,
msg=out, rc=rc,
err=err,
stdout=out, stderr=err)
"
-------------------------------------------------------------------------
"Recom
PRs: 63467, 64120"
-------------------------------------------------------------------------
=========================================================================
"short_description: Gathers information for virtual machines running on Citrix Hypervisor/XenServer host or pool
"
-------------------------------------------------------------------------
"short_description: Gathers facts for virtual machines running on Citrix Hypervisor/XenServer host or pool
"
-------------------------------------------------------------------------
"short_description: Gathers facts for virtual machines running on Citrix Hypervisor/XenServer host or pool
"
-------------------------------------------------------------------------
"Recom
PRs: 63728, 63816"
-------------------------------------------------------------------------
=========================================================================
"if key == ""vlan_id"" or value is None:
"
-------------------------------------------------------------------------
"want = param_list_to_dict(want, ""vlan_id"", remove_key=False)
have = param_list_to_dict(have, ""vlan_id"", remove_key=False)
"
-------------------------------------------------------------------------
"want = param_list_to_dict(want, ""vlan_id"", remove_key=False)
have = param_list_to_dict(have, ""vlan_id"", remove_key=False)
"
-------------------------------------------------------------------------
"Recom
PRs: 63689, 63687"
-------------------------------------------------------------------------
=========================================================================
"- ""The only allowed value according to L(RFC 2986,https://tools.ietf.org/html/rfc2986#section-4.1)
   is 1.""
- This option will no longer accept unsupported values from Ansible 2.14 on.
"
-------------------------------------------------------------------------
"- ""The only allowed value according to L(RFC 2986,https://tools.ietf.org/html/rfc2986#section-4.1)
   is 1.""
"
-------------------------------------------------------------------------
"- ""The only allowed value according to L(RFC 2986,https://tools.ietf.org/html/rfc2986#section-4.1)
   is 1.""
"
-------------------------------------------------------------------------
"Recom
PRs: 63432, 63675"
-------------------------------------------------------------------------
=========================================================================
"- ""The only allowed value according to L(RFC 2986,https://tools.ietf.org/html/rfc2986#section-4.1)
   is 1.""
- This option will no longer accept unsupported values from Ansible 2.14 on.
"
-------------------------------------------------------------------------
"- ""The only allowed value according to L(RFC 2986,https://tools.ietf.org/html/rfc2986#section-4.1)
   is 1.""
"
-------------------------------------------------------------------------
"- ""The only allowed value according to L(RFC 2986,https://tools.ietf.org/html/rfc2986#section-4.1)
   is 1.""
"
-------------------------------------------------------------------------
"Recom
PRs: 63432, 63674"
-------------------------------------------------------------------------
=========================================================================
"- If not set, the value will be remain the same if container exists and will be inherited
  from the host machine if it is (re-)created.
Specification for mounts to be added to the container. More powerful alternative to I(volumes).
"
-------------------------------------------------------------------------
"- If not set, the value will be remain the same if container exists and will be inherited
  from the host machine if it is (re-)created.
"
-------------------------------------------------------------------------
"- If not set, the value will be remain the same if container exists and will be inherited
  from the host machine if it is (re-)created.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- bind
- npipe
- tmpfs
- volume
- Whether the mount should be read-only.
- The consistency requirement for the mount.
- cached
- consistent
- default
- delegated
- private
- rprivate
- shared
- rshared
- slave
- rslave
"
-------------------------------------------------------------------------
"- Connect the container to a network. Choices are C(bridge), C(host), C(none) or C(container:<name|id>).
- Set the user namespace mode for the container. Currently, the only valid value are C(host) and the empty string.
- To remove a container from one or more networks, use the I(purge_networks) option.
  network if I(networks) is specified. You need to explicitly use I(purge_networks) to enforce
  the removal of the default network (and all other networks not explicitly mentioned in I(networks)).
  Alternatively, use the I(networks_cli_compatible) option, which will be enabled by default from Ansible 2.12 on.
"
-------------------------------------------------------------------------
"- Connect the container to a network. Choices are C(bridge), C(host), C(none) or C(container:<name|id>).
- Set the user namespace mode for the container. Currently, the only valid value are C(host) and the empty string.
- To remove a container from one or more networks, use the I(purge_networks) option.
  network if I(networks) is specified. You need to explicitly use I(purge_networks) to enforce
  the removal of the default network (and all other networks not explicitly mentioned in I(networks)).
  Alternatively, use the I(networks_cli_compatible) option, which will be enabled by default from Ansible 2.12 on.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- Dictionary of options specific to the chosen volume_driver. See
  L(here,https://docs.docker.com/storage/volumes/#use-a-volume-driver) for details.
- ""The size for the tmpfs mount in bytes in format <number>[<unit>].""
   C(T) (tebibyte), or C(P) (pebibyte).""
"
-------------------------------------------------------------------------
"not attached. This module with I(networks: {name: other}) will create a container
C(docker run --network) and will *not* add the default network if I(networks) is
specified. If I(networks) is not specified, the default network will be attached.""
Note that docker CLI also sets I(network_mode) to the name of the first network
explicitly have to set I(network_mode) to the name of the first network you're
"
-------------------------------------------------------------------------
"not attached. This module with I(networks: {name: other}) will create a container
C(docker run --network) and will *not* add the default network if I(networks) is
specified. If I(networks) is not specified, the default network will be attached.""
Note that docker CLI also sets I(network_mode) to the name of the first network
explicitly have to set I(network_mode) to the name of the first network you're
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- Connect the container to a network. Choices are C(bridge), C(host), C(none) or C(container:<name|id>).
- Set the user namespace mode for the container. Currently, the only valid value are C(host) and the empty string.
- To remove a container from one or more networks, use the I(purge_networks) option.
  network if I(networks) is specified. You need to explicitly use I(purge_networks) to enforce
  the removal of the default network (and all other networks not explicitly mentioned in I(networks)).
  Alternatively, use the I(networks_cli_compatible) option, which will be enabled by default from Ansible 2.12 on.
"
-------------------------------------------------------------------------
"- If set to true, output of the container command will be printed.
- Only effective when I(log_driver) is set to C(json-file) or C(journald).
"
-------------------------------------------------------------------------
"- If set to true, output of the container command will be printed.
- Only effective when I(log_driver) is set to C(json-file) or C(journald).
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"not attached. This module with I(networks: {name: other}) will create a container
C(docker run --network) and will *not* add the default network if I(networks) is
specified. If I(networks) is not specified, the default network will be attached.""
Note that docker CLI also sets I(network_mode) to the name of the first network
explicitly have to set I(network_mode) to the name of the first network you're
"
-------------------------------------------------------------------------
"- Note that Docker SDK for Python < 2.0 only supports C(host). Newer versions of the
  Docker SDK for Python (docker) allow all values supported by the Docker daemon.
- Set C(-1) for unlimited PIDs.
"
-------------------------------------------------------------------------
"- Note that Docker SDK for Python < 2.0 only supports C(host). Newer versions of the
  Docker SDK for Python (docker) allow all values supported by the Docker daemon.
- Set C(-1) for unlimited PIDs.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- If set to true, output of the container command will be printed.
- Only effective when I(log_driver) is set to C(json-file) or C(journald).
"
-------------------------------------------------------------------------
"- ""Bind addresses must be either IPv4 or IPv6 addresses. Hostnames are *not* allowed. This
- If I(networks) parameter is provided, will inspect each network to see if there exists
  a bridge network with optional parameter C(com.docker.network.bridge.host_binding_ipv4).
  will be bound to the host IP pointed to by C(com.docker.network.bridge.host_binding_ipv4).
  Note that the first bridge network with a C(com.docker.network.bridge.host_binding_ipv4)
  value encountered in the list of I(networks) is the one that will be used.
"
-------------------------------------------------------------------------
"- ""Bind addresses must be either IPv4 or IPv6 addresses. Hostnames are *not* allowed. This
- If I(networks) parameter is provided, will inspect each network to see if there exists
  a bridge network with optional parameter C(com.docker.network.bridge.host_binding_ipv4).
  will be bound to the host IP pointed to by C(com.docker.network.bridge.host_binding_ipv4).
  Note that the first bridge network with a C(com.docker.network.bridge.host_binding_ipv4)
  value encountered in the list of I(networks) is the one that will be used.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- Note that Docker SDK for Python < 2.0 only supports C(host). Newer versions of the
  Docker SDK for Python (docker) allow all values supported by the Docker daemon.
- Set C(-1) for unlimited PIDs.
"
-------------------------------------------------------------------------
"- ""*Note:* images are only pulled when specified by name. If the image is specified
  as a image ID (hash), it cannot be pulled.""
- Remove the container from ALL networks not included in I(networks) parameter.
- Any default networks such as C(bridge), if not found in I(networks), will be removed as well.
"
-------------------------------------------------------------------------
"- ""*Note:* images are only pulled when specified by name. If the image is specified
  as a image ID (hash), it cannot be pulled.""
- Remove the container from ALL networks not included in I(networks) parameter.
- Any default networks such as C(bridge), if not found in I(networks), will be removed as well.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- ""Bind addresses must be either IPv4 or IPv6 addresses. Hostnames are *not* allowed. This
- If I(networks) parameter is provided, will inspect each network to see if there exists
  a bridge network with optional parameter C(com.docker.network.bridge.host_binding_ipv4).
  will be bound to the host IP pointed to by C(com.docker.network.bridge.host_binding_ipv4).
  Note that the first bridge network with a C(com.docker.network.bridge.host_binding_ipv4)
  value encountered in the list of I(networks) is the one that will be used.
"
-------------------------------------------------------------------------
"- Container restart policy.
- Place quotes around C(no) option.
"
-------------------------------------------------------------------------
"- Container restart policy.
- Place quotes around C(no) option.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- ""*Note:* images are only pulled when specified by name. If the image is specified
  as a image ID (hash), it cannot be pulled.""
- Remove the container from ALL networks not included in I(networks) parameter.
- Any default networks such as C(bridge), if not found in I(networks), will be removed as well.
"
-------------------------------------------------------------------------
"- ""Size of C(/dev/shm) in format C(<number>[<unit>]). Number is positive integer.
- Omitting the unit defaults to bytes. If you omit the size entirely, Docker daemon uses C(64M).
- List of security options in the form of C(""label:user:User"").
- 'C(absent) - A container matching the specified name will be stopped and removed. Use I(force_kill) to kill the container
   rather than stopping it. Use I(keep_volumes) to retain volumes associated with the removed container.'
- 'C(present) - Asserts the existence of a container matching the name and any provided configuration parameters. If no
  with the requested config.'
- 'C(started) - Asserts that the container is first C(present), and then if the container is not running moves it to a running
  state. Use I(restart) to force a matching container to be stopped and restarted.'
- 'C(stopped) - Asserts that the container is first C(present), and then if the container is running moves it to a stopped
  state.'
- To control what will be taken into account when comparing configuration, see the I(comparisons) option. To avoid that the
  image version will be taken into account, you can also use the I(ignore_image) option.
- Use the I(recreate) option to always force re-creation of a matching container, even if it is running.
- If the container should be killed instead of stopped in case it needs to be stopped for recreation, or because I(state) is
  C(stopped), please use the I(force_kill) option. Use I(keep_volumes) to retain volumes associated with a removed container.
- Use I(keep_volumes) to retain volumes associated with a removed container.
"
-------------------------------------------------------------------------
"- ""Size of C(/dev/shm) in format C(<number>[<unit>]). Number is positive integer.
- Omitting the unit defaults to bytes. If you omit the size entirely, Docker daemon uses C(64M).
- List of security options in the form of C(""label:user:User"").
- 'C(absent) - A container matching the specified name will be stopped and removed. Use I(force_kill) to kill the container
   rather than stopping it. Use I(keep_volumes) to retain volumes associated with the removed container.'
- 'C(present) - Asserts the existence of a container matching the name and any provided configuration parameters. If no
  with the requested config.'
- 'C(started) - Asserts that the container is first C(present), and then if the container is not running moves it to a running
  state. Use I(restart) to force a matching container to be stopped and restarted.'
- 'C(stopped) - Asserts that the container is first C(present), and then if the container is running moves it to a stopped
  state.'
- To control what will be taken into account when comparing configuration, see the I(comparisons) option. To avoid that the
  image version will be taken into account, you can also use the I(ignore_image) option.
- Use the I(recreate) option to always force re-creation of a matching container, even if it is running.
- If the container should be killed instead of stopped in case it needs to be stopped for recreation, or because I(state) is
  C(stopped), please use the I(force_kill) option. Use I(keep_volumes) to retain volumes associated with a removed container.
- Use I(keep_volumes) to retain volumes associated with a removed container.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- Container restart policy.
- Place quotes around C(no) option.
"
-------------------------------------------------------------------------
"- Number of seconds to wait for the container to stop before sending C(SIGKILL).
"
-------------------------------------------------------------------------
"- Number of seconds to wait for the container to stop before sending C(SIGKILL).
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- ""Size of C(/dev/shm) in format C(<number>[<unit>]). Number is positive integer.
- Omitting the unit defaults to bytes. If you omit the size entirely, Docker daemon uses C(64M).
- List of security options in the form of C(""label:user:User"").
- 'C(absent) - A container matching the specified name will be stopped and removed. Use I(force_kill) to kill the container
   rather than stopping it. Use I(keep_volumes) to retain volumes associated with the removed container.'
- 'C(present) - Asserts the existence of a container matching the name and any provided configuration parameters. If no
  with the requested config.'
- 'C(started) - Asserts that the container is first C(present), and then if the container is not running moves it to a running
  state. Use I(restart) to force a matching container to be stopped and restarted.'
- 'C(stopped) - Asserts that the container is first C(present), and then if the container is running moves it to a stopped
  state.'
- To control what will be taken into account when comparing configuration, see the I(comparisons) option. To avoid that the
  image version will be taken into account, you can also use the I(ignore_image) option.
- Use the I(recreate) option to always force re-creation of a matching container, even if it is running.
- If the container should be killed instead of stopped in case it needs to be stopped for recreation, or because I(state) is
  C(stopped), please use the I(force_kill) option. Use I(keep_volumes) to retain volumes associated with a removed container.
- Use I(keep_volumes) to retain volumes associated with a removed container.
"
-------------------------------------------------------------------------
"- Mount a tmpfs directory.
"
-------------------------------------------------------------------------
"- Mount a tmpfs directory.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- Number of seconds to wait for the container to stop before sending C(SIGKILL).
"
-------------------------------------------------------------------------
"- ""List of ulimit options. A ulimit is specified as C(nofile:262144:262144).""
"
-------------------------------------------------------------------------
"- ""List of ulimit options. A ulimit is specified as C(nofile:262144:262144).""
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- Mount a tmpfs directory.
"
-------------------------------------------------------------------------
"- ""Can be of the forms C(user), C(user:group), C(uid), C(uid:gid), C(user:gid) or C(uid:group).""
"
-------------------------------------------------------------------------
"- ""Can be of the forms C(user), C(user:group), C(uid), C(uid:gid), C(user:gid) or C(uid:group).""
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- ""List of ulimit options. A ulimit is specified as C(nofile:262144:262144).""
"
-------------------------------------------------------------------------
"- SELinux hosts can additionally use C(z) or C(Z) to use a shared or private label for the volume.
"
-------------------------------------------------------------------------
"- SELinux hosts can additionally use C(z) or C(Z) to use a shared or private label for the volume.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- ""Can be of the forms C(user), C(user:group), C(uid), C(uid:gid), C(user:gid) or C(uid:group).""
"
-------------------------------------------------------------------------
"- List of container names or IDs to get volumes from.
"
-------------------------------------------------------------------------
"- List of container names or IDs to get volumes from.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- SELinux hosts can additionally use C(z) or C(Z) to use a shared or private label for the volume.
"
-------------------------------------------------------------------------
"- Empty if I(state) is C(absent)
- If I(detached) is C(false), will include C(Output) attribute containing any output from container run.
"
-------------------------------------------------------------------------
"- Empty if I(state) is C(absent)
- If I(detached) is C(false), will include C(Output) attribute containing any output from container run.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- When passed dictionaries valid sub-options are I(name), which is required, and
  I(aliases) and I(options).
"
-------------------------------------------------------------------------
"- ""Service memory reservation in format C(<number>[<unit>]). Number is a positive integer.
"
-------------------------------------------------------------------------
"- ""Service memory reservation in format C(<number>[<unit>]). Number is a positive integer.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"n_url = self.api_server
if self.api_server == 'https://galaxy.ansible.com' or self.api_server == 'https://galaxy.ansible.com/':
    n_url = 'https://galaxy.ansible.com/api/'

try:
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
except (AnsibleError, GalaxyError, ValueError, KeyError):
    # Either the URL doesnt exist, or other error. Or the URL exists, but isn't a galaxy API
    # root (not JSON, no 'available_versions') so try appending '/api/'
    n_url = _urljoin(n_url, '/api/')

    # let exceptions here bubble up
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
    if 'available_versions' not in data:
        raise AnsibleError(""Tried to find galaxy API root at %s but no 'available_versions' are available on %s""
                           % (n_url, self.api_server))
available_versions = data.get('available_versions', {u'v1': u'v1/'})
    available_versions[u'v2'] = u'v2/'
"
-------------------------------------------------------------------------
"n_url = self.api_server
if self.api_server == 'https://galaxy.ansible.com' or self.api_server == 'https://galaxy.ansible.com/':
    n_url = 'https://galaxy.ansible.com/api/'

try:
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
except (AnsibleError, GalaxyError, ValueError, KeyError):
    # Either the URL doesnt exist, or other error. Or the URL exists, but isn't a galaxy API
    # root (not JSON, no 'available_versions') so try appending '/api/'
    n_url = _urljoin(n_url, '/api/')

    # let exceptions here bubble up
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
    if 'available_versions' not in data:
        raise AnsibleError(""Tried to find galaxy API root at %s but no 'available_versions' are available on %s""
                           % (n_url, self.api_server))

    # Update api_server to point to the ""real"" API root, which in this case
    # was the configured url  '/api/' appended.
    self.api_server = n_url
available_versions = data.get('available_versions', {u'v1': u'v1/'})
    available_versions[u'v2'] = u'v2/'
"
-------------------------------------------------------------------------
"n_url = self.api_server
if self.api_server == 'https://galaxy.ansible.com' or self.api_server == 'https://galaxy.ansible.com/':
    n_url = 'https://galaxy.ansible.com/api/'

try:
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
except (AnsibleError, GalaxyError, ValueError, KeyError):
    # Either the URL doesnt exist, or other error. Or the URL exists, but isn't a galaxy API
    # root (not JSON, no 'available_versions') so try appending '/api/'
    n_url = _urljoin(n_url, '/api/')

    # let exceptions here bubble up
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
    if 'available_versions' not in data:
        raise AnsibleError(""Tried to find galaxy API root at %s but no 'available_versions' are available on %s""
                           % (n_url, self.api_server))

    # Update api_server to point to the ""real"" API root, which in this case
    # was the configured url  '/api/' appended.
    self.api_server = n_url
available_versions = data.get('available_versions', {u'v1': u'v1/'})
    available_versions[u'v2'] = u'v2/'
"
-------------------------------------------------------------------------
"Recom
PRs: 63238, 63293"
-------------------------------------------------------------------------
=========================================================================
"cron_cmd = self.module.get_bin_path('crontab', required=True)
        return ""su %s -c '%s -l'"" % (shlex_quote(self.user), shlex_quote(cron_cmd))
        return ""%s -l %s"" % (shlex_quote(cron_cmd), shlex_quote(self.user))
        return ""%s %s %s"" % (cron_cmd, '-l', shlex_quote(self.user))
return ""%s %s %s"" % (cron_cmd, user, '-l')
cron_cmd = self.module.get_bin_path('crontab', required=True)
        return ""chown %s %s ; su '%s' -c '%s %s'"" % (shlex_quote(self.user), shlex_quote(path), shlex_quote(self.user), cron_cmd, shlex_quote(path))
return ""%s %s %s"" % (cron_cmd, user, shlex_quote(path))
"
-------------------------------------------------------------------------
"self.cron_cmd = self.module.get_bin_path('crontab', required=True)
"
-------------------------------------------------------------------------
"self.cron_cmd = self.module.get_bin_path('crontab', required=True)
"
-------------------------------------------------------------------------
"Recom
PRs: 59765, 62546"
-------------------------------------------------------------------------
=========================================================================
"cron_cmd = self.module.get_bin_path('crontab', required=True)
        return ""su %s -c '%s -l'"" % (shlex_quote(self.user), shlex_quote(cron_cmd))
        return ""%s -l %s"" % (shlex_quote(cron_cmd), shlex_quote(self.user))
        return ""%s %s %s"" % (cron_cmd, '-l', shlex_quote(self.user))
return ""%s %s %s"" % (cron_cmd, user, '-l')
cron_cmd = self.module.get_bin_path('crontab', required=True)
        return ""chown %s %s ; su '%s' -c '%s %s'"" % (shlex_quote(self.user), shlex_quote(path), shlex_quote(self.user), cron_cmd, shlex_quote(path))
return ""%s %s %s"" % (cron_cmd, user, shlex_quote(path))
"
-------------------------------------------------------------------------
"self.cron_cmd = self.module.get_bin_path('cronvar', required=True)
"
-------------------------------------------------------------------------
"self.cron_cmd = self.module.get_bin_path('cronvar', required=True)
"
-------------------------------------------------------------------------
"Recom
PRs: 59765, 62546"
-------------------------------------------------------------------------
=========================================================================
