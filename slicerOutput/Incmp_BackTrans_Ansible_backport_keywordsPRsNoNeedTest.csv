"VERSION = '2.10'
"
-------------------------------------------------------------------------
"from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

"
-------------------------------------------------------------------------
"from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

"
-------------------------------------------------------------------------
"Recom
PRs: 73616, 73637"
-------------------------------------------------------------------------
=========================================================================
"# -*- coding: utf-8 -*-
#
# documentation build configuration file, created by
# sphinx-quickstart on Sat Sep 27 13:23:22 2008-2009.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# The contents of this file are pickled, so don't put values in the namespace
# that aren't pickleable (module imports are okay, they're removed
# automatically).
#
# All configuration values have a default value; values that are commented out
# serve to show the default value.

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import sys
import os

# pip install sphinx_rtd_theme
# import sphinx_rtd_theme
# html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]

# If your extensions are in another directory, add it here. If the directory
# is relative to the documentation root, use os.path.abspath to make it
# absolute, like shown here.
# sys.path.append(os.path.abspath('some/directory'))
#
sys.path.insert(0, os.path.join('ansible', 'lib'))
sys.path.append(os.path.abspath(os.path.join('..', '_extensions')))

# We want sphinx to document the ansible modules contained in this repository,
# not those that may happen to be installed in the version
# of Python used to run sphinx.  When sphinx loads in order to document,
# the repository version needs to be the one that is loaded:
sys.path.insert(0, os.path.abspath(os.path.join('..', '..', '..', 'lib')))

VERSION = 'devel'
AUTHOR = 'Ansible, Inc'


# General configuration
# ---------------------

# Add any Sphinx extension module names here, as strings.
# They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
# TEST: 'sphinxcontrib.fulltoc'
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.intersphinx', 'pygments_lexer', 'notfound.extension']

# Later on, add 'sphinx.ext.viewcode' to the list if you want to have
# colorized code generated too for references.


# Add any paths that contain templates here, relative to this directory.
templates_path = ['.templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The master toctree document.
master_doc = 'index'

# General substitutions.
project = 'Ansible'
copyright = ""2021 Red Hat, Inc.""

# The default replacements for |version| and |release|, also used in various
# other places throughout the built documents.
#
# The short X.Y version.
version = VERSION
# The full version, including alpha/beta/rc tags.
release = VERSION

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
# today = ''
# Else, today_fmt is used as the format for a strftime call.
today_fmt = '%B %d, %Y'

# List of documents that shouldn't be included in the build.
# unused_docs = []

# List of directories, relative to source directories, that shouldn't be
# searched for source files.
# exclude_dirs = []

# A list of glob-style patterns that should be excluded when looking
# for source files.
exclude_patterns = [
'2.10_index.rst',
'ansible_index.rst',
'core_index.rst',
'porting_guides/core_porting_guides.rst',
'porting_guides/porting_guide_base_2.10.rst',
'porting_guides/porting_guide_core_2.11.rst',
'roadmap/index.rst',
'roadmap/ansible_base_roadmap_index.rst',
'roadmap/ROADMAP_2_10.rst',
'roadmap/ROADMAP_2_11.rst'


e reST default role (used for this markup: `text`) to use for all
cuments.
fault_role = None

 true, '()' will be appended to :func: etc. cross-reference text.
d_function_parentheses = True

 true, the current module name will be prepended to all description
it titles (such as .. function::).
d_module_names = True

 true, sectionauthor and moduleauthor directives will be shown in the
tput. They are ignored by default.
ow_authors = False

e name of the Pygments (syntax highlighting) style to use.
ents_style = 'sphinx'

light_language = 'YAMLJinja'

bstitutions, variables, entities, & shortcuts for text which do not need to link to anything.
r titles which should be a link, use the intersphinx anchors set at the index, chapter, and section levels, such as  qi_start_:
r| is useful for formatting fields inside of tables
| is a nonbreaking space; similarly useful inside of tables
epilog = """"""
br| raw:: html

br>
_| unicode:: 0xA0
:trim:



tions for HTML output
---------------------

_theme_path = ['../_themes']
_theme = 'sphinx_rtd_theme'
_short_title = 'Ansible Documentation'
_show_sphinx = False

_theme_options = {
'canonical_url': ""https://docs.ansible.com/ansible/latest/"",
'vcs_pageview_mode': 'edit'


_context = {
'display_github': 'True',
'github_user': 'ansible',
'github_repo': 'ansible',
'github_version': 'devel/docs/docsite/rst/',
'github_module_version': 'devel/lib/ansible/modules/',
'github_root_dir': 'devel/lib/ansible',
'github_cli_version': 'devel/lib/ansible/cli/',
'current_version': version,
'latest_version': '2.10',
# list specifically out of order to make latest work
'available_versions': ('latest', '2.9', '2.9_ja', '2.8', 'devel'),
'css_files': ('_static/ansible.css',  # overrides to the standard theme
              ),


e style sheet to use for HTML and HTML Help pages. A file of that name
st exist either in Sphinx' static/ path, or in one of the custom paths
ven in html_static_path.
ml_style = 'solar.css'

e name for this set of Sphinx documents.  If None, it defaults to
project> v<release> documentation"".
_title = 'Ansible Documentation'

shorter title for the navigation bar.  Default is the same as html_title.
ml_short_title = None

e name of an image file (within the static path) to place at the top of
e sidebar.
ml_logo =

e name of an image file (within the static path) to use as favicon of the
cs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
xels large.
ml_favicon = 'favicon.ico'

d any paths that contain custom static files (such as style sheets) here,
lative to this directory. They are copied after the builtin static files,
 a file named ""default.css"" will overwrite the builtin ""default.css"".
_static_path = ['../_static']

 not '', a 'Last updated on:' timestamp is inserted at every page bottom,
ing the given strftime format.
_last_updated_fmt = '%b %d, %Y'

 true, SmartyPants will be used to convert quotes and dashes to
pographically correct entities.
ml_use_smartypants = True

stom sidebar templates, maps document names to template names.
ml_sidebars = {}

ditional templates that should be rendered to pages, maps page names to
mplate names.
ml_additional_pages = {}

 false, no module index is generated.
ml_use_modindex = True

 false, no index is generated.
ml_use_index = True

 true, the index is split into individual pages for each letter.
ml_split_index = False

 true, the reST sources are included in the HTML build as _sources/<name>.
_copy_source = False

 true, an OpenSearch description file will be output, and all pages will
ntain a <link> tag referring to it.  The value of this option must be the
se URL from which the finished HTML is served.
ml_use_opensearch = 'https://docs.ansible.com/ansible/latest'

 nonempty, this is the file name suffix for HTML files (e.g. "".xhtml"").
ml_file_suffix = ''

tput file base name for HTML help builder.
help_basename = 'Poseidodoc'

nfiguration for sphinx-notfound-pages
th no 'notfound_template' and no 'notfound_context' set,
e extension builds 404.rst into a location-agnostic 404 page

fault is `en` - using this for the sub-site:
ound_default_language = ""ansible""
fault is `latest`:
tting explicitly - docsite serves up /ansible/latest/404.html
 keep this set to `latest` even on the `devel` branch
en no maintenance is needed when we branch a new stable_x.x
ound_default_version = ""latest""
kes default setting explicit:
ound_no_urls_prefix = False

tions for LaTeX output
----------------------

e paper size ('letter' or 'a4').
tex_paper_size = 'letter'

e font size ('10pt', '11pt' or '12pt').
tex_font_size = '10pt'

ouping the document tree into LaTeX files. List of tuples
ource start file, target name, title, author, document class
owto/manual]).
x_documents = [
('index', 'ansible.tex', 'Ansible 2.2 Documentation', AUTHOR, 'manual'),


e name of an image file (relative to this directory) to place at the top of
e title page.
tex_logo = None

r ""manual"" documents, if this is true, then toplevel headings are parts,
t chapters.
tex_use_parts = False

ditional stuff for the LaTeX preamble.
tex_preamble = ''

cuments to append as an appendix to all manuals.
tex_appendices = []

 false, no module index is generated.
tex_use_modindex = True

class_content = 'both'

te:  Our strategy for intersphinx mappings is to have the upstream build location as the
nonical source and then cached copies of the mapping stored locally in case someone is building
en disconnected from the internet.  We then have a script to update the cached copies.

cause of that, each entry in this mapping should have this format:
name: ('http://UPSTREAM_URL', (None, 'path/to/local/cache.inv'))

e update script depends on this format so deviating from this (for instance, adding a third
cation for the mappning to live) will confuse it.
rsphinx_mapping = {'python': ('https://docs.python.org/2/', (None, '../python2.inv')),
                   'python3': ('https://docs.python.org/3/', (None, '../python3.inv')),
                   'jinja2': ('http://jinja.palletsprojects.com/', (None, '../jinja2.inv')),
                   'ansible_2_10': ('https://docs.ansible.com/ansible/2.10/', (None, '../ansible_2_10.inv')),
                   'ansible_2_9': ('https://docs.ansible.com/ansible/2.9/', (None, '../ansible_2_9.inv')),
                   'ansible_2_8': ('https://docs.ansible.com/ansible/2.8/', (None, '../ansible_2_8.inv')),
                   'ansible_2_7': ('https://docs.ansible.com/ansible/2.7/', (None, '../ansible_2_7.inv')),
                   'ansible_2_6': ('https://docs.ansible.com/ansible/2.6/', (None, '../ansible_2_6.inv')),
                   'ansible_2_5': ('https://docs.ansible.com/ansible/2.5/', (None, '../ansible_2_5.inv')),
                   }

nckchecker settings
check_ignore = [
r'http://irc\.freenode\.net',

check_workers = 25
nkcheck_anchors = False
"
-------------------------------------------------------------------------
"# -*- coding: utf-8 -*-
#
# documentation build configuration file, created by
# sphinx-quickstart on Sat Sep 27 13:23:22 2008-2009.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# The contents of this file are pickled, so don't put values in the namespace
# that aren't pickleable (module imports are okay, they're removed
# automatically).
#
# All configuration values have a default value; values that are commented out
# serve to show the default value.

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import sys
import os

# pip install sphinx_rtd_theme
# import sphinx_rtd_theme
# html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]

# If your extensions are in another directory, add it here. If the directory
# is relative to the documentation root, use os.path.abspath to make it
# absolute, like shown here.
# sys.path.append(os.path.abspath('some/directory'))
#
sys.path.insert(0, os.path.join('ansible', 'lib'))
sys.path.append(os.path.abspath(os.path.join('..', '_extensions')))

# We want sphinx to document the ansible modules contained in this repository,
# not those that may happen to be installed in the version
# of Python used to run sphinx.  When sphinx loads in order to document,
# the repository version needs to be the one that is loaded:
sys.path.insert(0, os.path.abspath(os.path.join('..', '..', '..', 'lib')))

VERSION = '3'
AUTHOR = 'Ansible, Inc'


# General configuration
# ---------------------

# Add any Sphinx extension module names here, as strings.
# They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
# TEST: 'sphinxcontrib.fulltoc'
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.intersphinx', 'pygments_lexer', 'notfound.extension']

# Later on, add 'sphinx.ext.viewcode' to the list if you want to have
# colorized code generated too for references.


# Add any paths that contain templates here, relative to this directory.
templates_path = ['.templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The master toctree document.
master_doc = 'index'

# General substitutions.
project = 'Ansible'
copyright = ""2021 Red Hat, Inc.""

# The default replacements for |version| and |release|, also used in various
# other places throughout the built documents.
#
# The short X.Y version.
version = VERSION
# The full version, including alpha/beta/rc tags.
release = VERSION

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
# today = ''
# Else, today_fmt is used as the format for a strftime call.
today_fmt = '%B %d, %Y'

# List of documents that shouldn't be included in the build.
# unused_docs = []

# List of directories, relative to source directories, that shouldn't be
# searched for source files.
# exclude_dirs = []

# A list of glob-style patterns that should be excluded when looking
# for source files.
exclude_patterns = [
'2.10_index.rst',
'ansible_index.rst',
'core_index.rst',
'porting_guides/core_porting_guides.rst',
'porting_guides/porting_guide_base_2.10.rst',
'porting_guides/porting_guide_core_2.11.rst',
'roadmap/index.rst',
'roadmap/ansible_base_roadmap_index.rst',
'roadmap/ROADMAP_2_10.rst',
'roadmap/ROADMAP_2_11.rst'


e reST default role (used for this markup: `text`) to use for all
cuments.
fault_role = None

 true, '()' will be appended to :func: etc. cross-reference text.
d_function_parentheses = True

 true, the current module name will be prepended to all description
it titles (such as .. function::).
d_module_names = True

 true, sectionauthor and moduleauthor directives will be shown in the
tput. They are ignored by default.
ow_authors = False

e name of the Pygments (syntax highlighting) style to use.
ents_style = 'sphinx'

light_language = 'YAMLJinja'

bstitutions, variables, entities, & shortcuts for text which do not need to link to anything.
r titles which should be a link, use the intersphinx anchors set at the index, chapter, and section levels, such as  qi_start_:
r| is useful for formatting fields inside of tables
| is a nonbreaking space; similarly useful inside of tables
epilog = """"""
br| raw:: html

br>
_| unicode:: 0xA0
:trim:



tions for HTML output
---------------------

_theme_path = ['../_themes']
_theme = 'sphinx_rtd_theme'
_short_title = 'Ansible Documentation'
_show_sphinx = False

_theme_options = {
'canonical_url': ""https://docs.ansible.com/ansible/latest/"",
'vcs_pageview_mode': 'edit'


_context = {
'display_github': 'True',
'github_user': 'ansible',
'github_repo': 'ansible',
'github_version': 'devel/docs/docsite/rst/',
'github_module_version': 'devel/lib/ansible/modules/',
'github_root_dir': 'devel/lib/ansible',
'github_cli_version': 'devel/lib/ansible/cli/',
'current_version': version,
'latest_version': '3',
# list specifically out of order to make latest work
'available_versions': ('latest', '2.10', '2.9', '2.9_ja', '2.8', 'devel'),
'css_files': ('_static/ansible.css',  # overrides to the standard theme
              ),


e style sheet to use for HTML and HTML Help pages. A file of that name
st exist either in Sphinx' static/ path, or in one of the custom paths
ven in html_static_path.
ml_style = 'solar.css'

e name for this set of Sphinx documents.  If None, it defaults to
project> v<release> documentation"".
_title = 'Ansible Documentation'

shorter title for the navigation bar.  Default is the same as html_title.
ml_short_title = None

e name of an image file (within the static path) to place at the top of
e sidebar.
ml_logo =

e name of an image file (within the static path) to use as favicon of the
cs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
xels large.
ml_favicon = 'favicon.ico'

d any paths that contain custom static files (such as style sheets) here,
lative to this directory. They are copied after the builtin static files,
 a file named ""default.css"" will overwrite the builtin ""default.css"".
_static_path = ['../_static']

 not '', a 'Last updated on:' timestamp is inserted at every page bottom,
ing the given strftime format.
_last_updated_fmt = '%b %d, %Y'

 true, SmartyPants will be used to convert quotes and dashes to
pographically correct entities.
ml_use_smartypants = True

stom sidebar templates, maps document names to template names.
ml_sidebars = {}

ditional templates that should be rendered to pages, maps page names to
mplate names.
ml_additional_pages = {}

 false, no module index is generated.
ml_use_modindex = True

 false, no index is generated.
ml_use_index = True

 true, the index is split into individual pages for each letter.
ml_split_index = False

 true, the reST sources are included in the HTML build as _sources/<name>.
_copy_source = False

 true, an OpenSearch description file will be output, and all pages will
ntain a <link> tag referring to it.  The value of this option must be the
se URL from which the finished HTML is served.
ml_use_opensearch = 'https://docs.ansible.com/ansible/latest'

 nonempty, this is the file name suffix for HTML files (e.g. "".xhtml"").
ml_file_suffix = ''

tput file base name for HTML help builder.
help_basename = 'Poseidodoc'

nfiguration for sphinx-notfound-pages
th no 'notfound_template' and no 'notfound_context' set,
e extension builds 404.rst into a location-agnostic 404 page

fault is `en` - using this for the sub-site:
ound_default_language = ""ansible""
fault is `latest`:
tting explicitly - docsite serves up /ansible/latest/404.html
 keep this set to `latest` even on the `devel` branch
en no maintenance is needed when we branch a new stable_x.x
ound_default_version = ""latest""
kes default setting explicit:
ound_no_urls_prefix = False

tions for LaTeX output
----------------------

e paper size ('letter' or 'a4').
tex_paper_size = 'letter'

e font size ('10pt', '11pt' or '12pt').
tex_font_size = '10pt'

ouping the document tree into LaTeX files. List of tuples
ource start file, target name, title, author, document class
owto/manual]).
x_documents = [
('index', 'ansible.tex', 'Ansible 2.2 Documentation', AUTHOR, 'manual'),


e name of an image file (relative to this directory) to place at the top of
e title page.
tex_logo = None

r ""manual"" documents, if this is true, then toplevel headings are parts,
t chapters.
tex_use_parts = False

ditional stuff for the LaTeX preamble.
tex_preamble = ''

cuments to append as an appendix to all manuals.
tex_appendices = []

 false, no module index is generated.
tex_use_modindex = True

class_content = 'both'

te:  Our strategy for intersphinx mappings is to have the upstream build location as the
nonical source and then cached copies of the mapping stored locally in case someone is building
en disconnected from the internet.  We then have a script to update the cached copies.

cause of that, each entry in this mapping should have this format:
name: ('http://UPSTREAM_URL', (None, 'path/to/local/cache.inv'))

e update script depends on this format so deviating from this (for instance, adding a third
cation for the mappning to live) will confuse it.
rsphinx_mapping = {'python': ('https://docs.python.org/2/', (None, '../python2.inv')),
                   'python3': ('https://docs.python.org/3/', (None, '../python3.inv')),
                   'jinja2': ('http://jinja.palletsprojects.com/', (None, '../jinja2.inv')),
                   'ansible_2_10': ('https://docs.ansible.com/ansible/2.10/', (None, '../ansible_2_10.inv')),
                   'ansible_2_9': ('https://docs.ansible.com/ansible/2.9/', (None, '../ansible_2_9.inv')),
                   'ansible_2_8': ('https://docs.ansible.com/ansible/2.8/', (None, '../ansible_2_8.inv')),
                   'ansible_2_7': ('https://docs.ansible.com/ansible/2.7/', (None, '../ansible_2_7.inv')),
                   'ansible_2_6': ('https://docs.ansible.com/ansible/2.6/', (None, '../ansible_2_6.inv')),
                   'ansible_2_5': ('https://docs.ansible.com/ansible/2.5/', (None, '../ansible_2_5.inv')),
                   }

nckchecker settings
check_ignore = [
r'http://irc\.freenode\.net',

check_workers = 25
nkcheck_anchors = False
"
-------------------------------------------------------------------------
"# -*- coding: utf-8 -*-
#
# documentation build configuration file, created by
# sphinx-quickstart on Sat Sep 27 13:23:22 2008-2009.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# The contents of this file are pickled, so don't put values in the namespace
# that aren't pickleable (module imports are okay, they're removed
# automatically).
#
# All configuration values have a default value; values that are commented out
# serve to show the default value.

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import sys
import os

# pip install sphinx_rtd_theme
# import sphinx_rtd_theme
# html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]

# If your extensions are in another directory, add it here. If the directory
# is relative to the documentation root, use os.path.abspath to make it
# absolute, like shown here.
# sys.path.append(os.path.abspath('some/directory'))
#
sys.path.insert(0, os.path.join('ansible', 'lib'))
sys.path.append(os.path.abspath(os.path.join('..', '_extensions')))

# We want sphinx to document the ansible modules contained in this repository,
# not those that may happen to be installed in the version
# of Python used to run sphinx.  When sphinx loads in order to document,
# the repository version needs to be the one that is loaded:
sys.path.insert(0, os.path.abspath(os.path.join('..', '..', '..', 'lib')))

VERSION = '3'
AUTHOR = 'Ansible, Inc'


# General configuration
# ---------------------

# Add any Sphinx extension module names here, as strings.
# They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
# TEST: 'sphinxcontrib.fulltoc'
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.intersphinx', 'pygments_lexer', 'notfound.extension']

# Later on, add 'sphinx.ext.viewcode' to the list if you want to have
# colorized code generated too for references.


# Add any paths that contain templates here, relative to this directory.
templates_path = ['.templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The master toctree document.
master_doc = 'index'

# General substitutions.
project = 'Ansible'
copyright = ""2021 Red Hat, Inc.""

# The default replacements for |version| and |release|, also used in various
# other places throughout the built documents.
#
# The short X.Y version.
version = VERSION
# The full version, including alpha/beta/rc tags.
release = VERSION

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
# today = ''
# Else, today_fmt is used as the format for a strftime call.
today_fmt = '%B %d, %Y'

# List of documents that shouldn't be included in the build.
# unused_docs = []

# List of directories, relative to source directories, that shouldn't be
# searched for source files.
# exclude_dirs = []

# A list of glob-style patterns that should be excluded when looking
# for source files.
exclude_patterns = [
'2.10_index.rst',
'ansible_index.rst',
'core_index.rst',
'porting_guides/core_porting_guides.rst',
'porting_guides/porting_guide_base_2.10.rst',
'porting_guides/porting_guide_core_2.11.rst',
'roadmap/index.rst',
'roadmap/ansible_base_roadmap_index.rst',
'roadmap/ROADMAP_2_10.rst',
'roadmap/ROADMAP_2_11.rst'


e reST default role (used for this markup: `text`) to use for all
cuments.
fault_role = None

 true, '()' will be appended to :func: etc. cross-reference text.
d_function_parentheses = True

 true, the current module name will be prepended to all description
it titles (such as .. function::).
d_module_names = True

 true, sectionauthor and moduleauthor directives will be shown in the
tput. They are ignored by default.
ow_authors = False

e name of the Pygments (syntax highlighting) style to use.
ents_style = 'sphinx'

light_language = 'YAMLJinja'

bstitutions, variables, entities, & shortcuts for text which do not need to link to anything.
r titles which should be a link, use the intersphinx anchors set at the index, chapter, and section levels, such as  qi_start_:
r| is useful for formatting fields inside of tables
| is a nonbreaking space; similarly useful inside of tables
epilog = """"""
br| raw:: html

br>
_| unicode:: 0xA0
:trim:



tions for HTML output
---------------------

_theme_path = ['../_themes']
_theme = 'sphinx_rtd_theme'
_short_title = 'Ansible Documentation'
_show_sphinx = False

_theme_options = {
'canonical_url': ""https://docs.ansible.com/ansible/latest/"",
'vcs_pageview_mode': 'edit'


_context = {
'display_github': 'True',
'github_user': 'ansible',
'github_repo': 'ansible',
'github_version': 'devel/docs/docsite/rst/',
'github_module_version': 'devel/lib/ansible/modules/',
'github_root_dir': 'devel/lib/ansible',
'github_cli_version': 'devel/lib/ansible/cli/',
'current_version': version,
'latest_version': '3',
# list specifically out of order to make latest work
'available_versions': ('latest', '2.10', '2.9', '2.9_ja', '2.8', 'devel'),
'css_files': ('_static/ansible.css',  # overrides to the standard theme
              ),


e style sheet to use for HTML and HTML Help pages. A file of that name
st exist either in Sphinx' static/ path, or in one of the custom paths
ven in html_static_path.
ml_style = 'solar.css'

e name for this set of Sphinx documents.  If None, it defaults to
project> v<release> documentation"".
_title = 'Ansible Documentation'

shorter title for the navigation bar.  Default is the same as html_title.
ml_short_title = None

e name of an image file (within the static path) to place at the top of
e sidebar.
ml_logo =

e name of an image file (within the static path) to use as favicon of the
cs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
xels large.
ml_favicon = 'favicon.ico'

d any paths that contain custom static files (such as style sheets) here,
lative to this directory. They are copied after the builtin static files,
 a file named ""default.css"" will overwrite the builtin ""default.css"".
_static_path = ['../_static']

 not '', a 'Last updated on:' timestamp is inserted at every page bottom,
ing the given strftime format.
_last_updated_fmt = '%b %d, %Y'

 true, SmartyPants will be used to convert quotes and dashes to
pographically correct entities.
ml_use_smartypants = True

stom sidebar templates, maps document names to template names.
ml_sidebars = {}

ditional templates that should be rendered to pages, maps page names to
mplate names.
ml_additional_pages = {}

 false, no module index is generated.
ml_use_modindex = True

 false, no index is generated.
ml_use_index = True

 true, the index is split into individual pages for each letter.
ml_split_index = False

 true, the reST sources are included in the HTML build as _sources/<name>.
_copy_source = False

 true, an OpenSearch description file will be output, and all pages will
ntain a <link> tag referring to it.  The value of this option must be the
se URL from which the finished HTML is served.
ml_use_opensearch = 'https://docs.ansible.com/ansible/latest'

 nonempty, this is the file name suffix for HTML files (e.g. "".xhtml"").
ml_file_suffix = ''

tput file base name for HTML help builder.
help_basename = 'Poseidodoc'

nfiguration for sphinx-notfound-pages
th no 'notfound_template' and no 'notfound_context' set,
e extension builds 404.rst into a location-agnostic 404 page

fault is `en` - using this for the sub-site:
ound_default_language = ""ansible""
fault is `latest`:
tting explicitly - docsite serves up /ansible/latest/404.html
 keep this set to `latest` even on the `devel` branch
en no maintenance is needed when we branch a new stable_x.x
ound_default_version = ""latest""
kes default setting explicit:
ound_no_urls_prefix = False

tions for LaTeX output
----------------------

e paper size ('letter' or 'a4').
tex_paper_size = 'letter'

e font size ('10pt', '11pt' or '12pt').
tex_font_size = '10pt'

ouping the document tree into LaTeX files. List of tuples
ource start file, target name, title, author, document class
owto/manual]).
x_documents = [
('index', 'ansible.tex', 'Ansible 2.2 Documentation', AUTHOR, 'manual'),


e name of an image file (relative to this directory) to place at the top of
e title page.
tex_logo = None

r ""manual"" documents, if this is true, then toplevel headings are parts,
t chapters.
tex_use_parts = False

ditional stuff for the LaTeX preamble.
tex_preamble = ''

cuments to append as an appendix to all manuals.
tex_appendices = []

 false, no module index is generated.
tex_use_modindex = True

class_content = 'both'

te:  Our strategy for intersphinx mappings is to have the upstream build location as the
nonical source and then cached copies of the mapping stored locally in case someone is building
en disconnected from the internet.  We then have a script to update the cached copies.

cause of that, each entry in this mapping should have this format:
name: ('http://UPSTREAM_URL', (None, 'path/to/local/cache.inv'))

e update script depends on this format so deviating from this (for instance, adding a third
cation for the mappning to live) will confuse it.
rsphinx_mapping = {'python': ('https://docs.python.org/2/', (None, '../python2.inv')),
                   'python3': ('https://docs.python.org/3/', (None, '../python3.inv')),
                   'jinja2': ('http://jinja.palletsprojects.com/', (None, '../jinja2.inv')),
                   'ansible_2_10': ('https://docs.ansible.com/ansible/2.10/', (None, '../ansible_2_10.inv')),
                   'ansible_2_9': ('https://docs.ansible.com/ansible/2.9/', (None, '../ansible_2_9.inv')),
                   'ansible_2_8': ('https://docs.ansible.com/ansible/2.8/', (None, '../ansible_2_8.inv')),
                   'ansible_2_7': ('https://docs.ansible.com/ansible/2.7/', (None, '../ansible_2_7.inv')),
                   'ansible_2_6': ('https://docs.ansible.com/ansible/2.6/', (None, '../ansible_2_6.inv')),
                   'ansible_2_5': ('https://docs.ansible.com/ansible/2.5/', (None, '../ansible_2_5.inv')),
                   }

nckchecker settings
check_ignore = [
r'http://irc\.freenode\.net',

check_workers = 25
nkcheck_anchors = False
"
-------------------------------------------------------------------------
"Recom
PRs: 73616, 73637"
-------------------------------------------------------------------------
=========================================================================
"'EulerOS', 'openEuler', 'AlmaLinux'],
"
-------------------------------------------------------------------------
"'OEL', 'Amazon', 'Virtuozzo', 'XenServer', 'Alibaba',
'AlmaLinux'],
"
-------------------------------------------------------------------------
"'OEL', 'Amazon', 'Virtuozzo', 'XenServer', 'Alibaba',
'AlmaLinux'],
"
-------------------------------------------------------------------------
"Recom
PRs: 73541, 73544"
-------------------------------------------------------------------------
=========================================================================
"if 'BHYVE' in out:
    guest_tech.add('bhyve')
    if not found_virt:
        virtual_facts['virtualization_type'] = 'bhyve'
        virtual_facts['virtualization_role'] = 'guest'
        found_virt = True

"
-------------------------------------------------------------------------
"if 'BHYVE' in out:
    virtual_facts['virtualization_type'] = 'bhyve'
    virtual_facts['virtualization_role'] = 'guest'
    return virtual_facts

"
-------------------------------------------------------------------------
"if 'BHYVE' in out:
    virtual_facts['virtualization_type'] = 'bhyve'
    virtual_facts['virtualization_role'] = 'guest'
    return virtual_facts

"
-------------------------------------------------------------------------
"Recom
PRs: 73204, 73234"
-------------------------------------------------------------------------
=========================================================================
"if 'BHYVE' in out:
    guest_tech.add('bhyve')
    if not found_virt:
        virtual_facts['virtualization_type'] = 'bhyve'
        virtual_facts['virtualization_role'] = 'guest'
        found_virt = True

"
-------------------------------------------------------------------------
"if 'BHYVE' in out:
    virtual_facts['virtualization_type'] = 'bhyve'
    virtual_facts['virtualization_role'] = 'guest'
    return virtual_facts

"
-------------------------------------------------------------------------
"if 'BHYVE' in out:
    virtual_facts['virtualization_type'] = 'bhyve'
    virtual_facts['virtualization_role'] = 'guest'
    return virtual_facts

"
-------------------------------------------------------------------------
"Recom
PRs: 73204, 73233"
-------------------------------------------------------------------------
=========================================================================
"to_text,
"
-------------------------------------------------------------------------
"yield DirectoryTarget(to_text(sorted(matched_directories, key=len)[0]), target.modules)
"
-------------------------------------------------------------------------
"yield DirectoryTarget(to_text(sorted(matched_directories, key=len)[0]), target.modules)
"
-------------------------------------------------------------------------
"Recom
PRs: 72623, 72866"
-------------------------------------------------------------------------
=========================================================================
"yield IntegrationTarget(to_text(path), modules, prefixes)
"
-------------------------------------------------------------------------
"yield TestTarget(to_text(file_path), module_path, prefix, path, symlink)
"
-------------------------------------------------------------------------
"yield TestTarget(to_text(file_path), module_path, prefix, path, symlink)
"
-------------------------------------------------------------------------
"Recom
PRs: 72623, 72866"
-------------------------------------------------------------------------
=========================================================================
"import sys
"
-------------------------------------------------------------------------
"import sys
import time
"
-------------------------------------------------------------------------
"import sys
import time
"
-------------------------------------------------------------------------
"Recom
PRs: 72604, 72610"
-------------------------------------------------------------------------
=========================================================================
"import sys
"
-------------------------------------------------------------------------
"import sys
import time
"
-------------------------------------------------------------------------
"import sys
import time
"
-------------------------------------------------------------------------
"Recom
PRs: 72604, 72609"
-------------------------------------------------------------------------
=========================================================================
"@staticmethod
def _combine_plugin_doc(plugin, plugin_type, doc, plainexamples, returndocs, metadata):
    # generate extra data
    if plugin_type == 'module':
        # is there corresponding action plugin?
        if plugin in action_loader:
            doc['has_action'] = True
        else:
            doc['has_action'] = False

    # return everything as one dictionary
    return {'doc': doc, 'examples': plainexamples, 'return': returndocs, 'metadata': metadata}

"
-------------------------------------------------------------------------
"def _combine_plugin_doc(plugin, plugin_type, doc, plainexamples, returndocs, metadata):
            doc['has_action'] = True
            doc['has_action'] = False

    # return everything as one dictionary
    return {'doc': doc, 'examples': plainexamples, 'return': returndocs, 'metadata': metadata}
@staticmethod
def format_plugin_doc(plugin, plugin_type, doc, plainexamples, returndocs, metadata):
    # assign from other sections
    doc['plainexamples'] = plainexamples
    doc['returndocs'] = returndocs
    doc['metadata'] = metadata
"
-------------------------------------------------------------------------
"def _combine_plugin_doc(plugin, plugin_type, doc, plainexamples, returndocs, metadata):
            doc['has_action'] = True
            doc['has_action'] = False

    # return everything as one dictionary
    return {'doc': doc, 'examples': plainexamples, 'return': returndocs, 'metadata': metadata}
@staticmethod
def format_plugin_doc(plugin, plugin_type, doc, plainexamples, returndocs, metadata):
    # assign from other sections
    doc['plainexamples'] = plainexamples
    doc['returndocs'] = returndocs
    doc['metadata'] = metadata
"
-------------------------------------------------------------------------
"Recom
PRs: 72359, 72416"
-------------------------------------------------------------------------
=========================================================================
"
# Workaround for https://github.com/ansible/ansible/issues/71528
elif err and rc == 1 and 'Failed to parse bus message' in err:
    result['status'] = parse_systemctl_show(to_native(out).split('\n'))

    (rc, out, err) = module.run_command(""{systemctl} list-units '{unit}*'"".format(systemctl=systemctl, unit=unit))
    is_systemd = unit in out

    (rc, out, err) = module.run_command(""{systemctl} is-active '{unit}'"".format(systemctl=systemctl, unit=unit))
    result['status']['ActiveState'] = out.rstrip('\n')

"
-------------------------------------------------------------------------
"
# Workaround for https://github.com/ansible/ansible/issues/71528
elif err and rc == 1 and 'Failed to parse bus message' in err:
    result['status'] = parse_systemctl_show(to_native(out).split('\n'))

    unit, sep, suffix = unit.partition('@')
    unit_search = '{unit}{sep}*'.format(unit=unit, sep=sep)
    (rc, out, err) = module.run_command(""{systemctl} list-unit-files '{unit_search}'"".format(systemctl=systemctl, unit_search=unit_search))
    is_systemd = unit in out

    (rc, out, err) = module.run_command(""{systemctl} is-active '{unit}'"".format(systemctl=systemctl, unit=unit))
    result['status']['ActiveState'] = out.rstrip('\n')

"
-------------------------------------------------------------------------
"
# Workaround for https://github.com/ansible/ansible/issues/71528
elif err and rc == 1 and 'Failed to parse bus message' in err:
    result['status'] = parse_systemctl_show(to_native(out).split('\n'))

    unit, sep, suffix = unit.partition('@')
    unit_search = '{unit}{sep}*'.format(unit=unit, sep=sep)
    (rc, out, err) = module.run_command(""{systemctl} list-unit-files '{unit_search}'"".format(systemctl=systemctl, unit_search=unit_search))
    is_systemd = unit in out

    (rc, out, err) = module.run_command(""{systemctl} is-active '{unit}'"".format(systemctl=systemctl, unit=unit))
    result['status']['ActiveState'] = out.rstrip('\n')

"
-------------------------------------------------------------------------
"Recom
PRs: 72337, 72348"
-------------------------------------------------------------------------
=========================================================================
"
# Workaround for https://github.com/ansible/ansible/issues/71528
elif err and rc == 1 and 'Failed to parse bus message' in err:
    result['status'] = parse_systemctl_show(to_native(out).split('\n'))

    (rc, out, err) = module.run_command(""{systemctl} list-units '{unit}*'"".format(systemctl=systemctl, unit=unit))
    is_systemd = unit in out

    (rc, out, err) = module.run_command(""{systemctl} is-active '{unit}'"".format(systemctl=systemctl, unit=unit))
    result['status']['ActiveState'] = out.rstrip('\n')

"
-------------------------------------------------------------------------
"
# Workaround for https://github.com/ansible/ansible/issues/71528
elif err and rc == 1 and 'Failed to parse bus message' in err:
    result['status'] = parse_systemctl_show(to_native(out).split('\n'))

    unit, sep, suffix = unit.partition('@')
    unit_search = '{unit}{sep}*'.format(unit=unit, sep=sep)
    (rc, out, err) = module.run_command(""{systemctl} list-unit-files '{unit_search}'"".format(systemctl=systemctl, unit_search=unit_search))
    is_systemd = unit in out

    (rc, out, err) = module.run_command(""{systemctl} is-active '{unit}'"".format(systemctl=systemctl, unit=unit))
    result['status']['ActiveState'] = out.rstrip('\n')

"
-------------------------------------------------------------------------
"
# Workaround for https://github.com/ansible/ansible/issues/71528
elif err and rc == 1 and 'Failed to parse bus message' in err:
    result['status'] = parse_systemctl_show(to_native(out).split('\n'))

    unit, sep, suffix = unit.partition('@')
    unit_search = '{unit}{sep}*'.format(unit=unit, sep=sep)
    (rc, out, err) = module.run_command(""{systemctl} list-unit-files '{unit_search}'"".format(systemctl=systemctl, unit_search=unit_search))
    is_systemd = unit in out

    (rc, out, err) = module.run_command(""{systemctl} is-active '{unit}'"".format(systemctl=systemctl, unit=unit))
    result['status']['ActiveState'] = out.rstrip('\n')

"
-------------------------------------------------------------------------
"Recom
PRs: 72337, 72347"
-------------------------------------------------------------------------
=========================================================================
"(rc, _out, _err) = self.execute_command([lchage_cmd, '-E', to_native(lexpires), self.name])
return (rc, out, err)
(rc, _out, _err) = self.execute_command([lgroupmod_cmd, '-M', self.name, add_group])
"
-------------------------------------------------------------------------
"(rc, _out, _err) = self.execute_command([lchage_cmd, '-E', to_native(lexpires), self.name])
"
-------------------------------------------------------------------------
"(rc, _out, _err) = self.execute_command([lchage_cmd, '-E', to_native(lexpires), self.name])
"
-------------------------------------------------------------------------
"Recom
PRs: 72088, 72340"
-------------------------------------------------------------------------
=========================================================================
"(rc, out, err) = (None, '', '')
    (rc, out, err) = self.execute_command(cmd)
    return (rc, out, err)
    (rc, _out, _err) = self.execute_command([lchage_cmd, '-E', to_native(lexpires), self.name])
    return (rc, out, err)
    (rc, _out, _err) = self.execute_command([lgroupmod_cmd, '-M', self.name, add_group])
    (rc, _out, _err) = self.execute_command([lgroupmod_cmd, '-m', self.name, del_group])
"
-------------------------------------------------------------------------
"(rc, out, err) = (None, '', '')
    (rc, out, err) = self.execute_command(cmd)
    return (rc, out, err)
    (rc, _out, _err) = self.execute_command([lchage_cmd, '-E', to_native(lexpires), self.name])
"
-------------------------------------------------------------------------
"(rc, out, err) = (None, '', '')
    (rc, out, err) = self.execute_command(cmd)
    return (rc, out, err)
    (rc, _out, _err) = self.execute_command([lchage_cmd, '-E', to_native(lexpires), self.name])
"
-------------------------------------------------------------------------
"Recom
PRs: 72088, 72340"
-------------------------------------------------------------------------
=========================================================================
"def post_process_whens(result, task, templar):

cond = None
if task.changed_when:
    cond = Conditional(loader=templar._loader)
    cond.when = task.changed_when
    result['changed'] = cond.evaluate_conditional(templar, templar.available_variables)

if task.failed_when:
    if cond is None:
        cond = Conditional(loader=templar._loader)
    cond.when = task.failed_when
    failed_when_result = cond.evaluate_conditional(templar, templar.available_variables)
    result['failed_when_result'] = result['failed'] = failed_when_result


"
-------------------------------------------------------------------------
"_sentinel = StrategySentinel()


"
-------------------------------------------------------------------------
"_sentinel = StrategySentinel()


"
-------------------------------------------------------------------------
"Recom
PRs: 70919, 72118"
-------------------------------------------------------------------------
=========================================================================
"post_process_whens(result_item, original_task, handler_templar)
post_process_whens(result_item, original_task, handler_templar)
"
-------------------------------------------------------------------------
"def post_process_whens(result, task, templar):
cond = None
if task.changed_when:
    cond = Conditional(loader=templar._loader)
    cond.when = task.changed_when
    result['changed'] = cond.evaluate_conditional(templar, templar.available_variables)

if task.failed_when:
    if cond is None:
        cond = Conditional(loader=templar._loader)
    cond.when = task.failed_when
    failed_when_result = cond.evaluate_conditional(templar, templar.available_variables)
    result['failed_when_result'] = result['failed'] = failed_when_result
"
-------------------------------------------------------------------------
"def post_process_whens(result, task, templar):
cond = None
if task.changed_when:
    cond = Conditional(loader=templar._loader)
    cond.when = task.changed_when
    result['changed'] = cond.evaluate_conditional(templar, templar.available_variables)

if task.failed_when:
    if cond is None:
        cond = Conditional(loader=templar._loader)
    cond.when = task.failed_when
    failed_when_result = cond.evaluate_conditional(templar, templar.available_variables)
    result['failed_when_result'] = result['failed'] = failed_when_result
"
-------------------------------------------------------------------------
"Recom
PRs: 70919, 72118"
-------------------------------------------------------------------------
=========================================================================
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
                self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
                fail = True
        else:  # fatal error
            fail = True

        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg)

"
-------------------------------------------------------------------------
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
                self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
                fail = True
        else:  # fatal error
            fail = True

        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg=msg)

"
-------------------------------------------------------------------------
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
                self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
                fail = True
        else:  # fatal error
            fail = True

        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg=msg)

"
-------------------------------------------------------------------------
"Recom
PRs: 71537, 71541"
-------------------------------------------------------------------------
=========================================================================
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
                self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
                fail = True
        else:  # fatal error
            fail = True

        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg)

"
-------------------------------------------------------------------------
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
                self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
                fail = True
        else:  # fatal error
            fail = True

        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg=msg)

"
-------------------------------------------------------------------------
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
                self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
                fail = True
        else:  # fatal error
            fail = True

        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg=msg)

"
-------------------------------------------------------------------------
"Recom
PRs: 71537, 71540"
-------------------------------------------------------------------------
=========================================================================
"self._created_files = set()

    self._uses_common_file_args = True
"
-------------------------------------------------------------------------
"if mode is None:
    return changed

"
-------------------------------------------------------------------------
"if mode is None:
    return changed

"
-------------------------------------------------------------------------
"Recom
PRs: 71260, 71514"
-------------------------------------------------------------------------
=========================================================================
"# Remove paths so we do not warn about creating with default permissions
# since we are calling this method on the path and setting the specified mode.
try:
    self._created_files.remove(path)
except KeyError:
    pass

"
-------------------------------------------------------------------------
"_DEFAULT_PERM = 0o0666       # default file permission bits
"
-------------------------------------------------------------------------
"_DEFAULT_PERM = 0o0666       # default file permission bits
"
-------------------------------------------------------------------------
"Recom
PRs: 71260, 71514"
-------------------------------------------------------------------------
=========================================================================
"_DEFAULT_PERM = 0o0600       # default file permission bits
"
-------------------------------------------------------------------------
"stat1.st_mode = 0o0644
"
-------------------------------------------------------------------------
"stat1.st_mode = 0o0644
"
-------------------------------------------------------------------------
"Recom
PRs: 71260, 71514"
-------------------------------------------------------------------------
=========================================================================
"- module: ansible.builtin.blockinfile
- module: ansible.builtin.copy
- module: ansible.builtin.file
- module: ansible.builtin.replace
- module: ansible.builtin.template
- module: ansible.windows.win_lineinfile
"
-------------------------------------------------------------------------
"- module: ansible.builtin.blockinfile
- module: ansible.builtin.copy
- module: ansible.builtin.file
- module: ansible.builtin.replace
- module: ansible.builtin.template
- module: community.windows.win_lineinfile
"
-------------------------------------------------------------------------
"- module: ansible.builtin.blockinfile
- module: ansible.builtin.copy
- module: ansible.builtin.file
- module: ansible.builtin.replace
- module: ansible.builtin.template
- module: community.windows.win_lineinfile
"
-------------------------------------------------------------------------
"Recom
PRs: 70530, 71380"
-------------------------------------------------------------------------
=========================================================================
"- module: ansible.builtin.copy
- module: ansible.windows.win_copy
- module: ansible.windows.win_template
"
-------------------------------------------------------------------------
"- For Windows you can use M(ansible.windows.win_template) which uses '\\r\\n' as C(newline_sequence) by default.
- module: ansible.builtin.copy
- module: ansible.windows.win_copy
- module: ansible.windows.win_template
"
-------------------------------------------------------------------------
"- For Windows you can use M(ansible.windows.win_template) which uses '\\r\\n' as C(newline_sequence) by default.
- module: ansible.builtin.copy
- module: ansible.windows.win_copy
- module: ansible.windows.win_template
"
-------------------------------------------------------------------------
"Recom
PRs: 70530, 71380"
-------------------------------------------------------------------------
=========================================================================
"- module: ansible.builtin.authorized_key
- module: ansible.builtin.group
- module: ansible.windows.win_user
"
-------------------------------------------------------------------------
"- module: ansible.posix.authorized_key
- module: ansible.builtin.group
- module: ansible.windows.win_user
"
-------------------------------------------------------------------------
"- module: ansible.posix.authorized_key
- module: ansible.builtin.group
- module: ansible.windows.win_user
"
-------------------------------------------------------------------------
"Recom
PRs: 70530, 71380"
-------------------------------------------------------------------------
=========================================================================
"- module: ansible.builtin.wait_for
- module: ansible.windows.win_wait_for
- module: ansible.windows.win_wait_for_process
"
-------------------------------------------------------------------------
"- module: ansible.builtin.wait_for
- module: ansible.windows.win_wait_for
- module: community.windows.win_wait_for_process
"
-------------------------------------------------------------------------
"- module: ansible.builtin.wait_for
- module: ansible.windows.win_wait_for
- module: community.windows.win_wait_for_process
"
-------------------------------------------------------------------------
"Recom
PRs: 70530, 71380"
-------------------------------------------------------------------------
=========================================================================
"- If you wish to update an existing repository definition use M(ansible.builtin.ini_file) instead.
"
-------------------------------------------------------------------------
"- If you wish to update an existing repository definition use M(community.general.ini_file) instead.
"
-------------------------------------------------------------------------
"- If you wish to update an existing repository definition use M(community.general.ini_file) instead.
"
-------------------------------------------------------------------------
"Recom
PRs: 70530, 71380"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils.common.collections import is_sequence, Mapping
def _fail_on_undefined(data):
""""""Recursively find an undefined value in a nested data structure
and properly raise the undefined exception.
""""""
if isinstance(data, Mapping):
    for value in data.values():
        _fail_on_undefined(value)
elif is_sequence(data):
    for item in data:
        _fail_on_undefined(item)
else:
    if isinstance(data, StrictUndefined):
        # To actually raise the undefined exception we need to
        # access the undefined object otherwise the exception would
        # be raised on the next access which might not be properly
        # handled.
        # See https://github.com/ansible/ansible/issues/52158
        # and StrictUndefined implementation in upstream Jinja2.
        str(data)

return data


https://github.com/pallets/jinja/blob/master/src/jinja2/nativetypes.py
""""""
    out = _fail_on_undefined(head[0])
    out = u''.join([to_text(_fail_on_undefined(v)) for v in nodes])
"
-------------------------------------------------------------------------
"from ansible.module_utils.common.collections import is_sequence, Mapping
"
-------------------------------------------------------------------------
"from ansible.module_utils.common.collections import is_sequence, Mapping
"
-------------------------------------------------------------------------
"Recom
PRs: 68432, 71105"
-------------------------------------------------------------------------
=========================================================================
"# Instantiate our ResultsCollector for handling results as
# they come in. Ansible expects this to be one of its main
# display outlets.
callback = ResultsCollector()

# Instantiate task queue manager, which takes care of forking
# and setting up all objects to iterate over host list and tasks.
# IMPORTANT: This also adds library dirs paths to the module loader
# IMPORTANT: and so it must be initialized before calling `Play.load()`.
tqm = TaskQueueManager(
    inventory=inventory,
    variable_manager=variable_manager,
    loader=loader,
    passwords=passwords,
    stdout_callback=callback,
)

"
-------------------------------------------------------------------------
"loader = DataLoader()  # Takes care of finding and reading yaml, json and ini files
passwords = dict(vault_pass='secret')
# Instantiate our ResultsCollectorJSONCallback for handling results as they come in. Ansible expects this to be one of its main display outlets
results_callback = ResultsCollectorJSONCallback()
# create inventory, use path to host config file as source or hosts in a comma separated string

# variable manager takes care of merging all the different sources to give you a unified view of variables available in each context
# instantiate task queue manager, which takes care of forking and setting up all objects to iterate over host list and tasks
"
-------------------------------------------------------------------------
"loader = DataLoader()  # Takes care of finding and reading yaml, json and ini files
passwords = dict(vault_pass='secret')
# Instantiate our ResultsCollectorJSONCallback for handling results as they come in. Ansible expects this to be one of its main display outlets
results_callback = ResultsCollectorJSONCallback()
# create inventory, use path to host config file as source or hosts in a comma separated string

# variable manager takes care of merging all the different sources to give you a unified view of variables available in each context
# instantiate task queue manager, which takes care of forking and setting up all objects to iterate over host list and tasks
"
-------------------------------------------------------------------------
"Recom
PRs: 70842, 70851"
-------------------------------------------------------------------------
=========================================================================
"# Instantiate our ResultsCollector for handling results as
# they come in. Ansible expects this to be one of its main
# display outlets.
callback = ResultsCollector()

# Instantiate task queue manager, which takes care of forking
# and setting up all objects to iterate over host list and tasks.
# IMPORTANT: This also adds library dirs paths to the module loader
# IMPORTANT: and so it must be initialized before calling `Play.load()`.
tqm = TaskQueueManager(
    inventory=inventory,
    variable_manager=variable_manager,
    loader=loader,
    passwords=passwords,
    stdout_callback=callback,
)

"
-------------------------------------------------------------------------
"loader = DataLoader()  # Takes care of finding and reading yaml, json and ini files
passwords = dict(vault_pass='secret')
# Instantiate our ResultsCollectorJSONCallback for handling results as they come in. Ansible expects this to be one of its main display outlets
results_callback = ResultsCollectorJSONCallback()
# create inventory, use path to host config file as source or hosts in a comma separated string

# variable manager takes care of merging all the different sources to give you a unified view of variables available in each context
# instantiate task queue manager, which takes care of forking and setting up all objects to iterate over host list and tasks
"
-------------------------------------------------------------------------
"loader = DataLoader()  # Takes care of finding and reading yaml, json and ini files
passwords = dict(vault_pass='secret')
# Instantiate our ResultsCollectorJSONCallback for handling results as they come in. Ansible expects this to be one of its main display outlets
results_callback = ResultsCollectorJSONCallback()
# create inventory, use path to host config file as source or hosts in a comma separated string

# variable manager takes care of merging all the different sources to give you a unified view of variables available in each context
# instantiate task queue manager, which takes care of forking and setting up all objects to iterate over host list and tasks
"
-------------------------------------------------------------------------
"Recom
PRs: 70445, 70850"
-------------------------------------------------------------------------
=========================================================================
"# `distutils` must be imported after `setuptools` or it will cause explosions
# with `setuptools >=48.0.0, <49.1`.
# Refs:
# * https://github.com/ansible/ansible/issues/70456
# * https://github.com/pypa/setuptools/issues/2230
# * https://github.com/pypa/setuptools/commit/bd110264
from distutils.command.build_scripts import build_scripts as BuildScripts
from distutils.command.sdist import sdist as SDist

"
-------------------------------------------------------------------------
"# `distutils` must be imported after `setuptools` or it will cause explosions
# with `setuptools >=48.0.0, <49.1`.
# Refs:
# * https://github.com/ansible/ansible/issues/70456
# * https://github.com/pypa/setuptools/issues/2230
# * https://github.com/pypa/setuptools/commit/bd110264
from distutils.command.build_scripts import build_scripts as BuildScripts
from distutils.command.sdist import sdist as SDist


def find_package_info(*file_paths):
try:
    with open(os.path.join(*file_paths), 'r') as f:
        info_file = f.read()
except Exception:
    raise RuntimeError(""Unable to find package info."")

# The version line must have the form
# __version__ = 'ver'
version_match = re.search(r""^__version__ = ['\""]([^'\""]*)['\""]"",
                          info_file, re.M)
author_match = re.search(r""^__author__ = ['\""]([^'\""]*)['\""]"",
                         info_file, re.M)

if version_match and author_match:
    return version_match.group(1), author_match.group(1)
raise RuntimeError(""Unable to find package info."")


_validate_install_ansible_base():
""""""Validate that we can install ansible-base. Currently this only
cares about upgrading to ansible-base from ansible<2.10
""""""
if os.getenv('ANSIBLE_SKIP_CONFLICT_CHECK', '') not in ('', '0'):
    return

# Save these for later restoring things to pre invocation
sys_modules = sys.modules.copy()
sys_modules_keys = set(sys_modules)

# Make sure `lib` isn't in `sys.path` that could confuse this
sys_path = sys.path[:]
abspath = os.path.abspath
sys.path[:] = [p for p in sys.path if abspath(p) != abspath('lib')]

try:
    from ansible.release import __version__
except ImportError:
    pass
else:
    version_tuple = tuple(int(v) for v in __version__.split('.')[:2])
    if version_tuple < (2, 10):
        stars = '*' * 76
        raise RuntimeError(
            '''

%s

Cannot install ansible-base with a pre-existing ansible==%s
installation.

Installing ansible-base with ansible-2.9 or older currently installed with
pip is known to cause problems. Please uninstall ansible and install the new
version:

    pip uninstall ansible
    pip install ansible-base

If you want to skip the conflict checks and manually resolve any issues
afterwards, set the ANSIBLE_SKIP_CONFLICT_CHECK environment variable:

    ANSIBLE_SKIP_CONFLICT_CHECK=1 pip install ansible-base

%s
            ''' % (stars, __version__, stars)
        )
finally:
    sys.path[:] = sys_path
    for key in sys_modules_keys.symmetric_difference(sys.modules):
        sys.modules.pop(key, None)
    sys.modules.update(sys_modules)


idate_install_ansible_base()
"
-------------------------------------------------------------------------
"# `distutils` must be imported after `setuptools` or it will cause explosions
# with `setuptools >=48.0.0, <49.1`.
# Refs:
# * https://github.com/ansible/ansible/issues/70456
# * https://github.com/pypa/setuptools/issues/2230
# * https://github.com/pypa/setuptools/commit/bd110264
from distutils.command.build_scripts import build_scripts as BuildScripts
from distutils.command.sdist import sdist as SDist


def find_package_info(*file_paths):
try:
    with open(os.path.join(*file_paths), 'r') as f:
        info_file = f.read()
except Exception:
    raise RuntimeError(""Unable to find package info."")

# The version line must have the form
# __version__ = 'ver'
version_match = re.search(r""^__version__ = ['\""]([^'\""]*)['\""]"",
                          info_file, re.M)
author_match = re.search(r""^__author__ = ['\""]([^'\""]*)['\""]"",
                         info_file, re.M)

if version_match and author_match:
    return version_match.group(1), author_match.group(1)
raise RuntimeError(""Unable to find package info."")


_validate_install_ansible_base():
""""""Validate that we can install ansible-base. Currently this only
cares about upgrading to ansible-base from ansible<2.10
""""""
if os.getenv('ANSIBLE_SKIP_CONFLICT_CHECK', '') not in ('', '0'):
    return

# Save these for later restoring things to pre invocation
sys_modules = sys.modules.copy()
sys_modules_keys = set(sys_modules)

# Make sure `lib` isn't in `sys.path` that could confuse this
sys_path = sys.path[:]
abspath = os.path.abspath
sys.path[:] = [p for p in sys.path if abspath(p) != abspath('lib')]

try:
    from ansible.release import __version__
except ImportError:
    pass
else:
    version_tuple = tuple(int(v) for v in __version__.split('.')[:2])
    if version_tuple < (2, 10):
        stars = '*' * 76
        raise RuntimeError(
            '''

%s

Cannot install ansible-base with a pre-existing ansible==%s
installation.

Installing ansible-base with ansible-2.9 or older currently installed with
pip is known to cause problems. Please uninstall ansible and install the new
version:

    pip uninstall ansible
    pip install ansible-base

If you want to skip the conflict checks and manually resolve any issues
afterwards, set the ANSIBLE_SKIP_CONFLICT_CHECK environment variable:

    ANSIBLE_SKIP_CONFLICT_CHECK=1 pip install ansible-base

%s
            ''' % (stars, __version__, stars)
        )
finally:
    sys.path[:] = sys_path
    for key in sys_modules_keys.symmetric_difference(sys.modules):
        sys.modules.pop(key, None)
    sys.modules.update(sys_modules)


idate_install_ansible_base()
"
-------------------------------------------------------------------------
"Recom
PRs: 70525, 70760"
-------------------------------------------------------------------------
=========================================================================
"# -*- coding: utf-8 -*-
# Copyright (c) 2019 Ansible Project
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)

from __future__ import absolute_import, division, print_function
__metaclass__ = type

import os
import pytest

from ansible.module_utils.facts.system.distribution import DistributionFiles


@pytest.fixture
def test_input():
return {
    'name': 'Clearlinux',
    'path': '/usr/lib/os-release',
    'collected_facts': None,
}


test_parse_distribution_file_clear_linux(mock_module, test_input):
test_input['data'] = open(os.path.join(os.path.dirname(__file__), '../../fixtures/distribution_files/ClearLinux')).read()

result = (
    True,
    {
        'distribution': 'Clear Linux OS',
        'distribution_major_version': '28120',
        'distribution_release': 'clear-linux-os',
        'distribution_version': '28120'
    }
)

distribution = DistributionFiles(module=mock_module())
assert result == distribution.parse_distribution_file_ClearLinux(**test_input)


est.mark.parametrize('distro_file', ('CoreOS', 'LinuxMint'))
test_parse_distribution_file_clear_linux_no_match(mock_module, distro_file, test_input):
""""""
Test against data from Linux Mint and CoreOS to ensure we do not get a reported
match from parse_distribution_file_ClearLinux()
""""""
test_input['data'] = open(os.path.join(os.path.dirname(__file__), '../../fixtures/distribution_files', distro_file)).read()

result = (False, {})

distribution = DistributionFiles(module=mock_module())
assert result == distribution.parse_distribution_file_ClearLinux(**test_input)
"
-------------------------------------------------------------------------
"import os
import pytest
@pytest.fixture
def test_input():
return {

test_parse_distribution_file_clear_linux(mock_module, test_input):
test_input['data'] = open(os.path.join(os.path.dirname(__file__), '../../fixtures/distribution_files/ClearLinux')).read()

"
-------------------------------------------------------------------------
"import os
import pytest
@pytest.fixture
def test_input():
return {

test_parse_distribution_file_clear_linux(mock_module, test_input):
test_input['data'] = open(os.path.join(os.path.dirname(__file__), '../../fixtures/distribution_files/ClearLinux')).read()

"
-------------------------------------------------------------------------
"Recom
PRs: 68142, 70718"
-------------------------------------------------------------------------
=========================================================================
"if 'stderr' in fail_mode:
    print('printed to stderr', file=sys.stderr)

"
-------------------------------------------------------------------------
"from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

"
-------------------------------------------------------------------------
"from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

"
-------------------------------------------------------------------------
"Recom
PRs: 70593, 70630"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils.common.text.converters import container_to_text, to_native
from ansible.module_utils.six import string_types, PY2
"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_native
from ansible.module_utils.common.text.converters import container_to_text
from ansible.module_utils.six import string_types, PY2
"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_native
from ansible.module_utils.common.text.converters import container_to_text
from ansible.module_utils.six import string_types, PY2
"
-------------------------------------------------------------------------
"Recom
PRs: 68576, 69626"
-------------------------------------------------------------------------
=========================================================================
"- The file name of the destination archive. The parent directory must exists on the remote host.
"
-------------------------------------------------------------------------
"try:
    if fmt == 'zip':
        arcfile.write(n_fullpath, n_arcname)
    else:
        arcfile.add(n_fullpath, n_arcname, recursive=False)

    b_successes.append(b_fullpath)
except Exception as e:
    errors.append('Adding %s: %s' % (to_native(b_path), to_native(e)))
"
-------------------------------------------------------------------------
"try:
    if fmt == 'zip':
        arcfile.write(n_fullpath, n_arcname)
    else:
        arcfile.add(n_fullpath, n_arcname, recursive=False)

    b_successes.append(b_fullpath)
except Exception as e:
    errors.append('Adding %s: %s' % (to_native(b_path), to_native(e)))
"
-------------------------------------------------------------------------
"Recom
PRs: 64895, 69420"
-------------------------------------------------------------------------
=========================================================================
"stdin_data = None
    if self.has_option_password_from_stdin():
        bits.append(""--password-from-stdin"")
        stdin_data = self.password
    else:
        self.module.warn(""The authentication provided will be used on the svn command line and is not secure. ""
                         ""To securely pass credentials, upgrade svn to version 1.10.0 or greater."")
        bits.extend([""--password"", self.password])
rc, out, err = self.module.run_command(bits, check_rc, data=stdin_data)
"
-------------------------------------------------------------------------
"stdin_data = None
    if self.has_option_password_from_stdin():
        bits.append(""--password-from-stdin"")
        stdin_data = self.password
    else:
        self.module.warn(""The authentication provided will be used on the svn command line and is not secure. ""
                         ""To securely pass credentials, upgrade svn to version 1.10.0 or greater."")
        bits.extend([""--password"", self.password])
rc, out, err = self.module.run_command(bits, check_rc, data=stdin_data)

"
-------------------------------------------------------------------------
"stdin_data = None
    if self.has_option_password_from_stdin():
        bits.append(""--password-from-stdin"")
        stdin_data = self.password
    else:
        self.module.warn(""The authentication provided will be used on the svn command line and is not secure. ""
                         ""To securely pass credentials, upgrade svn to version 1.10.0 or greater."")
        bits.extend([""--password"", self.password])
rc, out, err = self.module.run_command(bits, check_rc, data=stdin_data)

"
-------------------------------------------------------------------------
"Recom
PRs: 67829, 68913"
-------------------------------------------------------------------------
=========================================================================
"# Write config; make sure it has permissions 0x600
content = json.dumps(self._config, indent=4, sort_keys=True).encode('utf-8')
f = os.open(self._config_path, os.O_WRONLY | os.O_CREAT | os.O_TRUNC, 0o600)
try:
    os.write(f, content)
finally:
    os.close(f)
"
-------------------------------------------------------------------------
"# Write config; make sure it has permissions 0x600
content = json.dumps(config, indent=5, sort_keys=True).encode('utf-8')
f = os.open(path, os.O_WRONLY | os.O_CREAT | os.O_TRUNC, 0o600)
try:
    os.write(f, content)
finally:
    os.close(f)
"
-------------------------------------------------------------------------
"# Write config; make sure it has permissions 0x600
content = json.dumps(config, indent=5, sort_keys=True).encode('utf-8')
f = os.open(path, os.O_WRONLY | os.O_CREAT | os.O_TRUNC, 0o600)
try:
    os.write(f, content)
finally:
    os.close(f)
"
-------------------------------------------------------------------------
"Recom
PRs: 67353, 67441"
-------------------------------------------------------------------------
=========================================================================
"vlan_id=10,
name=""tenreplaced"",
 = ['vlan 10', 'name tenreplaced', 'state suspend']
"
-------------------------------------------------------------------------
"#
# (c) 2019, Ansible by Red Hat, inc
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
#

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

from units.compat.mock import patch
from ansible.modules.network.eos import eos_vlans
from units.modules.utils import set_module_args
from .eos_module import TestEosModule, load_fixture


class TestEosVlansModule(TestEosModule):
module = eos_vlans

def setUp(self):
    super(TestEosVlansModule, self).setUp()

    self.mock_get_config = patch('ansible.module_utils.network.common.network.Config.get_config')
    self.get_config = self.mock_get_config.start()

    self.mock_load_config = patch('ansible.module_utils.network.common.network.Config.load_config')
    self.load_config = self.mock_load_config.start()

    self.mock_get_resource_connection_config = patch('ansible.module_utils.network.common.cfg.base.get_resource_connection')
    self.get_resource_connection_config = self.mock_get_resource_connection_config.start()

    self.mock_get_resource_connection_facts = patch('ansible.module_utils.network.common.facts.facts.get_resource_connection')
    self.get_resource_connection_facts = self.mock_get_resource_connection_facts.start()

    self.mock_edit_config = patch('ansible.module_utils.network.eos.providers.providers.CliProvider.edit_config')
    self.edit_config = self.mock_edit_config.start()

    self.mock_execute_show_command = patch('ansible.module_utils.network.eos.config.vlans.vlans.Vlans.get_vlans_facts')
    self.execute_show_command = self.mock_execute_show_command.start()

def tearDown(self):
    super(TestEosVlansModule, self).tearDown()
    self.mock_get_resource_connection_config.stop()
    self.mock_get_resource_connection_facts.stop()
    self.mock_edit_config.stop()
    self.mock_get_config.stop()
    self.mock_load_config.stop()
    self.mock_execute_show_command.stop()

def load_fixtures(self, commands=None, transport='cli'):
    file_cmd = load_fixture('eos_vlan_config.cfg').split()
    file_cmd_dict = {}
    for i in range(0, len(file_cmd), 2):
        if file_cmd[i] == 'vlan_id':
            y = int(file_cmd[i  1])
        else:
            y = file_cmd[i  1]
        file_cmd_dict.update({file_cmd[i]: y})
    self.execute_show_command.return_value = [file_cmd_dict]

def test_eos_vlan_default(self):
    self.execute_show_command.return_value = []
    set_module_args(dict(
        config=[dict(
            vlan_id=30,
            name=""thirty""
        )]
    ))
    commands = ['vlan 30', 'name thirty']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_default_idempotent(self):
    self.execute_show_command.return_value = load_fixture('eos_vlan_config.cfg')
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten""
        )]
    ))
    self.execute_module(changed=False, commands=[])

def test_eos_vlan_merged(self):
    self.execute_show_command.return_value = []
    set_module_args(dict(
        config=[dict(
            vlan_id=30,
            name=""thirty""
        )], state=""merged""
    ))
    commands = ['vlan 30', 'name thirty']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_merged_idempotent(self):
    self.execute_show_command.return_value = load_fixture('eos_vlan_config.cfg')
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten""
        )], state=""merged""
    ))
    self.execute_module(changed=False, commands=[])

def test_eos_vlan_replaced(self):
    self.execute_show_command.return_value = []
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""tenreplaced"",
            state=""suspend""
        )], state=""replaced""
    ))
    commands = ['vlan 10', 'name tenreplaced', 'state suspend']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_replaced_idempotent(self):
    self.execute_show_command.return_value = load_fixture('eos_vlan_config.cfg')
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten""
        )], state=""replaced""
    ))
    self.execute_module(changed=False, commands=[])

def test_eos_vlan_overridden(self):
    self.execute_show_command.return_value = []
    set_module_args(dict(
        config=[dict(
            vlan_id=30,
            name=""thirty"",
            state=""suspend""
        )], state=""overridden""
    ))
    commands = ['no vlan 10', 'vlan 30', 'name thirty', 'state suspend']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_overridden_idempotent(self):
    self.execute_show_command.return_value = load_fixture('eos_vlan_config.cfg')
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten""
        )], state=""overridden""
    ))
    self.execute_module(changed=False, commands=[])

def test_eos_vlan_deleted(self):
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten"",
        )], state=""deleted""
    ))
    commands = ['no vlan 10']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_id_datatype(self):
    set_module_args(dict(
        config=[dict(
            vlan_id=""thirty""
        )]
    ))
    result = self.execute_module(failed=True)
    self.assertIn(""we were unable to convert to int"", result['msg'])

def test_eos_vlan_state_datatype(self):
    set_module_args(dict(
        config=[dict(
            vlan_id=30,
            state=10
        )]
    ))
    result = self.execute_module(failed=True)
    self.assertIn(""value of state must be one of: active, suspend"", result['msg'])
"
-------------------------------------------------------------------------
"#
# (c) 2019, Ansible by Red Hat, inc
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
#

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

from units.compat.mock import patch
from ansible.modules.network.eos import eos_vlans
from units.modules.utils import set_module_args
from .eos_module import TestEosModule, load_fixture


class TestEosVlansModule(TestEosModule):
module = eos_vlans

def setUp(self):
    super(TestEosVlansModule, self).setUp()

    self.mock_get_config = patch('ansible.module_utils.network.common.network.Config.get_config')
    self.get_config = self.mock_get_config.start()

    self.mock_load_config = patch('ansible.module_utils.network.common.network.Config.load_config')
    self.load_config = self.mock_load_config.start()

    self.mock_get_resource_connection_config = patch('ansible.module_utils.network.common.cfg.base.get_resource_connection')
    self.get_resource_connection_config = self.mock_get_resource_connection_config.start()

    self.mock_get_resource_connection_facts = patch('ansible.module_utils.network.common.facts.facts.get_resource_connection')
    self.get_resource_connection_facts = self.mock_get_resource_connection_facts.start()

    self.mock_edit_config = patch('ansible.module_utils.network.eos.providers.providers.CliProvider.edit_config')
    self.edit_config = self.mock_edit_config.start()

    self.mock_execute_show_command = patch('ansible.module_utils.network.eos.config.vlans.vlans.Vlans.get_vlans_facts')
    self.execute_show_command = self.mock_execute_show_command.start()

def tearDown(self):
    super(TestEosVlansModule, self).tearDown()
    self.mock_get_resource_connection_config.stop()
    self.mock_get_resource_connection_facts.stop()
    self.mock_edit_config.stop()
    self.mock_get_config.stop()
    self.mock_load_config.stop()
    self.mock_execute_show_command.stop()

def load_fixtures(self, commands=None, transport='cli'):
    file_cmd = load_fixture('eos_vlan_config.cfg').split()
    file_cmd_dict = {}
    for i in range(0, len(file_cmd), 2):
        if file_cmd[i] == 'vlan_id':
            y = int(file_cmd[i  1])
        else:
            y = file_cmd[i  1]
        file_cmd_dict.update({file_cmd[i]: y})
    self.execute_show_command.return_value = [file_cmd_dict]

def test_eos_vlan_default(self):
    self.execute_show_command.return_value = []
    set_module_args(dict(
        config=[dict(
            vlan_id=30,
            name=""thirty""
        )]
    ))
    commands = ['vlan 30', 'name thirty']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_default_idempotent(self):
    self.execute_show_command.return_value = load_fixture('eos_vlan_config.cfg')
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten""
        )]
    ))
    self.execute_module(changed=False, commands=[])

def test_eos_vlan_merged(self):
    self.execute_show_command.return_value = []
    set_module_args(dict(
        config=[dict(
            vlan_id=30,
            name=""thirty""
        )], state=""merged""
    ))
    commands = ['vlan 30', 'name thirty']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_merged_idempotent(self):
    self.execute_show_command.return_value = load_fixture('eos_vlan_config.cfg')
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten""
        )], state=""merged""
    ))
    self.execute_module(changed=False, commands=[])

def test_eos_vlan_replaced(self):
    self.execute_show_command.return_value = []
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""tenreplaced"",
            state=""suspend""
        )], state=""replaced""
    ))
    commands = ['vlan 10', 'name tenreplaced', 'state suspend']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_replaced_idempotent(self):
    self.execute_show_command.return_value = load_fixture('eos_vlan_config.cfg')
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten""
        )], state=""replaced""
    ))
    self.execute_module(changed=False, commands=[])

def test_eos_vlan_overridden(self):
    self.execute_show_command.return_value = []
    set_module_args(dict(
        config=[dict(
            vlan_id=30,
            name=""thirty"",
            state=""suspend""
        )], state=""overridden""
    ))
    commands = ['no vlan 10', 'vlan 30', 'name thirty', 'state suspend']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_overridden_idempotent(self):
    self.execute_show_command.return_value = load_fixture('eos_vlan_config.cfg')
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten""
        )], state=""overridden""
    ))
    self.execute_module(changed=False, commands=[])

def test_eos_vlan_deleted(self):
    set_module_args(dict(
        config=[dict(
            vlan_id=10,
            name=""ten"",
        )], state=""deleted""
    ))
    commands = ['no vlan 10']
    self.execute_module(changed=True, commands=commands)

def test_eos_vlan_id_datatype(self):
    set_module_args(dict(
        config=[dict(
            vlan_id=""thirty""
        )]
    ))
    result = self.execute_module(failed=True)
    self.assertIn(""we were unable to convert to int"", result['msg'])

def test_eos_vlan_state_datatype(self):
    set_module_args(dict(
        config=[dict(
            vlan_id=30,
            state=10
        )]
    ))
    result = self.execute_module(failed=True)
    self.assertIn(""value of state must be one of: active, suspend"", result['msg'])
"
-------------------------------------------------------------------------
"Recom
PRs: 67318, 67346"
-------------------------------------------------------------------------
=========================================================================
"def get_fingerprint(path, passphrase=None, content=None, backend='pyopenssl'):
privatekey = load_privatekey(path, passphrase=passphrase, content=content, check_passphrase=False, backend=backend)

if backend == 'pyopenssl':
        publickey = crypto.dump_publickey(crypto.FILETYPE_ASN1, privatekey)
        # If PyOpenSSL < 16.0 crypto.dump_publickey() will fail.
        try:
            bio = crypto._new_mem_buf()
            rc = crypto._lib.i2d_PUBKEY_bio(bio, privatekey._pkey)
            if rc != 1:
                crypto._raise_current_error()
            publickey = crypto._bio_to_string(bio)
        except AttributeError:
            # By doing this we prevent the code from raising an error
            # yet we return no value in the fingerprint hash.
            return None
elif backend == 'cryptography':
    publickey = privatekey.public_key().public_bytes(
        serialization.Encoding.DER,
        serialization.PublicFormat.SubjectPublicKeyInfo
    )

"
-------------------------------------------------------------------------
"def get_fingerprint(path, passphrase=None, backend='pyopenssl'):
privatekey = load_privatekey(path, passphrase, check_passphrase=False, backend=backend)

if backend == 'pyopenssl':
        publickey = crypto.dump_publickey(crypto.FILETYPE_ASN1, privatekey)
        # If PyOpenSSL < 16.0 crypto.dump_publickey() will fail.
        try:
            bio = crypto._new_mem_buf()
            rc = crypto._lib.i2d_PUBKEY_bio(bio, privatekey._pkey)
            if rc != 1:
                crypto._raise_current_error()
            publickey = crypto._bio_to_string(bio)
        except AttributeError:
            # By doing this we prevent the code from raising an error
            # yet we return no value in the fingerprint hash.
            return None
elif backend == 'cryptography':
    publickey = privatekey.public_key().public_bytes(
        serialization.Encoding.DER,
        serialization.PublicFormat.SubjectPublicKeyInfo
    )

"
-------------------------------------------------------------------------
"def get_fingerprint(path, passphrase=None, backend='pyopenssl'):
privatekey = load_privatekey(path, passphrase, check_passphrase=False, backend=backend)

if backend == 'pyopenssl':
        publickey = crypto.dump_publickey(crypto.FILETYPE_ASN1, privatekey)
        # If PyOpenSSL < 16.0 crypto.dump_publickey() will fail.
        try:
            bio = crypto._new_mem_buf()
            rc = crypto._lib.i2d_PUBKEY_bio(bio, privatekey._pkey)
            if rc != 1:
                crypto._raise_current_error()
            publickey = crypto._bio_to_string(bio)
        except AttributeError:
            # By doing this we prevent the code from raising an error
            # yet we return no value in the fingerprint hash.
            return None
elif backend == 'cryptography':
    publickey = privatekey.public_key().public_bytes(
        serialization.Encoding.DER,
        serialization.PublicFormat.SubjectPublicKeyInfo
    )

"
-------------------------------------------------------------------------
"Recom
PRs: 67036, 67039"
-------------------------------------------------------------------------
=========================================================================
"'CREATE ROLE', 'DROP ROLE', 'APPLICATION_PASSWORD_ADMIN',
'AUDIT_ADMIN', 'BACKUP_ADMIN', 'BINLOG_ADMIN',
'BINLOG_ENCRYPTION_ADMIN', 'CLONE_ADMIN', 'CONNECTION_ADMIN',
'ENCRYPTION_KEY_ADMIN', 'FIREWALL_ADMIN', 'FIREWALL_USER',
'GROUP_REPLICATION_ADMIN', 'INNODB_REDO_LOG_ARCHIVE',
'NDB_STORED_USER', 'PERSIST_RO_VARIABLES_ADMIN',
'REPLICATION_APPLIER', 'REPLICATION_SLAVE_ADMIN',
'RESOURCE_GROUP_ADMIN', 'RESOURCE_GROUP_USER',
'ROLE_ADMIN', 'SESSION_VARIABLES_ADMIN', 'SET_USER_ID',
'SYSTEM_USER', 'SYSTEM_VARIABLES_ADMIN', 'SYSTEM_USER',
'TABLE_ENCRYPTION_ADMIN', 'VERSION_TOKEN_ADMIN',
'XA_RECOVER_ADMIN', 'LOAD FROM S3', 'SELECT INTO S3'))
"
-------------------------------------------------------------------------
"'CREATE ROLE', 'DROP ROLE', 'APPLICATION_PASSWORD_ADMIN',
'AUDIT_ADMIN', 'BACKUP_ADMIN', 'BINLOG_ADMIN',
'BINLOG_ENCRYPTION_ADMIN', 'CONNECTION_ADMIN',
'ENCRYPTION_KEY_ADMIN', 'FIREWALL_ADMIN', 'FIREWALL_USER',
'GROUP_REPLICATION_ADMIN', 'PERSIST_RO_VARIABLES_ADMIN',
'REPLICATION_SLAVE_ADMIN', 'RESOURCE_GROUP_ADMIN', 'RESOURCE_GROUP_USER',
'ROLE_ADMIN', 'SESSION_VARIABLES_ADMIN', 'SET_USER_ID',
'SYSTEM_VARIABLES_ADMIN', 'VERSION_TOKEN_ADMIN', 'XA_RECOVER_ADMIN'))
"
-------------------------------------------------------------------------
"'CREATE ROLE', 'DROP ROLE', 'APPLICATION_PASSWORD_ADMIN',
'AUDIT_ADMIN', 'BACKUP_ADMIN', 'BINLOG_ADMIN',
'BINLOG_ENCRYPTION_ADMIN', 'CONNECTION_ADMIN',
'ENCRYPTION_KEY_ADMIN', 'FIREWALL_ADMIN', 'FIREWALL_USER',
'GROUP_REPLICATION_ADMIN', 'PERSIST_RO_VARIABLES_ADMIN',
'REPLICATION_SLAVE_ADMIN', 'RESOURCE_GROUP_ADMIN', 'RESOURCE_GROUP_USER',
'ROLE_ADMIN', 'SESSION_VARIABLES_ADMIN', 'SET_USER_ID',
'SYSTEM_VARIABLES_ADMIN', 'VERSION_TOKEN_ADMIN', 'XA_RECOVER_ADMIN'))
"
-------------------------------------------------------------------------
"Recom
PRs: 66995, 66999"
-------------------------------------------------------------------------
=========================================================================
"if not container.exists or container.removing:
    if container.removing:
        self.log('Found container in removal phase')
    else:
        self.log('No container found')
    if container.removing:
        # Wait for container to be removed before trying to create it
        self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"if not container.exists or container.removing:
    if container.removing:
        self.log('Found container in removal phase')
    else:
        self.log('No container found')
    if container.removing and not self.check_mode:
        # Wait for container to be removed before trying to create it
        self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"if not container.exists or container.removing:
    if container.removing:
        self.log('Found container in removal phase')
    else:
        self.log('No container found')
    if container.removing and not self.check_mode:
        # Wait for container to be removed before trying to create it
        self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"Recom
PRs: 65854, 66118"
-------------------------------------------------------------------------
=========================================================================
"self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"if not self.check_mode:
    self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"if not self.check_mode:
    self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"Recom
PRs: 65854, 66118"
-------------------------------------------------------------------------
=========================================================================
"if not container.exists or container.removing:
    if container.removing:
        self.log('Found container in removal phase')
    else:
        self.log('No container found')
    if container.removing:
        # Wait for container to be removed before trying to create it
        self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"if not container.exists or container.removing:
    if container.removing:
        self.log('Found container in removal phase')
    else:
        self.log('No container found')
    if container.removing and not self.check_mode:
        # Wait for container to be removed before trying to create it
        self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"if not container.exists or container.removing:
    if container.removing:
        self.log('Found container in removal phase')
    else:
        self.log('No container found')
    if container.removing and not self.check_mode:
        # Wait for container to be removed before trying to create it
        self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"Recom
PRs: 65854, 66117"
-------------------------------------------------------------------------
=========================================================================
"self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"if not self.check_mode:
    self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"if not self.check_mode:
    self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"Recom
PRs: 65854, 66117"
-------------------------------------------------------------------------
=========================================================================
"@property
    if self._yum_base:
        return self._yum_base
    else:
        # Only init once
        self._yum_base = yum.YumBase()
        self._yum_base.preconf.debuglevel = 0
        self._yum_base.preconf.errorlevel = 0
        self._yum_base.preconf.plugins = True
        self._yum_base.preconf.enabled_plugins = self.enable_plugin
        self._yum_base.preconf.disabled_plugins = self.disable_plugin
        if self.releasever:
            self._yum_base.preconf.releasever = self.releasever
        if self.installroot != '/':
            # do not setup installroot by default, because of error
            # CRITICAL:yum.cli:Config Error: Error accessing file for config file:////etc/yum.conf
            # in old yum version (like in CentOS 6.6)
            self._yum_base.preconf.root = self.installroot
            self._yum_base.conf.installroot = self.installroot
        if self.conf_file and os.path.exists(self.conf_file):
            self._yum_base.preconf.fn = self.conf_file
        if os.geteuid() != 0:
            if hasattr(self._yum_base, 'setCacheDir'):
                self._yum_base.setCacheDir()
            else:
                cachedir = yum.misc.getCacheDir()
                self._yum_base.repos.setCacheDir(cachedir)
                self._yum_base.conf.cache = 0
        if self.disable_excludes:
            self._yum_base.conf.disable_excludes = self.disable_excludes
        # A sideeffect of accessing conf is that the configuration is
        # loaded and plugins are discovered
        self.yum_base.conf

        try:
            self._enablerepos_with_error_checking(self._yum_base)

            for rid in self.disablerepo:
                self.yum_base.repos.disableRepo(rid)
        except Exception as e:
            self.module.fail_json(msg=""Failure talking to yum: %s"" % to_native(e))

    return self._yum_base
"
-------------------------------------------------------------------------
"self._yum_base = None
"
-------------------------------------------------------------------------
"self._yum_base = None
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"groups_list = self.yum_base.doGroupLists(return_evgrps=True)
groups_list = self.yum_base.doGroupLists()
"
-------------------------------------------------------------------------
"def _enablerepos_with_error_checking(self, yumbase):
    # NOTE: This seems unintuitive, but it mirrors yum's CLI bahavior
    if len(self.enablerepo) == 1:
        try:
            yumbase.repos.enableRepo(self.enablerepo[0])
        except yum.Errors.YumBaseError as e:
            if u'repository not found' in to_text(e):
                self.module.fail_json(msg=""Repository %s not found."" % self.enablerepo[0])
            else:
                raise e
    else:
        for rid in self.enablerepo:
            try:
                yumbase.repos.enableRepo(rid)
            except yum.Errors.YumBaseError as e:
                if u'repository not found' in to_text(e):
                    self.module.warn(""Repository %s not found."" % rid)
                else:
                    raise e

@property
    if self._yum_base:
        return self._yum_base
    else:
        # Only init once
        self._yum_base = yum.YumBase()
        self._yum_base.preconf.debuglevel = 0
        self._yum_base.preconf.errorlevel = 0
        self._yum_base.preconf.plugins = True
        self._yum_base.preconf.enabled_plugins = self.enable_plugin
        self._yum_base.preconf.disabled_plugins = self.disable_plugin
        if self.releasever:
            self._yum_base.preconf.releasever = self.releasever
        if self.installroot != '/':
            # do not setup installroot by default, because of error
            # CRITICAL:yum.cli:Config Error: Error accessing file for config file:////etc/yum.conf
            # in old yum version (like in CentOS 6.6)
            self._yum_base.preconf.root = self.installroot
            self._yum_base.conf.installroot = self.installroot
        if self.conf_file and os.path.exists(self.conf_file):
            self._yum_base.preconf.fn = self.conf_file
        if os.geteuid() != 0:
            if hasattr(self._yum_base, 'setCacheDir'):
                self._yum_base.setCacheDir()
            else:
                cachedir = yum.misc.getCacheDir()
                self._yum_base.repos.setCacheDir(cachedir)
                self._yum_base.conf.cache = 0
        if self.disable_excludes:
            self._yum_base.conf.disable_excludes = self.disable_excludes

        # A sideeffect of accessing conf is that the configuration is
        # loaded and plugins are discovered
        self.yum_base.conf
        try:
            self._enablerepos_with_error_checking(self._yum_base)

            for rid in self.disablerepo:
                self.yum_base.repos.disableRepo(rid)
        except Exception as e:
            self.module.fail_json(msg=""Failure talking to yum: %s"" % to_native(e))

    return self._yum_base
"
-------------------------------------------------------------------------
"def _enablerepos_with_error_checking(self, yumbase):
    # NOTE: This seems unintuitive, but it mirrors yum's CLI bahavior
    if len(self.enablerepo) == 1:
        try:
            yumbase.repos.enableRepo(self.enablerepo[0])
        except yum.Errors.YumBaseError as e:
            if u'repository not found' in to_text(e):
                self.module.fail_json(msg=""Repository %s not found."" % self.enablerepo[0])
            else:
                raise e
    else:
        for rid in self.enablerepo:
            try:
                yumbase.repos.enableRepo(rid)
            except yum.Errors.YumBaseError as e:
                if u'repository not found' in to_text(e):
                    self.module.warn(""Repository %s not found."" % rid)
                else:
                    raise e

@property
    if self._yum_base:
        return self._yum_base
    else:
        # Only init once
        self._yum_base = yum.YumBase()
        self._yum_base.preconf.debuglevel = 0
        self._yum_base.preconf.errorlevel = 0
        self._yum_base.preconf.plugins = True
        self._yum_base.preconf.enabled_plugins = self.enable_plugin
        self._yum_base.preconf.disabled_plugins = self.disable_plugin
        if self.releasever:
            self._yum_base.preconf.releasever = self.releasever
        if self.installroot != '/':
            # do not setup installroot by default, because of error
            # CRITICAL:yum.cli:Config Error: Error accessing file for config file:////etc/yum.conf
            # in old yum version (like in CentOS 6.6)
            self._yum_base.preconf.root = self.installroot
            self._yum_base.conf.installroot = self.installroot
        if self.conf_file and os.path.exists(self.conf_file):
            self._yum_base.preconf.fn = self.conf_file
        if os.geteuid() != 0:
            if hasattr(self._yum_base, 'setCacheDir'):
                self._yum_base.setCacheDir()
            else:
                cachedir = yum.misc.getCacheDir()
                self._yum_base.repos.setCacheDir(cachedir)
                self._yum_base.conf.cache = 0
        if self.disable_excludes:
            self._yum_base.conf.disable_excludes = self.disable_excludes

        # A sideeffect of accessing conf is that the configuration is
        # loaded and plugins are discovered
        self.yum_base.conf
        try:
            self._enablerepos_with_error_checking(self._yum_base)

            for rid in self.disablerepo:
                self.yum_base.repos.disableRepo(rid)
        except Exception as e:
            self.module.fail_json(msg=""Failure talking to yum: %s"" % to_native(e))

    return self._yum_base
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"e, m, _ = self.yum_base.rpmdb.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnInstalledPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"groups_list = self.yum_base.doGroupLists(return_evgrps=True)
groups_list = self.yum_base.doGroupLists()
"
-------------------------------------------------------------------------
"groups_list = self.yum_base.doGroupLists(return_evgrps=True)
groups_list = self.yum_base.doGroupLists()
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"e, m, _ = self.yum_base.rpmdb.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnInstalledPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"e, m, _ = self.yum_base.rpmdb.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnInstalledPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"pkgs = self.yum_base.returnPackagesByDep(pkgspec)  \
    self.yum_base.returnInstalledPackagesByDep(pkgspec)
    e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
updates = self.yum_base.doPackageLists(pkgnarrow='updates').updates
"
-------------------------------------------------------------------------
"e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"pkgs = self.yum_base.returnPackagesByDep(req_spec)  \
    self.yum_base.returnInstalledPackagesByDep(req_spec)
"
-------------------------------------------------------------------------
"pkgs = self.yum_base.returnPackagesByDep(pkgspec)  \
    self.yum_base.returnInstalledPackagesByDep(pkgspec)
    e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
updates = self.yum_base.doPackageLists(pkgnarrow='updates').updates
"
-------------------------------------------------------------------------
"pkgs = self.yum_base.returnPackagesByDep(pkgspec)  \
    self.yum_base.returnInstalledPackagesByDep(pkgspec)
    e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
updates = self.yum_base.doPackageLists(pkgnarrow='updates').updates
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"pkgs = self.yum_base.returnPackagesByDep(req_spec)  \
    self.yum_base.returnInstalledPackagesByDep(req_spec)
, _ = self.yum_base.pkgSack.matchPackageNames([req_spec])
, _ = self.yum_base.rpmdb.matchPackageNames([req_spec])
"
-------------------------------------------------------------------------
"pkgs = self.yum_base.returnPackagesByDep(req_spec)  \
    self.yum_base.returnInstalledPackagesByDep(req_spec)
"
-------------------------------------------------------------------------
"pkgs = self.yum_base.returnPackagesByDep(req_spec)  \
    self.yum_base.returnInstalledPackagesByDep(req_spec)
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"if self.yum_base.conf.proxy and self.yum_base.conf.proxy not in (""_none_"",):
    if self.yum_base.conf.proxy_username:
        namepass = namepass  self.yum_base.conf.proxy_username
        proxy_url = self.yum_base.conf.proxy
        if self.yum_base.conf.proxy_password:
            namepass = namepass  "":""  self.yum_base.conf.proxy_password
    elif '@' in self.yum_base.conf.proxy:
        namepass = self.yum_base.conf.proxy.split('@')[0].split('//')[-1]
        proxy_url = self.yum_base.conf.proxy.replace(""{0}@"".format(namepass), """")
"
-------------------------------------------------------------------------
"pkgs = self.yum_base.returnPackagesByDep(req_spec)  \
    self.yum_base.returnInstalledPackagesByDep(req_spec)
, _ = self.yum_base.pkgSack.matchPackageNames([req_spec])
, _ = self.yum_base.rpmdb.matchPackageNames([req_spec])
"
-------------------------------------------------------------------------
"pkgs = self.yum_base.returnPackagesByDep(req_spec)  \
    self.yum_base.returnInstalledPackagesByDep(req_spec)
, _ = self.yum_base.pkgSack.matchPackageNames([req_spec])
, _ = self.yum_base.rpmdb.matchPackageNames([req_spec])
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"os.environ[item  ""_proxy""] = self.yum_base.conf.proxy
"
-------------------------------------------------------------------------
"if self.yum_base.conf.proxy and self.yum_base.conf.proxy not in (""_none_"",):
    if self.yum_base.conf.proxy_username:
        namepass = namepass  self.yum_base.conf.proxy_username
        proxy_url = self.yum_base.conf.proxy
        if self.yum_base.conf.proxy_password:
            namepass = namepass  "":""  self.yum_base.conf.proxy_password
    elif '@' in self.yum_base.conf.proxy:
        namepass = self.yum_base.conf.proxy.split('@')[0].split('//')[-1]
        proxy_url = self.yum_base.conf.proxy.replace(""{0}@"".format(namepass), """")
"
-------------------------------------------------------------------------
"if self.yum_base.conf.proxy and self.yum_base.conf.proxy not in (""_none_"",):
    if self.yum_base.conf.proxy_username:
        namepass = namepass  self.yum_base.conf.proxy_username
        proxy_url = self.yum_base.conf.proxy
        if self.yum_base.conf.proxy_password:
            namepass = namepass  "":""  self.yum_base.conf.proxy_password
    elif '@' in self.yum_base.conf.proxy:
        namepass = self.yum_base.conf.proxy.split('@')[0].split('//')[-1]
        proxy_url = self.yum_base.conf.proxy.replace(""{0}@"".format(namepass), """")
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"self._yum_base = None  # previous YumBase package index is now invalid
"
-------------------------------------------------------------------------
"os.environ[item  ""_proxy""] = self.yum_base.conf.proxy
"
-------------------------------------------------------------------------
"os.environ[item  ""_proxy""] = self.yum_base.conf.proxy
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"try: self.yum_base.repos.disableRepo(disablerepo)
try: self.yum_base.repos.enableRepo(enablerepo)
"
-------------------------------------------------------------------------
"self._yum_base = None  # previous YumBase package index is now invalid
"
-------------------------------------------------------------------------
"self._yum_base = None  # previous YumBase package index is now invalid
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"current_repos = self.yum_base.repos.repos.keys()
        new_repos = self.yum_base.repos.repos.keys()
                rid = self.yum_base.repos.getRepo(i)
"
-------------------------------------------------------------------------
"try: self.yum_base.repos.disableRepo(disablerepo)
try: self.yum_base.repos.enableRepo(enablerepo)
"
-------------------------------------------------------------------------
"try: self.yum_base.repos.disableRepo(disablerepo)
try: self.yum_base.repos.enableRepo(enablerepo)
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"yum_plugins = self.yum_base.plugins._plugins
"
-------------------------------------------------------------------------
"current_repos = self.yum_base.repos.repos.keys()
        new_repos = self.yum_base.repos.repos.keys()
                rid = self.yum_base.repos.getRepo(i)
"
-------------------------------------------------------------------------
"current_repos = self.yum_base.repos.repos.keys()
        new_repos = self.yum_base.repos.repos.keys()
                rid = self.yum_base.repos.getRepo(i)
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"elif current_condition['Field'] == condition['Field'] and current_condition['Values'] == condition['Values']:
"
-------------------------------------------------------------------------
"elif current_condition['Field'] == condition['Field'] and sorted(current_condition['Values']) == sorted(condition['Values']):
"
-------------------------------------------------------------------------
"elif current_condition['Field'] == condition['Field'] and sorted(current_condition['Values']) == sorted(condition['Values']):
"
-------------------------------------------------------------------------
"Recom
PRs: 65021, 65212"
-------------------------------------------------------------------------
=========================================================================
"""WHERE indexrelname = %(name)s ""
""AND schemaname = %(schema)s"")
exec_sql(self, query, query_params={'name': self.name, 'schema': self.schema},
         add_to_executed=False)
"
-------------------------------------------------------------------------
"""WHERE i.indexname = %(name)s"")
c_sql(self, query, query_params={'name': self.name}, add_to_executed=False)
"
-------------------------------------------------------------------------
"""WHERE i.indexname = %(name)s"")
c_sql(self, query, query_params={'name': self.name}, add_to_executed=False)
"
-------------------------------------------------------------------------
"Recom
PRs: 64661, 65034"
-------------------------------------------------------------------------
=========================================================================
"feed_ca_cert:
      The ca_cert alias will be removed in Ansible 2.14.
  aliases: [ importer_ssl_ca_cert, ca_cert ]
feed_client_cert:
  version_added: ""2.10""
"
-------------------------------------------------------------------------
"feed_ca_cert:
      The ca_cert alias will be removed in Ansible 2.14.
  aliases: [ importer_ssl_ca_cert, ca_cert ]
feed_client_cert:
  version_added: ""2.9.2""
"
-------------------------------------------------------------------------
"feed_ca_cert:
      The ca_cert alias will be removed in Ansible 2.14.
  aliases: [ importer_ssl_ca_cert, ca_cert ]
feed_client_cert:
  version_added: ""2.9.2""
"
-------------------------------------------------------------------------
"Recom
PRs: 59522, 65014"
-------------------------------------------------------------------------
=========================================================================
"- If not specified the default value will come from client_cert. Which will
  change in Ansible 2.14.
_client_key:
rsion_added: ""2.10""
- If not specified the default value will come from client_key. Which will
  change in Ansible 2.14.
"
-------------------------------------------------------------------------
"- If not specified the default value will come from client_cert. Which will
  change in Ansible 2.14.
_client_key:
rsion_added: ""2.9.2""
- If not specified the default value will come from client_key. Which will
  change in Ansible 2.14.
"
-------------------------------------------------------------------------
"- If not specified the default value will come from client_cert. Which will
  change in Ansible 2.14.
_client_key:
rsion_added: ""2.9.2""
- If not specified the default value will come from client_key. Which will
  change in Ansible 2.14.
"
-------------------------------------------------------------------------
"Recom
PRs: 59522, 65014"
-------------------------------------------------------------------------
=========================================================================
"importer_ssl_ca_cert = module.params['feed_ca_cert']
importer_ssl_client_cert = module.params['feed_client_cert']
if importer_ssl_client_cert is None and module.params['client_cert'] is not None:
    importer_ssl_client_cert = module.params['client_cert']
    module.deprecate((""To specify client certificates to be used with the repo to sync, and not for communication with pulp.io, use the new options ""
                      ""`feed_client_cert` and `feed_client_key` (available since Ansible 2.10). Until Ansible 2.14, the default value for ""
                      ""`feed_client_cert` will be taken from `client_cert` if only the latter is specified""), version=""2.14"")
importer_ssl_client_key = module.params['feed_client_key']
if importer_ssl_client_key is None and module.params['client_key'] is not None:
    importer_ssl_client_key = module.params['client_key']
    module.deprecate(""In Ansible 2.10 `feed_client_key` option was added. Until 2.14 the default value will come from client_key option"", version=""2.14"")
"
-------------------------------------------------------------------------
"importer_ssl_ca_cert = module.params['feed_ca_cert']
importer_ssl_client_cert = module.params['feed_client_cert']
if importer_ssl_client_cert is None and module.params['client_cert'] is not None:
    importer_ssl_client_cert = module.params['client_cert']
    module.deprecate(""To specify client certificates to be used with the repo to sync, and not for communication with the ""
                     ""Pulp instance, use the new options `feed_client_cert` and `feed_client_key` (available since ""
                     ""Ansible 2.9.2). Until Ansible 2.14, the default value for `feed_client_cert` will be taken from ""
                     ""`client_cert` if only the latter is specified"", version=""2.14"")
importer_ssl_client_key = module.params['feed_client_key']
if importer_ssl_client_key is None and module.params['client_key'] is not None:
    importer_ssl_client_key = module.params['client_key']
    module.deprecate(""In Ansible 2.9.2 `feed_client_key` option was added. Until 2.14 the default value will come from client_key option"", version=""2.14"")
"
-------------------------------------------------------------------------
"importer_ssl_ca_cert = module.params['feed_ca_cert']
importer_ssl_client_cert = module.params['feed_client_cert']
if importer_ssl_client_cert is None and module.params['client_cert'] is not None:
    importer_ssl_client_cert = module.params['client_cert']
    module.deprecate(""To specify client certificates to be used with the repo to sync, and not for communication with the ""
                     ""Pulp instance, use the new options `feed_client_cert` and `feed_client_key` (available since ""
                     ""Ansible 2.9.2). Until Ansible 2.14, the default value for `feed_client_cert` will be taken from ""
                     ""`client_cert` if only the latter is specified"", version=""2.14"")
importer_ssl_client_key = module.params['feed_client_key']
if importer_ssl_client_key is None and module.params['client_key'] is not None:
    importer_ssl_client_key = module.params['client_key']
    module.deprecate(""In Ansible 2.9.2 `feed_client_key` option was added. Until 2.14 the default value will come from client_key option"", version=""2.14"")
"
-------------------------------------------------------------------------
"Recom
PRs: 59522, 65014"
-------------------------------------------------------------------------
=========================================================================
"
notes:
- Return values I(out) and I(err) have been deprecated and will be removed in Ansible 2.14. Use I(stdout) and I(stderr) instead.
"
-------------------------------------------------------------------------
"rc=rc,
out=out, err=err,
stdout=out, stderr=err)
"
-------------------------------------------------------------------------
"rc=rc,
out=out, err=err,
stdout=out, stderr=err)
"
-------------------------------------------------------------------------
"Recom
PRs: 63467, 64120"
-------------------------------------------------------------------------
=========================================================================
"rc=rc,
out=out, err=err,  # Deprecated
stdout=out, stderr=err)
"
-------------------------------------------------------------------------
"module.exit_json(
    changed=False,
    rc=rc,
    stdout=out,
    stderr=err)
    rc=rc,
    stdout=out,
    stderr=err,
"
-------------------------------------------------------------------------
"module.exit_json(
    changed=False,
    rc=rc,
    stdout=out,
    stderr=err)
    rc=rc,
    stdout=out,
    stderr=err,
"
-------------------------------------------------------------------------
"Recom
PRs: 63467, 64120"
-------------------------------------------------------------------------
=========================================================================
"module.exit_json(
    changed=False,
    rc=rc,
    stdout=out,
    stderr=err)
    rc=rc,
    stdout=out,
    stderr=err,
"
-------------------------------------------------------------------------
"out=out, err=err,
stdout=out, stderr=err)
changed=True,
msg=out, rc=rc,
err=err,
stdout=out, stderr=err)
"
-------------------------------------------------------------------------
"out=out, err=err,
stdout=out, stderr=err)
changed=True,
msg=out, rc=rc,
err=err,
stdout=out, stderr=err)
"
-------------------------------------------------------------------------
"Recom
PRs: 63467, 64120"
-------------------------------------------------------------------------
=========================================================================
"short_description: Gathers information for virtual machines running on Citrix Hypervisor/XenServer host or pool
"
-------------------------------------------------------------------------
"short_description: Gathers facts for virtual machines running on Citrix Hypervisor/XenServer host or pool
"
-------------------------------------------------------------------------
"short_description: Gathers facts for virtual machines running on Citrix Hypervisor/XenServer host or pool
"
-------------------------------------------------------------------------
"Recom
PRs: 63728, 63816"
-------------------------------------------------------------------------
=========================================================================
"if key == ""vlan_id"" or value is None:
"
-------------------------------------------------------------------------
"want = param_list_to_dict(want, ""vlan_id"", remove_key=False)
have = param_list_to_dict(have, ""vlan_id"", remove_key=False)
"
-------------------------------------------------------------------------
"want = param_list_to_dict(want, ""vlan_id"", remove_key=False)
have = param_list_to_dict(have, ""vlan_id"", remove_key=False)
"
-------------------------------------------------------------------------
"Recom
PRs: 63689, 63687"
-------------------------------------------------------------------------
=========================================================================
"- ""The only allowed value according to L(RFC 2986,https://tools.ietf.org/html/rfc2986#section-4.1)
   is 1.""
- This option will no longer accept unsupported values from Ansible 2.14 on.
"
-------------------------------------------------------------------------
"- ""The only allowed value according to L(RFC 2986,https://tools.ietf.org/html/rfc2986#section-4.1)
   is 1.""
"
-------------------------------------------------------------------------
"- ""The only allowed value according to L(RFC 2986,https://tools.ietf.org/html/rfc2986#section-4.1)
   is 1.""
"
-------------------------------------------------------------------------
"Recom
PRs: 63432, 63675"
-------------------------------------------------------------------------
=========================================================================
"- ""The only allowed value according to L(RFC 2986,https://tools.ietf.org/html/rfc2986#section-4.1)
   is 1.""
- This option will no longer accept unsupported values from Ansible 2.14 on.
"
-------------------------------------------------------------------------
"- ""The only allowed value according to L(RFC 2986,https://tools.ietf.org/html/rfc2986#section-4.1)
   is 1.""
"
-------------------------------------------------------------------------
"- ""The only allowed value according to L(RFC 2986,https://tools.ietf.org/html/rfc2986#section-4.1)
   is 1.""
"
-------------------------------------------------------------------------
"Recom
PRs: 63432, 63674"
-------------------------------------------------------------------------
=========================================================================
"- If not set, the value will be remain the same if container exists and will be inherited
  from the host machine if it is (re-)created.
Specification for mounts to be added to the container. More powerful alternative to I(volumes).
"
-------------------------------------------------------------------------
"- If not set, the value will be remain the same if container exists and will be inherited
  from the host machine if it is (re-)created.
"
-------------------------------------------------------------------------
"- If not set, the value will be remain the same if container exists and will be inherited
  from the host machine if it is (re-)created.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- bind
- npipe
- tmpfs
- volume
- Whether the mount should be read-only.
- The consistency requirement for the mount.
- cached
- consistent
- default
- delegated
- private
- rprivate
- shared
- rshared
- slave
- rslave
"
-------------------------------------------------------------------------
"- Connect the container to a network. Choices are C(bridge), C(host), C(none) or C(container:<name|id>).
- Set the user namespace mode for the container. Currently, the only valid value are C(host) and the empty string.
- To remove a container from one or more networks, use the I(purge_networks) option.
  network if I(networks) is specified. You need to explicitly use I(purge_networks) to enforce
  the removal of the default network (and all other networks not explicitly mentioned in I(networks)).
  Alternatively, use the I(networks_cli_compatible) option, which will be enabled by default from Ansible 2.12 on.
"
-------------------------------------------------------------------------
"- Connect the container to a network. Choices are C(bridge), C(host), C(none) or C(container:<name|id>).
- Set the user namespace mode for the container. Currently, the only valid value are C(host) and the empty string.
- To remove a container from one or more networks, use the I(purge_networks) option.
  network if I(networks) is specified. You need to explicitly use I(purge_networks) to enforce
  the removal of the default network (and all other networks not explicitly mentioned in I(networks)).
  Alternatively, use the I(networks_cli_compatible) option, which will be enabled by default from Ansible 2.12 on.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- Dictionary of options specific to the chosen volume_driver. See
  L(here,https://docs.docker.com/storage/volumes/#use-a-volume-driver) for details.
- ""The size for the tmpfs mount in bytes in format <number>[<unit>].""
   C(T) (tebibyte), or C(P) (pebibyte).""
"
-------------------------------------------------------------------------
"not attached. This module with I(networks: {name: other}) will create a container
C(docker run --network) and will *not* add the default network if I(networks) is
specified. If I(networks) is not specified, the default network will be attached.""
Note that docker CLI also sets I(network_mode) to the name of the first network
explicitly have to set I(network_mode) to the name of the first network you're
"
-------------------------------------------------------------------------
"not attached. This module with I(networks: {name: other}) will create a container
C(docker run --network) and will *not* add the default network if I(networks) is
specified. If I(networks) is not specified, the default network will be attached.""
Note that docker CLI also sets I(network_mode) to the name of the first network
explicitly have to set I(network_mode) to the name of the first network you're
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- Connect the container to a network. Choices are C(bridge), C(host), C(none) or C(container:<name|id>).
- Set the user namespace mode for the container. Currently, the only valid value are C(host) and the empty string.
- To remove a container from one or more networks, use the I(purge_networks) option.
  network if I(networks) is specified. You need to explicitly use I(purge_networks) to enforce
  the removal of the default network (and all other networks not explicitly mentioned in I(networks)).
  Alternatively, use the I(networks_cli_compatible) option, which will be enabled by default from Ansible 2.12 on.
"
-------------------------------------------------------------------------
"- If set to true, output of the container command will be printed.
- Only effective when I(log_driver) is set to C(json-file) or C(journald).
"
-------------------------------------------------------------------------
"- If set to true, output of the container command will be printed.
- Only effective when I(log_driver) is set to C(json-file) or C(journald).
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"not attached. This module with I(networks: {name: other}) will create a container
C(docker run --network) and will *not* add the default network if I(networks) is
specified. If I(networks) is not specified, the default network will be attached.""
Note that docker CLI also sets I(network_mode) to the name of the first network
explicitly have to set I(network_mode) to the name of the first network you're
"
-------------------------------------------------------------------------
"- Note that Docker SDK for Python < 2.0 only supports C(host). Newer versions of the
  Docker SDK for Python (docker) allow all values supported by the Docker daemon.
- Set C(-1) for unlimited PIDs.
"
-------------------------------------------------------------------------
"- Note that Docker SDK for Python < 2.0 only supports C(host). Newer versions of the
  Docker SDK for Python (docker) allow all values supported by the Docker daemon.
- Set C(-1) for unlimited PIDs.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- If set to true, output of the container command will be printed.
- Only effective when I(log_driver) is set to C(json-file) or C(journald).
"
-------------------------------------------------------------------------
"- ""Bind addresses must be either IPv4 or IPv6 addresses. Hostnames are *not* allowed. This
- If I(networks) parameter is provided, will inspect each network to see if there exists
  a bridge network with optional parameter C(com.docker.network.bridge.host_binding_ipv4).
  will be bound to the host IP pointed to by C(com.docker.network.bridge.host_binding_ipv4).
  Note that the first bridge network with a C(com.docker.network.bridge.host_binding_ipv4)
  value encountered in the list of I(networks) is the one that will be used.
"
-------------------------------------------------------------------------
"- ""Bind addresses must be either IPv4 or IPv6 addresses. Hostnames are *not* allowed. This
- If I(networks) parameter is provided, will inspect each network to see if there exists
  a bridge network with optional parameter C(com.docker.network.bridge.host_binding_ipv4).
  will be bound to the host IP pointed to by C(com.docker.network.bridge.host_binding_ipv4).
  Note that the first bridge network with a C(com.docker.network.bridge.host_binding_ipv4)
  value encountered in the list of I(networks) is the one that will be used.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- Note that Docker SDK for Python < 2.0 only supports C(host). Newer versions of the
  Docker SDK for Python (docker) allow all values supported by the Docker daemon.
- Set C(-1) for unlimited PIDs.
"
-------------------------------------------------------------------------
"- ""*Note:* images are only pulled when specified by name. If the image is specified
  as a image ID (hash), it cannot be pulled.""
- Remove the container from ALL networks not included in I(networks) parameter.
- Any default networks such as C(bridge), if not found in I(networks), will be removed as well.
"
-------------------------------------------------------------------------
"- ""*Note:* images are only pulled when specified by name. If the image is specified
  as a image ID (hash), it cannot be pulled.""
- Remove the container from ALL networks not included in I(networks) parameter.
- Any default networks such as C(bridge), if not found in I(networks), will be removed as well.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- ""Bind addresses must be either IPv4 or IPv6 addresses. Hostnames are *not* allowed. This
- If I(networks) parameter is provided, will inspect each network to see if there exists
  a bridge network with optional parameter C(com.docker.network.bridge.host_binding_ipv4).
  will be bound to the host IP pointed to by C(com.docker.network.bridge.host_binding_ipv4).
  Note that the first bridge network with a C(com.docker.network.bridge.host_binding_ipv4)
  value encountered in the list of I(networks) is the one that will be used.
"
-------------------------------------------------------------------------
"- Container restart policy.
- Place quotes around C(no) option.
"
-------------------------------------------------------------------------
"- Container restart policy.
- Place quotes around C(no) option.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- ""*Note:* images are only pulled when specified by name. If the image is specified
  as a image ID (hash), it cannot be pulled.""
- Remove the container from ALL networks not included in I(networks) parameter.
- Any default networks such as C(bridge), if not found in I(networks), will be removed as well.
"
-------------------------------------------------------------------------
"- ""Size of C(/dev/shm) in format C(<number>[<unit>]). Number is positive integer.
- Omitting the unit defaults to bytes. If you omit the size entirely, Docker daemon uses C(64M).
- List of security options in the form of C(""label:user:User"").
- 'C(absent) - A container matching the specified name will be stopped and removed. Use I(force_kill) to kill the container
   rather than stopping it. Use I(keep_volumes) to retain volumes associated with the removed container.'
- 'C(present) - Asserts the existence of a container matching the name and any provided configuration parameters. If no
  with the requested config.'
- 'C(started) - Asserts that the container is first C(present), and then if the container is not running moves it to a running
  state. Use I(restart) to force a matching container to be stopped and restarted.'
- 'C(stopped) - Asserts that the container is first C(present), and then if the container is running moves it to a stopped
  state.'
- To control what will be taken into account when comparing configuration, see the I(comparisons) option. To avoid that the
  image version will be taken into account, you can also use the I(ignore_image) option.
- Use the I(recreate) option to always force re-creation of a matching container, even if it is running.
- If the container should be killed instead of stopped in case it needs to be stopped for recreation, or because I(state) is
  C(stopped), please use the I(force_kill) option. Use I(keep_volumes) to retain volumes associated with a removed container.
- Use I(keep_volumes) to retain volumes associated with a removed container.
"
-------------------------------------------------------------------------
"- ""Size of C(/dev/shm) in format C(<number>[<unit>]). Number is positive integer.
- Omitting the unit defaults to bytes. If you omit the size entirely, Docker daemon uses C(64M).
- List of security options in the form of C(""label:user:User"").
- 'C(absent) - A container matching the specified name will be stopped and removed. Use I(force_kill) to kill the container
   rather than stopping it. Use I(keep_volumes) to retain volumes associated with the removed container.'
- 'C(present) - Asserts the existence of a container matching the name and any provided configuration parameters. If no
  with the requested config.'
- 'C(started) - Asserts that the container is first C(present), and then if the container is not running moves it to a running
  state. Use I(restart) to force a matching container to be stopped and restarted.'
- 'C(stopped) - Asserts that the container is first C(present), and then if the container is running moves it to a stopped
  state.'
- To control what will be taken into account when comparing configuration, see the I(comparisons) option. To avoid that the
  image version will be taken into account, you can also use the I(ignore_image) option.
- Use the I(recreate) option to always force re-creation of a matching container, even if it is running.
- If the container should be killed instead of stopped in case it needs to be stopped for recreation, or because I(state) is
  C(stopped), please use the I(force_kill) option. Use I(keep_volumes) to retain volumes associated with a removed container.
- Use I(keep_volumes) to retain volumes associated with a removed container.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- Container restart policy.
- Place quotes around C(no) option.
"
-------------------------------------------------------------------------
"- Number of seconds to wait for the container to stop before sending C(SIGKILL).
"
-------------------------------------------------------------------------
"- Number of seconds to wait for the container to stop before sending C(SIGKILL).
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- ""Size of C(/dev/shm) in format C(<number>[<unit>]). Number is positive integer.
- Omitting the unit defaults to bytes. If you omit the size entirely, Docker daemon uses C(64M).
- List of security options in the form of C(""label:user:User"").
- 'C(absent) - A container matching the specified name will be stopped and removed. Use I(force_kill) to kill the container
   rather than stopping it. Use I(keep_volumes) to retain volumes associated with the removed container.'
- 'C(present) - Asserts the existence of a container matching the name and any provided configuration parameters. If no
  with the requested config.'
- 'C(started) - Asserts that the container is first C(present), and then if the container is not running moves it to a running
  state. Use I(restart) to force a matching container to be stopped and restarted.'
- 'C(stopped) - Asserts that the container is first C(present), and then if the container is running moves it to a stopped
  state.'
- To control what will be taken into account when comparing configuration, see the I(comparisons) option. To avoid that the
  image version will be taken into account, you can also use the I(ignore_image) option.
- Use the I(recreate) option to always force re-creation of a matching container, even if it is running.
- If the container should be killed instead of stopped in case it needs to be stopped for recreation, or because I(state) is
  C(stopped), please use the I(force_kill) option. Use I(keep_volumes) to retain volumes associated with a removed container.
- Use I(keep_volumes) to retain volumes associated with a removed container.
"
-------------------------------------------------------------------------
"- Mount a tmpfs directory.
"
-------------------------------------------------------------------------
"- Mount a tmpfs directory.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- Number of seconds to wait for the container to stop before sending C(SIGKILL).
"
-------------------------------------------------------------------------
"- ""List of ulimit options. A ulimit is specified as C(nofile:262144:262144).""
"
-------------------------------------------------------------------------
"- ""List of ulimit options. A ulimit is specified as C(nofile:262144:262144).""
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- Mount a tmpfs directory.
"
-------------------------------------------------------------------------
"- ""Can be of the forms C(user), C(user:group), C(uid), C(uid:gid), C(user:gid) or C(uid:group).""
"
-------------------------------------------------------------------------
"- ""Can be of the forms C(user), C(user:group), C(uid), C(uid:gid), C(user:gid) or C(uid:group).""
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- ""List of ulimit options. A ulimit is specified as C(nofile:262144:262144).""
"
-------------------------------------------------------------------------
"- SELinux hosts can additionally use C(z) or C(Z) to use a shared or private label for the volume.
"
-------------------------------------------------------------------------
"- SELinux hosts can additionally use C(z) or C(Z) to use a shared or private label for the volume.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- ""Can be of the forms C(user), C(user:group), C(uid), C(uid:gid), C(user:gid) or C(uid:group).""
"
-------------------------------------------------------------------------
"- List of container names or IDs to get volumes from.
"
-------------------------------------------------------------------------
"- List of container names or IDs to get volumes from.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- SELinux hosts can additionally use C(z) or C(Z) to use a shared or private label for the volume.
"
-------------------------------------------------------------------------
"- Empty if I(state) is C(absent)
- If I(detached) is C(false), will include C(Output) attribute containing any output from container run.
"
-------------------------------------------------------------------------
"- Empty if I(state) is C(absent)
- If I(detached) is C(false), will include C(Output) attribute containing any output from container run.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- When passed dictionaries valid sub-options are I(name), which is required, and
  I(aliases) and I(options).
"
-------------------------------------------------------------------------
"- ""Service memory reservation in format C(<number>[<unit>]). Number is a positive integer.
"
-------------------------------------------------------------------------
"- ""Service memory reservation in format C(<number>[<unit>]). Number is a positive integer.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"- ""Service memory reservation in format C(<number>[<unit>]). Number is a positive integer.
"
-------------------------------------------------------------------------
"- C(absent) - A service matching the specified name will be removed and have its tasks stopped.
- C(present) - Asserts the existence of a service matching the name and provided configuration parameters.
"
-------------------------------------------------------------------------
"- C(absent) - A service matching the specified name will be removed and have its tasks stopped.
- C(present) - Asserts the existence of a service matching the name and provided configuration parameters.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"n_url = self.api_server
if self.api_server == 'https://galaxy.ansible.com' or self.api_server == 'https://galaxy.ansible.com/':
    n_url = 'https://galaxy.ansible.com/api/'

try:
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
except (AnsibleError, GalaxyError, ValueError, KeyError):
    # Either the URL doesnt exist, or other error. Or the URL exists, but isn't a galaxy API
    # root (not JSON, no 'available_versions') so try appending '/api/'
    n_url = _urljoin(n_url, '/api/')

    # let exceptions here bubble up
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
    if 'available_versions' not in data:
        raise AnsibleError(""Tried to find galaxy API root at %s but no 'available_versions' are available on %s""
                           % (n_url, self.api_server))
available_versions = data.get('available_versions', {u'v1': u'v1/'})
    available_versions[u'v2'] = u'v2/'
"
-------------------------------------------------------------------------
"n_url = self.api_server
if self.api_server == 'https://galaxy.ansible.com' or self.api_server == 'https://galaxy.ansible.com/':
    n_url = 'https://galaxy.ansible.com/api/'

try:
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
except (AnsibleError, GalaxyError, ValueError, KeyError):
    # Either the URL doesnt exist, or other error. Or the URL exists, but isn't a galaxy API
    # root (not JSON, no 'available_versions') so try appending '/api/'
    n_url = _urljoin(n_url, '/api/')

    # let exceptions here bubble up
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
    if 'available_versions' not in data:
        raise AnsibleError(""Tried to find galaxy API root at %s but no 'available_versions' are available on %s""
                           % (n_url, self.api_server))

    # Update api_server to point to the ""real"" API root, which in this case
    # was the configured url  '/api/' appended.
    self.api_server = n_url
available_versions = data.get('available_versions', {u'v1': u'v1/'})
    available_versions[u'v2'] = u'v2/'
"
-------------------------------------------------------------------------
"n_url = self.api_server
if self.api_server == 'https://galaxy.ansible.com' or self.api_server == 'https://galaxy.ansible.com/':
    n_url = 'https://galaxy.ansible.com/api/'

try:
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
except (AnsibleError, GalaxyError, ValueError, KeyError):
    # Either the URL doesnt exist, or other error. Or the URL exists, but isn't a galaxy API
    # root (not JSON, no 'available_versions') so try appending '/api/'
    n_url = _urljoin(n_url, '/api/')

    # let exceptions here bubble up
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
    if 'available_versions' not in data:
        raise AnsibleError(""Tried to find galaxy API root at %s but no 'available_versions' are available on %s""
                           % (n_url, self.api_server))

    # Update api_server to point to the ""real"" API root, which in this case
    # was the configured url  '/api/' appended.
    self.api_server = n_url
available_versions = data.get('available_versions', {u'v1': u'v1/'})
    available_versions[u'v2'] = u'v2/'
"
-------------------------------------------------------------------------
"Recom
PRs: 63238, 63293"
-------------------------------------------------------------------------
=========================================================================
"cron_cmd = self.module.get_bin_path('crontab', required=True)
        return ""su %s -c '%s -l'"" % (shlex_quote(self.user), shlex_quote(cron_cmd))
        return ""%s -l %s"" % (shlex_quote(cron_cmd), shlex_quote(self.user))
        return ""%s %s %s"" % (cron_cmd, '-l', shlex_quote(self.user))
return ""%s %s %s"" % (cron_cmd, user, '-l')
cron_cmd = self.module.get_bin_path('crontab', required=True)
        return ""chown %s %s ; su '%s' -c '%s %s'"" % (shlex_quote(self.user), shlex_quote(path), shlex_quote(self.user), cron_cmd, shlex_quote(path))
return ""%s %s %s"" % (cron_cmd, user, shlex_quote(path))
"
-------------------------------------------------------------------------
"self.cron_cmd = self.module.get_bin_path('crontab', required=True)
"
-------------------------------------------------------------------------
"self.cron_cmd = self.module.get_bin_path('crontab', required=True)
"
-------------------------------------------------------------------------
"Recom
PRs: 59765, 62546"
-------------------------------------------------------------------------
=========================================================================
"cron_cmd = self.module.get_bin_path('crontab', required=True)
        return ""su %s -c '%s -l'"" % (shlex_quote(self.user), shlex_quote(cron_cmd))
        return ""%s -l %s"" % (shlex_quote(cron_cmd), shlex_quote(self.user))
        return ""%s %s %s"" % (cron_cmd, '-l', shlex_quote(self.user))
return ""%s %s %s"" % (cron_cmd, user, '-l')
cron_cmd = self.module.get_bin_path('crontab', required=True)
        return ""chown %s %s ; su '%s' -c '%s %s'"" % (shlex_quote(self.user), shlex_quote(path), shlex_quote(self.user), cron_cmd, shlex_quote(path))
return ""%s %s %s"" % (cron_cmd, user, shlex_quote(path))
"
-------------------------------------------------------------------------
"self.cron_cmd = self.module.get_bin_path('cronvar', required=True)
"
-------------------------------------------------------------------------
"self.cron_cmd = self.module.get_bin_path('cronvar', required=True)
"
-------------------------------------------------------------------------
"Recom
PRs: 59765, 62546"
-------------------------------------------------------------------------
=========================================================================
"- Prompt user for inventory on launch.
"
-------------------------------------------------------------------------
"description: My very first Workflow Template
"
-------------------------------------------------------------------------
"description: My very first Workflow Template
"
-------------------------------------------------------------------------
"Recom
PRs: 62202, 62257"
-------------------------------------------------------------------------
=========================================================================
"# This is a helper class to sort the changes in a valid order
# ""Greater than"" means a change has to happen after another one.
# As an example, let's say self is daily (key == 1) and other is weekly (key == 2)
class ChangeHelper:
def __init__(self, old, new):
    self.key = new.key
    self.old = old
    self.new = new

def __gt__(self, other):
    if self.key < other.key:
        # You cannot disable daily if weekly is enabled, so later
        if self.new.enabled < other.old.enabled:
            return True
        # Enabling daily is OK if weekly is disabled
        elif self.new.enabled > other.old.enabled:
            return False
        # Otherwise, decreasing the daily level below the current weekly level has to be done later
        else:
            return self.new.level < other.old.level
    else:
        return not (self.old > self.new)


"
-------------------------------------------------------------------------
"# This is a helper class to sort the changes in a valid order
# ""Greater than"" means a change has to happen after another one.
# As an example, let's say self is daily (key == 1) and other is weekly (key == 2)
class ChangeHelper:
def __init__(self, old, new):
    self.key = new.key
    self.old = old
    self.new = new

def __eq__(self, other):
    return ((self.key, self.new.enabled, self.new.level) ==
            (other.key, other.new.enabled, other.new.level))

def __gt__(self, other):
    if self.key < other.key:
        # You cannot disable daily if weekly is enabled, so later
        if self.new.enabled < other.old.enabled:
            return True
        # Enabling daily is OK if weekly is disabled
        elif self.new.enabled > other.old.enabled:
            return False
        # Otherwise, decreasing the daily level below the current weekly level has to be done later
        else:
            return self.new.level < other.old.level
    else:
        return not (other > self)

def __ge__(self, other):
    return (self > other) or (self == other)

def __lt__(self, other):
    return not (self >= other)

def __le__(self, other):
    return not (self > other)


"
-------------------------------------------------------------------------
"# This is a helper class to sort the changes in a valid order
# ""Greater than"" means a change has to happen after another one.
# As an example, let's say self is daily (key == 1) and other is weekly (key == 2)
class ChangeHelper:
def __init__(self, old, new):
    self.key = new.key
    self.old = old
    self.new = new

def __eq__(self, other):
    return ((self.key, self.new.enabled, self.new.level) ==
            (other.key, other.new.enabled, other.new.level))

def __gt__(self, other):
    if self.key < other.key:
        # You cannot disable daily if weekly is enabled, so later
        if self.new.enabled < other.old.enabled:
            return True
        # Enabling daily is OK if weekly is disabled
        elif self.new.enabled > other.old.enabled:
            return False
        # Otherwise, decreasing the daily level below the current weekly level has to be done later
        else:
            return self.new.level < other.old.level
    else:
        return not (other > self)

def __ge__(self, other):
    return (self > other) or (self == other)

def __lt__(self, other):
    return not (self >= other)

def __le__(self, other):
    return not (self > other)


"
-------------------------------------------------------------------------
"Recom
PRs: 61345, 62088"
-------------------------------------------------------------------------
=========================================================================
"- To create a disabled account on OpenBSD, set this to C('*************').
"
-------------------------------------------------------------------------
"- To create a disabled account on OpenBSD, set this to C('*************').
- See U(https://docs.ansible.com/ansible/faq.html#how-do-i-generate-encrypted-passwords-for-the-user-module)
"
-------------------------------------------------------------------------
"- To create a disabled account on OpenBSD, set this to C('*************').
- See U(https://docs.ansible.com/ansible/faq.html#how-do-i-generate-encrypted-passwords-for-the-user-module)
"
-------------------------------------------------------------------------
"Recom
PRs: 54893, 61791"
-------------------------------------------------------------------------
=========================================================================
"if module.params.get('permission') and not module.params.get('ignore_nonexistent_bucket'):
    # Wait for the bucket to exist before setting ACLs
    s3.get_waiter('bucket_exists').wait(Bucket=bucket)
"
-------------------------------------------------------------------------
"if module.params.get('permission'):
"
-------------------------------------------------------------------------
"if module.params.get('permission'):
"
-------------------------------------------------------------------------
"Recom
PRs: 61735, 61769"
-------------------------------------------------------------------------
=========================================================================
"if module.params.get('permission') and not module.params.get('ignore_nonexistent_bucket'):
    # Wait for the bucket to exist before setting ACLs
    s3.get_waiter('bucket_exists').wait(Bucket=bucket)
"
-------------------------------------------------------------------------
"if module.params.get('permission'):
    # Wait for the bucket to exist before setting ACLs
    s3.get_waiter('bucket_exists').wait(Bucket=bucket)
"
-------------------------------------------------------------------------
"if module.params.get('permission'):
    # Wait for the bucket to exist before setting ACLs
    s3.get_waiter('bucket_exists').wait(Bucket=bucket)
"
-------------------------------------------------------------------------
"Recom
PRs: 61735, 61768"
-------------------------------------------------------------------------
=========================================================================
"if self._cache is not None:
"
-------------------------------------------------------------------------
"if self._cache is not None:
# Store the cache to avoid running pkg_cache() for each item in the comprehension, which is very slow
cache = self.pkg_cache
return [pk for pk in cache.keys() if cache[pk].is_installed]
"
-------------------------------------------------------------------------
"if self._cache is not None:
# Store the cache to avoid running pkg_cache() for each item in the comprehension, which is very slow
cache = self.pkg_cache
return [pk for pk in cache.keys() if cache[pk].is_installed]
"
-------------------------------------------------------------------------
"Recom
PRs: 60511, 60574"
-------------------------------------------------------------------------
=========================================================================
"template_cluster:
    description:
        - ""Template cluster name. When not defined C(cluster) is used.""
        - ""Allows you to create virtual machine in diffrent cluster than template cluster name.""
    version_added: ""2.9""
"
-------------------------------------------------------------------------
"clusters_service = self._connection.system_service().clusters_service()
cluster = search_by_name(clusters_service, self.param('cluster'))
data_center = self._connection.follow_link(cluster.data_center)
    search='name=%s and datacenter=%s' % (self.param('template'), data_center.name)
"
-------------------------------------------------------------------------
"clusters_service = self._connection.system_service().clusters_service()
cluster = search_by_name(clusters_service, self.param('cluster'))
data_center = self._connection.follow_link(cluster.data_center)
    search='name=%s and datacenter=%s' % (self.param('template'), data_center.name)
"
-------------------------------------------------------------------------
"Recom
PRs: 59378, 60478"
-------------------------------------------------------------------------
=========================================================================
"cluster = self.param('template_cluster') if self.param('template_cluster') else self.param('cluster')
    search='name=%s and cluster=%s' % (self.param('template'), cluster)
if not templates:
    templates = templates_service.list(
        search='name=%s' % self.param('template')
    )
"
-------------------------------------------------------------------------
"""Template with name '%s' and version '%s' in data center '%s' was not found'"" % (
    data_center.name
"
-------------------------------------------------------------------------
"""Template with name '%s' and version '%s' in data center '%s' was not found'"" % (
    data_center.name
"
-------------------------------------------------------------------------
"Recom
PRs: 59378, 60478"
-------------------------------------------------------------------------
=========================================================================
"- ""Port mirroring, QoS and network filters are not supported on passthrough profiles.""
"
-------------------------------------------------------------------------
"- ""When enabled and C(migratable) not specified then C(migratable) is enabled.""
- ""Port mirroring, QoS and network filters are not supported on passthrough profiles.""
"
-------------------------------------------------------------------------
"- ""When enabled and C(migratable) not specified then C(migratable) is enabled.""
- ""Port mirroring, QoS and network filters are not supported on passthrough profiles.""
"
-------------------------------------------------------------------------
"Recom
PRs: 59727, 60198"
-------------------------------------------------------------------------
=========================================================================
"pass_through = getattr(entity.pass_through.mode, 'name', None)
    self._get_network_filter_id() == getattr(entity.network_filter, 'id', None) and
    self._get_qos_id() == getattr(entity.qos, 'id', None) and
    equal(self.param('pass_through'), pass_through.lower() if pass_through else None) and
"
-------------------------------------------------------------------------
"pass_through = getattr(entity.pass_through.mode, 'name', None)
    # The reason why we can't use equal method, is we get None from _get_network_filter_id or _get_qos_id method, when passing empty string.
    # And when first param of equal method is None it retruns true.
    self._get_network_filter_id() == getattr(entity.network_filter, 'id', None) and
    self._get_qos_id() == getattr(entity.qos, 'id', None) and
    equal(self.param('pass_through'), pass_through.lower() if pass_through else None) and
"
-------------------------------------------------------------------------
"pass_through = getattr(entity.pass_through.mode, 'name', None)
    # The reason why we can't use equal method, is we get None from _get_network_filter_id or _get_qos_id method, when passing empty string.
    # And when first param of equal method is None it retruns true.
    self._get_network_filter_id() == getattr(entity.network_filter, 'id', None) and
    self._get_qos_id() == getattr(entity.qos, 'id', None) and
    equal(self.param('pass_through'), pass_through.lower() if pass_through else None) and
"
-------------------------------------------------------------------------
"Recom
PRs: 59727, 60198"
-------------------------------------------------------------------------
=========================================================================
"if module.params['api']:
        user_token['user_api'] = array.create_api_token(module.params['name'])['api_token']
"
-------------------------------------------------------------------------
"if module.params['api']:
        user_token['user_api'] = array.create_api_token(module.params['name'])['api_token']
        # Added for 2.8.2: Not breaking user's playbooks in minor releases.
        user_token['api_token'] = user_token['user_api']
"
-------------------------------------------------------------------------
"if module.params['api']:
        user_token['user_api'] = array.create_api_token(module.params['name'])['api_token']
        # Added for 2.8.2: Not breaking user's playbooks in minor releases.
        user_token['api_token'] = user_token['user_api']
"
-------------------------------------------------------------------------
"Recom
PRs: 57588, 58544"
-------------------------------------------------------------------------
=========================================================================
"if module.params['api']:
        user_token['user_api'] = array.create_api_token(module.params['name'])['api_token']
"
-------------------------------------------------------------------------
"if module.params['api']:
        user_token['user_api'] = array.create_api_token(module.params['name'])['api_token']
        # Added for 2.8.2: Not breaking user's playbooks in minor releases.
        user_token['api_token'] = user_token['user_api']
"
-------------------------------------------------------------------------
"if module.params['api']:
        user_token['user_api'] = array.create_api_token(module.params['name'])['api_token']
        # Added for 2.8.2: Not breaking user's playbooks in minor releases.
        user_token['api_token'] = user_token['user_api']
"
-------------------------------------------------------------------------
"Recom
PRs: 57588, 58544"
-------------------------------------------------------------------------
=========================================================================
"- Has no effect when C(local) is C(True)
- Has no effect when C(local) is C(True)
"
-------------------------------------------------------------------------
"- Mutually exclusive with C(local)
- Mutually exclusive with C(local)
"
-------------------------------------------------------------------------
"- Mutually exclusive with C(local)
- Mutually exclusive with C(local)
"
-------------------------------------------------------------------------
"Recom
PRs: 55401, 58480"
-------------------------------------------------------------------------
=========================================================================
"if groups_need_mod and not self.local:
"
-------------------------------------------------------------------------
"if self.groups is not None and not self.local and len(self.groups):
"
-------------------------------------------------------------------------
"if self.groups is not None and not self.local and len(self.groups):
"
-------------------------------------------------------------------------
"Recom
PRs: 55401, 58480"
-------------------------------------------------------------------------
=========================================================================
"#
# (c) 2019 Red Hat Inc.
#
# This file is part of Ansible
#
# Ansible is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Ansible is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
#
from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

from os import path
import json

from mock import MagicMock, call

from units.compat import unittest
from ansible.plugins.cliconf import ios

FIXTURE_DIR = b'%s/fixtures/ios' % (
path.dirname(path.abspath(__file__)).encode('utf-8')



_connection_side_effect(*args, **kwargs):
try:
    if args:
        value = args[0]
    else:
        value = kwargs.get('command')

    fixture_path = path.abspath(
        b'%s/%s' % (FIXTURE_DIR, b'_'.join(value.split(b' ')))
    )
    with open(fixture_path, 'rb') as file_desc:
        return file_desc.read()
except (OSError, IOError):
    if args:
        value = args[0]
        return value
    elif kwargs.get('command'):
        value = kwargs.get('command')
        return value

    return 'Nope'


s TestPluginCLIConfIOS(unittest.TestCase):
"""""" Test class for IOS CLI Conf Methods
""""""
def setUp(self):
    self._mock_connection = MagicMock()
    self._mock_connection.send.side_effect = _connection_side_effect
    self._cliconf = ios.Cliconf(self._mock_connection)
    self.maxDiff = None

def tearDown(self):
    pass

def test_get_device_info(self):
    """""" Test get_device_info
    """"""
    device_info = self._cliconf.get_device_info()

    mock_device_info = {'network_os': 'ios',
                        'network_os_model': 'CSR1000V',
                        'network_os_version': '16.06.01',
                        'network_os_hostname': 'an-csr-01',
                        'network_os_image': 'bootflash:packages.conf'
                        }

    self.assertEqual(device_info, mock_device_info)

def test_get_capabilities(self):
    """""" Test get_capabilities
    """"""
    capabilities = json.loads(self._cliconf.get_capabilities())
    mock_capabilities = {
        'network_api': 'cliconf',
        'rpc': [
            'get_config',
            'edit_config',
            'get_capabilities',
            'get',
            'enable_response_logging',
            'disable_response_logging',
            'edit_banner',
            'get_diff',
            'run_commands',
            'get_defaults_flag'
        ],
        'device_operations': {
            'supports_diff_replace': True,
            'supports_commit': False,
            'supports_rollback': False,
            'supports_defaults': True,
            'supports_onbox_diff': False,
            'supports_commit_comment': False,
            'supports_multiline_delimiter': True,
            'supports_diff_match': True,
            'supports_diff_ignore_lines': True,
            'supports_generate_diff': True,
            'supports_replace': False
        },
        'device_info': {
            'network_os_hostname': 'an-csr-01',
            'network_os_image': 'bootflash:packages.conf',
            'network_os_model': 'CSR1000V',
            'network_os_version': '16.06.01',
            'network_os': 'ios'
        },
        'format': ['text'],
        'diff_match': ['line', 'strict', 'exact', 'none'],
        'diff_replace': ['line', 'block'],
        'output': []
    }

    self.assertEqual(
        mock_capabilities,
        capabilities
    )
"
-------------------------------------------------------------------------
"#
# (c) 2019 Red Hat Inc.
#
# This file is part of Ansible
#
# Ansible is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Ansible is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
#
from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

from os import path
import json

from mock import MagicMock, call

from units.compat import unittest
from ansible.plugins.cliconf import ios
from ansible.module_utils._text import to_bytes


b_FIXTURE_DIR = b'%s/fixtures/ios' % (
to_bytes(path.dirname(path.abspath(__file__)), errors='surrogate_or_strict')



_connection_side_effect(*args, **kwargs):
try:
    if args:
        value = args[0]
    else:
        value = kwargs.get('command')

    fixture_path = path.abspath(
        b'%s/%s' % (b_FIXTURE_DIR, b'_'.join(value.split(b' ')))
    )
    with open(fixture_path, 'rb') as file_desc:
        return file_desc.read()
except (OSError, IOError):
    if args:
        value = args[0]
        return value
    elif kwargs.get('command'):
        value = kwargs.get('command')
        return value

    return 'Nope'


s TestPluginCLIConfIOS(unittest.TestCase):
"""""" Test class for IOS CLI Conf Methods
""""""
def setUp(self):
    self._mock_connection = MagicMock()
    self._mock_connection.send.side_effect = _connection_side_effect
    self._cliconf = ios.Cliconf(self._mock_connection)
    self.maxDiff = None

def tearDown(self):
    pass

def test_get_device_info(self):
    """""" Test get_device_info
    """"""
    device_info = self._cliconf.get_device_info()

    mock_device_info = {'network_os': 'ios',
                        'network_os_model': 'CSR1000V',
                        'network_os_version': '16.06.01',
                        'network_os_hostname': 'an-csr-01',
                        'network_os_image': 'bootflash:packages.conf'
                        }

    self.assertEqual(device_info, mock_device_info)

def test_get_capabilities(self):
    """""" Test get_capabilities
    """"""
    capabilities = json.loads(self._cliconf.get_capabilities())
    mock_capabilities = {
        'network_api': 'cliconf',
        'rpc': [
            'get_config',
            'edit_config',
            'get_capabilities',
            'get',
            'enable_response_logging',
            'disable_response_logging',
            'edit_banner',
            'get_diff',
            'run_commands',
            'get_defaults_flag'
        ],
        'device_operations': {
            'supports_diff_replace': True,
            'supports_commit': False,
            'supports_rollback': False,
            'supports_defaults': True,
            'supports_onbox_diff': False,
            'supports_commit_comment': False,
            'supports_multiline_delimiter': True,
            'supports_diff_match': True,
            'supports_diff_ignore_lines': True,
            'supports_generate_diff': True,
            'supports_replace': False
        },
        'device_info': {
            'network_os_hostname': 'an-csr-01',
            'network_os_image': 'bootflash:packages.conf',
            'network_os_model': 'CSR1000V',
            'network_os_version': '16.06.01',
            'network_os': 'ios'
        },
        'format': ['text'],
        'diff_match': ['line', 'strict', 'exact', 'none'],
        'diff_replace': ['line', 'block'],
        'output': []
    }

    self.assertEqual(
        mock_capabilities,
        capabilities
    )
"
-------------------------------------------------------------------------
"#
# (c) 2019 Red Hat Inc.
#
# This file is part of Ansible
#
# Ansible is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Ansible is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
#
from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

from os import path
import json

from mock import MagicMock, call

from units.compat import unittest
from ansible.plugins.cliconf import ios
from ansible.module_utils._text import to_bytes


b_FIXTURE_DIR = b'%s/fixtures/ios' % (
to_bytes(path.dirname(path.abspath(__file__)), errors='surrogate_or_strict')



_connection_side_effect(*args, **kwargs):
try:
    if args:
        value = args[0]
    else:
        value = kwargs.get('command')

    fixture_path = path.abspath(
        b'%s/%s' % (b_FIXTURE_DIR, b'_'.join(value.split(b' ')))
    )
    with open(fixture_path, 'rb') as file_desc:
        return file_desc.read()
except (OSError, IOError):
    if args:
        value = args[0]
        return value
    elif kwargs.get('command'):
        value = kwargs.get('command')
        return value

    return 'Nope'


s TestPluginCLIConfIOS(unittest.TestCase):
"""""" Test class for IOS CLI Conf Methods
""""""
def setUp(self):
    self._mock_connection = MagicMock()
    self._mock_connection.send.side_effect = _connection_side_effect
    self._cliconf = ios.Cliconf(self._mock_connection)
    self.maxDiff = None

def tearDown(self):
    pass

def test_get_device_info(self):
    """""" Test get_device_info
    """"""
    device_info = self._cliconf.get_device_info()

    mock_device_info = {'network_os': 'ios',
                        'network_os_model': 'CSR1000V',
                        'network_os_version': '16.06.01',
                        'network_os_hostname': 'an-csr-01',
                        'network_os_image': 'bootflash:packages.conf'
                        }

    self.assertEqual(device_info, mock_device_info)

def test_get_capabilities(self):
    """""" Test get_capabilities
    """"""
    capabilities = json.loads(self._cliconf.get_capabilities())
    mock_capabilities = {
        'network_api': 'cliconf',
        'rpc': [
            'get_config',
            'edit_config',
            'get_capabilities',
            'get',
            'enable_response_logging',
            'disable_response_logging',
            'edit_banner',
            'get_diff',
            'run_commands',
            'get_defaults_flag'
        ],
        'device_operations': {
            'supports_diff_replace': True,
            'supports_commit': False,
            'supports_rollback': False,
            'supports_defaults': True,
            'supports_onbox_diff': False,
            'supports_commit_comment': False,
            'supports_multiline_delimiter': True,
            'supports_diff_match': True,
            'supports_diff_ignore_lines': True,
            'supports_generate_diff': True,
            'supports_replace': False
        },
        'device_info': {
            'network_os_hostname': 'an-csr-01',
            'network_os_image': 'bootflash:packages.conf',
            'network_os_model': 'CSR1000V',
            'network_os_version': '16.06.01',
            'network_os': 'ios'
        },
        'format': ['text'],
        'diff_match': ['line', 'strict', 'exact', 'none'],
        'diff_replace': ['line', 'block'],
        'output': []
    }

    self.assertEqual(
        mock_capabilities,
        capabilities
    )
"
-------------------------------------------------------------------------
"Recom
PRs: 58159, 58174"
-------------------------------------------------------------------------
=========================================================================
"- Use with state C(present) and source C(build) to provide an alternate name for the Dockerfile to use when building an image.
- This can also include a relative path (relative to I(path)).
"
-------------------------------------------------------------------------
"- This can also include a relative path (relative to I(path)).
"
-------------------------------------------------------------------------
"- This can also include a relative path (relative to I(path)).
"
-------------------------------------------------------------------------
"Recom
PRs: 57570, 57632"
-------------------------------------------------------------------------
=========================================================================
"#   loop: ""{{ sample_com_challenge.challenge_data_dns | dictsort }}""
#   when: sample_com_challenge is changed
"
-------------------------------------------------------------------------
"#   with_dict: sample_com_challenge.challenge_data_dns
#   when: sample_com_challenge is changed
"
-------------------------------------------------------------------------
"#   with_dict: sample_com_challenge.challenge_data_dns
#   when: sample_com_challenge is changed
"
-------------------------------------------------------------------------
"Recom
PRs: 57557, 57568"
-------------------------------------------------------------------------
=========================================================================
"if client.module.params['build'].get(build_option, default_value) != default_value:
"
-------------------------------------------------------------------------
"if client.module.params['build'].get(build_option, default_value) != default_value:
client.fail('If ""source"" is set to ""build"", the ""build.path"" option must be specified.')
"
-------------------------------------------------------------------------
"if client.module.params['build'].get(build_option, default_value) != default_value:
client.fail('If ""source"" is set to ""build"", the ""build.path"" option must be specified.')
"
-------------------------------------------------------------------------
"Recom
PRs: 56610, 57085"
-------------------------------------------------------------------------
=========================================================================
"if to_text(out, errors='surrogate_then_replace').strip().endswith('#'):
"
-------------------------------------------------------------------------
"
if to_text(out, errors='surrogate_then_replace').strip().endswith('#'):
    conn.send_command('exit discard')
"
-------------------------------------------------------------------------
"
if to_text(out, errors='surrogate_then_replace').strip().endswith('#'):
    conn.send_command('exit discard')
"
-------------------------------------------------------------------------
"Recom
PRs: 56389, 56401"
-------------------------------------------------------------------------
=========================================================================
"if to_text(out, errors='surrogate_then_replace').strip().endswith('#'):
"
-------------------------------------------------------------------------
"if to_text(out, errors='surrogate_then_replace').strip().endswith('#'):
    conn.send_command('exit discard')
"
-------------------------------------------------------------------------
"if to_text(out, errors='surrogate_then_replace').strip().endswith('#'):
    conn.send_command('exit discard')
"
-------------------------------------------------------------------------
"Recom
PRs: 56389, 56399"
-------------------------------------------------------------------------
=========================================================================
"p = subprocess.Popen(
    local_cmd,
    stdin=subprocess.PIPE,
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
)

if self.become and self.become.expect_prompt() and sudoable:
    display.debug(""handling privilege escalation"")
    fcntl.fcntl(p.stdout, fcntl.F_SETFL, fcntl.fcntl(p.stdout, fcntl.F_GETFL) | os.O_NONBLOCK)
    fcntl.fcntl(p.stderr, fcntl.F_SETFL, fcntl.fcntl(p.stderr, fcntl.F_GETFL) | os.O_NONBLOCK)

    selector = selectors.DefaultSelector()
    selector.register(p.stdout, selectors.EVENT_READ)
    selector.register(p.stderr, selectors.EVENT_READ)

    become_output = b''
    try:
        while not self.become.check_success(become_output) and not self.become.check_password_prompt(become_output):
            events = selector.select(self._play_context.timeout)
            if not events:
                stdout, stderr = p.communicate()
                raise AnsibleError('timeout waiting for privilege escalation password prompt:\n'  to_native(become_output))

            for key, event in events:
                if key.fileobj == p.stdout:
                    chunk = p.stdout.read()
                    break
                elif key.fileobj == p.stderr:
                    chunk = p.stderr.read()

            if not chunk:
                stdout, stderr = p.communicate()
                raise AnsibleError('privilege output closed while waiting for password prompt:\n'  to_native(become_output))
            become_output = chunk
    finally:
        selector.close()

    if not self.become.check_success(become_output):
        p.stdin.write(to_bytes(self._play_context.become_pass, errors='surrogate_or_strict')  b'\n')
    fcntl.fcntl(p.stdout, fcntl.F_SETFL, fcntl.fcntl(p.stdout, fcntl.F_GETFL) & ~os.O_NONBLOCK)
    fcntl.fcntl(p.stderr, fcntl.F_SETFL, fcntl.fcntl(p.stderr, fcntl.F_GETFL) & ~os.O_NONBLOCK)

display.debug(""getting output with communicate()"")
display.debug(""done communicating"")

display.debug(""done with docker.exec_command()"")
"
-------------------------------------------------------------------------
"p = subprocess.Popen(
    local_cmd,
    stdin=subprocess.PIPE,
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
)

if self._play_context.prompt and sudoable:
    fcntl.fcntl(p.stdout, fcntl.F_SETFL, fcntl.fcntl(p.stdout, fcntl.F_GETFL) | os.O_NONBLOCK)
    fcntl.fcntl(p.stderr, fcntl.F_SETFL, fcntl.fcntl(p.stderr, fcntl.F_GETFL) | os.O_NONBLOCK)
    selector = selectors.DefaultSelector()
    selector.register(p.stdout, selectors.EVENT_READ)
    selector.register(p.stderr, selectors.EVENT_READ)

    become_output = b''
    try:
        while not self.check_become_success(become_output) and not self.check_password_prompt(become_output):
            events = selector.select(self._play_context.timeout)
            if not events:
                stdout, stderr = p.communicate()
                raise AnsibleError('timeout waiting for privilege escalation password prompt:\n'  to_native(become_output))

            for key, event in events:
                if key.fileobj == p.stdout:
                    chunk = p.stdout.read()
                elif key.fileobj == p.stderr:
                    chunk = p.stderr.read()

            if not chunk:
                stdout, stderr = p.communicate()
                raise AnsibleError('privilege output closed while waiting for password prompt:\n'  to_native(become_output))
            become_output = chunk
    finally:
        selector.close()

    if not self.check_become_success(become_output):
        p.stdin.write(to_bytes(self._play_context.become_pass, errors='surrogate_or_strict')  b'\n')
    fcntl.fcntl(p.stdout, fcntl.F_SETFL, fcntl.fcntl(p.stdout, fcntl.F_GETFL) & ~os.O_NONBLOCK)
    fcntl.fcntl(p.stderr, fcntl.F_SETFL, fcntl.fcntl(p.stderr, fcntl.F_GETFL) & ~os.O_NONBLOCK)

display.debug(""getting output with communicate()"")
display.debug(""done communicating"")

display.debug(""done with docker.exec_command()"")
"
-------------------------------------------------------------------------
"p = subprocess.Popen(
    local_cmd,
    stdin=subprocess.PIPE,
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
)

if self._play_context.prompt and sudoable:
    fcntl.fcntl(p.stdout, fcntl.F_SETFL, fcntl.fcntl(p.stdout, fcntl.F_GETFL) | os.O_NONBLOCK)
    fcntl.fcntl(p.stderr, fcntl.F_SETFL, fcntl.fcntl(p.stderr, fcntl.F_GETFL) | os.O_NONBLOCK)
    selector = selectors.DefaultSelector()
    selector.register(p.stdout, selectors.EVENT_READ)
    selector.register(p.stderr, selectors.EVENT_READ)

    become_output = b''
    try:
        while not self.check_become_success(become_output) and not self.check_password_prompt(become_output):
            events = selector.select(self._play_context.timeout)
            if not events:
                stdout, stderr = p.communicate()
                raise AnsibleError('timeout waiting for privilege escalation password prompt:\n'  to_native(become_output))

            for key, event in events:
                if key.fileobj == p.stdout:
                    chunk = p.stdout.read()
                elif key.fileobj == p.stderr:
                    chunk = p.stderr.read()

            if not chunk:
                stdout, stderr = p.communicate()
                raise AnsibleError('privilege output closed while waiting for password prompt:\n'  to_native(become_output))
            become_output = chunk
    finally:
        selector.close()

    if not self.check_become_success(become_output):
        p.stdin.write(to_bytes(self._play_context.become_pass, errors='surrogate_or_strict')  b'\n')
    fcntl.fcntl(p.stdout, fcntl.F_SETFL, fcntl.fcntl(p.stdout, fcntl.F_GETFL) & ~os.O_NONBLOCK)
    fcntl.fcntl(p.stderr, fcntl.F_SETFL, fcntl.fcntl(p.stderr, fcntl.F_GETFL) & ~os.O_NONBLOCK)

display.debug(""getting output with communicate()"")
display.debug(""done communicating"")

display.debug(""done with docker.exec_command()"")
"
-------------------------------------------------------------------------
"Recom
PRs: 55816, 56278"
-------------------------------------------------------------------------
=========================================================================
"p = subprocess.Popen(
    local_cmd,
    stdin=subprocess.PIPE,
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
)

if self.become and self.become.expect_prompt() and sudoable:
    display.debug(""handling privilege escalation"")
    fcntl.fcntl(p.stdout, fcntl.F_SETFL, fcntl.fcntl(p.stdout, fcntl.F_GETFL) | os.O_NONBLOCK)
    fcntl.fcntl(p.stderr, fcntl.F_SETFL, fcntl.fcntl(p.stderr, fcntl.F_GETFL) | os.O_NONBLOCK)

    selector = selectors.DefaultSelector()
    selector.register(p.stdout, selectors.EVENT_READ)
    selector.register(p.stderr, selectors.EVENT_READ)

    become_output = b''
    try:
        while not self.become.check_success(become_output) and not self.become.check_password_prompt(become_output):
            events = selector.select(self._play_context.timeout)
            if not events:
                stdout, stderr = p.communicate()
                raise AnsibleError('timeout waiting for privilege escalation password prompt:\n'  to_native(become_output))

            for key, event in events:
                if key.fileobj == p.stdout:
                    chunk = p.stdout.read()
                    break
                elif key.fileobj == p.stderr:
                    chunk = p.stderr.read()

            if not chunk:
                stdout, stderr = p.communicate()
                raise AnsibleError('privilege output closed while waiting for password prompt:\n'  to_native(become_output))
            become_output = chunk
    finally:
        selector.close()

    if not self.become.check_success(become_output):
        p.stdin.write(to_bytes(self._play_context.become_pass, errors='surrogate_or_strict')  b'\n')
    fcntl.fcntl(p.stdout, fcntl.F_SETFL, fcntl.fcntl(p.stdout, fcntl.F_GETFL) & ~os.O_NONBLOCK)
    fcntl.fcntl(p.stderr, fcntl.F_SETFL, fcntl.fcntl(p.stderr, fcntl.F_GETFL) & ~os.O_NONBLOCK)

display.debug(""getting output with communicate()"")
display.debug(""done communicating"")

display.debug(""done with docker.exec_command()"")
"
-------------------------------------------------------------------------
"display.vvv(u""EXEC {0}"".format(to_text(local_cmd)), host=self._play_context.remote_addr)
display.debug(""opening command with Popen()"")

p = subprocess.Popen(
    local_cmd,
    stdin=subprocess.PIPE,
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
)
display.debug(""done running command with Popen()"")

if self.become and self.become.expect_prompt() and sudoable:
    fcntl.fcntl(p.stdout, fcntl.F_SETFL, fcntl.fcntl(p.stdout, fcntl.F_GETFL) | os.O_NONBLOCK)
    fcntl.fcntl(p.stderr, fcntl.F_SETFL, fcntl.fcntl(p.stderr, fcntl.F_GETFL) | os.O_NONBLOCK)
    selector = selectors.DefaultSelector()
    selector.register(p.stdout, selectors.EVENT_READ)
    selector.register(p.stderr, selectors.EVENT_READ)

    become_output = b''
    try:
        while not self.become.check_success(become_output) and not self.become.check_password_prompt(become_output):
            events = selector.select(self._play_context.timeout)
            if not events:
                stdout, stderr = p.communicate()
                raise AnsibleError('timeout waiting for privilege escalation password prompt:\n'  to_native(become_output))

            for key, event in events:
                if key.fileobj == p.stdout:
                    chunk = p.stdout.read()
                elif key.fileobj == p.stderr:
                    chunk = p.stderr.read()

            if not chunk:
                stdout, stderr = p.communicate()
                raise AnsibleError('privilege output closed while waiting for password prompt:\n'  to_native(become_output))
            become_output = chunk
    finally:
        selector.close()

    if not self.become.check_success(become_output):
        p.stdin.write(to_bytes(self._play_context.become_pass, errors='surrogate_or_strict')  b'\n')
    fcntl.fcntl(p.stdout, fcntl.F_SETFL, fcntl.fcntl(p.stdout, fcntl.F_GETFL) & ~os.O_NONBLOCK)
    fcntl.fcntl(p.stderr, fcntl.F_SETFL, fcntl.fcntl(p.stderr, fcntl.F_GETFL) & ~os.O_NONBLOCK)

display.debug(""getting output with communicate()"")
display.debug(""done communicating"")

display.debug(""done with docker.exec_command()"")
"
-------------------------------------------------------------------------
"display.vvv(u""EXEC {0}"".format(to_text(local_cmd)), host=self._play_context.remote_addr)
display.debug(""opening command with Popen()"")

p = subprocess.Popen(
    local_cmd,
    stdin=subprocess.PIPE,
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
)
display.debug(""done running command with Popen()"")

if self.become and self.become.expect_prompt() and sudoable:
    fcntl.fcntl(p.stdout, fcntl.F_SETFL, fcntl.fcntl(p.stdout, fcntl.F_GETFL) | os.O_NONBLOCK)
    fcntl.fcntl(p.stderr, fcntl.F_SETFL, fcntl.fcntl(p.stderr, fcntl.F_GETFL) | os.O_NONBLOCK)
    selector = selectors.DefaultSelector()
    selector.register(p.stdout, selectors.EVENT_READ)
    selector.register(p.stderr, selectors.EVENT_READ)

    become_output = b''
    try:
        while not self.become.check_success(become_output) and not self.become.check_password_prompt(become_output):
            events = selector.select(self._play_context.timeout)
            if not events:
                stdout, stderr = p.communicate()
                raise AnsibleError('timeout waiting for privilege escalation password prompt:\n'  to_native(become_output))

            for key, event in events:
                if key.fileobj == p.stdout:
                    chunk = p.stdout.read()
                elif key.fileobj == p.stderr:
                    chunk = p.stderr.read()

            if not chunk:
                stdout, stderr = p.communicate()
                raise AnsibleError('privilege output closed while waiting for password prompt:\n'  to_native(become_output))
            become_output = chunk
    finally:
        selector.close()

    if not self.become.check_success(become_output):
        p.stdin.write(to_bytes(self._play_context.become_pass, errors='surrogate_or_strict')  b'\n')
    fcntl.fcntl(p.stdout, fcntl.F_SETFL, fcntl.fcntl(p.stdout, fcntl.F_GETFL) & ~os.O_NONBLOCK)
    fcntl.fcntl(p.stderr, fcntl.F_SETFL, fcntl.fcntl(p.stderr, fcntl.F_GETFL) & ~os.O_NONBLOCK)

display.debug(""getting output with communicate()"")
display.debug(""done communicating"")

display.debug(""done with docker.exec_command()"")
"
-------------------------------------------------------------------------
"Recom
PRs: 55816, 56277"
-------------------------------------------------------------------------
=========================================================================
"- Seconds to wait before reboot. Passed as a parameter to the reboot command.
- Seconds to wait after the reboot command was successful before attempting to validate the system rebooted successfully.
- This timeout is evaluated separately for both reboot verification and test command success so the
"
-------------------------------------------------------------------------
"- Seconds to wait before reboot. Passed as a parameter to the reboot command.
- On Linux, macOS and OpenBSD, this is converted to minutes and rounded down. If less than 60, it will be set to 0.
- On Solaris and FreeBSD, this will be seconds.
- Seconds to wait after the reboot command was successful before attempting to validate the system rebooted successfully.
- This timeout is evaluated separately for both reboot verification and test command success so the
"
-------------------------------------------------------------------------
"- Seconds to wait before reboot. Passed as a parameter to the reboot command.
- On Linux, macOS and OpenBSD, this is converted to minutes and rounded down. If less than 60, it will be set to 0.
- On Solaris and FreeBSD, this will be seconds.
- Seconds to wait after the reboot command was successful before attempting to validate the system rebooted successfully.
- This timeout is evaluated separately for both reboot verification and test command success so the
"
-------------------------------------------------------------------------
"Recom
PRs: 55934, 55959"
-------------------------------------------------------------------------
=========================================================================
"- Seconds to wait before reboot. Passed as a parameter to the reboot command.
- Seconds to wait after the reboot command was successful before attempting to validate the system rebooted successfully.
"
-------------------------------------------------------------------------
"- Seconds to wait before reboot. Passed as a parameter to the reboot command.
- Seconds to wait after the reboot command was successful before attempting to validate the system rebooted successfully.
- This is useful if you want wait for something to settle despite your connection already working.
"
-------------------------------------------------------------------------
"- Seconds to wait before reboot. Passed as a parameter to the reboot command.
- Seconds to wait after the reboot command was successful before attempting to validate the system rebooted successfully.
- This is useful if you want wait for something to settle despite your connection already working.
"
-------------------------------------------------------------------------
"Recom
PRs: 55934, 55959"
-------------------------------------------------------------------------
=========================================================================
"- This timeout is evaluated separately for both reboot verification and test command success so maximum clock time is actually twice this value.
"
-------------------------------------------------------------------------
"- Maximum seconds to wait for machine to re-appear on the network and respond to a test command.
- This timeout is evaluated separately for both reboot verification and test command success so maximum clock time is actually twice this value.
"
-------------------------------------------------------------------------
"- Maximum seconds to wait for machine to re-appear on the network and respond to a test command.
- This timeout is evaluated separately for both reboot verification and test command success so maximum clock time is actually twice this value.
"
-------------------------------------------------------------------------
"Recom
PRs: 55934, 55959"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils._text import to_native
from ansible.module_utils.basic import missing_required_lib
HAS_NCCLIENT = True
NCCLIENT_IMP_ERR = None
pt (ImportError, AttributeError) as err:  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
HAS_NCCLIENT = False
NCCLIENT_IMP_ERR = err
"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_native
HAS_NCCLIENT = True
NCCLIENT_IMP_ERR = None
pt (ImportError, AttributeError) as err:  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
HAS_NCCLIENT = False
NCCLIENT_IMP_ERR = err
"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_native
HAS_NCCLIENT = True
NCCLIENT_IMP_ERR = None
pt (ImportError, AttributeError) as err:  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
HAS_NCCLIENT = False
NCCLIENT_IMP_ERR = err
"
-------------------------------------------------------------------------
"Recom
PRs: 55384, 55648"
-------------------------------------------------------------------------
=========================================================================
"def ensure_ncclient(func):
@wraps(func)
def wrapped(self, *args, **kwargs):
    if not HAS_NCCLIENT:
        raise AnsibleError(""%s: %s"" % (missing_required_lib('ncclient'), to_native(NCCLIENT_IMP_ERR)))
    return func(self, *args, **kwargs)
return wrapped


"
-------------------------------------------------------------------------
"def ensure_ncclient(func):
@wraps(func)
def wrapped(self, *args, **kwargs):
    if not HAS_NCCLIENT:
        raise AnsibleError(""Package ncclient is not installed: %s. Please install it with `pip install ncclient`"" % to_native(NCCLIENT_IMP_ERR))
    return func(self, *args, **kwargs)
return wrapped


"
-------------------------------------------------------------------------
"def ensure_ncclient(func):
@wraps(func)
def wrapped(self, *args, **kwargs):
    if not HAS_NCCLIENT:
        raise AnsibleError(""Package ncclient is not installed: %s. Please install it with `pip install ncclient`"" % to_native(NCCLIENT_IMP_ERR))
    return func(self, *args, **kwargs)
return wrapped


"
-------------------------------------------------------------------------
"Recom
PRs: 55384, 55648"
-------------------------------------------------------------------------
=========================================================================
"from ansible.errors import AnsibleConnectionFailure
from ansible.plugins.netconf import ensure_connected, ensure_ncclient
HAS_NCCLIENT = True
pt (ImportError, AttributeError):  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
HAS_NCCLIENT = False
@ensure_ncclient
@ensure_ncclient
"
-------------------------------------------------------------------------
"from ansible.errors import AnsibleConnectionFailure
from ansible.plugins.netconf import ensure_connected, ensure_ncclient
HAS_NCCLIENT = True
pt (ImportError, AttributeError):  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
HAS_NCCLIENT = False
"
-------------------------------------------------------------------------
"from ansible.errors import AnsibleConnectionFailure
from ansible.plugins.netconf import ensure_connected, ensure_ncclient
HAS_NCCLIENT = True
pt (ImportError, AttributeError):  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
HAS_NCCLIENT = False
"
-------------------------------------------------------------------------
"Recom
PRs: 55384, 55648"
-------------------------------------------------------------------------
=========================================================================
"from ansible.errors import AnsibleConnectionFailure
from ansible.plugins.netconf import ensure_connected, ensure_ncclient
from ncclient.xml_ import to_xml
HAS_NCCLIENT = True
pt (ImportError, AttributeError):  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
HAS_NCCLIENT = False
"
-------------------------------------------------------------------------
"@ensure_ncclient
"
-------------------------------------------------------------------------
"@ensure_ncclient
"
-------------------------------------------------------------------------
"Recom
PRs: 55384, 55648"
-------------------------------------------------------------------------
=========================================================================
"@ensure_ncclient
"
-------------------------------------------------------------------------
"from ansible.errors import AnsibleConnectionFailure
from ansible.plugins.netconf import ensure_connected, ensure_ncclient
from ncclient.xml_ import to_xml
HAS_NCCLIENT = True
pt (ImportError, AttributeError):  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
HAS_NCCLIENT = False
"
-------------------------------------------------------------------------
"from ansible.errors import AnsibleConnectionFailure
from ansible.plugins.netconf import ensure_connected, ensure_ncclient
from ncclient.xml_ import to_xml
HAS_NCCLIENT = True
pt (ImportError, AttributeError):  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
HAS_NCCLIENT = False
"
-------------------------------------------------------------------------
"Recom
PRs: 55384, 55648"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils._text import to_text, to_native
from ansible.errors import AnsibleConnectionFailure
from ansible.plugins.netconf import ensure_connected, ensure_ncclient
HAS_NCCLIENT = True
pt (ImportError, AttributeError):  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
HAS_NCCLIENT = False
@ensure_ncclient
"
-------------------------------------------------------------------------
"@ensure_ncclient
"
-------------------------------------------------------------------------
"@ensure_ncclient
"
-------------------------------------------------------------------------
"Recom
PRs: 55384, 55648"
-------------------------------------------------------------------------
=========================================================================
"@ensure_ncclient
"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_text
from ansible.errors import AnsibleConnectionFailure
from ansible.plugins.netconf import ensure_connected, ensure_ncclient
HAS_NCCLIENT = True
pt (ImportError, AttributeError):  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
HAS_NCCLIENT = False
@ensure_ncclient
"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_text
from ansible.errors import AnsibleConnectionFailure
from ansible.plugins.netconf import ensure_connected, ensure_ncclient
HAS_NCCLIENT = True
pt (ImportError, AttributeError):  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
HAS_NCCLIENT = False
@ensure_ncclient
"
-------------------------------------------------------------------------
"Recom
PRs: 55384, 55648"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils._text import to_text, to_native
from ansible.errors import AnsibleConnectionFailure
from ansible.plugins.netconf import ensure_ncclient
from ncclient.xml_ import to_ele
HAS_NCCLIENT = True
pt (ImportError, AttributeError):  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
HAS_NCCLIENT = False
"
-------------------------------------------------------------------------
"@ensure_ncclient
"
-------------------------------------------------------------------------
"@ensure_ncclient
"
-------------------------------------------------------------------------
"Recom
PRs: 55384, 55648"
-------------------------------------------------------------------------
=========================================================================
"@ensure_ncclient
"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_text
from ansible.errors import AnsibleConnectionFailure
from ansible.plugins.netconf import ensure_ncclient
from ncclient.xml_ import to_ele
HAS_NCCLIENT = True
pt (ImportError, AttributeError):  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
HAS_NCCLIENT = False
"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_text
from ansible.errors import AnsibleConnectionFailure
from ansible.plugins.netconf import ensure_ncclient
from ncclient.xml_ import to_ele
HAS_NCCLIENT = True
pt (ImportError, AttributeError):  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
HAS_NCCLIENT = False
"
-------------------------------------------------------------------------
"Recom
PRs: 55384, 55648"
-------------------------------------------------------------------------
=========================================================================
"type: str
type: str
  - File access mode inside the container. Must be an octal number (like C(0644) or C(0444)).
type: int
"
-------------------------------------------------------------------------
"- Every item must be a dictionary exposing the keys secret_id, secret_name, filename, uid (defaults to 0), gid (defaults to 0), mode (defaults to 0444)
"
-------------------------------------------------------------------------
"- Every item must be a dictionary exposing the keys secret_id, secret_name, filename, uid (defaults to 0), gid (defaults to 0), mode (defaults to 0444)
"
-------------------------------------------------------------------------
"Recom
PRs: 55591, 55617"
-------------------------------------------------------------------------
=========================================================================
"type: str
type: str
  - File access mode inside the container. Must be an octal number (like C(0644) or C(0444)).
"
-------------------------------------------------------------------------
"- Every item must be a dictionary exposing the keys config_id, config_name, filename, uid (defaults to 0), gid (defaults to 0), mode (defaults to 0444)
"
-------------------------------------------------------------------------
"- Every item must be a dictionary exposing the keys config_id, config_name, filename, uid (defaults to 0), gid (defaults to 0), mode (defaults to 0444)
"
-------------------------------------------------------------------------
"Recom
PRs: 55591, 55617"
-------------------------------------------------------------------------
=========================================================================
"'uid': config_data['File'].get('UID'),
'gid': config_data['File'].get('GID'),
"
-------------------------------------------------------------------------
"service_c['uid'] = str(param_m.get('uid', ""0""))
service_c['gid'] = str(param_m.get('gid', ""0""))
service_c['mode'] = int(param_m.get('mode', 0o444))
"
-------------------------------------------------------------------------
"service_c['uid'] = str(param_m.get('uid', ""0""))
service_c['gid'] = str(param_m.get('gid', ""0""))
service_c['mode'] = int(param_m.get('mode', 0o444))
"
-------------------------------------------------------------------------
"Recom
PRs: 55591, 55617"
-------------------------------------------------------------------------
=========================================================================
"'uid': secret_data['File'].get('UID'),
'gid': secret_data['File'].get('GID'),
"
-------------------------------------------------------------------------
"service_s['uid'] = str(param_m.get('uid', ""0""))
service_s['gid'] = str(param_m.get('gid', ""0""))
service_s['mode'] = int(param_m.get('mode', 0o444))
"
-------------------------------------------------------------------------
"service_s['uid'] = str(param_m.get('uid', ""0""))
service_s['gid'] = str(param_m.get('gid', ""0""))
service_s['mode'] = int(param_m.get('mode', 0o444))
"
-------------------------------------------------------------------------
"Recom
PRs: 55591, 55617"
-------------------------------------------------------------------------
=========================================================================
"uid=dict(type='str'),
gid=dict(type='str'),
uid=dict(type='str'),
gid=dict(type='str'),
"
-------------------------------------------------------------------------
"'uid': config_data['File'].get('UID'),
'gid': config_data['File'].get('GID'),
"
-------------------------------------------------------------------------
"'uid': config_data['File'].get('UID'),
'gid': config_data['File'].get('GID'),
"
-------------------------------------------------------------------------
"Recom
PRs: 55591, 55617"
-------------------------------------------------------------------------
=========================================================================
"# check if user is trying to perform state operation on a vm which doesn't exists
elif state in ['present', 'powered_off', 'powered_on'] and not all((vm_extra_config,
                                               vm_hardware, vm_disk, vm_nic, esxi)):
    module.exit_json(changed=False, msg=""vm %s not present"" % guest)


"
-------------------------------------------------------------------------
"elif state in ['present', 'powered_off', 'powered_on'] and not all((vm_hardware, vm_disk, vm_nic, esxi)):
    module.fail_json(msg=""vm %s not present and not all options neccessary to create are provided"" % guest)
"
-------------------------------------------------------------------------
"elif state in ['present', 'powered_off', 'powered_on'] and not all((vm_hardware, vm_disk, vm_nic, esxi)):
    module.fail_json(msg=""vm %s not present and not all options neccessary to create are provided"" % guest)
"
-------------------------------------------------------------------------
"Recom
PRs: 19716, 55285"
-------------------------------------------------------------------------
=========================================================================
"if params['direction'] not in ['outgoing', 'incoming', 'routed', None]:
    module.fail_json(msg='For default, direction must be one of ""outgoing"", ""incoming"" and ""routed"", or direction must not be specified.')
"
-------------------------------------------------------------------------
"if params['direction'] not in ['outgoing', 'incoming', 'routed', None]:
    module.fail_json(msg='For default, direction must be one of ""outgoing"", ""incoming"" and ""routed"", or direction must not be specified.')
    module.fail_json(msg='For rules, direction must be one of ""in"" and ""out"", or direction must not be specified.')
"
-------------------------------------------------------------------------
"if params['direction'] not in ['outgoing', 'incoming', 'routed', None]:
    module.fail_json(msg='For default, direction must be one of ""outgoing"", ""incoming"" and ""routed"", or direction must not be specified.')
    module.fail_json(msg='For rules, direction must be one of ""in"" and ""out"", or direction must not be specified.')
"
-------------------------------------------------------------------------
"Recom
PRs: 54799, 54987"
-------------------------------------------------------------------------
=========================================================================
"- Backreferences can be used ambiguously like C(\1), or explicitly like C(\g<1>).
- If specified, only content after this match will be replaced/removed.
- Uses DOTALL, which means the C(.) special character I(can match newlines).
- If specified, only content before this match will be replaced/removed.
- Uses DOTALL, which means the C(.) special character I(can match newlines).
"
-------------------------------------------------------------------------
"type: path
aliases: [ dest, destfile, name ]
"
-------------------------------------------------------------------------
"type: path
aliases: [ dest, destfile, name ]
"
-------------------------------------------------------------------------
"Recom
PRs: 31452, 54408"
-------------------------------------------------------------------------
=========================================================================
"- As of Ansible 2.7.10, the combined use of I(before) and I(after) works properly. If you were relying on the
  previous incorrect behavior, you may be need to adjust your tasks.
  See U(https://github.com/ansible/ansible/issues/31354) for details.
name: Before Ansible 2.3, option 'dest', 'destfile' or 'name' was used instead of 'path'
replace:
  path: /etc/apache2/sites-available/default.conf
  after: 'NameVirtualHost [*]'
  regexp: '^(.)$'
  replace: '# \1'
  path: /etc/apache2/sites-available/default.conf
  before: '# live site config'
  regexp: '^(.)$'
  replace: '# \1'
Prior to Ansible 2.7.10, using before and after in combination did the opposite of what was intended.
see https://github.com/ansible/ansible/issues/31354 for details.
  after: '<VirtualHost [*]>'
  before: '</VirtualHost>'
  regexp: '^(.)$'
  replace: '# \1'
name: Supports common file attributes
replace:
name: Supports a validate command
replace:
replace: path=/etc/hosts regexp='\\b(localhost)(\\d*)\\b' replace='\\1\\2.localdomain\\2 \\1\\2'
  path: /etc/hosts

name: Explicitly specifying positional matched groups in replacement
replace:
  path: /etc/ssh/sshd_config
  regexp: '^(ListenAddress[ ])[^\n]$'
  replace: '\g<1>0.0.0.0'

name: Explicitly specifying named matched groups
replace:
  path: /etc/ssh/sshd_config
  regexp: '^(?P<dctv>ListenAddress[ ])(?P<host>[^\n])$'
  replace: '#\g<dctv>\g<host>\n\g<dctv>0.0.0.0'
"
-------------------------------------------------------------------------
"type: path
aliases: [ dest, destfile, name ]
"
-------------------------------------------------------------------------
"type: path
aliases: [ dest, destfile, name ]
"
-------------------------------------------------------------------------
"Recom
PRs: 31452, 54408"
-------------------------------------------------------------------------
=========================================================================
"indices = [match.start('subsection'), match.end('subsection')]
"
-------------------------------------------------------------------------
"pattern = u'%s(?P<subsection>.*?)%s' % (params['after'], params['before'])
"
-------------------------------------------------------------------------
"pattern = u'%s(?P<subsection>.*?)%s' % (params['after'], params['before'])
"
-------------------------------------------------------------------------
"Recom
PRs: 31452, 54408"
-------------------------------------------------------------------------
=========================================================================
"result = (contents[:indices[0]]  result[0]  contents[indices[1]:], result[1])
"
-------------------------------------------------------------------------
"pattern = u'%s(?P<subsection>.*?)%s' % (params['after'], params['before'])
"
-------------------------------------------------------------------------
"pattern = u'%s(?P<subsection>.*?)%s' % (params['after'], params['before'])
"
-------------------------------------------------------------------------
"Recom
PRs: 31452, 54408"
-------------------------------------------------------------------------
=========================================================================
"crypto_utils.write_file(module, certificate.public_bytes(Encoding.PEM))
"
-------------------------------------------------------------------------
"crypto_utils.write_file(module, crypto.dump_certificate(crypto.FILETYPE_PEM, self.cert))
"
-------------------------------------------------------------------------
"crypto_utils.write_file(module, crypto.dump_certificate(crypto.FILETYPE_PEM, self.cert))
"
-------------------------------------------------------------------------
"Recom
PRs: 54085, 54354"
-------------------------------------------------------------------------
=========================================================================
"crypto_utils.write_file(module, certificate.public_bytes(Encoding.PEM))
"
-------------------------------------------------------------------------
"crypto_utils.write_file(module, to_bytes(crt))
"
-------------------------------------------------------------------------
"crypto_utils.write_file(module, to_bytes(crt))
"
-------------------------------------------------------------------------
"Recom
PRs: 54085, 54354"
-------------------------------------------------------------------------
=========================================================================
"crypto_utils.write_file(module, result)
"
-------------------------------------------------------------------------
"result = crypto.dump_certificate_request(crypto.FILETYPE_PEM, self.request)
crypto_utils.write_file(module, result)
"
-------------------------------------------------------------------------
"result = crypto.dump_certificate_request(crypto.FILETYPE_PEM, self.request)
crypto_utils.write_file(module, result)
"
-------------------------------------------------------------------------
"Recom
PRs: 54085, 54354"
-------------------------------------------------------------------------
=========================================================================
"crypto_utils.write_file(
    module,
    self.pkcs12.export(self.passphrase, self.iter_size, self.maciter_size),
    0o600
)
"
-------------------------------------------------------------------------
"crypto_utils.write_file(
    module,
    self.pkcs12.export(self.passphrase, self.iter_size, self.maciter_size),
    0o600
)
    with open(self.src, 'rb') as pkcs12_fh:
        pkcs12_content = pkcs12_fh.read()
    p12 = crypto.load_pkcs12(pkcs12_content,
    crypto_utils.write_file(module, b'%s%s' % (pkey, crt))
"
-------------------------------------------------------------------------
"crypto_utils.write_file(
    module,
    self.pkcs12.export(self.passphrase, self.iter_size, self.maciter_size),
    0o600
)
    with open(self.src, 'rb') as pkcs12_fh:
        pkcs12_content = pkcs12_fh.read()
    p12 = crypto.load_pkcs12(pkcs12_content,
    crypto_utils.write_file(module, b'%s%s' % (pkey, crt))
"
-------------------------------------------------------------------------
"Recom
PRs: 54085, 54354"
-------------------------------------------------------------------------
=========================================================================
"crypto_utils.write_file(module, privatekey_data, 0o600)
self.changed = True
"
-------------------------------------------------------------------------
"if self.cipher and self.passphrase:
    privatekey_data = crypto.dump_privatekey(crypto.FILETYPE_PEM, self.privatekey,
                                             self.cipher, to_bytes(self.passphrase))
else:
    privatekey_data = crypto.dump_privatekey(crypto.FILETYPE_PEM, self.privatekey)

crypto_utils.write_file(module, privatekey_data, 0o600)
self.changed = True
"
-------------------------------------------------------------------------
"if self.cipher and self.passphrase:
    privatekey_data = crypto.dump_privatekey(crypto.FILETYPE_PEM, self.privatekey,
                                             self.cipher, to_bytes(self.passphrase))
else:
    privatekey_data = crypto.dump_privatekey(crypto.FILETYPE_PEM, self.privatekey)

crypto_utils.write_file(module, privatekey_data, 0o600)
self.changed = True
"
-------------------------------------------------------------------------
"Recom
PRs: 54085, 54354"
-------------------------------------------------------------------------
=========================================================================
"def dump(self, check_mode=False):
    # Use only for absent

    result = {
        'changed': self.changed,
        'filename': self.path,
        'privatekey': self.privatekey_path,
        'csr': self.csr_path
    }

    return result

"
-------------------------------------------------------------------------
"class CertificateAbsent(Certificate):
def __init__(self, module):
    super(CertificateAbsent, self).__init__(module)

def generate(self, module):
    pass

def dump(self, check_mode=False):
    # Use only for absent

    result = {
        'changed': self.changed,
        'filename': self.path,
        'privatekey': self.privatekey_path,
        'csr': self.csr_path
    }

    return result


"
-------------------------------------------------------------------------
"class CertificateAbsent(Certificate):
def __init__(self, module):
    super(CertificateAbsent, self).__init__(module)

def generate(self, module):
    pass

def dump(self, check_mode=False):
    # Use only for absent

    result = {
        'changed': self.changed,
        'filename': self.path,
        'privatekey': self.privatekey_path,
        'csr': self.csr_path
    }

    return result


"
-------------------------------------------------------------------------
"Recom
PRs: 54298, 54348"
-------------------------------------------------------------------------
=========================================================================
"- It uses the pyOpenSSL python library to interact with openssl.
"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_native, to_bytes
"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_native, to_bytes
"
-------------------------------------------------------------------------
"Recom
PRs: 54192, 54248"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils._text import to_native, to_bytes
"
-------------------------------------------------------------------------
"with open(self.privatekey_path, 'rb') as private_key_fh:
    privatekey_content = private_key_fh.read()
key = crypto_serialization.load_pem_private_key(
    privatekey_content,
    password=None if self.privatekey_passphrase is None else to_bytes(self.privatekey_passphrase),
    backend=default_backend()
)
"
-------------------------------------------------------------------------
"with open(self.privatekey_path, 'rb') as private_key_fh:
    privatekey_content = private_key_fh.read()
key = crypto_serialization.load_pem_private_key(
    privatekey_content,
    password=None if self.privatekey_passphrase is None else to_bytes(self.privatekey_passphrase),
    backend=default_backend()
)
"
-------------------------------------------------------------------------
"Recom
PRs: 54192, 54248"
-------------------------------------------------------------------------
=========================================================================
"- It uses the pyOpenSSL python library to interact with openssl.
"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_native, to_bytes
"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_native, to_bytes
"
-------------------------------------------------------------------------
"Recom
PRs: 54192, 54247"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils._text import to_native, to_bytes
"
-------------------------------------------------------------------------
"with open(self.privatekey_path, 'rb') as private_key_fh:
    privatekey_content = private_key_fh.read()
key = crypto_serialization.load_pem_private_key(
    privatekey_content,
    password=None if self.privatekey_passphrase is None else to_bytes(self.privatekey_passphrase),
    backend=default_backend()
)
"
-------------------------------------------------------------------------
"with open(self.privatekey_path, 'rb') as private_key_fh:
    privatekey_content = private_key_fh.read()
key = crypto_serialization.load_pem_private_key(
    privatekey_content,
    password=None if self.privatekey_passphrase is None else to_bytes(self.privatekey_passphrase),
    backend=default_backend()
)
"
-------------------------------------------------------------------------
"Recom
PRs: 54192, 54247"
-------------------------------------------------------------------------
=========================================================================
"ret = []
rn ret.get('all_parameters')
"
-------------------------------------------------------------------------
"return {}
rn ret.get('all_parameters')
"
-------------------------------------------------------------------------
"return {}
rn ret.get('all_parameters')
"
-------------------------------------------------------------------------
"Recom
PRs: 51034, 54101"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils.six import string_types
"
-------------------------------------------------------------------------
"from ansible.module_utils.six import string_types

"
-------------------------------------------------------------------------
"from ansible.module_utils.six import string_types

"
-------------------------------------------------------------------------
"Recom
PRs: 53792, 53811"
-------------------------------------------------------------------------
=========================================================================
"plugins_data['plugins'] = {}

"
-------------------------------------------------------------------------
"if section == self.config.prelude_name:
    if not isinstance(lines, string_types):
        errors.append((fragment.path, 0, 0, 'section ""%s"" must be type str not %s' % (section, type(lines).__name__)))
else:
    # doesn't account for prelude but only the RM should be adding those
    if not isinstance(lines, list):
        errors.append((fragment.path, 0, 0, 'section ""%s"" must be type list not %s' % (section, type(lines).__name__)))

    if section not in self.config.sections:
        errors.append((fragment.path, 0, 0, 'invalid section: %s' % section))
        if not isinstance(line, string_types):
            errors.append((fragment.path, 0, 0, 'section ""%s"" list items must be type str not %s' % (section, type(line).__name__)))
            continue

elif isinstance(lines, string_types):
"
-------------------------------------------------------------------------
"if section == self.config.prelude_name:
    if not isinstance(lines, string_types):
        errors.append((fragment.path, 0, 0, 'section ""%s"" must be type str not %s' % (section, type(lines).__name__)))
else:
    # doesn't account for prelude but only the RM should be adding those
    if not isinstance(lines, list):
        errors.append((fragment.path, 0, 0, 'section ""%s"" must be type list not %s' % (section, type(lines).__name__)))

    if section not in self.config.sections:
        errors.append((fragment.path, 0, 0, 'invalid section: %s' % section))
        if not isinstance(line, string_types):
            errors.append((fragment.path, 0, 0, 'section ""%s"" list items must be type str not %s' % (section, type(line).__name__)))
            continue

elif isinstance(lines, string_types):
"
-------------------------------------------------------------------------
"Recom
PRs: 53792, 53811"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils.six import string_types
"
-------------------------------------------------------------------------
"from ansible.module_utils.six import string_types

"
-------------------------------------------------------------------------
"from ansible.module_utils.six import string_types

"
-------------------------------------------------------------------------
"Recom
PRs: 53792, 53810"
-------------------------------------------------------------------------
=========================================================================
"plugins_data['plugins'] = {}

"
-------------------------------------------------------------------------
"if section == self.config.prelude_name:
    if not isinstance(lines, string_types):
        errors.append((fragment.path, 0, 0, 'section ""%s"" must be type str not %s' % (section, type(lines).__name__)))
else:
    # doesn't account for prelude but only the RM should be adding those
    if not isinstance(lines, list):
        errors.append((fragment.path, 0, 0, 'section ""%s"" must be type list not %s' % (section, type(lines).__name__)))

    if section not in self.config.sections:
        errors.append((fragment.path, 0, 0, 'invalid section: %s' % section))
        if not isinstance(line, string_types):
            errors.append((fragment.path, 0, 0, 'section ""%s"" list items must be type str not %s' % (section, type(line).__name__)))
            continue

elif isinstance(lines, string_types):
"
-------------------------------------------------------------------------
"if section == self.config.prelude_name:
    if not isinstance(lines, string_types):
        errors.append((fragment.path, 0, 0, 'section ""%s"" must be type str not %s' % (section, type(lines).__name__)))
else:
    # doesn't account for prelude but only the RM should be adding those
    if not isinstance(lines, list):
        errors.append((fragment.path, 0, 0, 'section ""%s"" must be type list not %s' % (section, type(lines).__name__)))

    if section not in self.config.sections:
        errors.append((fragment.path, 0, 0, 'invalid section: %s' % section))
        if not isinstance(line, string_types):
            errors.append((fragment.path, 0, 0, 'section ""%s"" list items must be type str not %s' % (section, type(line).__name__)))
            continue

elif isinstance(lines, string_types):
"
-------------------------------------------------------------------------
"Recom
PRs: 53792, 53810"
-------------------------------------------------------------------------
=========================================================================
"- Tested with C(op) version 0.5.5
"
-------------------------------------------------------------------------
"- C(op) 1Password command line utility (v0.5.5). See U(https://support.1password.com/command-line/)
"
-------------------------------------------------------------------------
"- C(op) 1Password command line utility (v0.5.5). See U(https://support.1password.com/command-line/)
"
-------------------------------------------------------------------------
"Recom
PRs: 51953, 53657"
-------------------------------------------------------------------------
=========================================================================
"if self.token:
    # Adds the session token to all commands if we're logged in.
    args = [to_bytes('--session=')  self.token]

"
-------------------------------------------------------------------------
"self.token = None
if self.token:
    # Adds the session token to all commands if we're logged in.
    args = [to_bytes('--session=')  self.token]



"
-------------------------------------------------------------------------
"self.token = None
if self.token:
    # Adds the session token to all commands if we're logged in.
    args = [to_bytes('--session=')  self.token]



"
-------------------------------------------------------------------------
"Recom
PRs: 51953, 53657"
-------------------------------------------------------------------------
=========================================================================
"return {'document': document[1].strip()}
"
-------------------------------------------------------------------------
"self.token = None
if self.token:
    # Adds the session token to all commands if we're logged in.
    args = [to_bytes('--session=')  self.token]



"
-------------------------------------------------------------------------
"self.token = None
if self.token:
    # Adds the session token to all commands if we're logged in.
    args = [to_bytes('--session=')  self.token]



"
-------------------------------------------------------------------------
"Recom
PRs: 51953, 53657"
-------------------------------------------------------------------------
=========================================================================
"status_down = self.client.check_if_swarm_node_is_down(node_id=self.node_id, repeat_check=5)
"
-------------------------------------------------------------------------
"node_info = self.client.inspect_node(node_id=self.node_id)
"
-------------------------------------------------------------------------
"node_info = self.client.inspect_node(node_id=self.node_id)
"
-------------------------------------------------------------------------
"Recom
PRs: 53503, 53557"
-------------------------------------------------------------------------
=========================================================================
"self.client.remove_node(node_id=self.node_id, force=self.force)
"
-------------------------------------------------------------------------
"if _x > 0:
    sleep(5)
"
-------------------------------------------------------------------------
"if _x > 0:
    sleep(5)
"
-------------------------------------------------------------------------
"Recom
PRs: 53503, 53557"
-------------------------------------------------------------------------
=========================================================================
"# -*- coding: utf-8 -*-
# Copyright (c) 2019 Ansible Project
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)

from __future__ import absolute_import, division, print_function
__metaclass__ = type


from units.compat.mock import Mock
from ansible.module_utils.facts.system.distribution import DistributionFiles


def mock_module():
mock_module = Mock()
mock_module.params = {'gather_subset': ['all'],
                      'gather_timeout': 5,
                      'filter': '*'}
mock_module.get_bin_path = Mock(return_value=None)
return mock_module


test_parse_distribution_file_clear_linux():
test_input = {
    'name': 'Clearlinux',
    'data': 'NAME=""Clear Linux OS""\nVERSION=1\nID=clear-linux-os\nID_LIKE=clear-linux-os\nVERSION_ID=28120\nPRETTY_NAME=""Clear Linux OS""\nANSI_COLOR=""1;35""'
            '\nHOME_URL=""https://clearlinux.org""\nSUPPORT_URL=""https://clearlinux.org""\nBUG_REPORT_URL=""mailto:dev@lists.clearlinux.org""',
    'path': '/usr/lib/os-release',
    'collected_facts': None,
}

result = (
    True,
    {
        'distribution': 'Clear Linux OS',
        'distribution_major_version': '28120',
        'distribution_release': 'clear-linux-os',
        'distribution_version': '28120'
    }
)

distribution = DistributionFiles(module=mock_module())
assert result == distribution.parse_distribution_file_ClearLinux(**test_input)


test_parse_distribution_file_clear_linux_no_match():
# Test against data from Linux Mint and CoreOS to ensure we do not get a reported
# match from parse_distribution_file_ClearLinux()

scenarios = [
    {
        # CoreOS
        'case': {
            'name': 'Clearlinux',
            'data': 'NAME=""Container Linux by CoreOS""\nID=coreos\nVERSION=1911.5.0\nVERSION_ID=1911.5.0\nBUILD_ID=2018-12-15-2317\nPRETTY_NAME=""Container L'
                    'inux by CoreOS 1911.5.0 (Rhyolite)""\nANSI_COLOR=""38;5;75""\nHOME_URL=""https://coreos.com/""\nBUG_REPORT_URL=""https://issues.coreos.com""'
                    '\nCOREOS_BOARD=""amd64-usr""',
            'path': '/usr/lib/os-release',
            'collected_facts': None,
        },
        'result': (False, {}),
    },
    {
        # Linux Mint
        'case': {
            'name': 'Clearlinux',
            'data': 'NAME=""Linux Mint""\nVERSION=""19.1 (Tessa)""\nID=linuxmint\nID_LIKE=ubuntu\nPRETTY_NAME=""Linux Mint 19.1""\nVERSION_ID=""19.1""\nHOME_URL=""h'
                    'ttps://www.linuxmint.com/""\nSUPPORT_URL=""https://forums.ubuntu.com/""\nBUG_REPORT_URL=""http://linuxmint-troubleshooting-guide.readthedo'
                    'cs.io/en/latest/""\nPRIVACY_POLICY_URL=""https://www.linuxmint.com/""\nVERSION_CODENAME=tessa\nUBUNTU_CODENAME=bionic',
            'path': '/usr/lib/os-release',
            'collected_facts': None,
        },
        'result': (False, {}),
    },
]

distribution = DistributionFiles(module=mock_module())
for scenario in scenarios:
    assert scenario['result'] == distribution.parse_distribution_file_ClearLinux(**scenario['case'])
"
-------------------------------------------------------------------------
"# -*- coding: utf-8 -*-
# Copyright (c) 2019 Ansible Project
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)

from __future__ import absolute_import, division, print_function
__metaclass__ = type


from ansible.compat.tests.mock import Mock
from ansible.module_utils.facts.system.distribution import DistributionFiles


def mock_module():
mock_module = Mock()
mock_module.params = {'gather_subset': ['all'],
                      'gather_timeout': 5,
                      'filter': '*'}
mock_module.get_bin_path = Mock(return_value=None)
return mock_module


test_parse_distribution_file_clear_linux():
test_input = {
    'name': 'Clearlinux',
    'data': 'NAME=""Clear Linux OS""\nVERSION=1\nID=clear-linux-os\nID_LIKE=clear-linux-os\nVERSION_ID=28120\nPRETTY_NAME=""Clear Linux OS""\nANSI_COLOR=""1;35""'
            '\nHOME_URL=""https://clearlinux.org""\nSUPPORT_URL=""https://clearlinux.org""\nBUG_REPORT_URL=""mailto:dev@lists.clearlinux.org""',
    'path': '/usr/lib/os-release',
    'collected_facts': None,
}

result = (
    True,
    {
        'distribution': 'Clear Linux OS',
        'distribution_major_version': '28120',
        'distribution_release': 'clear-linux-os',
        'distribution_version': '28120'
    }
)

distribution = DistributionFiles(module=mock_module())
assert result == distribution.parse_distribution_file_ClearLinux(**test_input)


test_parse_distribution_file_clear_linux_no_match():
# Test against data from Linux Mint and CoreOS to ensure we do not get a reported
# match from parse_distribution_file_ClearLinux()

scenarios = [
    {
        # CoreOS
        'case': {
            'name': 'Clearlinux',
            'data': 'NAME=""Container Linux by CoreOS""\nID=coreos\nVERSION=1911.5.0\nVERSION_ID=1911.5.0\nBUILD_ID=2018-12-15-2317\nPRETTY_NAME=""Container L'
                    'inux by CoreOS 1911.5.0 (Rhyolite)""\nANSI_COLOR=""38;5;75""\nHOME_URL=""https://coreos.com/""\nBUG_REPORT_URL=""https://issues.coreos.com""'
                    '\nCOREOS_BOARD=""amd64-usr""',
            'path': '/usr/lib/os-release',
            'collected_facts': None,
        },
        'result': (False, {}),
    },
    {
        # Linux Mint
        'case': {
            'name': 'Clearlinux',
            'data': 'NAME=""Linux Mint""\nVERSION=""19.1 (Tessa)""\nID=linuxmint\nID_LIKE=ubuntu\nPRETTY_NAME=""Linux Mint 19.1""\nVERSION_ID=""19.1""\nHOME_URL=""h'
                    'ttps://www.linuxmint.com/""\nSUPPORT_URL=""https://forums.ubuntu.com/""\nBUG_REPORT_URL=""http://linuxmint-troubleshooting-guide.readthedo'
                    'cs.io/en/latest/""\nPRIVACY_POLICY_URL=""https://www.linuxmint.com/""\nVERSION_CODENAME=tessa\nUBUNTU_CODENAME=bionic',
            'path': '/usr/lib/os-release',
            'collected_facts': None,
        },
        'result': (False, {}),
    },
]

distribution = DistributionFiles(module=mock_module())
for scenario in scenarios:
    assert scenario['result'] == distribution.parse_distribution_file_ClearLinux(**scenario['case'])
"
-------------------------------------------------------------------------
"# -*- coding: utf-8 -*-
# Copyright (c) 2019 Ansible Project
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)

from __future__ import absolute_import, division, print_function
__metaclass__ = type


from ansible.compat.tests.mock import Mock
from ansible.module_utils.facts.system.distribution import DistributionFiles


def mock_module():
mock_module = Mock()
mock_module.params = {'gather_subset': ['all'],
                      'gather_timeout': 5,
                      'filter': '*'}
mock_module.get_bin_path = Mock(return_value=None)
return mock_module


test_parse_distribution_file_clear_linux():
test_input = {
    'name': 'Clearlinux',
    'data': 'NAME=""Clear Linux OS""\nVERSION=1\nID=clear-linux-os\nID_LIKE=clear-linux-os\nVERSION_ID=28120\nPRETTY_NAME=""Clear Linux OS""\nANSI_COLOR=""1;35""'
            '\nHOME_URL=""https://clearlinux.org""\nSUPPORT_URL=""https://clearlinux.org""\nBUG_REPORT_URL=""mailto:dev@lists.clearlinux.org""',
    'path': '/usr/lib/os-release',
    'collected_facts': None,
}

result = (
    True,
    {
        'distribution': 'Clear Linux OS',
        'distribution_major_version': '28120',
        'distribution_release': 'clear-linux-os',
        'distribution_version': '28120'
    }
)

distribution = DistributionFiles(module=mock_module())
assert result == distribution.parse_distribution_file_ClearLinux(**test_input)


test_parse_distribution_file_clear_linux_no_match():
# Test against data from Linux Mint and CoreOS to ensure we do not get a reported
# match from parse_distribution_file_ClearLinux()

scenarios = [
    {
        # CoreOS
        'case': {
            'name': 'Clearlinux',
            'data': 'NAME=""Container Linux by CoreOS""\nID=coreos\nVERSION=1911.5.0\nVERSION_ID=1911.5.0\nBUILD_ID=2018-12-15-2317\nPRETTY_NAME=""Container L'
                    'inux by CoreOS 1911.5.0 (Rhyolite)""\nANSI_COLOR=""38;5;75""\nHOME_URL=""https://coreos.com/""\nBUG_REPORT_URL=""https://issues.coreos.com""'
                    '\nCOREOS_BOARD=""amd64-usr""',
            'path': '/usr/lib/os-release',
            'collected_facts': None,
        },
        'result': (False, {}),
    },
    {
        # Linux Mint
        'case': {
            'name': 'Clearlinux',
            'data': 'NAME=""Linux Mint""\nVERSION=""19.1 (Tessa)""\nID=linuxmint\nID_LIKE=ubuntu\nPRETTY_NAME=""Linux Mint 19.1""\nVERSION_ID=""19.1""\nHOME_URL=""h'
                    'ttps://www.linuxmint.com/""\nSUPPORT_URL=""https://forums.ubuntu.com/""\nBUG_REPORT_URL=""http://linuxmint-troubleshooting-guide.readthedo'
                    'cs.io/en/latest/""\nPRIVACY_POLICY_URL=""https://www.linuxmint.com/""\nVERSION_CODENAME=tessa\nUBUNTU_CODENAME=bionic',
            'path': '/usr/lib/os-release',
            'collected_facts': None,
        },
        'result': (False, {}),
    },
]

distribution = DistributionFiles(module=mock_module())
for scenario in scenarios:
    assert scenario['result'] == distribution.parse_distribution_file_ClearLinux(**scenario['case'])
"
-------------------------------------------------------------------------
"Recom
PRs: 53298, 53541"
-------------------------------------------------------------------------
=========================================================================
"_mysql_cursor_param = 'cursor'
    _mysql_cursor_param = 'cursorclass'
"
-------------------------------------------------------------------------
"import MySQLdb.cursors
"
-------------------------------------------------------------------------
"import MySQLdb.cursors
"
-------------------------------------------------------------------------
"Recom
PRs: 47809, 53519"
-------------------------------------------------------------------------
=========================================================================
"kind: ssh
"
-------------------------------------------------------------------------
"kind: ssh

me: Create a valid SCM credential from a private_key file
wer_credential:
name: SCM Credential
organization: Default
state: present
kind: scm
username: joe
password: secret
ssh_key_data: ""{{ lookup('file', '/tmp/id_rsa') }}""
ssh_key_unlock: ""passphrase""

me: Add Credential Into Tower
wer_credential:
name: Workshop Credential
ssh_key_data: ""/home/{{ansible_user}}/.ssh/aws-private.pem""
kind: ssh
organization: Default
tower_username: admin
tower_password: ansible
tower_host: https://localhost
n_once: true
legate_to: localhost
"
-------------------------------------------------------------------------
"kind: ssh

me: Create a valid SCM credential from a private_key file
wer_credential:
name: SCM Credential
organization: Default
state: present
kind: scm
username: joe
password: secret
ssh_key_data: ""{{ lookup('file', '/tmp/id_rsa') }}""
ssh_key_unlock: ""passphrase""

me: Add Credential Into Tower
wer_credential:
name: Workshop Credential
ssh_key_data: ""/home/{{ansible_user}}/.ssh/aws-private.pem""
kind: ssh
organization: Default
tower_username: admin
tower_password: ansible
tower_host: https://localhost
n_once: true
legate_to: localhost
"
-------------------------------------------------------------------------
"Recom
PRs: 47224, 53411"
-------------------------------------------------------------------------
=========================================================================
"swarm_service=facts,
"
-------------------------------------------------------------------------
"client.module.exit_json(
    msg=msg,
    changed=changed,
    rebuilt=rebuilt,
    changes=changes,
    swarm_service=facts,
    ansible_docker_service=facts  # kept for backwards-compatibility, will be removed in Ansible 2.8
)
"
-------------------------------------------------------------------------
"client.module.exit_json(
    msg=msg,
    changed=changed,
    rebuilt=rebuilt,
    changes=changes,
    swarm_service=facts,
    ansible_docker_service=facts  # kept for backwards-compatibility, will be removed in Ansible 2.8
)
"
-------------------------------------------------------------------------
"Recom
PRs: 53229, 53408"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils.six import string_types, integer_types
"
-------------------------------------------------------------------------
"from ansible.module_utils.six import string_types, integer_types
# Simple type=int with a large value (will be of type long under Python 2)
({'arg': {'type': 'int'}}, {'arg': 18765432109876543210}, 18765432109876543210),
# Simple type=list, elements=int
({'arg': {'type': 'list', 'elements': 'int'}}, {'arg': [42, 32]}, [42, 32]),
"
-------------------------------------------------------------------------
"from ansible.module_utils.six import string_types, integer_types
# Simple type=int with a large value (will be of type long under Python 2)
({'arg': {'type': 'int'}}, {'arg': 18765432109876543210}, 18765432109876543210),
# Simple type=list, elements=int
({'arg': {'type': 'list', 'elements': 'int'}}, {'arg': [42, 32]}, [42, 32]),
"
-------------------------------------------------------------------------
"Recom
PRs: 53289, 53329"
-------------------------------------------------------------------------
=========================================================================
"# Simple type=int with a large value (will be of type long under Python 2)
({'arg': {'type': 'int'}}, {'arg': 18765432109876543210}, 18765432109876543210),
"
-------------------------------------------------------------------------
"if argspec['arg']['type'] == 'int':
    type_ = integer_types
else:
    type_ = getattr(builtins, argspec['arg']['type'])
"
-------------------------------------------------------------------------
"if argspec['arg']['type'] == 'int':
    type_ = integer_types
else:
    type_ = getattr(builtins, argspec['arg']['type'])
"
-------------------------------------------------------------------------
"Recom
PRs: 53289, 53329"
-------------------------------------------------------------------------
=========================================================================
"if argspec['arg']['type'] == 'int':
    type_ = integer_types
else:
    type_ = getattr(builtins, argspec['arg']['type'])
"
-------------------------------------------------------------------------
"@pytest.mark.parametrize('stdin', [{'arg': 42}, {'arg': 18765432109876543210}], indirect=['stdin'])
assert isinstance(am.params['arg'], integer_types)
"
-------------------------------------------------------------------------
"@pytest.mark.parametrize('stdin', [{'arg': 42}, {'arg': 18765432109876543210}], indirect=['stdin'])
assert isinstance(am.params['arg'], integer_types)
"
-------------------------------------------------------------------------
"Recom
PRs: 53289, 53329"
-------------------------------------------------------------------------
=========================================================================
"- This is only used by the C(selfsigned) provider.
"
-------------------------------------------------------------------------
"- Version of the C(selfsigned) certificate.
- Nowadays it should almost always be C(3).
- This is only used by the C(selfsigned) provider.
- This is only used by the C(selfsigned) provider.
- This is only used by the C(selfsigned) provider.
- This is only used by the C(selfsigned) provider.
- This is only used by the C(ownca) provider.
- This is only used by the C(ownca) provider.
- This is only used by the C(ownca) provider.
- This is only used by the C(ownca) provider.
- Version of the C(ownca) certificate.
- Nowadays it should almost always be C(3).
- This is only used by the C(ownca) provider.
- This is only used by the C(ownca) provider.
- This is only used by the C(ownca) provider.
- This is only used by the C(acme) provider.
- This is only used by the C(acme) provider.
- This is only used by the C(acme) provider.
- This is only used by the C(assertonly) provider.
- If you need to specify more than one value with the same key, use a list as value.
- This is only used by the C(assertonly) provider.
- This is only used by the C(assertonly) provider.
- This is only used by the C(assertonly) provider.
- This is only used by the C(assertonly) provider.
- Checks if the certificate is expired/not expired at the time the module is executed.
- This is only used by the C(assertonly) provider.
- The version of the certificate.
- Nowadays it should almost always be 3.
- This is only used by the C(assertonly) provider.
- The certificate must be valid at this point in time.
- The timestamp is formatted as an ASN.1 TIME.
- This is only used by the C(assertonly) provider.
- The certificate must be invalid at this point in time.
- The timestamp is formatted as an ASN.1 TIME.
- This is only used by the C(assertonly) provider.
- The certificate must start to become valid at this point in time.
- The timestamp is formatted as an ASN.1 TIME.
- This is only used by the C(assertonly) provider.
- The certificate must expire at this point in time.
- The timestamp is formatted as an ASN.1 TIME.
- This is only used by the C(assertonly) provider.
- This is only used by the C(assertonly) provider.
- This is only used by the C(assertonly) provider.
"
-------------------------------------------------------------------------
"- Version of the C(selfsigned) certificate.
- Nowadays it should almost always be C(3).
- This is only used by the C(selfsigned) provider.
- This is only used by the C(selfsigned) provider.
- This is only used by the C(selfsigned) provider.
- This is only used by the C(selfsigned) provider.
- This is only used by the C(ownca) provider.
- This is only used by the C(ownca) provider.
- This is only used by the C(ownca) provider.
- This is only used by the C(ownca) provider.
- Version of the C(ownca) certificate.
- Nowadays it should almost always be C(3).
- This is only used by the C(ownca) provider.
- This is only used by the C(ownca) provider.
- This is only used by the C(ownca) provider.
- This is only used by the C(acme) provider.
- This is only used by the C(acme) provider.
- This is only used by the C(acme) provider.
- This is only used by the C(assertonly) provider.
- If you need to specify more than one value with the same key, use a list as value.
- This is only used by the C(assertonly) provider.
- This is only used by the C(assertonly) provider.
- This is only used by the C(assertonly) provider.
- This is only used by the C(assertonly) provider.
- Checks if the certificate is expired/not expired at the time the module is executed.
- This is only used by the C(assertonly) provider.
- The version of the certificate.
- Nowadays it should almost always be 3.
- This is only used by the C(assertonly) provider.
- The certificate must be valid at this point in time.
- The timestamp is formatted as an ASN.1 TIME.
- This is only used by the C(assertonly) provider.
- The certificate must be invalid at this point in time.
- The timestamp is formatted as an ASN.1 TIME.
- This is only used by the C(assertonly) provider.
- The certificate must start to become valid at this point in time.
- The timestamp is formatted as an ASN.1 TIME.
- This is only used by the C(assertonly) provider.
- The certificate must expire at this point in time.
- The timestamp is formatted as an ASN.1 TIME.
- This is only used by the C(assertonly) provider.
- This is only used by the C(assertonly) provider.
- This is only used by the C(assertonly) provider.
"
-------------------------------------------------------------------------
"Recom
PRs: 53208, 53283"
-------------------------------------------------------------------------
=========================================================================
"- This is only used by the C(selfsigned) provider.
"
-------------------------------------------------------------------------
"- This is only used by the C(assertonly) provider.
- This is only used by the C(assertonly) provider.
"
-------------------------------------------------------------------------
"- This is only used by the C(assertonly) provider.
- This is only used by the C(assertonly) provider.
"
-------------------------------------------------------------------------
"Recom
PRs: 53208, 53283"
-------------------------------------------------------------------------
=========================================================================
"- This is only used by the C(selfsigned) provider.
"
-------------------------------------------------------------------------
"- This is only used by the C(assertonly) provider.
- This is only used by the C(assertonly) provider.
"
-------------------------------------------------------------------------
"- This is only used by the C(assertonly) provider.
- This is only used by the C(assertonly) provider.
"
-------------------------------------------------------------------------
"Recom
PRs: 53208, 53283"
-------------------------------------------------------------------------
=========================================================================
"- This is only used by the C(selfsigned) provider.
"
-------------------------------------------------------------------------
"- This is only used by the C(assertonly) provider.
"
-------------------------------------------------------------------------
"- This is only used by the C(assertonly) provider.
"
-------------------------------------------------------------------------
"Recom
PRs: 53208, 53283"
-------------------------------------------------------------------------
=========================================================================
"- This is only used by the C(ownca) provider.
- This is only used by the C(ownca) provider.
- This is only used by the C(ownca) provider.
- This is only used by the C(ownca) provider.
"
-------------------------------------------------------------------------
"
# provider: assertonly
"
-------------------------------------------------------------------------
"
# provider: assertonly
"
-------------------------------------------------------------------------
"Recom
PRs: 53208, 53283"
-------------------------------------------------------------------------
=========================================================================
"if module.check_mode:
    if os.path.exists(tmpsrc):
        os.remove(tmpsrc)
    result['changed'] = ('checksum_dest' not in result or
                         result['checksum_src'] != result['checksum_dest'])
    module.exit_json(msg=info.get('msg', ''), **result)

"
-------------------------------------------------------------------------
"if module.check_mode:
    if os.path.exists(tmpsrc):
        os.remove(tmpsrc)
    changed = (checksum_dest is None or
               checksum_src != checksum_dest)
    res_args = dict(url=url, changed=changed, dest=dest, src=tmpsrc,
                    checksum_dest=checksum_dest, checksum_src=checksum_src,
                    msg=info.get('msg', ''))
    module.exit_json(**res_args)

"
-------------------------------------------------------------------------
"if module.check_mode:
    if os.path.exists(tmpsrc):
        os.remove(tmpsrc)
    changed = (checksum_dest is None or
               checksum_src != checksum_dest)
    res_args = dict(url=url, changed=changed, dest=dest, src=tmpsrc,
                    checksum_dest=checksum_dest, checksum_src=checksum_src,
                    msg=info.get('msg', ''))
    module.exit_json(**res_args)

"
-------------------------------------------------------------------------
"Recom
PRs: 53070, 53172"
-------------------------------------------------------------------------
=========================================================================
"algorithms = ('md5', 'sha1', 'sha224', 'sha256', 'sha384', 'sha512')
"
-------------------------------------------------------------------------
"AVAILABLE_HASH_ALGORITHMS.pop('md5', None)
"
-------------------------------------------------------------------------
"AVAILABLE_HASH_ALGORITHMS.pop('md5', None)
"
-------------------------------------------------------------------------
"Recom
PRs: 52994, 53135"
-------------------------------------------------------------------------
=========================================================================
"- name: Add a new VLAN pool range
aci_encap_pool_range:
  pool_allocation_mode: static
  range_name: anstest
  range_start: 20
  range_end: 40
  allocation_mode: inherit
name: Remove a VLAN pool range
aci_encap_pool_range:
  pool_allocation_mode: static
  range_name: anstest
  range_start: 20
  range_end: 40
aci_encap_pool_range:
  pool_allocation_mode: static
  range_name: anstest
  range_start: 20
  range_end: 50
name: Query a VLAN pool for ranges by range_name
aci_encap_pool_range:
  host: apic
  username: admin
  password: SomeSecretPassword
  pool_type: vlan
  range_name: anstest
  state: query
delegate_to: localhost
register: query_result

name: Query a VLAN pool for ranges by range_start
aci_encap_pool_range:
  host: apic
  username: admin
  password: SomeSecretPassword
  pool_type: vlan
  range_start: 20
  state: query
delegate_to: localhost
register: query_result

name: Query a VLAN pool for ranges by range_start and range_end
aci_encap_pool_range:
  range_start: 20
  range_end: 40
name: Query all VLAN pool ranges
aci_encap_pool_range:
"
-------------------------------------------------------------------------
"- name: Add a new VLAN pool range
aci_encap_pool_range:
  pool_allocation_mode: static
  range_name: anstest
  range_start: 20
  range_end: 40
  allocation_mode: inherit
name: Remove a VLAN pool range
aci_encap_pool_range:
  pool_allocation_mode: static
  range_name: anstest
  range_start: 20
  range_end: 40
name: Query a VLAN range
aci_encap_pool_range:
  pool_allocation_mode: static
  range_name: anstest
  range_start: 20
  range_end: 50
name: Query a VLAN pool for ranges by range_name
aci_encap_pool_range:
  host: apic
  username: admin
  password: SomeSecretPassword
  pool_type: vlan
  range_name: anstest
  state: query
delegate_to: localhost
register: query_result

name: Query a VLAN pool for ranges by range_start
aci_encap_pool_range:
  host: apic
  username: admin
  password: SomeSecretPassword
  pool_type: vlan
  range_start: 20
  state: query
delegate_to: localhost
register: query_result

name: Query a VLAN pool for ranges by range_start and range_end
aci_encap_pool_range:
  range_start: 20
  range_end: 40
name: Query all VLAN pool ranges
aci_encap_pool_range:
"
-------------------------------------------------------------------------
"- name: Add a new VLAN pool range
aci_encap_pool_range:
  pool_allocation_mode: static
  range_name: anstest
  range_start: 20
  range_end: 40
  allocation_mode: inherit
name: Remove a VLAN pool range
aci_encap_pool_range:
  pool_allocation_mode: static
  range_name: anstest
  range_start: 20
  range_end: 40
name: Query a VLAN range
aci_encap_pool_range:
  pool_allocation_mode: static
  range_name: anstest
  range_start: 20
  range_end: 50
name: Query a VLAN pool for ranges by range_name
aci_encap_pool_range:
  host: apic
  username: admin
  password: SomeSecretPassword
  pool_type: vlan
  range_name: anstest
  state: query
delegate_to: localhost
register: query_result

name: Query a VLAN pool for ranges by range_start
aci_encap_pool_range:
  host: apic
  username: admin
  password: SomeSecretPassword
  pool_type: vlan
  range_start: 20
  state: query
delegate_to: localhost
register: query_result

name: Query a VLAN pool for ranges by range_start and range_end
aci_encap_pool_range:
  range_start: 20
  range_end: 40
name: Query all VLAN pool ranges
aci_encap_pool_range:
"
-------------------------------------------------------------------------
"Recom
PRs: 52958, 52965"
-------------------------------------------------------------------------
=========================================================================
"- name: Add a new VLAN pool range
aci_encap_pool_range:
  pool_allocation_mode: static
  range_name: anstest
  range_start: 20
  range_end: 40
  allocation_mode: inherit
name: Remove a VLAN pool range
aci_encap_pool_range:
  pool_allocation_mode: static
  range_name: anstest
  range_start: 20
  range_end: 40
aci_encap_pool_range:
  pool_allocation_mode: static
  range_name: anstest
  range_start: 20
  range_end: 50
name: Query a VLAN pool for ranges by range_name
aci_encap_pool_range:
  host: apic
  username: admin
  password: SomeSecretPassword
  pool_type: vlan
  range_name: anstest
  state: query
delegate_to: localhost
register: query_result

name: Query a VLAN pool for ranges by range_start
aci_encap_pool_range:
  host: apic
  username: admin
  password: SomeSecretPassword
  pool_type: vlan
  range_start: 20
  state: query
delegate_to: localhost
register: query_result

name: Query a VLAN pool for ranges by range_start and range_end
aci_encap_pool_range:
  range_start: 20
  range_end: 40
name: Query all VLAN pool ranges
aci_encap_pool_range:
"
-------------------------------------------------------------------------
"- name: Add a new VLAN pool range
aci_encap_pool_range:
  pool_allocation_mode: static
  range_name: anstest
  range_start: 20
  range_end: 40
  allocation_mode: inherit
name: Remove a VLAN pool range
aci_encap_pool_range:
  pool_allocation_mode: static
  range_name: anstest
  range_start: 20
  range_end: 40
name: Query a VLAN range
aci_encap_pool_range:
  pool_allocation_mode: static
  range_name: anstest
  range_start: 20
  range_end: 50
name: Query a VLAN pool for ranges by range_name
aci_encap_pool_range:
  host: apic
  username: admin
  password: SomeSecretPassword
  pool_type: vlan
  range_name: anstest
  state: query
delegate_to: localhost
register: query_result

name: Query a VLAN pool for ranges by range_start
aci_encap_pool_range:
  host: apic
  username: admin
  password: SomeSecretPassword
  pool_type: vlan
  range_start: 20
  state: query
delegate_to: localhost
register: query_result

name: Query a VLAN pool for ranges by range_start and range_end
aci_encap_pool_range:
  range_start: 20
  range_end: 40
name: Query all VLAN pool ranges
aci_encap_pool_range:
"
-------------------------------------------------------------------------
"- name: Add a new VLAN pool range
aci_encap_pool_range:
  pool_allocation_mode: static
  range_name: anstest
  range_start: 20
  range_end: 40
  allocation_mode: inherit
name: Remove a VLAN pool range
aci_encap_pool_range:
  pool_allocation_mode: static
  range_name: anstest
  range_start: 20
  range_end: 40
name: Query a VLAN range
aci_encap_pool_range:
  pool_allocation_mode: static
  range_name: anstest
  range_start: 20
  range_end: 50
name: Query a VLAN pool for ranges by range_name
aci_encap_pool_range:
  host: apic
  username: admin
  password: SomeSecretPassword
  pool_type: vlan
  range_name: anstest
  state: query
delegate_to: localhost
register: query_result

name: Query a VLAN pool for ranges by range_start
aci_encap_pool_range:
  host: apic
  username: admin
  password: SomeSecretPassword
  pool_type: vlan
  range_start: 20
  state: query
delegate_to: localhost
register: query_result

name: Query a VLAN pool for ranges by range_start and range_end
aci_encap_pool_range:
  range_start: 20
  range_end: 40
name: Query all VLAN pool ranges
aci_encap_pool_range:
"
-------------------------------------------------------------------------
"Recom
PRs: 52958, 52963"
-------------------------------------------------------------------------
=========================================================================
"import locale
locale.setlocale(locale.LC_ALL, '')
"
-------------------------------------------------------------------------
"
LVOL_ENV_VARS = dict(
# make sure we use the C locale when running lvol-related commands
LANG='C',
LC_ALL='C',
LC_MESSAGES='C',
LC_CTYPE='C',

"
-------------------------------------------------------------------------
"
LVOL_ENV_VARS = dict(
# make sure we use the C locale when running lvol-related commands
LANG='C',
LC_ALL='C',
LC_MESSAGES='C',
LC_CTYPE='C',

"
-------------------------------------------------------------------------
"Recom
PRs: 36811, 52836"
-------------------------------------------------------------------------
=========================================================================
"'size': locale.atof(parts[1]),
"
-------------------------------------------------------------------------
"'size': float(parts[1]),
"
-------------------------------------------------------------------------
"'size': float(parts[1]),
"
-------------------------------------------------------------------------
"Recom
PRs: 36811, 52836"
-------------------------------------------------------------------------
=========================================================================
"'size': locale.atof(parts[1]),
'free': locale.atof(parts[2]),
'ext_size': locale.atof(parts[3])
"
-------------------------------------------------------------------------
"'size': float(parts[1]),
'free': float(parts[2]),
'ext_size': float(parts[3])
"
-------------------------------------------------------------------------
"'size': float(parts[1]),
'free': float(parts[2]),
'ext_size': float(parts[3])
"
-------------------------------------------------------------------------
"Recom
PRs: 36811, 52836"
-------------------------------------------------------------------------
=========================================================================
"locale.atof(size)
"
-------------------------------------------------------------------------
"module.run_command_environ_update = LVOL_ENV_VARS

"
-------------------------------------------------------------------------
"module.run_command_environ_update = LVOL_ENV_VARS

"
-------------------------------------------------------------------------
"Recom
PRs: 36811, 52836"
-------------------------------------------------------------------------
=========================================================================
"if locale.atof(size) > this_lv['size']:
elif shrink and locale.atof(size) < this_lv['size']:
    if locale.atof(size) == 0:
"
-------------------------------------------------------------------------
"if float(size) > this_lv['size']:
elif shrink and float(size) < this_lv['size']:
    if float(size) == 0:
"
-------------------------------------------------------------------------
"if float(size) > this_lv['size']:
elif shrink and float(size) < this_lv['size']:
    if float(size) == 0:
"
-------------------------------------------------------------------------
"Recom
PRs: 36811, 52836"
-------------------------------------------------------------------------
=========================================================================
"-  For rebooting systems, use the M(reboot) or M(win_reboot) module.
"
-------------------------------------------------------------------------
"-  For rebooting systems, use the M(reboot) or M(win_reboot) module.
lso:
dule: raw
dule: script
dule: shell
dule: win_command
"
-------------------------------------------------------------------------
"-  For rebooting systems, use the M(reboot) or M(win_reboot) module.
lso:
dule: raw
dule: script
dule: shell
dule: win_command
"
-------------------------------------------------------------------------
"Recom
PRs: 51499, 52192"
-------------------------------------------------------------------------
=========================================================================
"- For rebooting systems, use the M(reboot) or M(win_reboot) module.
"
-------------------------------------------------------------------------
"- An alternative to using inline shell scripts with this module is to use
  the M(script) module possibly together with the M(template) module.
- For rebooting systems, use the M(reboot) or M(win_reboot) module.
ealso:
module: command
module: raw
module: script
"
-------------------------------------------------------------------------
"- An alternative to using inline shell scripts with this module is to use
  the M(script) module possibly together with the M(template) module.
- For rebooting systems, use the M(reboot) or M(win_reboot) module.
ealso:
module: command
module: raw
module: script
"
-------------------------------------------------------------------------
"Recom
PRs: 51499, 52192"
-------------------------------------------------------------------------
=========================================================================
"if params['direction'] not in ['outgoing', 'incoming', 'routed']:
    module.fail_json(msg='For default, direction must be one of ""outgoing"", ""incoming"" and ""routed"".')
"
-------------------------------------------------------------------------
"if params['direction'] not in ['outgoing', 'incoming', 'routed']:
    module.fail_json(msg='For default, direction must be one of ""outgoing"", ""incoming"" and ""routed"".')
if params['direction'] not in ['in', 'out', None]:
    module.fail_json(msg='For rules, direction must be one of ""in"" and ""out"".')
"
-------------------------------------------------------------------------
"if params['direction'] not in ['outgoing', 'incoming', 'routed']:
    module.fail_json(msg='For default, direction must be one of ""outgoing"", ""incoming"" and ""routed"".')
if params['direction'] not in ['in', 'out', None]:
    module.fail_json(msg='For rules, direction must be one of ""in"" and ""out"".')
"
-------------------------------------------------------------------------
"Recom
PRs: 50402, 52027"
-------------------------------------------------------------------------
=========================================================================
"altnames = [altname.strip() for altname in str(altnames_ext).split(',') if altname.strip()]
"
-------------------------------------------------------------------------
"altnames = [altname.strip() for altname in str(altnames_ext).split(',') if altname.strip() if altname.strip()]
"
-------------------------------------------------------------------------
"altnames = [altname.strip() for altname in str(altnames_ext).split(',') if altname.strip() if altname.strip()]
"
-------------------------------------------------------------------------
"Recom
PRs: 51473, 52024"
-------------------------------------------------------------------------
=========================================================================
"res = re.match(""""""GRANT (.) ON (.) TO (['`""]).*\\3@(['`""]).*\\4( IDENTIFIED BY PASSWORD (['`""]).\5)? ?(.*)"""""", grant[0])
if ""WITH GRANT OPTION"" in res.group(7):
if ""REQUIRE SSL"" in res.group(7):
"
-------------------------------------------------------------------------
"res = re.match(""""""GRANT (.) ON (.) TO (['`""]).*\\3@(['`""]).*\\4( IDENTIFIED BY PASSWORD (['`""]).\\6)? ?(.*)"""""", grant[0])
if ""WITH GRANT OPTION"" in res.group(7):
if ""REQUIRE SSL"" in res.group(7):
"
-------------------------------------------------------------------------
"res = re.match(""""""GRANT (.) ON (.) TO (['`""]).*\\3@(['`""]).*\\4( IDENTIFIED BY PASSWORD (['`""]).\\6)? ?(.*)"""""", grant[0])
if ""WITH GRANT OPTION"" in res.group(7):
if ""REQUIRE SSL"" in res.group(7):
"
-------------------------------------------------------------------------
"Recom
PRs: 40092, 51910"
-------------------------------------------------------------------------
=========================================================================
"res = re.match(""""""GRANT (.) ON (.) TO (['`""]).*\\3@(['`""]).*\\4( IDENTIFIED BY PASSWORD (['`""]).\5)? ?(.*)"""""", grant[0])
if ""WITH GRANT OPTION"" in res.group(7):
if ""REQUIRE SSL"" in res.group(7):
"
-------------------------------------------------------------------------
"res = re.match(""""""GRANT (.) ON (.) TO (['`""]).*\\3@(['`""]).*\\4( IDENTIFIED BY PASSWORD (['`""]).\\6)? ?(.*)"""""", grant[0])
if ""WITH GRANT OPTION"" in res.group(7):
if ""REQUIRE SSL"" in res.group(7):
"
-------------------------------------------------------------------------
"res = re.match(""""""GRANT (.) ON (.) TO (['`""]).*\\3@(['`""]).*\\4( IDENTIFIED BY PASSWORD (['`""]).\\6)? ?(.*)"""""", grant[0])
if ""WITH GRANT OPTION"" in res.group(7):
if ""REQUIRE SSL"" in res.group(7):
"
-------------------------------------------------------------------------
"Recom
PRs: 40092, 51909"
-------------------------------------------------------------------------
=========================================================================
"from ansible.errors import (
AnsibleAuthenticationFailure,
AnsibleConnectionFailure,
AnsibleError,
AnsibleFileNotFound,

"
-------------------------------------------------------------------------
"from ansible.errors import (
AnsibleAuthenticationFailure,
AnsibleConnectionFailure,
AnsibleError,
AnsibleFileNotFound,

 ansible.module_utils._text import to_bytes, to_native, to_text
"
-------------------------------------------------------------------------
"from ansible.errors import (
AnsibleAuthenticationFailure,
AnsibleConnectionFailure,
AnsibleError,
AnsibleFileNotFound,

 ansible.module_utils._text import to_bytes, to_native, to_text
"
-------------------------------------------------------------------------
"Recom
PRs: 50776, 51236"
-------------------------------------------------------------------------
=========================================================================
"- name: ansible_ssh_retries
  version_added: '2.7'
"
-------------------------------------------------------------------------
"from ansible.errors import (
AnsibleAuthenticationFailure,
AnsibleConnectionFailure,
AnsibleError,
AnsibleFileNotFound,

"
-------------------------------------------------------------------------
"from ansible.errors import (
AnsibleAuthenticationFailure,
AnsibleConnectionFailure,
AnsibleError,
AnsibleFileNotFound,

"
-------------------------------------------------------------------------
"Recom
PRs: 50776, 51236"
-------------------------------------------------------------------------
=========================================================================
"remaining_retries = remaining_tries - attempt - 1
_handle_error(remaining_retries, cmd[0], return_tuple, self._play_context.no_log, self.host)
= Invalid/incorrect password from sshpass
pt AnsibleAuthenticationFailure as e:
# Raising this exception, which is subclassed from AnsibleConnectionFailure, prevents further retries
raise


"
-------------------------------------------------------------------------
"remaining_retries = remaining_tries - attempt - 1
_handle_error(remaining_retries, cmd[0], return_tuple, self._play_context.no_log, self.host)

break

= Invalid/incorrect password from sshpass
pt AnsibleAuthenticationFailure as e:
# Raising this exception, which is subclassed from AnsibleConnectionFailure, prevents further retries
raise

"
-------------------------------------------------------------------------
"remaining_retries = remaining_tries - attempt - 1
_handle_error(remaining_retries, cmd[0], return_tuple, self._play_context.no_log, self.host)

break

= Invalid/incorrect password from sshpass
pt AnsibleAuthenticationFailure as e:
# Raising this exception, which is subclassed from AnsibleConnectionFailure, prevents further retries
raise

"
-------------------------------------------------------------------------
"Recom
PRs: 50776, 51236"
-------------------------------------------------------------------------
=========================================================================
"from ansible.errors import (
AnsibleAuthenticationFailure,
AnsibleConnectionFailure,
AnsibleError,
AnsibleFileNotFound,

"
-------------------------------------------------------------------------
"from ansible.errors import (
AnsibleAuthenticationFailure,
AnsibleConnectionFailure,
AnsibleError,
AnsibleFileNotFound,

 ansible.module_utils._text import to_bytes, to_native, to_text
"
-------------------------------------------------------------------------
"from ansible.errors import (
AnsibleAuthenticationFailure,
AnsibleConnectionFailure,
AnsibleError,
AnsibleFileNotFound,

 ansible.module_utils._text import to_bytes, to_native, to_text
"
-------------------------------------------------------------------------
"Recom
PRs: 50776, 51235"
-------------------------------------------------------------------------
=========================================================================
"- arg1: ""true""
- arg2: ""whatever""
"
-------------------------------------------------------------------------
"if not isinstance(value, string_types):
    self.client.module.warn(
        ""Non-string value found for env option. ""
        ""Ambiguous env options should be wrapped in quotes to avoid YAML parsing. ""
        ""This will become an error in Ansible 2.8. ""
        ""Key: %s; value will be treated as: %s"" % (name, str(value)))
"
-------------------------------------------------------------------------
"if not isinstance(value, string_types):
    self.client.module.warn(
        ""Non-string value found for env option. ""
        ""Ambiguous env options should be wrapped in quotes to avoid YAML parsing. ""
        ""This will become an error in Ansible 2.8. ""
        ""Key: %s; value will be treated as: %s"" % (name, str(value)))
"
-------------------------------------------------------------------------
"Recom
PRs: 49843, 50899"
-------------------------------------------------------------------------
=========================================================================
"if not differences.empty and self.parameters.force:
"
-------------------------------------------------------------------------
"if differences and self.parameters.force:
"
-------------------------------------------------------------------------
"if differences and self.parameters.force:
"
-------------------------------------------------------------------------
"Recom
PRs: 50663, 50821"
-------------------------------------------------------------------------
=========================================================================
"if not differences.empty and self.parameters.force:
"
-------------------------------------------------------------------------
"if differences and self.parameters.force:
"
-------------------------------------------------------------------------
"if differences and self.parameters.force:
"
-------------------------------------------------------------------------
"Recom
PRs: 50663, 50820"
-------------------------------------------------------------------------
=========================================================================
"
# Some types of 1Password items have a 'password' field directly alongside the 'fields' attribute,
# not inside it, so we need to check there first.
if (field_name in data['details']):
    return {field_name: data['details'][field_name]}

# Otherwise we continue looking inside the 'fields' attribute for the specified field.
else:
    if section_title is None:
        for field_data in data['details'].get('fields', []):
            if field_data.get('name').lower() == field_name.lower():
                return {field_name: field_data.get('value', '')}

    # Not found it yet, so now lets see if there are any sections defined
    # and search through those for the field. If a section was given, we skip
    # any non-matching sections, otherwise we search them all until we find the field.
    for section_data in data['details'].get('sections', []):
        if section_title is not None and section_title.lower() != section_data['title'].lower():
            continue
        for field_data in section_data.get('fields', []):
            if field_data.get('t').lower() == field_name.lower():
                return {field_name: field_data.get('v', '')}
"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_bytes, to_native
class AnsibleModuleError(Exception):
def __init__(self, results):
    self.results = results

def __repr__(self):
    return self.results


"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_bytes, to_native
class AnsibleModuleError(Exception):
def __init__(self, results):
    self.results = results

def __repr__(self):
    return self.results


"
-------------------------------------------------------------------------
"Recom
PRs: 47213, 50160"
-------------------------------------------------------------------------
=========================================================================
"user_password = module.params['user_password']
"
-------------------------------------------------------------------------
"if user_password is None or check_user_password(module, client, user_name, user_password):
user_password = user_password or ''
"
-------------------------------------------------------------------------
"if user_password is None or check_user_password(module, client, user_name, user_password):
user_password = user_password or ''
"
-------------------------------------------------------------------------
"Recom
PRs: 49084, 49973"
-------------------------------------------------------------------------
=========================================================================
"current_boot_time = self.get_system_boot_time(distribution)
en(current_boot_time) == 0 or current_boot_time == previous_boot_time:
raise ValueError(""boot time has not changed"")
test_command(self, distribution, **kwargs):
_command = self._task.args.get('test_command', self._get_value_from_facts('TEST_COMMANDS', distribution, 'DEFAULT_TEST_COMMAND'))
lay.vvv(""{action}: attempting post-reboot test command"".format(action=self._task.action))
lay.debug(""{action}: attempting post-reboot test command '{command}'"".format(action=self._task.action, command=test_command))
"
-------------------------------------------------------------------------
"DEFAULT_SHUTDOWN_COMMAND_ARGS = '-r {delay_min} ""{message}""'
    'openbsd': '/sbin/sysctl kern.boottime',
    'macosx': 'who -b',
    'solaris': 'who -b',
    'alpine': 'reboot',
    'alpine': '',
    'linux': DEFAULT_SHUTDOWN_COMMAND_ARGS,
    'macosx': '-r {delay_min} ""{message}""',
    'solaris': '-y -g {delay_sec} -i 6 ""{message}""',
    'sunos': '-y -g {delay_sec} -i 6 ""{message}""',
}

TEST_COMMANDS = {
    'solaris': 'who'
@property
def pre_reboot_delay(self):
    return self._check_delay('pre_reboot_delay', self.DEFAULT_PRE_REBOOT_DELAY)

@property
def post_reboot_delay(self):
    return self._check_delay('post_reboot_delay', self.DEFAULT_POST_REBOOT_DELAY)

def _check_delay(self, key, default):
    """"""Ensure that the value is positive or zero""""""
    value = int(self._task.args.get(key, self._task.args.get(key  '_sec', default)))
    if value < 0:
        value = 0
    return value

def _get_value_from_facts(self, variable_name, distribution, default_value):
    """"""Get distversion specific args first, then distribution, then family, lastly use default""""""
    attr = getattr(self, variable_name)
    value = attr.get(
        distribution['name']  distribution['version'],
        attr.get(
            distribution['name'],
            attr.get(
                distribution['family'],
                getattr(self, default_value))))
    return value

def get_shutdown_command_args(self, distribution):
    args = self._get_value_from_facts('SHUTDOWN_COMMAND_ARGS', distribution, 'DEFAULT_SHUTDOWN_COMMAND_ARGS')
    # Convert seconds to minutes. If less that 60, set it to 0.
    delay_min = self.pre_reboot_delay // 60
    reboot_message = self._task.args.get('msg', self.DEFAULT_REBOOT_MESSAGE)
    return args.format(delay_sec=self.pre_reboot_delay, delay_min=delay_min, message=reboot_message)

def get_distribution(self, task_vars):
    distribution = {}
    display.debug('{action}: running setup module to get distribution'.format(action=self._task.action))
    module_output = self._execute_module(
        task_vars=task_vars,
        module_name='setup',
        module_args={'gather_subset': 'min'})
    try:
        if module_output.get('failed', False):
            raise AnsibleError('Failed to determine system distribution. {0}, {1}'.format(
                to_native(module_output['module_stdout']).strip(),
                to_native(module_output['module_stderr']).strip()))
        distribution['name'] = module_output['ansible_facts']['ansible_distribution'].lower()
        distribution['version'] = to_text(module_output['ansible_facts']['ansible_distribution_version'].split('.')[0])
        distribution['family'] = to_text(module_output['ansible_facts']['ansible_os_family'].lower())
        display.debug(""{action}: distribution: {dist}"".format(action=self._task.action, dist=distribution))
        return distribution
    except KeyError as ke:
        raise AnsibleError('Failed to get distribution information. Missing ""{0}"" in output.'.format(ke.args[0]))

def get_shutdown_command(self, task_vars, distribution):
    shutdown_bin = self._get_value_from_facts('SHUTDOWN_COMMANDS', distribution, 'DEFAULT_SHUTDOWN_COMMAND')

    display.debug('{action}: running find module to get path for ""{command}""'.format(action=self._task.action, command=shutdown_bin))
    find_result = self._execute_module(
        task_vars=task_vars,
        module_name='find',
        module_args={
            'paths': ['/sbin', '/usr/sbin', '/usr/local/sbin'],
            'patterns': [shutdown_bin],
            'file_type': 'any'
        }
    )

    full_path = [x['path'] for x in find_result['files']]
    if not full_path:
        raise AnsibleError('Unable to find command ""{0}"" in system paths.'.format(shutdown_bin))
    self._shutdown_command = full_path[0]
    return self._shutdown_command
            display.warning(""Since Ansible {version}, {arg} is no longer a valid option for {action}"".format(
                version=version,
                arg=arg,
                action=self._task.action))

def get_system_boot_time(self, distribution):
    boot_time_command = self._get_value_from_facts('BOOT_TIME_COMMANDS', distribution, 'DEFAULT_BOOT_TIME_COMMAND')
    display.debug(""{action}: getting boot time with command: '{command}'"".format(action=self._task.action, command=boot_time_command))
        stdout = command_result['stdout']
        stderr = command_result['stderr']
        raise AnsibleError(""{action}: failed to get host boot time info, rc: {rc}, stdout: {out}, stderr: {err}"".format(
                           action=self._task.action,
                           rc=command_result['rc'],
                           out=to_native(stdout),
                           err=to_native(stderr)))
    display.debug(""{action}: last boot time: {boot}"".format(action=self._task.action, boot=command_result['stdout'].strip()))
def check_boot_time(self, distribution, previous_boot_time):
    display.vvv(""{action}: attempting to get system boot time"".format(action=self._task.action))
            display.debug(""{action}: setting connect_timeout to {value}"".format(action=self._task.action, value=connect_timeout))
"
-------------------------------------------------------------------------
"DEFAULT_SHUTDOWN_COMMAND_ARGS = '-r {delay_min} ""{message}""'
    'openbsd': '/sbin/sysctl kern.boottime',
    'macosx': 'who -b',
    'solaris': 'who -b',
    'alpine': 'reboot',
    'alpine': '',
    'linux': DEFAULT_SHUTDOWN_COMMAND_ARGS,
    'macosx': '-r {delay_min} ""{message}""',
    'solaris': '-y -g {delay_sec} -i 6 ""{message}""',
    'sunos': '-y -g {delay_sec} -i 6 ""{message}""',
}

TEST_COMMANDS = {
    'solaris': 'who'
@property
def pre_reboot_delay(self):
    return self._check_delay('pre_reboot_delay', self.DEFAULT_PRE_REBOOT_DELAY)

@property
def post_reboot_delay(self):
    return self._check_delay('post_reboot_delay', self.DEFAULT_POST_REBOOT_DELAY)

def _check_delay(self, key, default):
    """"""Ensure that the value is positive or zero""""""
    value = int(self._task.args.get(key, self._task.args.get(key  '_sec', default)))
    if value < 0:
        value = 0
    return value

def _get_value_from_facts(self, variable_name, distribution, default_value):
    """"""Get distversion specific args first, then distribution, then family, lastly use default""""""
    attr = getattr(self, variable_name)
    value = attr.get(
        distribution['name']  distribution['version'],
        attr.get(
            distribution['name'],
            attr.get(
                distribution['family'],
                getattr(self, default_value))))
    return value

def get_shutdown_command_args(self, distribution):
    args = self._get_value_from_facts('SHUTDOWN_COMMAND_ARGS', distribution, 'DEFAULT_SHUTDOWN_COMMAND_ARGS')
    # Convert seconds to minutes. If less that 60, set it to 0.
    delay_min = self.pre_reboot_delay // 60
    reboot_message = self._task.args.get('msg', self.DEFAULT_REBOOT_MESSAGE)
    return args.format(delay_sec=self.pre_reboot_delay, delay_min=delay_min, message=reboot_message)

def get_distribution(self, task_vars):
    distribution = {}
    display.debug('{action}: running setup module to get distribution'.format(action=self._task.action))
    module_output = self._execute_module(
        task_vars=task_vars,
        module_name='setup',
        module_args={'gather_subset': 'min'})
    try:
        if module_output.get('failed', False):
            raise AnsibleError('Failed to determine system distribution. {0}, {1}'.format(
                to_native(module_output['module_stdout']).strip(),
                to_native(module_output['module_stderr']).strip()))
        distribution['name'] = module_output['ansible_facts']['ansible_distribution'].lower()
        distribution['version'] = to_text(module_output['ansible_facts']['ansible_distribution_version'].split('.')[0])
        distribution['family'] = to_text(module_output['ansible_facts']['ansible_os_family'].lower())
        display.debug(""{action}: distribution: {dist}"".format(action=self._task.action, dist=distribution))
        return distribution
    except KeyError as ke:
        raise AnsibleError('Failed to get distribution information. Missing ""{0}"" in output.'.format(ke.args[0]))

def get_shutdown_command(self, task_vars, distribution):
    shutdown_bin = self._get_value_from_facts('SHUTDOWN_COMMANDS', distribution, 'DEFAULT_SHUTDOWN_COMMAND')

    display.debug('{action}: running find module to get path for ""{command}""'.format(action=self._task.action, command=shutdown_bin))
    find_result = self._execute_module(
        task_vars=task_vars,
        module_name='find',
        module_args={
            'paths': ['/sbin', '/usr/sbin', '/usr/local/sbin'],
            'patterns': [shutdown_bin],
            'file_type': 'any'
        }
    )

    full_path = [x['path'] for x in find_result['files']]
    if not full_path:
        raise AnsibleError('Unable to find command ""{0}"" in system paths.'.format(shutdown_bin))
    self._shutdown_command = full_path[0]
    return self._shutdown_command
            display.warning(""Since Ansible {version}, {arg} is no longer a valid option for {action}"".format(
                version=version,
                arg=arg,
                action=self._task.action))

def get_system_boot_time(self, distribution):
    boot_time_command = self._get_value_from_facts('BOOT_TIME_COMMANDS', distribution, 'DEFAULT_BOOT_TIME_COMMAND')
    display.debug(""{action}: getting boot time with command: '{command}'"".format(action=self._task.action, command=boot_time_command))
        stdout = command_result['stdout']
        stderr = command_result['stderr']
        raise AnsibleError(""{action}: failed to get host boot time info, rc: {rc}, stdout: {out}, stderr: {err}"".format(
                           action=self._task.action,
                           rc=command_result['rc'],
                           out=to_native(stdout),
                           err=to_native(stderr)))
    display.debug(""{action}: last boot time: {boot}"".format(action=self._task.action, boot=command_result['stdout'].strip()))
def check_boot_time(self, distribution, previous_boot_time):
    display.vvv(""{action}: attempting to get system boot time"".format(action=self._task.action))
            display.debug(""{action}: setting connect_timeout to {value}"".format(action=self._task.action, value=connect_timeout))
"
-------------------------------------------------------------------------
"Recom
PRs: 49272, 49777"
-------------------------------------------------------------------------
=========================================================================
"msg = 'Test command failed: {err} {out}'.format(
    err=to_native(command_result['stderr']),
    out=to_native(command_result['stdout']))
raise RuntimeError(msg)
lay.vvv(""{action}: system sucessfully rebooted"".format(action=self._task.action))
ntil_success_or_timeout(self, action, reboot_timeout, action_desc, distribution, action_kwargs=None):
ction_kwargs is None:
action_kwargs = {}
    action(distribution=distribution, **action_kwargs)
        display.debug('{action}: {desc} success'.format(action=self._task.action, desc=action_desc))
"
-------------------------------------------------------------------------
"current_boot_time = self.get_system_boot_time(distribution)
en(current_boot_time) == 0 or current_boot_time == previous_boot_time:
raise ValueError(""boot time has not changed"")
test_command(self, distribution, **kwargs):
_command = self._task.args.get('test_command', self._get_value_from_facts('TEST_COMMANDS', distribution, 'DEFAULT_TEST_COMMAND'))
lay.vvv(""{action}: attempting post-reboot test command"".format(action=self._task.action))
lay.debug(""{action}: attempting post-reboot test command '{command}'"".format(action=self._task.action, command=test_command))
"
-------------------------------------------------------------------------
"current_boot_time = self.get_system_boot_time(distribution)
en(current_boot_time) == 0 or current_boot_time == previous_boot_time:
raise ValueError(""boot time has not changed"")
test_command(self, distribution, **kwargs):
_command = self._task.args.get('test_command', self._get_value_from_facts('TEST_COMMANDS', distribution, 'DEFAULT_TEST_COMMAND'))
lay.vvv(""{action}: attempting post-reboot test command"".format(action=self._task.action))
lay.debug(""{action}: attempting post-reboot test command '{command}'"".format(action=self._task.action, command=test_command))
"
-------------------------------------------------------------------------
"Recom
PRs: 49272, 49777"
-------------------------------------------------------------------------
=========================================================================
"display.debug(""{action}: {desc} fail '{err}', retrying in {sleep:.4} seconds..."".format(
    action=self._task.action,
    desc=action_desc,
    err=error,
    sleep=fail_sleep))
utException('Timed out waiting for {desc} (timeout={timeout})'.format(desc=action_desc, timeout=reboot_timeout))
ot(self, task_vars, distribution):
mand = self.get_shutdown_command(task_vars, distribution)
mand_args = self.get_shutdown_command_args(distribution)
nd = '{0} {1}'.format(shutdown_command, shutdown_command_args)
vvv(""{action}: rebooting server..."".format(action=self._task.action))
debug(""{action}: rebooting server with command '{command}'"".format(action=self._task.action, command=reboot_command))
esult = self._low_level_execute_command(reboot_command, sudoable=self.DEFAULT_SUDOABLE)
debug('{action}: AnsibleConnectionFailure caught and handled: {error}'.format(action=self._task.action, error=to_native(e)))
"
-------------------------------------------------------------------------
"msg = 'Test command failed: {err} {out}'.format(
    err=to_native(command_result['stderr']),
    out=to_native(command_result['stdout']))
raise RuntimeError(msg)
lay.vvv(""{action}: system sucessfully rebooted"".format(action=self._task.action))
ntil_success_or_timeout(self, action, reboot_timeout, action_desc, distribution, action_kwargs=None):
ction_kwargs is None:
action_kwargs = {}
    action(distribution=distribution, **action_kwargs)
        display.debug('{action}: {desc} success'.format(action=self._task.action, desc=action_desc))
"
-------------------------------------------------------------------------
"msg = 'Test command failed: {err} {out}'.format(
    err=to_native(command_result['stderr']),
    out=to_native(command_result['stdout']))
raise RuntimeError(msg)
lay.vvv(""{action}: system sucessfully rebooted"".format(action=self._task.action))
ntil_success_or_timeout(self, action, reboot_timeout, action_desc, distribution, action_kwargs=None):
ction_kwargs is None:
action_kwargs = {}
    action(distribution=distribution, **action_kwargs)
        display.debug('{action}: {desc} success'.format(action=self._task.action, desc=action_desc))
"
-------------------------------------------------------------------------
"Recom
PRs: 49272, 49777"
-------------------------------------------------------------------------
=========================================================================
"result['msg'] = ""Reboot command failed. Error was {stdout}, {stderr}"".format(
    stdout=to_native(reboot_result['stdout'].strip()),
    stderr=to_native(reboot_result['stderr'].strip()))
date_reboot(self, distribution, original_connection_timeout=None, action_kwargs=None):
lay.vvv('{action}: validating reboot'.format(action=self._task.action))
self.do_until_success_or_timeout(
    action=self.check_boot_time,
    action_desc=""last boot time check"",
    reboot_timeout=reboot_timeout,
    distribution=distribution,
    action_kwargs=action_kwargs)

if connect_timeout and original_connection_timeout:
        display.debug(""{action}: setting connect_timeout back to original value of {value}"".format(
            action=self._task.action,
            value=original_connection_timeout))
        self._connection.set_option(""connection_timeout"", original_connection_timeout)
        display.debug(""{action}: failed to reset connection_timeout back to default: {error}"".format(action=self._task.action, error=to_text(e)))
self.do_until_success_or_timeout(
    action=self.run_test_command,
    action_desc=""post-reboot test command"",
    reboot_timeout=reboot_timeout,
    distribution=distribution,
    action_kwargs=action_kwargs)
"
-------------------------------------------------------------------------
"display.debug(""{action}: {desc} fail '{err}', retrying in {sleep:.4} seconds..."".format(
    action=self._task.action,
    desc=action_desc,
    err=error,
    sleep=fail_sleep))
utException('Timed out waiting for {desc} (timeout={timeout})'.format(desc=action_desc, timeout=reboot_timeout))
ot(self, task_vars, distribution):
mand = self.get_shutdown_command(task_vars, distribution)
mand_args = self.get_shutdown_command_args(distribution)
nd = '{0} {1}'.format(shutdown_command, shutdown_command_args)
vvv(""{action}: rebooting server..."".format(action=self._task.action))
debug(""{action}: rebooting server with command '{command}'"".format(action=self._task.action, command=reboot_command))
esult = self._low_level_execute_command(reboot_command, sudoable=self.DEFAULT_SUDOABLE)
debug('{action}: AnsibleConnectionFailure caught and handled: {error}'.format(action=self._task.action, error=to_native(e)))
"
-------------------------------------------------------------------------
"display.debug(""{action}: {desc} fail '{err}', retrying in {sleep:.4} seconds..."".format(
    action=self._task.action,
    desc=action_desc,
    err=error,
    sleep=fail_sleep))
utException('Timed out waiting for {desc} (timeout={timeout})'.format(desc=action_desc, timeout=reboot_timeout))
ot(self, task_vars, distribution):
mand = self.get_shutdown_command(task_vars, distribution)
mand_args = self.get_shutdown_command_args(distribution)
nd = '{0} {1}'.format(shutdown_command, shutdown_command_args)
vvv(""{action}: rebooting server..."".format(action=self._task.action))
debug(""{action}: rebooting server with command '{command}'"".format(action=self._task.action, command=reboot_command))
esult = self._low_level_execute_command(reboot_command, sudoable=self.DEFAULT_SUDOABLE)
debug('{action}: AnsibleConnectionFailure caught and handled: {error}'.format(action=self._task.action, error=to_native(e)))
"
-------------------------------------------------------------------------
"Recom
PRs: 49272, 49777"
-------------------------------------------------------------------------
=========================================================================
"return {'changed': False, 'elapsed': 0, 'rebooted': False, 'failed': True, 'msg': msg}
return {'changed': True, 'elapsed': 0, 'rebooted': True}
task_vars = {}
"
-------------------------------------------------------------------------
"result['msg'] = ""Reboot command failed. Error was {stdout}, {stderr}"".format(
    stdout=to_native(reboot_result['stdout'].strip()),
    stderr=to_native(reboot_result['stderr'].strip()))
date_reboot(self, distribution, original_connection_timeout=None, action_kwargs=None):
lay.vvv('{action}: validating reboot'.format(action=self._task.action))
self.do_until_success_or_timeout(
    action=self.check_boot_time,
    action_desc=""last boot time check"",
    reboot_timeout=reboot_timeout,
    distribution=distribution,
    action_kwargs=action_kwargs)

if connect_timeout and original_connection_timeout:
        display.debug(""{action}: setting connect_timeout back to original value of {value}"".format(
            action=self._task.action,
            value=original_connection_timeout))
        self._connection.set_option(""connection_timeout"", original_connection_timeout)
        display.debug(""{action}: failed to reset connection_timeout back to default: {error}"".format(action=self._task.action, error=to_text(e)))
self.do_until_success_or_timeout(
    action=self.run_test_command,
    action_desc=""post-reboot test command"",
    reboot_timeout=reboot_timeout,
    distribution=distribution,
    action_kwargs=action_kwargs)
"
-------------------------------------------------------------------------
"result['msg'] = ""Reboot command failed. Error was {stdout}, {stderr}"".format(
    stdout=to_native(reboot_result['stdout'].strip()),
    stderr=to_native(reboot_result['stderr'].strip()))
date_reboot(self, distribution, original_connection_timeout=None, action_kwargs=None):
lay.vvv('{action}: validating reboot'.format(action=self._task.action))
self.do_until_success_or_timeout(
    action=self.check_boot_time,
    action_desc=""last boot time check"",
    reboot_timeout=reboot_timeout,
    distribution=distribution,
    action_kwargs=action_kwargs)

if connect_timeout and original_connection_timeout:
        display.debug(""{action}: setting connect_timeout back to original value of {value}"".format(
            action=self._task.action,
            value=original_connection_timeout))
        self._connection.set_option(""connection_timeout"", original_connection_timeout)
        display.debug(""{action}: failed to reset connection_timeout back to default: {error}"".format(action=self._task.action, error=to_text(e)))
self.do_until_success_or_timeout(
    action=self.run_test_command,
    action_desc=""post-reboot test command"",
    reboot_timeout=reboot_timeout,
    distribution=distribution,
    action_kwargs=action_kwargs)
"
-------------------------------------------------------------------------
"Recom
PRs: 49272, 49777"
-------------------------------------------------------------------------
=========================================================================
"distribution = self.get_distribution(task_vars)

    previous_boot_time = self.get_system_boot_time(distribution)
# Get the original connection_timeout option var so it can be reset after
original_connection_timeout = None
try:
    original_connection_timeout = self._connection.get_option('connection_timeout')
    display.debug(""{action}: saving original connect_timeout of {timeout}"".format(action=self._task.action, timeout=original_connection_timeout))
except AnsibleError:
    display.debug(""{action}: connect_timeout connection option has not been set"".format(action=self._task.action))
reboot_result = self.perform_reboot(task_vars, distribution)
"
-------------------------------------------------------------------------
"return {'changed': False, 'elapsed': 0, 'rebooted': False, 'failed': True, 'msg': msg}
return {'changed': True, 'elapsed': 0, 'rebooted': True}
task_vars = {}
"
-------------------------------------------------------------------------
"return {'changed': False, 'elapsed': 0, 'rebooted': False, 'failed': True, 'msg': msg}
return {'changed': True, 'elapsed': 0, 'rebooted': True}
task_vars = {}
"
-------------------------------------------------------------------------
"Recom
PRs: 49272, 49777"
-------------------------------------------------------------------------
=========================================================================
"if self.post_reboot_delay != 0:
    display.debug(""{action}: waiting an additional {delay} seconds"".format(action=self._task.action, delay=self.post_reboot_delay))
    display.vvv(""{action}: waiting an additional {delay} seconds"".format(action=self._task.action, delay=self.post_reboot_delay))
    time.sleep(self.post_reboot_delay)
result = self.validate_reboot(distribution, original_connection_timeout, action_kwargs={'previous_boot_time': previous_boot_time})
"
-------------------------------------------------------------------------
"distribution = self.get_distribution(task_vars)

    previous_boot_time = self.get_system_boot_time(distribution)
# Get the original connection_timeout option var so it can be reset after
original_connection_timeout = None
try:
    original_connection_timeout = self._connection.get_option('connection_timeout')
    display.debug(""{action}: saving original connect_timeout of {timeout}"".format(action=self._task.action, timeout=original_connection_timeout))
except AnsibleError:
    display.debug(""{action}: connect_timeout connection option has not been set"".format(action=self._task.action))
reboot_result = self.perform_reboot(task_vars, distribution)
"
-------------------------------------------------------------------------
"distribution = self.get_distribution(task_vars)

    previous_boot_time = self.get_system_boot_time(distribution)
# Get the original connection_timeout option var so it can be reset after
original_connection_timeout = None
try:
    original_connection_timeout = self._connection.get_option('connection_timeout')
    display.debug(""{action}: saving original connect_timeout of {timeout}"".format(action=self._task.action, timeout=original_connection_timeout))
except AnsibleError:
    display.debug(""{action}: connect_timeout connection option has not been set"".format(action=self._task.action))
reboot_result = self.perform_reboot(task_vars, distribution)
"
-------------------------------------------------------------------------
"Recom
PRs: 49272, 49777"
-------------------------------------------------------------------------
=========================================================================
"if len(split_fields) == 2 and split_fields[0:2] == ['iam', 'info_instanceprofilearn']:
    new_fields[self._prefix % ""iam-instance-profile-role""] = value.split('/')[1]
"
-------------------------------------------------------------------------
"# Parse out the IAM role name (which is _not_ the same as the instance profile name)
if len(split_fields) == 3 and split_fields[0:2] == ['iam', 'security-credentials'] and ':' not in split_fields[2]:
    new_fields[self._prefix % ""iam-instance-profile-role""] = split_fields[2]
"
-------------------------------------------------------------------------
"# Parse out the IAM role name (which is _not_ the same as the instance profile name)
if len(split_fields) == 3 and split_fields[0:2] == ['iam', 'security-credentials'] and ':' not in split_fields[2]:
    new_fields[self._prefix % ""iam-instance-profile-role""] = split_fields[2]
"
-------------------------------------------------------------------------
"Recom
PRs: 45534, 49428"
-------------------------------------------------------------------------
=========================================================================
"if len(split_fields) == 2 and split_fields[0:2] == ['iam', 'info_instanceprofilearn']:
    new_fields[self._prefix % ""iam-instance-profile-role""] = value.split('/')[1]
"
-------------------------------------------------------------------------
"# Parse out the IAM role name (which is _not_ the same as the instance profile name)
if len(split_fields) == 3 and split_fields[0:2] == ['iam', 'security-credentials'] and ':' not in split_fields[2]:
    new_fields[self._prefix % ""iam-instance-profile-role""] = split_fields[2]
"
-------------------------------------------------------------------------
"# Parse out the IAM role name (which is _not_ the same as the instance profile name)
if len(split_fields) == 3 and split_fields[0:2] == ['iam', 'security-credentials'] and ':' not in split_fields[2]:
    new_fields[self._prefix % ""iam-instance-profile-role""] = split_fields[2]
"
-------------------------------------------------------------------------
"Recom
PRs: 45534, 49427"
-------------------------------------------------------------------------
=========================================================================
"- When connecting to Docker daemon with TLS, you might need to install additional Python packages.
  For the Docker SDK for Python, version 2.4 or newer, this can be done by installing C(docker[tls]) with M(pip).
"
-------------------------------------------------------------------------
"U(https://docker-py.readthedocs.io/en/stable/machine/) for more details.
When connecting to Docker daemon with TLS, you might need to install additional Python packages.
For the Docker SDK for Python, version 2.4 or newer, this can be done by installing C(docker[tls]) with M(pip).
"
-------------------------------------------------------------------------
"U(https://docker-py.readthedocs.io/en/stable/machine/) for more details.
When connecting to Docker daemon with TLS, you might need to install additional Python packages.
For the Docker SDK for Python, version 2.4 or newer, this can be done by installing C(docker[tls]) with M(pip).
"
-------------------------------------------------------------------------
"Recom
PRs: 49095, 49153"
-------------------------------------------------------------------------
=========================================================================
"self.log(differences.get_legacy_docker_container_diffs(), pretty_print=True)
"
-------------------------------------------------------------------------
"if network.get('ipv4_address') is not None or network.get('ipv6_address') is not None:
"
-------------------------------------------------------------------------
"if network.get('ipv4_address') is not None or network.get('ipv6_address') is not None:
"
-------------------------------------------------------------------------
"Recom
PRs: 49078, 49152"
-------------------------------------------------------------------------
=========================================================================
"#     value: ""{{ sample_com_challenge.challenge_data['sample.com']['dns-01'].resource_value | regex_replace('^(.*)$', '\""\\1\""') }}""
"
-------------------------------------------------------------------------
"#     state: present
#     value: ""{{ sample_com_challenge.challenge_data['sample.com']['dns-01'].resource_value | regex_replace('^(.*)$', '\""\\1\""') }}""
"
-------------------------------------------------------------------------
"#     state: present
#     value: ""{{ sample_com_challenge.challenge_data['sample.com']['dns-01'].resource_value | regex_replace('^(.*)$', '\""\\1\""') }}""
"
-------------------------------------------------------------------------
"Recom
PRs: 49031, 49082"
-------------------------------------------------------------------------
=========================================================================
"#     value: ""{{ item.value | map('regex_replace', '^(.*)$', '\""\\1\""' ) | list }}""
"
-------------------------------------------------------------------------
"#     state: present
#     value: ""{{ item.value | map('regex_replace', '^(.*)$', '\""\\1\""' ) | list }}""
"
-------------------------------------------------------------------------
"#     state: present
#     value: ""{{ item.value | map('regex_replace', '^(.*)$', '\""\\1\""' ) | list }}""
"
-------------------------------------------------------------------------
"Recom
PRs: 49031, 49082"
-------------------------------------------------------------------------
=========================================================================
"type: list
suboptions:
  path:
    type: str
    required: true
    description:
    - Device path in the container.
  rate:
    type: str
    required: true
    description:
    - ""Device read limit. Format: <number>[<unit>]""
    - ""Number is a positive integer. Unit can be one of C(B) (byte), C(K) (kibibyte, 1024B), C(M) (mebibyte), C(G) (gibibyte),
      C(T) (tebibyte), or C(P) (pebibyte)""
    - ""Omitting the unit defaults to bytes.""
type: list
suboptions:
  path:
    type: str
    required: true
    description:
    - Device path in the container.
  rate:
    type: str
    required: true
    description:
    - ""Device read limit. Format: <number>[<unit>]""
    - ""Number is a positive integer. Unit can be one of C(B) (byte), C(K) (kibibyte, 1024B), C(M) (mebibyte), C(G) (gibibyte),
      C(T) (tebibyte), or C(P) (pebibyte)""
    - ""Omitting the unit defaults to bytes.""
type: list
suboptions:
  path:
    type: str
    required: true
    description:
    - Device path in the container.
  rate:
    type: int
    required: true
    description:
    - ""Device read limit.""
    - ""Must be a positive integer.""
type: list
suboptions:
  path:
    type: str
    required: true
    description:
    - Device path in the container.
  rate:
    type: int
    required: true
    description:
    - ""Device read limit.""
    - ""Must be a positive integer.""
"
-------------------------------------------------------------------------
"type: list
suboptions:
   name:
      type: str
      required: true
      description:
        - The network's name.
   ipv4_address:
      type: str
      description:
        - The container's IPv4 address in this network.
   ipv6_address:
      type: str
      description:
        - The container's IPv6 address in this network.
   links:
      type: list
      description:
        - A list of containers to link to.
   aliases:
      type: list
      description:
        - List of aliases for this container in this network. These names
          can be used in the network to reach this container.
"
-------------------------------------------------------------------------
"type: list
suboptions:
   name:
      type: str
      required: true
      description:
        - The network's name.
   ipv4_address:
      type: str
      description:
        - The container's IPv4 address in this network.
   ipv6_address:
      type: str
      description:
        - The container's IPv6 address in this network.
   links:
      type: list
      description:
        - A list of containers to link to.
   aliases:
      type: list
      description:
        - List of aliases for this container in this network. These names
          can be used in the network to reach this container.
"
-------------------------------------------------------------------------
"Recom
PRs: 48491, 48895"
-------------------------------------------------------------------------
=========================================================================
"- 'I(interval), I(timeout) and I(start_period) are specified as durations. They accept duration as a string in a format
boptions:
test:
  description:
    - Command to run to check health.
    - Must be either a string or a list. If it is a list, the first item must be one of C(NONE), C(CMD) or C(CMD-SHELL).
interval:
  description:
    - 'Time between running the check. (default: 30s)'
  type: str
timeout:
  description:
    - 'Maximum time to allow one check to run. (default: 30s)'
  type: str
retries:
  description:
    - 'Consecutive failures needed to report unhealthy. It accept integer value. (default: 3)'
  type: int
start_period:
  description:
    - 'Start period for the container to initialize before starting health-retries countdown. (default: 0s)'
  type: str
"
-------------------------------------------------------------------------
"type: list
suboptions:
   name:
      type: str
      required: true
      description:
        - The network's name.
   ipv4_address:
      type: str
      description:
        - The container's IPv4 address in this network.
   ipv6_address:
      type: str
      description:
        - The container's IPv6 address in this network.
   links:
      type: list
      description:
        - A list of containers to link to.
   aliases:
      type: list
      description:
        - List of aliases for this container in this network. These names
          can be used in the network to reach this container.
"
-------------------------------------------------------------------------
"type: list
suboptions:
   name:
      type: str
      required: true
      description:
        - The network's name.
   ipv4_address:
      type: str
      description:
        - The container's IPv4 address in this network.
   ipv6_address:
      type: str
      description:
        - The container's IPv6 address in this network.
   links:
      type: list
      description:
        - A list of containers to link to.
   aliases:
      type: list
      description:
        - List of aliases for this container in this network. These names
          can be used in the network to reach this container.
"
-------------------------------------------------------------------------
"Recom
PRs: 48491, 48895"
-------------------------------------------------------------------------
=========================================================================
"if self.healthcheck.get(value) is None:
    # due to recursive argument_spec, all keys are always present
    # (but have default value None if not specified)
    continue
"
-------------------------------------------------------------------------
"security_opts=dict(type='list', elements='str'),
tmpfs=dict(type='list', elements='str'),
ulimits=dict(type='list', elements='str'),
volumes=dict(type='list', elements='str'),
volumes_from=dict(type='list', elements='str'),
"
-------------------------------------------------------------------------
"security_opts=dict(type='list', elements='str'),
tmpfs=dict(type='list', elements='str'),
ulimits=dict(type='list', elements='str'),
volumes=dict(type='list', elements='str'),
volumes_from=dict(type='list', elements='str'),
"
-------------------------------------------------------------------------
"Recom
PRs: 48491, 48895"
-------------------------------------------------------------------------
=========================================================================
"device_dict['Rate'] = human_to_bytes(device_dict['Rate'])
"
-------------------------------------------------------------------------
"container_limits=dict(type='dict', options=dict(
    memory=dict(type='int'),
    memswap=dict(type='int'),
    cpushares=dict(type='int'),
    cpusetcpus=dict(type='str'),
)),
"
-------------------------------------------------------------------------
"container_limits=dict(type='dict', options=dict(
    memory=dict(type='int'),
    memswap=dict(type='int'),
    cpushares=dict(type='int'),
    cpusetcpus=dict(type='str'),
)),
"
-------------------------------------------------------------------------
"Recom
PRs: 48491, 48895"
-------------------------------------------------------------------------
=========================================================================
"device_dict = dict((x.title(), y) for x, y in v.items())
devices_list.append(device_dict)
"
-------------------------------------------------------------------------
"name=dict(type='list', elements='str'),
"
-------------------------------------------------------------------------
"name=dict(type='list', elements='str'),
"
-------------------------------------------------------------------------
"Recom
PRs: 48491, 48895"
-------------------------------------------------------------------------
=========================================================================
"if network.get('aliases'):
    if not compare_generic(network['aliases'], connected_networks[network['name']].get('Aliases'), 'allow_more_present', 'set'):
        diff = True
if network.get('links'):
    if not compare_generic(expected_links, connected_networks[network['name']].get('Links'), 'allow_more_present', 'set'):
        diff = True
"
-------------------------------------------------------------------------
"if value is None:
    # due to recursive argument_spec, all keys are always present
    # (but have default value None if not specified)
    continue
"
-------------------------------------------------------------------------
"if value is None:
    # due to recursive argument_spec, all keys are always present
    # (but have default value None if not specified)
    continue
"
-------------------------------------------------------------------------
"Recom
PRs: 48491, 48895"
-------------------------------------------------------------------------
=========================================================================
"container_limits=dict(type='dict', options=dict(
    memory=dict(type='int'),
    memswap=dict(type='int'),
    cpushares=dict(type='int'),
    cpusetcpus=dict(type='str'),
)),
"
-------------------------------------------------------------------------
"if (self.parameters.ipam_options['subnet'] or self.parameters.ipam_options['iprange'] or
        self.parameters.ipam_options['gateway'] or self.parameters.ipam_options['aux_addresses']):
"
-------------------------------------------------------------------------
"if (self.parameters.ipam_options['subnet'] or self.parameters.ipam_options['iprange'] or
        self.parameters.ipam_options['gateway'] or self.parameters.ipam_options['aux_addresses']):
"
-------------------------------------------------------------------------
"Recom
PRs: 48491, 48895"
-------------------------------------------------------------------------
=========================================================================
"name=dict(type='list', elements='str'),
"
-------------------------------------------------------------------------
"connected=dict(type='list', default=[], aliases=['containers'], elements='str'),
ipam_driver=dict(type='str'),
ipam_options=dict(type='dict', default={}, options=dict(
    subnet=dict(type='str'),
    iprange=dict(type='str'),
    gateway=dict(type='str'),
    aux_addresses=dict(type='dict'),
)),
"
-------------------------------------------------------------------------
"connected=dict(type='list', default=[], aliases=['containers'], elements='str'),
ipam_driver=dict(type='str'),
ipam_options=dict(type='dict', default={}, options=dict(
    subnet=dict(type='str'),
    iprange=dict(type='str'),
    gateway=dict(type='str'),
    aux_addresses=dict(type='dict'),
)),
"
-------------------------------------------------------------------------
"Recom
PRs: 48491, 48895"
-------------------------------------------------------------------------
=========================================================================
"- Deprecated in 2.8, will be removed in 2.12. Use parameter C(ipam_config) instead. In Docker 1.10.0, IPAM
"
-------------------------------------------------------------------------
"files=dict(type='list', elements='path'),
"
-------------------------------------------------------------------------
"files=dict(type='list', elements='path'),
"
-------------------------------------------------------------------------
"Recom
PRs: 48491, 48895"
-------------------------------------------------------------------------
=========================================================================
"Note that I(iprange) is spelled differently here (we use the notation from the Docker Python SDK).
ptions:
bnet:
description:
  - IP subset in CIDR notation.
type: str
range:
description:
  - IP address range in CIDR notation.
type: str
teway:
description:
  - IP gateway address.
type: str
x_addresses:
description:
  - Auxiliary IP addresses used by Network driver, as a mapping from hostname to IP.
type: dict
"
-------------------------------------------------------------------------
"services=dict(type='list', elements='str'),
"
-------------------------------------------------------------------------
"services=dict(type='list', elements='str'),
"
-------------------------------------------------------------------------
"Recom
PRs: 48491, 48895"
-------------------------------------------------------------------------
=========================================================================
"if (self.parameters.ipam_options['subnet'] or self.parameters.ipam_options['iprange'] or
        self.parameters.ipam_options['gateway'] or self.parameters.ipam_options['aux_addresses']):
"
-------------------------------------------------------------------------
"remote_addrs=dict(type='list', elements='str'),
"
-------------------------------------------------------------------------
"remote_addrs=dict(type='list', elements='str'),
"
-------------------------------------------------------------------------
"Recom
PRs: 48491, 48895"
-------------------------------------------------------------------------
=========================================================================
"absent. This was available in Ansible version 2.4 and removed in 2.8""
"
-------------------------------------------------------------------------
"
"
-------------------------------------------------------------------------
"
"
-------------------------------------------------------------------------
"Recom
PRs: 47695, 48307"
-------------------------------------------------------------------------
=========================================================================
"new_args = parse_module_arguments(new_args)

changes = 0
    rule_changed = False
        if(current_rule.rule_type != new_type):
            rule_changed = True
            current_rule.rule_type = new_type
        if(current_rule.rule_control != new_control):
            rule_changed = True
            current_rule.rule_control = new_control
        if(current_rule.rule_path != new_path):
            rule_changed = True
            current_rule.rule_path = new_path
        if(current_rule.rule_args != new_args):
            rule_changed = True
            current_rule.rule_args = new_args

    if rule_changed:
        changes = 1
return changes
changes = 0
"
-------------------------------------------------------------------------
"valid_simple_controls = ['required', 'requisite', 'sufficient', 'optional', 'include', 'substack', 'definitive']
"
-------------------------------------------------------------------------
"valid_simple_controls = ['required', 'requisite', 'sufficient', 'optional', 'include', 'substack', 'definitive']
"
-------------------------------------------------------------------------
"Recom
PRs: 47695, 48307"
-------------------------------------------------------------------------
=========================================================================
"choices=VALID_TYPES),
    choices=VALID_TYPES),
"
-------------------------------------------------------------------------
"rule_match = RULE_REGEX.search(line)
rule_args = parse_module_arguments(rule_match.group('args'))
return cls(rule_match.group('rule_type'), rule_match.group('control'), rule_match.group('path'), rule_args)
"
-------------------------------------------------------------------------
"rule_match = RULE_REGEX.search(line)
rule_args = parse_module_arguments(rule_match.group('args'))
return cls(rule_match.group('rule_type'), rule_match.group('control'), rule_match.group('path'), rule_args)
"
-------------------------------------------------------------------------
"Recom
PRs: 47695, 48307"
-------------------------------------------------------------------------
=========================================================================
"result = dict(
    changed=(changes > 0),
    change_count=changes,
    backupdest='',
)

if not module.check_mode and result['changed']:
        result['backupdest'] = module.backup_local(fname)
"
-------------------------------------------------------------------------
"result = dict(
    changed=(changes > 0),
    change_count=changes,
    backupdest='',
    action=action,
)

if not module.check_mode and result['changed']:
        result['backupdest'] = module.backup_local(fname)
"
-------------------------------------------------------------------------
"result = dict(
    changed=(changes > 0),
    change_count=changes,
    backupdest='',
    action=action,
)

if not module.check_mode and result['changed']:
        result['backupdest'] = module.backup_local(fname)
"
-------------------------------------------------------------------------
"Recom
PRs: 47695, 48307"
-------------------------------------------------------------------------
=========================================================================
"- No default setting. If the value is not set, the system setting from
  C(/etc/yum.conf) or system default of C(no) will be used.
"
-------------------------------------------------------------------------
"description: Facts to add to ansible_facts about the services on the system
  services:
    description: States of the services with service name as key.
    returned: always
    type: complex
    contains:
      source:
        description: Init system of the service. One of C(systemd), C(sysv), C(upstart).
        returned: always
        type: string
        sample: sysv
      state:
        description: State of the service. Either C(running) or C(stopped).
        returned: always
        type: string
        sample: running
      name:
        description: Name of the service.
        returned: always
        type: string
        sample: arp-ethers.service
"
-------------------------------------------------------------------------
"description: Facts to add to ansible_facts about the services on the system
  services:
    description: States of the services with service name as key.
    returned: always
    type: complex
    contains:
      source:
        description: Init system of the service. One of C(systemd), C(sysv), C(upstart).
        returned: always
        type: string
        sample: sysv
      state:
        description: State of the service. Either C(running) or C(stopped).
        returned: always
        type: string
        sample: running
      name:
        description: Name of the service.
        returned: always
        type: string
        sample: arp-ethers.service
"
-------------------------------------------------------------------------
"Recom
PRs: 45796, 48111"
-------------------------------------------------------------------------
=========================================================================
"AnsibleDockerClient,
"
-------------------------------------------------------------------------
"from ansible.module_utils.docker_common import AnsibleDockerClient, DockerBaseClass, sanitize_result
from ansible.module_utils.docker_common import docker_version
if LooseVersion(docker_version) >= LooseVersion('1.10.0'):
pt Exception as dummy:
"
-------------------------------------------------------------------------
"from ansible.module_utils.docker_common import AnsibleDockerClient, DockerBaseClass, sanitize_result
from ansible.module_utils.docker_common import docker_version
if LooseVersion(docker_version) >= LooseVersion('1.10.0'):
pt Exception as dummy:
"
-------------------------------------------------------------------------
"Recom
PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils.docker_common import docker_version
if LooseVersion(docker_version) >= LooseVersion('1.10.0'):
"
-------------------------------------------------------------------------
"blkio_weight='blkio_weight',
cpuset_mems='cpuset_mems',
    if self.client.option_minimal_versions[value]['supported']:
        result[key] = getattr(self, value)
"
-------------------------------------------------------------------------
"blkio_weight='blkio_weight',
cpuset_mems='cpuset_mems',
    if self.client.option_minimal_versions[value]['supported']:
        result[key] = getattr(self, value)
"
-------------------------------------------------------------------------
"Recom
PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"blkio_weight='blkio_weight',
cpuset_mems='cpuset_mems',
    if self.client.option_minimal_versions[value]['supported']:
        result[key] = getattr(self, value)
"
-------------------------------------------------------------------------
"if self.client.docker_py_version < LooseVersion('3.0'):
    # cpu_shares and volume_driver moved to create_host_config in > 3
"
-------------------------------------------------------------------------
"if self.client.docker_py_version < LooseVersion('3.0'):
    # cpu_shares and volume_driver moved to create_host_config in > 3
"
-------------------------------------------------------------------------
"Recom
PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"stop_timeout='stop_timeout',
healthcheck='healthcheck',
elf.client.docker_py_version < LooseVersion('3.0'):
# cpu_shares and volume_driver moved to create_host_config in > 3
"
-------------------------------------------------------------------------
"if self.client.option_minimal_versions[value]['supported']:
    result[key] = getattr(self, value)
"
-------------------------------------------------------------------------
"if self.client.option_minimal_versions[value]['supported']:
    result[key] = getattr(self, value)
"
-------------------------------------------------------------------------
"Recom
PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"if self.client.option_minimal_versions[value]['supported']:
    result[key] = getattr(self, value)
"
-------------------------------------------------------------------------
"init='init',
uts_mode='uts',
auto_remove='auto_remove',
elf.client.docker_py_version >= LooseVersion('1.9') and self.client.docker_api_version >= LooseVersion('1.22'):
# blkio_weight can always be updated, but can only be set on creation
# when docker-py and docker API are new enough
elf.client.docker_py_version >= LooseVersion('3.0'):
    if self.client.option_minimal_versions[value]['supported']:
        params[key] = getattr(self, value)
"
-------------------------------------------------------------------------
"init='init',
uts_mode='uts',
auto_remove='auto_remove',
elf.client.docker_py_version >= LooseVersion('1.9') and self.client.docker_api_version >= LooseVersion('1.22'):
# blkio_weight can always be updated, but can only be set on creation
# when docker-py and docker API are new enough
elf.client.docker_py_version >= LooseVersion('3.0'):
    if self.client.option_minimal_versions[value]['supported']:
        params[key] = getattr(self, value)
"
-------------------------------------------------------------------------
"Recom
PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"init='init',
uts_mode='uts',
runtime='runtime',
auto_remove='auto_remove',
device_read_bps='device_read_bps',
device_write_bps='device_write_bps',
device_read_iops='device_read_iops',
device_write_iops='device_write_iops',
elf.client.docker_py_version >= LooseVersion('1.9') and self.client.docker_api_version >= LooseVersion('1.22'):
# blkio_weight can always be updated, but can only be set on creation
# when docker-py and docker API are new enough
elf.client.docker_py_version >= LooseVersion('3.0'):
    if self.client.option_minimal_versions[value]['supported']:
        params[key] = getattr(self, value)
"
-------------------------------------------------------------------------
"volume_driver=host_config.get('VolumeDriver'),
tions which don't make sense without their accompanying option
elf.parameters.client.option_minimal_versions['auto_remove']['supported']:
# auto_remove is only supported in docker>=2; unfortunately it has a default
# value, that's why we have to jump through the hoops here
elf.parameters.client.docker_api_version < LooseVersion('1.22'):
# For docker API < 1.22, update_container() is not supported. Thus
# we need to handle all limits which are usually handled by
# update_container() as configuration changes which require a container
# restart.
config_mapping.update(dict(
    blkio_weight=host_config.get('BlkioWeight'),
    cpu_period=host_config.get('CpuPeriod'),
    cpu_quota=host_config.get('CpuQuota'),
    cpu_shares=host_config.get('CpuShares'),
    cpuset_cpus=host_config.get('CpusetCpus'),
    cpuset_mems=host_config.get('CpusetMems'),
    kernel_memory=host_config.get(""KernelMemory""),
    memory=host_config.get('Memory'),
    memory_reservation=host_config.get('MemoryReservation'),
    memory_swap=host_config.get('MemorySwap'),
))
"
-------------------------------------------------------------------------
"volume_driver=host_config.get('VolumeDriver'),
tions which don't make sense without their accompanying option
elf.parameters.client.option_minimal_versions['auto_remove']['supported']:
# auto_remove is only supported in docker>=2; unfortunately it has a default
# value, that's why we have to jump through the hoops here
elf.parameters.client.docker_api_version < LooseVersion('1.22'):
# For docker API < 1.22, update_container() is not supported. Thus
# we need to handle all limits which are usually handled by
# update_container() as configuration changes which require a container
# restart.
config_mapping.update(dict(
    blkio_weight=host_config.get('BlkioWeight'),
    cpu_period=host_config.get('CpuPeriod'),
    cpu_quota=host_config.get('CpuQuota'),
    cpu_shares=host_config.get('CpuShares'),
    cpuset_cpus=host_config.get('CpusetCpus'),
    cpuset_mems=host_config.get('CpusetMems'),
    kernel_memory=host_config.get(""KernelMemory""),
    memory=host_config.get('Memory'),
    memory_reservation=host_config.get('MemoryReservation'),
    memory_swap=host_config.get('MemorySwap'),
))
"
-------------------------------------------------------------------------
"Recom
PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"volume_driver=host_config.get('VolumeDriver'),
"
-------------------------------------------------------------------------
"if self.parameters.client.docker_api_version < LooseVersion('1.22'):
    # update_container() call not supported
    return False, []
    blkio_weight=host_config.get('BlkioWeight'),
    cpu_shares=host_config.get('CpuShares'),
    cpuset_mems=host_config.get('CpusetMems'),
"
-------------------------------------------------------------------------
"if self.parameters.client.docker_api_version < LooseVersion('1.22'):
    # update_container() call not supported
    return False, []
    blkio_weight=host_config.get('BlkioWeight'),
    cpu_shares=host_config.get('CpuShares'),
    cpuset_mems=host_config.get('CpusetMems'),
"
-------------------------------------------------------------------------
"Recom
PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"# Options which don't make sense without their accompanying option
if self.parameters.client.option_minimal_versions['auto_remove']['supported']:
    # auto_remove is only supported in docker>=2; unfortunately it has a default
    # value, that's why we have to jump through the hoops here
if self.parameters.client.option_minimal_versions['stop_timeout']['supported']:
    # stop_timeout is only supported in docker>=2.1. Note that stop_timeout
    # has a hybrid role, in that it used to be something only used for stopping
    # containers, and is now also used as a container property. That's why
    # it needs special handling here.
if self.parameters.client.docker_api_version < LooseVersion('1.22'):
    # For docker API < 1.22, update_container() is not supported. Thus
    # we need to handle all limits which are usually handled by
    # update_container() as configuration changes which require a container
    # restart.
    config_mapping.update(dict(
        blkio_weight=host_config.get('BlkioWeight'),
        cpu_period=host_config.get('CpuPeriod'),
        cpu_quota=host_config.get('CpuQuota'),
        cpu_shares=host_config.get('CpuShares'),
        cpuset_cpus=host_config.get('CpusetCpus'),
        cpuset_mems=host_config.get('CpusetMems'),
        kernel_memory=host_config.get(""KernelMemory""),
        memory=host_config.get('Memory'),
        memory_reservation=host_config.get('MemoryReservation'),
        memory_swap=host_config.get('MemorySwap'),
    ))
"
-------------------------------------------------------------------------
"if client.module.params.get('restart_retries') is not None and not client.module.params.get('restart_policy'):
"
-------------------------------------------------------------------------
"if client.module.params.get('restart_retries') is not None and not client.module.params.get('restart_policy'):
"
-------------------------------------------------------------------------
"Recom
PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"if self.parameters.client.docker_api_version < LooseVersion('1.22'):
    # update_container() call not supported
    return False, []
    blkio_weight=host_config.get('BlkioWeight'),
    cpu_shares=host_config.get('CpuShares'),
    cpuset_mems=host_config.get('CpusetMems'),
"
-------------------------------------------------------------------------
"if self.client.docker_py_version >= LooseVersion('3.0'):
"
-------------------------------------------------------------------------
"if self.client.docker_py_version >= LooseVersion('3.0'):
"
-------------------------------------------------------------------------
"Recom
PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"if client.module.params.get('restart_retries') is not None and not client.module.params.get('restart_policy'):
"
-------------------------------------------------------------------------
"# A list of module options which are not docker container properties
__NON_CONTAINER_PROPERTY_OPTIONS = (
    'docker_host', 'tls_hostname', 'api_version', 'timeout', 'cacert_path', 'cert_path',
    'key_path', 'ssl_version', 'tls', 'tls_verify', 'debug', 'env_file', 'force_kill',
    'keep_volumes', 'ignore_image', 'name', 'pull', 'purge_networks', 'recreate',
    'restart', 'state', 'stop_timeout', 'trust_image_content', 'networks', 'cleanup',
    'kill_signal', 'output_logs', 'paused'
)
"
-------------------------------------------------------------------------
"# A list of module options which are not docker container properties
__NON_CONTAINER_PROPERTY_OPTIONS = (
    'docker_host', 'tls_hostname', 'api_version', 'timeout', 'cacert_path', 'cert_path',
    'key_path', 'ssl_version', 'tls', 'tls_verify', 'debug', 'env_file', 'force_kill',
    'keep_volumes', 'ignore_image', 'name', 'pull', 'purge_networks', 'recreate',
    'restart', 'state', 'stop_timeout', 'trust_image_content', 'networks', 'cleanup',
    'kill_signal', 'output_logs', 'paused'
)
"
-------------------------------------------------------------------------
"Recom
PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"if self.client.docker_py_version >= LooseVersion('3.0'):
"
-------------------------------------------------------------------------
"if self.client.docker_py_version < LooseVersion('3.0'):
    # cpu_shares and volume_driver moved to create_host_config in > 3
"
-------------------------------------------------------------------------
"if self.client.docker_py_version < LooseVersion('3.0'):
    # cpu_shares and volume_driver moved to create_host_config in > 3
"
-------------------------------------------------------------------------
"Recom
PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"# A list of module options which are not docker container properties
__NON_CONTAINER_PROPERTY_OPTIONS = (
    'docker_host', 'tls_hostname', 'api_version', 'timeout', 'cacert_path', 'cert_path',
    'key_path', 'ssl_version', 'tls', 'tls_verify', 'debug', 'env_file', 'force_kill',
    'keep_volumes', 'ignore_image', 'name', 'pull', 'purge_networks', 'recreate',
    'restart', 'state', 'trust_image_content', 'networks', 'cleanup', 'kill_signal',
    'output_logs', 'paused'
)
"
-------------------------------------------------------------------------
"def _get_minimal_versions(self):
    # Helper function to detect whether any specified network uses ipv4_address or ipv6_address
    def detect_ipvX_address_usage():
        for network in self.module.params.get(""networks"") or []:
                return True
        return False

    self.option_minimal_versions = dict(
        # internal options
        log_config=dict(),
        publish_all_ports=dict(),
        ports=dict(),
        volume_binds=dict(),
        name=dict(),
    )
    for option, data in self.module.argument_spec.items():
        if option in self.__NON_CONTAINER_PROPERTY_OPTIONS:
            continue
        self.option_minimal_versions[option] = dict()
    self.option_minimal_versions.update(dict(
        dns_opts=dict(docker_api_version='1.21', docker_py_version='1.10.0'),
        ipc_mode=dict(docker_api_version='1.25'),
        mac_address=dict(docker_api_version='1.25'),
        oom_killer=dict(docker_py_version='2.0.0'),
        oom_score_adj=dict(docker_api_version='1.22', docker_py_version='2.0.0'),
        shm_size=dict(docker_api_version='1.22'),
        stop_signal=dict(docker_api_version='1.21'),
        tmpfs=dict(docker_api_version='1.22'),
        volume_driver=dict(docker_api_version='1.21'),
        memory_reservation=dict(docker_api_version='1.21'),
        kernel_memory=dict(docker_api_version='1.21'),
        auto_remove=dict(docker_py_version='2.1.0', docker_api_version='1.25'),
        init=dict(docker_py_version='2.2.0', docker_api_version='1.25'),
        sysctls=dict(docker_py_version='1.10.0', docker_api_version='1.24'),
        userns_mode=dict(docker_py_version='1.10.0', docker_api_version='1.23'),
        uts=dict(docker_py_version='3.5.0', docker_api_version='1.25'),
        # specials
        ipvX_address_supported=dict(docker_py_version='1.9.0', detect_usage=detect_ipvX_address_usage,
                                    usage_msg='ipv4_address or ipv6_address in networks'),
    ))

    for option, data in self.option_minimal_versions.items():
        # Test whether option is supported, and store result
        support_docker_py = True
        support_docker_api = True
        if 'docker_py_version' in data:
            support_docker_py = self.docker_py_version >= LooseVersion(data['docker_py_version'])
        if 'docker_api_version' in data:
            support_docker_api = self.docker_api_version >= LooseVersion(data['docker_api_version'])
        data['supported'] = support_docker_py and support_docker_api
        # Fail if option is not supported but used
        if not data['supported']:
            # Test whether option is specified
            if 'detect_usage' in data:
                used = data['detect_usage']()
            else:
                used = self.module.params.get(option) is not None
                if used and 'default' in self.module.argument_spec[option]:
                    used = self.module.params[option] != self.module.argument_spec[option]['default']
            if used:
                # If the option is used, compose error message.
                if 'usage_msg' in data:
                    usg = data['usage_msg']
                else:
                    usg = 'set %s option' % (option, )
                if not support_docker_api:
                    msg = 'docker API version is %s. Minimum version required is %s to %s.'
                    msg = msg % (self.docker_api_version_str, data['docker_api_version'], usg)
                elif not support_docker_py:
                    if LooseVersion(data['docker_py_version']) < LooseVersion('2.0.0'):
                        msg = (""docker-py version is %s. Minimum version required is %s to %s. ""
                               ""Consider switching to the 'docker' package if you do not require Python 2.6 support."")
                    elif self.docker_py_version < LooseVersion('2.0.0'):
                        msg = (""docker-py version is %s. Minimum version required is %s to %s. ""
                               ""You have to switch to the Python 'docker' package. First uninstall 'docker-py' before ""
                               ""installing 'docker' to avoid a broken installation."")
                    else:
                        msg = ""docker version is %s. Minimum version required is %s to %s.""
                    msg = msg % (docker_version, data['docker_py_version'], usg)
                else:
                    # should not happen
                    msg = 'Cannot %s with your configuration.' % (usg, )
                self.fail(msg)
def __init__(self, **kwargs):
    super(AnsibleDockerClientContainer, self).__init__(**kwargs)
    self._get_minimal_versions()
"
-------------------------------------------------------------------------
"def _get_minimal_versions(self):
    # Helper function to detect whether any specified network uses ipv4_address or ipv6_address
    def detect_ipvX_address_usage():
        for network in self.module.params.get(""networks"") or []:
                return True
        return False

    self.option_minimal_versions = dict(
        # internal options
        log_config=dict(),
        publish_all_ports=dict(),
        ports=dict(),
        volume_binds=dict(),
        name=dict(),
    )
    for option, data in self.module.argument_spec.items():
        if option in self.__NON_CONTAINER_PROPERTY_OPTIONS:
            continue
        self.option_minimal_versions[option] = dict()
    self.option_minimal_versions.update(dict(
        dns_opts=dict(docker_api_version='1.21', docker_py_version='1.10.0'),
        ipc_mode=dict(docker_api_version='1.25'),
        mac_address=dict(docker_api_version='1.25'),
        oom_killer=dict(docker_py_version='2.0.0'),
        oom_score_adj=dict(docker_api_version='1.22', docker_py_version='2.0.0'),
        shm_size=dict(docker_api_version='1.22'),
        stop_signal=dict(docker_api_version='1.21'),
        tmpfs=dict(docker_api_version='1.22'),
        volume_driver=dict(docker_api_version='1.21'),
        memory_reservation=dict(docker_api_version='1.21'),
        kernel_memory=dict(docker_api_version='1.21'),
        auto_remove=dict(docker_py_version='2.1.0', docker_api_version='1.25'),
        init=dict(docker_py_version='2.2.0', docker_api_version='1.25'),
        sysctls=dict(docker_py_version='1.10.0', docker_api_version='1.24'),
        userns_mode=dict(docker_py_version='1.10.0', docker_api_version='1.23'),
        uts=dict(docker_py_version='3.5.0', docker_api_version='1.25'),
        # specials
        ipvX_address_supported=dict(docker_py_version='1.9.0', detect_usage=detect_ipvX_address_usage,
                                    usage_msg='ipv4_address or ipv6_address in networks'),
    ))

    for option, data in self.option_minimal_versions.items():
        # Test whether option is supported, and store result
        support_docker_py = True
        support_docker_api = True
        if 'docker_py_version' in data:
            support_docker_py = self.docker_py_version >= LooseVersion(data['docker_py_version'])
        if 'docker_api_version' in data:
            support_docker_api = self.docker_api_version >= LooseVersion(data['docker_api_version'])
        data['supported'] = support_docker_py and support_docker_api
        # Fail if option is not supported but used
        if not data['supported']:
            # Test whether option is specified
            if 'detect_usage' in data:
                used = data['detect_usage']()
            else:
                used = self.module.params.get(option) is not None
                if used and 'default' in self.module.argument_spec[option]:
                    used = self.module.params[option] != self.module.argument_spec[option]['default']
            if used:
                # If the option is used, compose error message.
                if 'usage_msg' in data:
                    usg = data['usage_msg']
                else:
                    usg = 'set %s option' % (option, )
                if not support_docker_api:
                    msg = 'docker API version is %s. Minimum version required is %s to %s.'
                    msg = msg % (self.docker_api_version_str, data['docker_api_version'], usg)
                elif not support_docker_py:
                    if LooseVersion(data['docker_py_version']) < LooseVersion('2.0.0'):
                        msg = (""docker-py version is %s. Minimum version required is %s to %s. ""
                               ""Consider switching to the 'docker' package if you do not require Python 2.6 support."")
                    elif self.docker_py_version < LooseVersion('2.0.0'):
                        msg = (""docker-py version is %s. Minimum version required is %s to %s. ""
                               ""You have to switch to the Python 'docker' package. First uninstall 'docker-py' before ""
                               ""installing 'docker' to avoid a broken installation."")
                    else:
                        msg = ""docker version is %s. Minimum version required is %s to %s.""
                    msg = msg % (docker_version, data['docker_py_version'], usg)
                else:
                    # should not happen
                    msg = 'Cannot %s with your configuration.' % (usg, )
                self.fail(msg)
def __init__(self, **kwargs):
    super(AnsibleDockerClientContainer, self).__init__(**kwargs)
    self._get_minimal_versions()
"
-------------------------------------------------------------------------
"Recom
PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"def __init__(self, module, account):
    self.directory, dummy = account.get_request(self.directory_root)
"
-------------------------------------------------------------------------
"self.directory, dummy = account.get_request(self.directory_root, get_only=True)
"
-------------------------------------------------------------------------
"self.directory, dummy = account.get_request(self.directory_root, get_only=True)
"
-------------------------------------------------------------------------
"Recom
PRs: 45051, 48043"
-------------------------------------------------------------------------
=========================================================================
"self.directory = ACMEDirectory(module, self)

"
-------------------------------------------------------------------------
"if payload is None:
    payload64 = ''
else:
    payload64 = nopad_b64(self.module.jsonify(payload).encode('utf8'))
"
-------------------------------------------------------------------------
"if payload is None:
    payload64 = ''
else:
    payload64 = nopad_b64(self.module.jsonify(payload).encode('utf8'))
"
-------------------------------------------------------------------------
"Recom
PRs: 45051, 48043"
-------------------------------------------------------------------------
=========================================================================
"def send_signed_request(self, url, payload, key_data=None, jws_header=None, parse_json_result=True):
"
-------------------------------------------------------------------------
"
If payload is None, a POST-as-GET is performed.
(https://tools.ietf.org/html/draft-ietf-acme-acme-15#section-6.3)
"
-------------------------------------------------------------------------
"
If payload is None, a POST-as-GET is performed.
(https://tools.ietf.org/html/draft-ietf-acme-acme-15#section-6.3)
"
-------------------------------------------------------------------------
"Recom
PRs: 45051, 48043"
-------------------------------------------------------------------------
=========================================================================
"ModuleFailException, write_file, nopad_b64, pem_to_der, ACMEAccount,
"
-------------------------------------------------------------------------
"def get_request(self, uri, parse_json_result=True, headers=None, get_only=False):
    '''
    Perform a GET-like request. Will try POST-as-GET for ACMEv2, with fallback
    to GET if server replies with a status code of 405.
    '''
    if not get_only and self.version != 1:
        # Try POST-as-GET
        content, info = self.send_signed_request(uri, None, parse_json_result=False)
        if info['status'] == 405:
            # Instead, do unauthenticated GET
            get_only = True
    else:
        # Do unauthenticated GET
        get_only = True
    if get_only:
        # Perform unauthenticated GET
        resp, info = fetch_url(self.module, uri, method='GET', headers=headers)
        try:
            content = resp.read()
        except AttributeError:
            content = info.get('body')

    # Process result
"
-------------------------------------------------------------------------
"def get_request(self, uri, parse_json_result=True, headers=None, get_only=False):
    '''
    Perform a GET-like request. Will try POST-as-GET for ACMEv2, with fallback
    to GET if server replies with a status code of 405.
    '''
    if not get_only and self.version != 1:
        # Try POST-as-GET
        content, info = self.send_signed_request(uri, None, parse_json_result=False)
        if info['status'] == 405:
            # Instead, do unauthenticated GET
            get_only = True
    else:
        # Do unauthenticated GET
        get_only = True
    if get_only:
        # Perform unauthenticated GET
        resp, info = fetch_url(self.module, uri, method='GET', headers=headers)
        try:
            content = resp.read()
        except AttributeError:
            content = info.get('body')

    # Process result
"
-------------------------------------------------------------------------
"Recom
PRs: 45051, 48043"
-------------------------------------------------------------------------
=========================================================================
"if self.module.check_mode:
    self.module.debug('In check mode, would have run: ""%s""' % cmd)
    return (0, '', '')

master_in_fd, slave_in_fd = pty.openpty()
master_out_fd, slave_out_fd = pty.openpty()
master_err_fd, slave_err_fd = pty.openpty()
env = os.environ.copy()
env['LC_ALL'] = 'C'
try:
    p = subprocess.Popen([to_bytes(c) for c in cmd],
                         stdin=slave_in_fd,
                         stdout=slave_out_fd,
                         stderr=slave_err_fd,
                         preexec_fn=os.setsid,
                         env=env)
    out_buffer = b''
    err_buffer = b''
    while p.poll() is None:
        r, w, e = select.select([master_out_fd, master_err_fd], [], [], 1)
        first_prompt = b'Enter passphrase (empty for no passphrase):'
        second_prompt = b'Enter same passphrase again'
        prompt = first_prompt
        for fd in r:
            if fd == master_out_fd:
                chunk = os.read(master_out_fd, 10240)
                out_buffer = chunk
                if prompt in out_buffer:
                    os.write(master_in_fd, self.ssh_passphrase  b'\r')
                    prompt = second_prompt
            else:
                chunk = os.read(master_err_fd, 10240)
                err_buffer = chunk
                if prompt in err_buffer:
                    os.write(master_in_fd, self.ssh_passphrase  b'\r')
                    prompt = second_prompt
            if b'Overwrite (y/n)?' in out_buffer or b'Overwrite (y/n)?' in err_buffer:
                # This created between us checking for existence and now
                return (None, 'Key already exists', '')

    rc = p.returncode
    out = to_native(out_buffer)
    err = to_native(err_buffer)
except OSError as e:
    return (1, '', to_native(e))
cmd.append('-N')
(rc, out, err) = self.execute_command(cmd)

"
-------------------------------------------------------------------------
"if self.module.check_mode:
    self.module.debug('In check mode, would have run: ""%s""' % cmd)
    return (0, '', '')

master_in_fd, slave_in_fd = pty.openpty()
master_out_fd, slave_out_fd = pty.openpty()
master_err_fd, slave_err_fd = pty.openpty()
env = os.environ.copy()
env['LC_ALL'] = 'C'
try:
    p = subprocess.Popen([to_bytes(c) for c in cmd],
                         stdin=slave_in_fd,
                         stdout=slave_out_fd,
                         stderr=slave_err_fd,
                         preexec_fn=os.setsid,
                         env=env)
    out_buffer = b''
    err_buffer = b''
    while p.poll() is None:
        r, w, e = select.select([master_out_fd, master_err_fd], [], [], 1)
        first_prompt = b'Enter passphrase (empty for no passphrase):'
        second_prompt = b'Enter same passphrase again'
        prompt = first_prompt
        for fd in r:
            if fd == master_out_fd:
                chunk = os.read(master_out_fd, 10240)
                out_buffer = chunk
                if prompt in out_buffer:
                    os.write(master_in_fd, to_bytes(self.ssh_passphrase, errors='strict')  b'\r')
                    prompt = second_prompt
            else:
                chunk = os.read(master_err_fd, 10240)
                err_buffer = chunk
                if prompt in err_buffer:
                    os.write(master_in_fd, to_bytes(self.ssh_passphrase, errors='strict')  b'\r')
                    prompt = second_prompt
            if b'Overwrite (y/n)?' in out_buffer or b'Overwrite (y/n)?' in err_buffer:
                # The key was created between us checking for existence and now
                return (None, 'Key already exists', '')

    rc = p.returncode
    out = to_native(out_buffer)
    err = to_native(err_buffer)
except OSError as e:
    return (1, '', to_native(e))
cmd.append('-N')
(rc, out, err) = self.execute_command(cmd)

"
-------------------------------------------------------------------------
"if self.module.check_mode:
    self.module.debug('In check mode, would have run: ""%s""' % cmd)
    return (0, '', '')

master_in_fd, slave_in_fd = pty.openpty()
master_out_fd, slave_out_fd = pty.openpty()
master_err_fd, slave_err_fd = pty.openpty()
env = os.environ.copy()
env['LC_ALL'] = 'C'
try:
    p = subprocess.Popen([to_bytes(c) for c in cmd],
                         stdin=slave_in_fd,
                         stdout=slave_out_fd,
                         stderr=slave_err_fd,
                         preexec_fn=os.setsid,
                         env=env)
    out_buffer = b''
    err_buffer = b''
    while p.poll() is None:
        r, w, e = select.select([master_out_fd, master_err_fd], [], [], 1)
        first_prompt = b'Enter passphrase (empty for no passphrase):'
        second_prompt = b'Enter same passphrase again'
        prompt = first_prompt
        for fd in r:
            if fd == master_out_fd:
                chunk = os.read(master_out_fd, 10240)
                out_buffer = chunk
                if prompt in out_buffer:
                    os.write(master_in_fd, to_bytes(self.ssh_passphrase, errors='strict')  b'\r')
                    prompt = second_prompt
            else:
                chunk = os.read(master_err_fd, 10240)
                err_buffer = chunk
                if prompt in err_buffer:
                    os.write(master_in_fd, to_bytes(self.ssh_passphrase, errors='strict')  b'\r')
                    prompt = second_prompt
            if b'Overwrite (y/n)?' in out_buffer or b'Overwrite (y/n)?' in err_buffer:
                # The key was created between us checking for existence and now
                return (None, 'Key already exists', '')

    rc = p.returncode
    out = to_native(out_buffer)
    err = to_native(err_buffer)
except OSError as e:
    return (1, '', to_native(e))
cmd.append('-N')
(rc, out, err) = self.execute_command(cmd)

"
-------------------------------------------------------------------------
"Recom
PRs: 47436, 47487"
-------------------------------------------------------------------------
=========================================================================
"if self.parameters.auto_remove:
    output = ""Cannot retrieve result as auto_remove is enabled""
        self.client.module.warn('Cannot output_logs if auto_remove is enabled!')
    config = self.client.inspect_container(container_id)
    logging_driver = config['HostConfig']['LogConfig']['Type']

    if logging_driver == 'json-file' or logging_driver == 'journald':
        output = self.client.logs(container_id, stdout=True, stderr=True, stream=False, timestamps=False)
        if self.parameters.output_logs:
            self._output_logs(msg=output)
    else:
        output = ""Result logged using `%s` driver"" % logging_driver
    self.container_remove(container_id, force=True, ignore_failure=self.parameters.auto_remove)
"
-------------------------------------------------------------------------
"self.container_remove(container_id, force=True)
"
-------------------------------------------------------------------------
"self.container_remove(container_id, force=True)
"
-------------------------------------------------------------------------
"Recom
PRs: 47396, 47484"
-------------------------------------------------------------------------
=========================================================================
"def container_remove(self, container_id, link=False, force=False, ignore_failure=False):
"
-------------------------------------------------------------------------
"self.container_remove(container_id, force=True)
"
-------------------------------------------------------------------------
"self.container_remove(container_id, force=True)
"
-------------------------------------------------------------------------
"Recom
PRs: 47396, 47484"
-------------------------------------------------------------------------
=========================================================================
"if not ignore_failure:
    self.fail(""Error removing container %s: %s"" % (container_id, str(exc)))
"
-------------------------------------------------------------------------
"def container_remove(self, container_id, link=False, force=False):
"
-------------------------------------------------------------------------
"def container_remove(self, container_id, link=False, force=False):
"
-------------------------------------------------------------------------
"Recom
PRs: 47396, 47484"
-------------------------------------------------------------------------
=========================================================================
"try:
    if secure != 'never':
        try:
            smtp = smtplib.SMTP_SSL(timeout=timeout)
            code, smtpmessage = smtp.connect(host, port=port)
            secure_state = True
        except ssl.SSLError as e:
            if secure == 'always':
                                           (host, port, to_native(e)), exception=traceback.format_exc())
    if not secure_state:
        smtp = smtplib.SMTP(timeout=timeout)
except smtplib.SMTPException as e:
    module.fail_json(rc=1, msg='Unable to Connect %s:%s: %s' % (host, port, to_native(e)), exception=traceback.format_exc())
if int(code) > 0:
    if not secure_state and secure in ('starttls', 'try'):
"
-------------------------------------------------------------------------
"except:
    pass
"
-------------------------------------------------------------------------
"except:
    pass
"
-------------------------------------------------------------------------
"Recom
PRs: 37098, 47019"
-------------------------------------------------------------------------
=========================================================================
"- A value of C(all) will publish all exposed container ports to random host ports, ignoring
"
-------------------------------------------------------------------------
"self.parameters_map['expected_ports'] = 'expected_ports'
"
-------------------------------------------------------------------------
"self.parameters_map['expected_ports'] = 'expected_ports'
"
-------------------------------------------------------------------------
"Recom
PRs: 46594, 46640"
-------------------------------------------------------------------------
=========================================================================
"working_dir=config.get('WorkingDir'),
publish_all_ports=host_config.get('PublishAllPorts'),
"
-------------------------------------------------------------------------
"comparisons['expected_ports'] = dict(type='dict', comparison=comparisons['published_ports']['comparison'], name='expected_ports')
"
-------------------------------------------------------------------------
"comparisons['expected_ports'] = dict(type='dict', comparison=comparisons['published_ports']['comparison'], name='expected_ports')
"
-------------------------------------------------------------------------
"Recom
PRs: 46594, 46640"
-------------------------------------------------------------------------
=========================================================================
"# version comparison. Otherwise we handle this depending on whether
# the container already runs or not; in the former case, in case the
# container needs to be restarted, we use the existing container's
# image ID.
image = self._get_image()
self.log(image, pretty_print=True)
if not container.exists:
    # New container
    self.log('No container found')
    if not self.parameters.image:
        self.fail('Cannot create container when image is not specified!')
    new_container = self.container_create(self.parameters.image, self.parameters.create_parameters)
    if new_container:
        container = new_container
else:
    # Existing container
    different, differences = container.has_different_configuration(image)
    image_different = False
    if self.parameters.comparisons['image']['comparison'] == 'strict':
        image_different = self._image_is_different(image, container)
    if image_different or different or self.parameters.recreate:
        self.diff['differences'] = differences
        if image_different:
            self.diff['image_different'] = True
        self.log(""differences"")
        self.log(differences, pretty_print=True)
        image_to_use = self.parameters.image
        if not image_to_use and container and container.Image:
            image_to_use = container.Image
        if not image_to_use:
            self.fail('Cannot recreate container when image is not specified or cannot be extracted from current container!')
        if container.running:
            self.container_stop(container.Id)
        self.container_remove(container.Id)
        new_container = self.container_create(image_to_use, self.parameters.create_parameters)
"
-------------------------------------------------------------------------
"
# If the image parameter was passed then we need to deal with the image
# version comparison. Otherwise we handle this depending on whether
# the container already runs or not; in the former case, in case the
# container needs to be restarted, we use the existing container's
# image ID.
    if not self.parameters.image:
        self.fail('Cannot create container when image is not specified!')
"
-------------------------------------------------------------------------
"
# If the image parameter was passed then we need to deal with the image
# version comparison. Otherwise we handle this depending on whether
# the container already runs or not; in the former case, in case the
# container needs to be restarted, we use the existing container's
# image ID.
    if not self.parameters.image:
        self.fail('Cannot create container when image is not specified!')
"
-------------------------------------------------------------------------
"Recom
PRs: 46322, 46576"
-------------------------------------------------------------------------
=========================================================================
"- On macOS, this module uses C(dscl) to create, modify, and delete accounts. C(dseditgroup) is used to
  modify group membership. Accounts are hidden from the login window by modifying
  C(/Library/Preferences/com.apple.loginwindow.plist).
- On FreeBSD, this module uses C(pw useradd) and C(chpass) to create, C(pw usermod) and C(chpass) to modify,
  C(pw userdel) remove, C(pw lock) to lock, and C(pw unlock) to unlock accounts.
- On all other platforms, this module uses C(useradd) to create, C(usermod) to modify, and
  C(userdel) to remove accounts.
"
-------------------------------------------------------------------------
"- On SunOS platforms, the shadow file is backed up automatically since this module edits it directly.
  On other platforms, the shadow file is backed up by the underlying tools used by this module.
- On macOS, this module uses C(dscl) to create, modify, and delete accounts. C(dseditgroup) is used to
  modify group membership. Accounts are hidden from the login window by modifying
  C(/Library/Preferences/com.apple.loginwindow.plist).
- On FreeBSD, this module uses C(pw useradd) and C(chpass) to create, C(pw usermod) and C(chpass) to modify,
  C(pw userdel) remove, C(pw lock) to lock, and C(pw unlock) to unlock accounts.
- On all other platforms, this module uses C(useradd) to create, C(usermod) to modify, and
  C(userdel) to remove accounts.
"
-------------------------------------------------------------------------
"- On SunOS platforms, the shadow file is backed up automatically since this module edits it directly.
  On other platforms, the shadow file is backed up by the underlying tools used by this module.
- On macOS, this module uses C(dscl) to create, modify, and delete accounts. C(dseditgroup) is used to
  modify group membership. Accounts are hidden from the login window by modifying
  C(/Library/Preferences/com.apple.loginwindow.plist).
- On FreeBSD, this module uses C(pw useradd) and C(chpass) to create, C(pw usermod) and C(chpass) to modify,
  C(pw userdel) remove, C(pw lock) to lock, and C(pw unlock) to unlock accounts.
- On all other platforms, this module uses C(useradd) to create, C(usermod) to modify, and
  C(userdel) to remove accounts.
"
-------------------------------------------------------------------------
"Recom
PRs: 46455, 46512"
-------------------------------------------------------------------------
=========================================================================
"- On other operating systems, the default shell is determined by the underlying tool being
  used. See Notes for details.
"
-------------------------------------------------------------------------
"- macOS only, optionally hide the user from the login window and system preferences.
"
-------------------------------------------------------------------------
"- macOS only, optionally hide the user from the login window and system preferences.
"
-------------------------------------------------------------------------
"Recom
PRs: 46455, 46512"
-------------------------------------------------------------------------
=========================================================================
"if module.params['scope'] in (None, 'system') and \
        not out.strip().endswith('disabled') and \
        sysv_is_enabled(unit):
"
-------------------------------------------------------------------------
"not out.strip().endswith('disabled') and \
sysv_is_enabled(unit):
"
-------------------------------------------------------------------------
"not out.strip().endswith('disabled') and \
sysv_is_enabled(unit):
"
-------------------------------------------------------------------------
"Recom
PRs: 46245, 46317"
-------------------------------------------------------------------------
=========================================================================
"- On Linux, macOS and OpenBSD, this is converted to minutes and rounded down. If less than 60, it will be set to 0.
"
-------------------------------------------------------------------------
"- On Linux, macOS, and OpenBSD this is converted to minutes and rounded down. If less than 60, it will be set to 0.
- On Solaris and FreeBSD this will be seconds.
"
-------------------------------------------------------------------------
"- On Linux, macOS, and OpenBSD this is converted to minutes and rounded down. If less than 60, it will be set to 0.
- On Solaris and FreeBSD this will be seconds.
"
-------------------------------------------------------------------------
"Recom
PRs: 46147, 46289"
-------------------------------------------------------------------------
=========================================================================
"if len(split_fields) == 3 and split_fields[0:2] == ['iam', 'security-credentials']:
"
-------------------------------------------------------------------------
"if len(split_fields) == 2 and split_fields[0:2] == ['iam', 'info_instanceprofilearn']:
    new_fields[self._prefix % ""iam-instance-profile-role""] = value.split('/')[1]
"
-------------------------------------------------------------------------
"if len(split_fields) == 2 and split_fields[0:2] == ['iam', 'info_instanceprofilearn']:
    new_fields[self._prefix % ""iam-instance-profile-role""] = value.split('/')[1]
"
-------------------------------------------------------------------------
"Recom
PRs: 38664, 46077"
-------------------------------------------------------------------------
=========================================================================
"if len(split_fields) == 3 and split_fields[0:2] == ['iam', 'security-credentials']:
"
-------------------------------------------------------------------------
"if len(split_fields) == 2 and split_fields[0:2] == ['iam', 'info_instanceprofilearn']:
    new_fields[self._prefix % ""iam-instance-profile-role""] = value.split('/')[1]
"
-------------------------------------------------------------------------
"if len(split_fields) == 2 and split_fields[0:2] == ['iam', 'info_instanceprofilearn']:
    new_fields[self._prefix % ""iam-instance-profile-role""] = value.split('/')[1]
"
-------------------------------------------------------------------------
"Recom
PRs: 38664, 46076"
-------------------------------------------------------------------------
=========================================================================
"self.comparisons = client.comparisons
if self.groups:
    # In case integers are passed as groups, we need to convert them to
    # strings as docker internally treats them as strings.
    self.groups = [str(g) for g in self.groups]

"
-------------------------------------------------------------------------
"self.comparisons = client.comparisons

if self.groups:
    # In case integers are passed as groups, we need to convert them to
    # strings as docker internally treats them as strings.
    self.groups = [str(g) for g in self.groups]
"
-------------------------------------------------------------------------
"self.comparisons = client.comparisons

if self.groups:
    # In case integers are passed as groups, we need to convert them to
    # strings as docker internally treats them as strings.
    self.groups = [str(g) for g in self.groups]
"
-------------------------------------------------------------------------
"Recom
PRs: 45905, 46063"
-------------------------------------------------------------------------
=========================================================================
"cap_drop=host_config.get('CapDrop'),
"
-------------------------------------------------------------------------
"compare = self.parameters.client.comparisons[self.parameters_map.get(key, key)]
self.log('check differences %s %s vs %s (%s)' % (key, getattr(self.parameters, key), str(value), compare))
    match = self._compare(getattr(self.parameters, key), value, compare)
"
-------------------------------------------------------------------------
"compare = self.parameters.client.comparisons[self.parameters_map.get(key, key)]
self.log('check differences %s %s vs %s (%s)' % (key, getattr(self.parameters, key), str(value), compare))
    match = self._compare(getattr(self.parameters, key), value, compare)
"
-------------------------------------------------------------------------
"Recom
PRs: 45905, 46063"
-------------------------------------------------------------------------
=========================================================================
"compare = self.parameters.client.comparisons[self.parameters_map.get(key, key)]
self.log('check differences %s %s vs %s (%s)' % (key, getattr(self.parameters, key), str(value), compare))
    match = self._compare(getattr(self.parameters, key), value, compare)
"
-------------------------------------------------------------------------
"if self.parameters.client.HAS_BLKIO_WEIGHT_OPT:
    # blkio_weight is only supported in docker>=1.9
    config_mapping['blkio_weight'] = host_config.get('BlkioWeight')

if self.parameters.client.HAS_CPUSET_MEMS_OPT:
    # cpuset_mems is only supported in docker>=2.3
    config_mapping['cpuset_mems'] = host_config.get('CpusetMems')

    if getattr(self.parameters, key, None):
        compare = self.parameters.client.comparisons[self.parameters_map.get(key, key)]
        match = self._compare(getattr(self.parameters, key), value, compare)

        if not match:
            # no match. record the differences
            item = dict()
            item[key] = dict(
                parameter=getattr(self.parameters, key),
                container=value
            )
            differences.append(item)
"
-------------------------------------------------------------------------
"if self.parameters.client.HAS_BLKIO_WEIGHT_OPT:
    # blkio_weight is only supported in docker>=1.9
    config_mapping['blkio_weight'] = host_config.get('BlkioWeight')

if self.parameters.client.HAS_CPUSET_MEMS_OPT:
    # cpuset_mems is only supported in docker>=2.3
    config_mapping['cpuset_mems'] = host_config.get('CpusetMems')

    if getattr(self.parameters, key, None):
        compare = self.parameters.client.comparisons[self.parameters_map.get(key, key)]
        match = self._compare(getattr(self.parameters, key), value, compare)

        if not match:
            # no match. record the differences
            item = dict()
            item[key] = dict(
                parameter=getattr(self.parameters, key),
                container=value
            )
            differences.append(item)
"
-------------------------------------------------------------------------
"Recom
PRs: 45905, 46063"
-------------------------------------------------------------------------
=========================================================================
"if self.parameters.client.HAS_BLKIO_WEIGHT_OPT:
    # blkio_weight is only supported in docker>=1.9
    config_mapping['blkio_weight'] = host_config.get('BlkioWeight')

if self.parameters.client.HAS_CPUSET_MEMS_OPT:
    # cpuset_mems is only supported in docker>=2.3
    config_mapping['cpuset_mems'] = host_config.get('CpusetMems')

    if getattr(self.parameters, key, None):
        compare = self.parameters.client.comparisons[self.parameters_map.get(key, key)]
        match = self._compare(getattr(self.parameters, key), value, compare)

        if not match:
            # no match. record the differences
            item = dict()
            item[key] = dict(
                parameter=getattr(self.parameters, key),
                container=value
            )
            differences.append(item)
"
-------------------------------------------------------------------------
"if self.parameters.comparisons['image']['comparison'] == 'strict':
"
-------------------------------------------------------------------------
"if self.parameters.comparisons['image']['comparison'] == 'strict':
"
-------------------------------------------------------------------------
"Recom
PRs: 45905, 46063"
-------------------------------------------------------------------------
=========================================================================
"if self.parameters.comparisons['image']['comparison'] == 'strict':
"
-------------------------------------------------------------------------
"def _setup_comparisons(self):
    comparisons = {}
    comp_aliases = {}
    # Put in defaults
    explicit_types = dict(
        command='list',
        devices='set(dict)',
        dns_search_domains='list',
        dns_servers='list',
        env='set',
        entrypoint='list',
        etc_hosts='set',
        ulimits='set(dict)',
    )
    for option, data in self.module.argument_spec.items():
        # Ignore options which aren't used as container properties
        if option in ('docker_host', 'tls_hostname', 'api_version', 'timeout', 'cacert_path', 'cert_path',
                      'key_path', 'ssl_version', 'tls', 'tls_verify', 'debug', 'env_file', 'force_kill',
                      'keep_volumes', 'ignore_image', 'name', 'pull', 'purge_networks', 'recreate',
                      'restart', 'state', 'stop_timeout', 'trust_image_content', 'networks'):
            continue
        # Determine option type
        if option in explicit_types:
            type = explicit_types[option]
        elif data['type'] == 'list':
            type = 'set'
        elif data['type'] == 'dict':
            type = 'dict'
        else:
            type = 'value'
        # Determine comparison type
        if type in ('list', 'value'):
            comparison = 'strict'
        else:
            comparison = 'allow_more_present'
        comparisons[option] = dict(type=type, comparison=comparison, name=option)
        # Keep track of aliases
        comp_aliases[option] = option
        for alias in data.get('aliases', []):
            comp_aliases[alias] = option
    # Process legacy ignore options
    if self.module.params['ignore_image']:
        comparisons['image']['comparison'] = 'ignore'
    self.comparisons = comparisons

"
-------------------------------------------------------------------------
"def _setup_comparisons(self):
    comparisons = {}
    comp_aliases = {}
    # Put in defaults
    explicit_types = dict(
        command='list',
        devices='set(dict)',
        dns_search_domains='list',
        dns_servers='list',
        env='set',
        entrypoint='list',
        etc_hosts='set',
        ulimits='set(dict)',
    )
    for option, data in self.module.argument_spec.items():
        # Ignore options which aren't used as container properties
        if option in ('docker_host', 'tls_hostname', 'api_version', 'timeout', 'cacert_path', 'cert_path',
                      'key_path', 'ssl_version', 'tls', 'tls_verify', 'debug', 'env_file', 'force_kill',
                      'keep_volumes', 'ignore_image', 'name', 'pull', 'purge_networks', 'recreate',
                      'restart', 'state', 'stop_timeout', 'trust_image_content', 'networks'):
            continue
        # Determine option type
        if option in explicit_types:
            type = explicit_types[option]
        elif data['type'] == 'list':
            type = 'set'
        elif data['type'] == 'dict':
            type = 'dict'
        else:
            type = 'value'
        # Determine comparison type
        if type in ('list', 'value'):
            comparison = 'strict'
        else:
            comparison = 'allow_more_present'
        comparisons[option] = dict(type=type, comparison=comparison, name=option)
        # Keep track of aliases
        comp_aliases[option] = option
        for alias in data.get('aliases', []):
            comp_aliases[alias] = option
    # Process legacy ignore options
    if self.module.params['ignore_image']:
        comparisons['image']['comparison'] = 'ignore'
    self.comparisons = comparisons

"
-------------------------------------------------------------------------
"Recom
PRs: 45905, 46063"
-------------------------------------------------------------------------
=========================================================================
"def _setup_comparisons(self):
    comparisons = {}
    comp_aliases = {}
    # Put in defaults
    explicit_types = dict(
        command='list',
        devices='set(dict)',
        dns_search_domains='list',
        dns_servers='list',
        env='set',
        entrypoint='list',
        etc_hosts='set',
        ulimits='set(dict)',
    )
    for option, data in self.module.argument_spec.items():
        # Ignore options which aren't used as container properties
        if option in ('docker_host', 'tls_hostname', 'api_version', 'timeout', 'cacert_path', 'cert_path',
                      'key_path', 'ssl_version', 'tls', 'tls_verify', 'debug', 'env_file', 'force_kill',
                      'keep_volumes', 'ignore_image', 'name', 'pull', 'purge_networks', 'recreate',
                      'restart', 'state', 'stop_timeout', 'trust_image_content', 'networks'):
            continue
        # Determine option type
        if option in explicit_types:
            type = explicit_types[option]
        elif data['type'] == 'list':
            type = 'set'
        elif data['type'] == 'dict':
            type = 'dict'
        else:
            type = 'value'
        # Determine comparison type
        if type in ('list', 'value'):
            comparison = 'strict'
        else:
            comparison = 'allow_more_present'
        comparisons[option] = dict(type=type, comparison=comparison, name=option)
        # Keep track of aliases
        comp_aliases[option] = option
        for alias in data.get('aliases', []):
            comp_aliases[alias] = option
    # Process legacy ignore options
    if self.module.params['ignore_image']:
        comparisons['image']['comparison'] = 'ignore'
    self.comparisons = comparisons

"
-------------------------------------------------------------------------
"self.comparisons = client.comparisons

if self.groups:
    # In case integers are passed as groups, we need to convert them to
    # strings as docker internally treats them as strings.
    self.groups = [str(g) for g in self.groups]
"
-------------------------------------------------------------------------
"self.comparisons = client.comparisons

if self.groups:
    # In case integers are passed as groups, we need to convert them to
    # strings as docker internally treats them as strings.
    self.groups = [str(g) for g in self.groups]
"
-------------------------------------------------------------------------
"Recom
PRs: 45905, 46063"
-------------------------------------------------------------------------
=========================================================================
"entrypoint=dict(type='list'),
"
-------------------------------------------------------------------------
"shm_size=dict(type='str'),
sysctls=dict(type='dict'),
userns_mode=dict(type='str'),
volume_driver=dict(type='str'),
"
-------------------------------------------------------------------------
"shm_size=dict(type='str'),
sysctls=dict(type='dict'),
userns_mode=dict(type='str'),
volume_driver=dict(type='str'),
"
-------------------------------------------------------------------------
"Recom
PRs: 45905, 46063"
-------------------------------------------------------------------------
=========================================================================
"if vpc_id:
    vpc_wins = dict((group['GroupName'], group) for group in all_groups if group['VpcId'] == vpc_id)
    groups.update(vpc_wins)
"
-------------------------------------------------------------------------
"if vpc_id:
    vpc_wins = dict((group['GroupName'], group) for group in all_groups if group.get('VpcId') and group['VpcId'] == vpc_id)
    groups.update(vpc_wins)
"
-------------------------------------------------------------------------
"if vpc_id:
    vpc_wins = dict((group['GroupName'], group) for group in all_groups if group.get('VpcId') and group['VpcId'] == vpc_id)
    groups.update(vpc_wins)
"
-------------------------------------------------------------------------
"Recom
PRs: 45787, 45815"
-------------------------------------------------------------------------
=========================================================================
"stdout = ''
stderr = ''
"
-------------------------------------------------------------------------
"stdout = u''
stderr = u''
"
-------------------------------------------------------------------------
"stdout = u''
stderr = u''
"
-------------------------------------------------------------------------
"Recom
PRs: 45607, 45791"
-------------------------------------------------------------------------
=========================================================================
"specified_rules = flatten_nested_targets(module, deepcopy(specified_rules))
"
-------------------------------------------------------------------------
"def flatten_nested_targets(module, rules):
def _flatten(targets):
    for target in targets:
        if isinstance(target, list):
            for t in _flatten(target):
                yield t
        elif isinstance(target, string_types):
            yield target

if rules is not None:
    for rule in rules:
        target_list_type = None
        if isinstance(rule.get('cidr_ip'), list):
            target_list_type = 'cidr_ip'
        elif isinstance(rule.get('cidr_ipv6'), list):
            target_list_type = 'cidr_ipv6'
        if target_list_type is not None:
            rule[target_list_type] = list(_flatten(rule[target_list_type]))
return rules


"
-------------------------------------------------------------------------
"def flatten_nested_targets(module, rules):
def _flatten(targets):
    for target in targets:
        if isinstance(target, list):
            for t in _flatten(target):
                yield t
        elif isinstance(target, string_types):
            yield target

if rules is not None:
    for rule in rules:
        target_list_type = None
        if isinstance(rule.get('cidr_ip'), list):
            target_list_type = 'cidr_ip'
        elif isinstance(rule.get('cidr_ipv6'), list):
            target_list_type = 'cidr_ipv6'
        if target_list_type is not None:
            rule[target_list_type] = list(_flatten(rule[target_list_type]))
return rules


"
-------------------------------------------------------------------------
"Recom
PRs: 45594, 45748"
-------------------------------------------------------------------------
=========================================================================
"if rule.get('ports') and (isinstance(rule['ports'], string_types) or isinstance(rule['ports'], int)):
"
-------------------------------------------------------------------------
"rules = flatten_nested_targets(module, deepcopy(module.params['rules']))
rules_egress = flatten_nested_targets(module, deepcopy(module.params['rules_egress']))
rules = deduplicate_rules_args(rules_expand_sources(rules_expand_ports(rules)))
rules_egress = deduplicate_rules_args(rules_expand_sources(rules_expand_ports(rules_egress)))
"
-------------------------------------------------------------------------
"rules = flatten_nested_targets(module, deepcopy(module.params['rules']))
rules_egress = flatten_nested_targets(module, deepcopy(module.params['rules_egress']))
rules = deduplicate_rules_args(rules_expand_sources(rules_expand_ports(rules)))
rules_egress = deduplicate_rules_args(rules_expand_sources(rules_expand_ports(rules_egress)))
"
-------------------------------------------------------------------------
"Recom
PRs: 45594, 45748"
-------------------------------------------------------------------------
=========================================================================
"type: boolean
"
-------------------------------------------------------------------------
"type: boolean
type: boolean
"
-------------------------------------------------------------------------
"type: boolean
type: boolean
"
-------------------------------------------------------------------------
"Recom
PRs: 45736, 45738"
-------------------------------------------------------------------------
=========================================================================
"if checksum != destination_checksum:
    checksum_mismatch = True

t forcing redownload, unless checksum does not match
ot force and not checksum_mismatch:
# Not forcing redownload, unless checksum does not match
# allow file attribute changes
module.params['path'] = dest
file_args = module.load_file_common_arguments(module.params)
file_args['path'] = dest
result['changed'] = module.set_fs_attributes_if_different(file_args, False)
if result['changed']:
    module.exit_json(msg=""file already exists but file attributes changed"", **result)
module.exit_json(msg=""file already exists"", **result)
"
-------------------------------------------------------------------------
"if checksum != destination_checksum:
    checksum_mismatch = True

t forcing redownload, unless checksum does not match
ot force and not checksum_mismatch:
# allow file attribute changes
module.params['path'] = dest
file_args = module.load_file_common_arguments(module.params)
file_args['path'] = dest
changed = module.set_fs_attributes_if_different(file_args, False)
if changed:
    module.exit_json(msg=""file already exists but file attributes changed"", dest=dest, url=url, changed=changed)
module.exit_json(msg=""file already exists"", dest=dest, url=url, changed=changed)
"
-------------------------------------------------------------------------
"if checksum != destination_checksum:
    checksum_mismatch = True

t forcing redownload, unless checksum does not match
ot force and not checksum_mismatch:
# allow file attribute changes
module.params['path'] = dest
file_args = module.load_file_common_arguments(module.params)
file_args['path'] = dest
changed = module.set_fs_attributes_if_different(file_args, False)
if changed:
    module.exit_json(msg=""file already exists but file attributes changed"", dest=dest, url=url, changed=changed)
module.exit_json(msg=""file already exists"", dest=dest, url=url, changed=changed)
"
-------------------------------------------------------------------------
"Recom
PRs: 45495, 45567"
-------------------------------------------------------------------------
=========================================================================
"if checksum != destination_checksum:
    checksum_mismatch = True

t forcing redownload, unless checksum does not match
ot force and not checksum_mismatch:
# Not forcing redownload, unless checksum does not match
# allow file attribute changes
module.params['path'] = dest
file_args = module.load_file_common_arguments(module.params)
file_args['path'] = dest
result['changed'] = module.set_fs_attributes_if_different(file_args, False)
if result['changed']:
    module.exit_json(msg=""file already exists but file attributes changed"", **result)
module.exit_json(msg=""file already exists"", **result)
"
-------------------------------------------------------------------------
"if checksum != destination_checksum:
    checksum_mismatch = True

t forcing redownload, unless checksum does not match
ot force and not checksum_mismatch:
# Not forcing redownload, unless checksum does not match
# allow file attribute changes
module.params['path'] = dest
file_args = module.load_file_common_arguments(module.params)
file_args['path'] = dest
changed = module.set_fs_attributes_if_different(file_args, False)
if changed:
    module.exit_json(msg=""file already exists but file attributes changed"", dest=dest, url=url, changed=changed)
module.exit_json(msg=""file already exists"", dest=dest, url=url, changed=changed)
"
-------------------------------------------------------------------------
"if checksum != destination_checksum:
    checksum_mismatch = True

t forcing redownload, unless checksum does not match
ot force and not checksum_mismatch:
# Not forcing redownload, unless checksum does not match
# allow file attribute changes
module.params['path'] = dest
file_args = module.load_file_common_arguments(module.params)
file_args['path'] = dest
changed = module.set_fs_attributes_if_different(file_args, False)
if changed:
    module.exit_json(msg=""file already exists but file attributes changed"", dest=dest, url=url, changed=changed)
module.exit_json(msg=""file already exists"", dest=dest, url=url, changed=changed)
"
-------------------------------------------------------------------------
"Recom
PRs: 45495, 45565"
-------------------------------------------------------------------------
=========================================================================
"- name: Start a container and use an env file
docker_container:
  name: agent
  image: jenkinsci/ssh-slave
  env_file: /var/tmp/jenkins/agent.env

"
-------------------------------------------------------------------------
"- name: Start a container and use an env file
docker_container:
  name: agent
  image: jenkinsci/ssh-slave
  env_file: /var/tmp/jenkins/agent.env
"
-------------------------------------------------------------------------
"- name: Start a container and use an env file
docker_container:
  name: agent
  image: jenkinsci/ssh-slave
  env_file: /var/tmp/jenkins/agent.env
"
-------------------------------------------------------------------------
"Recom
PRs: 44535, 44565"
-------------------------------------------------------------------------
=========================================================================
"out = to_text(out, errors='surrogate_or_strict')
        out = out.strip()
"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_bytes, to_text
"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_bytes, to_text
"
-------------------------------------------------------------------------
"Recom
PRs: 43155, 43156"
-------------------------------------------------------------------------
=========================================================================
"if regexp is not None:
"
-------------------------------------------------------------------------
"regexp = params['regexp']
line = params['line']

if regexp == '':
    module.warn(
        ""The regular expression is an empty string, which will match every line in the file. ""
        ""This may have unintended consequences, such as replacing the last line in the file rather than appending. ""
        ""If this is desired, use '^' to match every line in the file and avoid this warning."")
    if backrefs and regexp is None:
        module.fail_json(msg='regexp is required with backrefs=true')
    if line is None:
        module.fail_json(msg='line is required with state=present')
"
-------------------------------------------------------------------------
"regexp = params['regexp']
line = params['line']

if regexp == '':
    module.warn(
        ""The regular expression is an empty string, which will match every line in the file. ""
        ""This may have unintended consequences, such as replacing the last line in the file rather than appending. ""
        ""If this is desired, use '^' to match every line in the file and avoid this warning."")
    if backrefs and regexp is None:
        module.fail_json(msg='regexp is required with backrefs=true')
    if line is None:
        module.fail_json(msg='line is required with state=present')
"
-------------------------------------------------------------------------
"Recom
PRs: 42013, 42207"
-------------------------------------------------------------------------
=========================================================================
"if regexp is not None:
"
-------------------------------------------------------------------------
"if regexp is None and line is None:
    module.fail_json(msg='one of line or regexp is required with state=absent')
"
-------------------------------------------------------------------------
"if regexp is None and line is None:
    module.fail_json(msg='one of line or regexp is required with state=absent')
"
-------------------------------------------------------------------------
"Recom
PRs: 42013, 42207"
-------------------------------------------------------------------------
=========================================================================
"if regexp is not None:
"
-------------------------------------------------------------------------
"regexp = params['regexp']
line = params['line']

if regexp == '':
    module.warn(
        ""The regular expression is an empty string, which will match every line in the file. ""
        ""This may have unintended consequences, such as replacing the last line in the file rather than appending. ""
        ""If this is desired, use '^' to match every line in the file and avoid this warning."")
    if backrefs and regexp is None:
        module.fail_json(msg='regexp is required with backrefs=true')
    if line is None:
        module.fail_json(msg='line is required with state=present')
"
-------------------------------------------------------------------------
"regexp = params['regexp']
line = params['line']

if regexp == '':
    module.warn(
        ""The regular expression is an empty string, which will match every line in the file. ""
        ""This may have unintended consequences, such as replacing the last line in the file rather than appending. ""
        ""If this is desired, use '^' to match every line in the file and avoid this warning."")
    if backrefs and regexp is None:
        module.fail_json(msg='regexp is required with backrefs=true')
    if line is None:
        module.fail_json(msg='line is required with state=present')
"
-------------------------------------------------------------------------
"Recom
PRs: 42013, 42204"
-------------------------------------------------------------------------
=========================================================================
"if regexp is not None:
"
-------------------------------------------------------------------------
"if regexp is None and line is None:
    module.fail_json(msg='one of line or regexp is required with state=absent')
"
-------------------------------------------------------------------------
"if regexp is None and line is None:
    module.fail_json(msg='one of line or regexp is required with state=absent')
"
-------------------------------------------------------------------------
"Recom
PRs: 42013, 42204"
-------------------------------------------------------------------------
=========================================================================
"- The C(backup) argument will backup the current device's active
  in the playbook root directory or role root directory if the
  playbook is part of an ansible role. If the directory does not
  exist, it is created.
"
-------------------------------------------------------------------------
"- The C(backup) argument will backup the current device's active
  in the playbook root directory or role root directory if the
  playbook is part of an ansible role. If the directory does not
  exist, it is created.
pe: bool
fault: 'no'
"
-------------------------------------------------------------------------
"- The C(backup) argument will backup the current device's active
  in the playbook root directory or role root directory if the
  playbook is part of an ansible role. If the directory does not
  exist, it is created.
pe: bool
fault: 'no'
"
-------------------------------------------------------------------------
"Recom
PRs: 39530, 40548"
-------------------------------------------------------------------------
=========================================================================
"err = '\n'
"
-------------------------------------------------------------------------
"err = to_native(stderr or """")

if err and not err.endswith('\n'):
    err = '\n'
"
-------------------------------------------------------------------------
"err = to_native(stderr or """")

if err and not err.endswith('\n'):
    err = '\n'
"
-------------------------------------------------------------------------
"Recom
PRs: 39019, 39430"
-------------------------------------------------------------------------
=========================================================================
"- ""To use this module, it has to be executed twice. Either as two
   different tasks in the same run or during two runs. Note that the output
   of the first run needs to be recorded and passed to the second run as the
   module argument C(data).""
   U(https://tools.ietf.org/html/draft-ietf-acme-acme-09#section-8).
   Also, consider the examples provided for this module.""
"
-------------------------------------------------------------------------
"- ""To use this module, it has to be executed twice. Either as two
   different tasks in the same run or during two runs. Note that the output
   of the first run needs to be recorded and passed to the second run as the
   module argument C(data).""
"
-------------------------------------------------------------------------
"- ""To use this module, it has to be executed twice. Either as two
   different tasks in the same run or during two runs. Note that the output
   of the first run needs to be recorded and passed to the second run as the
   module argument C(data).""
"
-------------------------------------------------------------------------
"Recom
PRs: 38135, 38160"
-------------------------------------------------------------------------
=========================================================================
"- ""The data to validate ongoing challenges. This must be specified for
   the second run of the module only.""
   of this module. See the examples for more details.""
"
-------------------------------------------------------------------------
"U(https://tools.ietf.org/html/draft-ietf-acme-acme-09#section-8).
Also, consider the examples provided for this module.""
"
-------------------------------------------------------------------------
"U(https://tools.ietf.org/html/draft-ietf-acme-acme-09#section-8).
Also, consider the examples provided for this module.""
"
-------------------------------------------------------------------------
"Recom
PRs: 38135, 38160"
-------------------------------------------------------------------------
=========================================================================
"self.module_fail_args = args
module.fail_json(msg=self.msg, other=self.module_fail_args)
"
-------------------------------------------------------------------------
"https://tools.ietf.org/html/draft-ietf-acme-acme-10#section-6.2
"
-------------------------------------------------------------------------
"https://tools.ietf.org/html/draft-ietf-acme-acme-10#section-6.2
"
-------------------------------------------------------------------------
"Recom
PRs: 37165, 37190"
-------------------------------------------------------------------------
=========================================================================
"https://tools.ietf.org/html/draft-ietf-acme-acme-10#section-6.2
"
-------------------------------------------------------------------------
"headers = {
    'Content-Type': 'application/josejson',
}
resp, info = fetch_url(self.module, url, data=data, headers=headers, method='POST')
"
-------------------------------------------------------------------------
"headers = {
    'Content-Type': 'application/josejson',
}
resp, info = fetch_url(self.module, url, data=data, headers=headers, method='POST')
"
-------------------------------------------------------------------------
"Recom
PRs: 37165, 37190"
-------------------------------------------------------------------------
=========================================================================
"headers = {
    'Content-Type': 'application/josejson',
}
resp, info = fetch_url(self.module, url, data=data, headers=headers, method='POST')
"
-------------------------------------------------------------------------
"challenge_response = {}
if self.version == 1:
    token = re.sub(r""[^A-Za-z0-9_\-]"", ""_"", challenge['token'])
    keyauthorization = self.account.get_keyauthorization(token)
    challenge_response[""resource""] = ""challenge""
    challenge_response[""keyAuthorization""] = keyauthorization
"
-------------------------------------------------------------------------
"challenge_response = {}
if self.version == 1:
    token = re.sub(r""[^A-Za-z0-9_\-]"", ""_"", challenge['token'])
    keyauthorization = self.account.get_keyauthorization(token)
    challenge_response[""resource""] = ""challenge""
    challenge_response[""keyAuthorization""] = keyauthorization
"
-------------------------------------------------------------------------
"Recom
PRs: 37165, 37190"
-------------------------------------------------------------------------
=========================================================================
"new_ir = self._copy_included_file(included_file)
new_blocks, handler_blocks = new_ir.get_block_list(
"
-------------------------------------------------------------------------
"new_ir = self._copy_included_file(included_file)
"
-------------------------------------------------------------------------
"new_ir = self._copy_included_file(included_file)
"
-------------------------------------------------------------------------
"Recom
PRs: 36470, 36526"
-------------------------------------------------------------------------
=========================================================================
"part['size'] = bytes_to_human((float(part['sectors']) * 512.0))
"
-------------------------------------------------------------------------
"part['size'] = self.module.pretty_bytes((float(part['sectors']) * 512.0))
"
-------------------------------------------------------------------------
"part['size'] = self.module.pretty_bytes((float(part['sectors']) * 512.0))
"
-------------------------------------------------------------------------
"Recom
PRs: 34475, 34645"
-------------------------------------------------------------------------
=========================================================================
"d['size'] = bytes_to_human(float(d['sectors']) * 512.0)
"
-------------------------------------------------------------------------
"d['size'] = self.module.pretty_bytes(float(d['sectors']) * 512.0)
"
-------------------------------------------------------------------------
"d['size'] = self.module.pretty_bytes(float(d['sectors']) * 512.0)
"
-------------------------------------------------------------------------
"Recom
PRs: 34475, 34645"
-------------------------------------------------------------------------
=========================================================================
"if moid in ['group-d1', 'ha-folder-root']:
"
-------------------------------------------------------------------------
"try:
    moid = thisobj._moId
except AttributeError:
    moid = None
if moid in ['group-d1', 'ha-folder-root']:
"
-------------------------------------------------------------------------
"try:
    moid = thisobj._moId
except AttributeError:
    moid = None
if moid in ['group-d1', 'ha-folder-root']:
"
-------------------------------------------------------------------------
"Recom
PRs: 31133, 32671"
-------------------------------------------------------------------------
=========================================================================
"s3.put_object(Bucket=bucket, Key=obj, Body=b'')
module.exit_json(msg=""Virtual directory %s created in bucket %s"" % (obj, bucket), changed=True)
"
-------------------------------------------------------------------------
"if formatted_keys:
    s3.delete_objects(Bucket=bucket, Delete={'Objects': formatted_keys})
"
-------------------------------------------------------------------------
"if formatted_keys:
    s3.delete_objects(Bucket=bucket, Delete={'Objects': formatted_keys})
"
-------------------------------------------------------------------------
"Recom
PRs: 32169, 32198"
-------------------------------------------------------------------------
=========================================================================
"sample:
  arn: 'arn:aws:events:us-east-1:123456789012:rule/MyCronTask'
  description: 'Run my scheduled task'
  name: 'MyCronTask'
  schedule_expression: 'cron(0 20 * * ? *)'
  state: 'ENABLED'

import botocore
pass  # handled by AnsibleAWSModule
 ansible.module_utils.aws.core import AnsibleAWSModule
 ansible.module_utils.ec2 import boto3_conn, camel_dict_to_snake_dict
 ansible.module_utils.ec2 import ec2_argument_spec, get_aws_connection_info
"
-------------------------------------------------------------------------
"import botocore
"
-------------------------------------------------------------------------
"import botocore
"
-------------------------------------------------------------------------
"Recom
PRs: 30823, 30942"
-------------------------------------------------------------------------
=========================================================================
"self.module = module
"
-------------------------------------------------------------------------
"except botocore.exceptions.ProfileNotFound as e:
"
-------------------------------------------------------------------------
"except botocore.exceptions.ProfileNotFound as e:
"
-------------------------------------------------------------------------
"Recom
PRs: 30823, 30942"
-------------------------------------------------------------------------
=========================================================================
"if not no_password_changes and (password is not None or role_attr_flags != '' or expires is not None):
"
-------------------------------------------------------------------------
"if not no_password_changes and (password is not None or role_attr_flags != ''):
"
-------------------------------------------------------------------------
"if not no_password_changes and (password is not None or role_attr_flags != ''):
"
-------------------------------------------------------------------------
"Recom
PRs: 26539, 26541"
-------------------------------------------------------------------------
=========================================================================
"if expires is not None:
    cursor.execute(""SELECT %s::timestamptz;"", (expires,))
    expires_with_tz = cursor.fetchone()[0]
    expires_changing = expires_with_tz != current_role_attrs.get('rolvaliduntil')
else:
    expires_changing = False
"
-------------------------------------------------------------------------
"expires_changing = (expires is not None and expires == current_role_attrs['rolvaliduntil'])
"
-------------------------------------------------------------------------
"expires_changing = (expires is not None and expires == current_role_attrs['rolvaliduntil'])
"
-------------------------------------------------------------------------
"Recom
PRs: 26539, 26541"
-------------------------------------------------------------------------
=========================================================================
"from hashlib import md5
"
-------------------------------------------------------------------------
"if not no_password_changes and (password is not None or role_attr_flags != '' or expires is not None):
"
-------------------------------------------------------------------------
"if not no_password_changes and (password is not None or role_attr_flags != '' or expires is not None):
"
-------------------------------------------------------------------------
"Recom
PRs: 23862, 26539"
-------------------------------------------------------------------------
=========================================================================
"
FLAGS = ('SUPERUSER', 'CREATEROLE', 'CREATEUSER', 'CREATEDB', 'INHERIT', 'LOGIN', 'REPLICATION')
FLAGS_BY_VERSION = {'BYPASSRLS': '9.5.0'}
database=frozenset(('CREATE', 'CONNECT', 'TEMPORARY', 'TEMP', 'ALL')),)
"
-------------------------------------------------------------------------
"if expires is not None:
    cursor.execute(""SELECT %s::timestamptz;"", (expires,))
    expires_with_tz = cursor.fetchone()[0]
    expires_changing = expires_with_tz != current_role_attrs.get('rolvaliduntil')
else:
    expires_changing = False
"
-------------------------------------------------------------------------
"if expires is not None:
    cursor.execute(""SELECT %s::timestamptz;"", (expires,))
    expires_with_tz = cursor.fetchone()[0]
    expires_changing = expires_with_tz != current_role_attrs.get('rolvaliduntil')
else:
    expires_changing = False
"
-------------------------------------------------------------------------
"Recom
PRs: 23862, 26539"
-------------------------------------------------------------------------
=========================================================================
