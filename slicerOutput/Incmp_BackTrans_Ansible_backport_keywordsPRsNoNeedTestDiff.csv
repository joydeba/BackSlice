"# -*- coding: utf-8 -*-
#
# documentation build configuration file, created by
# sphinx-quickstart on Sat Sep 27 13:23:22 2008-2009.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# The contents of this file are pickled, so don't put values in the namespace
# that aren't pickleable (module imports are okay, they're removed
# automatically).
#
# All configuration values have a default value; values that are commented out
# serve to show the default value.
from __future__ import (absolute_import, division, print_function)
__metaclass__ = type
import sys
import os
# pip install sphinx_rtd_theme
# import sphinx_rtd_theme
# html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]
# If your extensions are in another directory, add it here. If the directory
# is relative to the documentation root, use os.path.abspath to make it
# absolute, like shown here.
# sys.path.append(os.path.abspath('some/directory'))
#
sys.path.insert(0, os.path.join('ansible', 'lib'))
sys.path.append(os.path.abspath(os.path.join('..', '_extensions')))
# We want sphinx to document the ansible modules contained in this repository,
# not those that may happen to be installed in the version
# of Python used to run sphinx.  When sphinx loads in order to document,
# the repository version needs to be the one that is loaded:
sys.path.insert(0, os.path.abspath(os.path.join('..', '..', '..', 'lib')))
VERSION = 'devel'
AUTHOR = 'Ansible, Inc'
# General configuration
# ---------------------
# Add any Sphinx extension module names here, as strings.
# They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
# TEST: 'sphinxcontrib.fulltoc'
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.intersphinx', 'pygments_lexer', 'notfound.extension']
# Later on, add 'sphinx.ext.viewcode' to the list if you want to have
# colorized code generated too for references.
# Add any paths that contain templates here, relative to this directory.
templates_path = ['.templates']
# The suffix of source filenames.
source_suffix = '.rst'
# The master toctree document.
master_doc = 'index'
# General substitutions.
project = 'Ansible'
copyright = ""2021 Red Hat, Inc.""
# The default replacements for |version| and |release|, also used in various
# other places throughout the built documents.
#
# The short X.Y version.
version = VERSION
# The full version, including alpha/beta/rc tags.
release = VERSION
# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
# today = ''
# Else, today_fmt is used as the format for a strftime call.
today_fmt = '%B %d, %Y'
# List of documents that shouldn't be included in the build.
# unused_docs = []
# List of directories, relative to source directories, that shouldn't be
# searched for source files.
# exclude_dirs = []
# A list of glob-style patterns that should be excluded when looking
# for source files.
exclude_patterns = [
    '2.10_index.rst',
    'ansible_index.rst',
    'core_index.rst',
    'porting_guides/core_porting_guides.rst',
    'porting_guides/porting_guide_base_2.10.rst',
    'porting_guides/porting_guide_core_2.11.rst',
    'roadmap/index.rst',
    'roadmap/ansible_base_roadmap_index.rst',
    'roadmap/ROADMAP_2_10.rst',
    'roadmap/ROADMAP_2_11.rst'
]
# The reST default role (used for this markup: `text`) to use for all
# documents.
# default_role = None
# If true, '()' will be appended to :func: etc. cross-reference text.
# add_function_parentheses = True
# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
# add_module_names = True
# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
# show_authors = False
# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'
highlight_language = 'YAMLJinja'
# Substitutions, variables, entities, & shortcuts for text which do not need to link to anything.
# For titles which should be a link, use the intersphinx anchors set at the index, chapter, and section levels, such as  qi_start_:
# |br| is useful for formatting fields inside of tables
# |_| is a nonbreaking space; similarly useful inside of tables
rst_epilog = """"""
.. |br| raw:: html
   <br>
.. |_| unicode:: 0xA0
    :trim:
""""""
# Options for HTML output
# -----------------------
html_theme_path = ['../_themes']
html_theme = 'sphinx_rtd_theme'
html_short_title = 'Ansible Documentation'
html_show_sphinx = False
html_theme_options = {
    'canonical_url': ""https://docs.ansible.com/ansible/latest/"",
    'vcs_pageview_mode': 'edit'
}
html_context = {
    'display_github': 'True',
    'github_user': 'ansible',
    'github_repo': 'ansible',
    'github_version': 'devel/docs/docsite/rst/',
    'github_module_version': 'devel/lib/ansible/modules/',
    'github_root_dir': 'devel/lib/ansible',
    'github_cli_version': 'devel/lib/ansible/cli/',
    'current_version': version,
    'latest_version': '2.10',
    # list specifically out of order to make latest work
    'available_versions': ('latest', '2.9', '2.9_ja', '2.8', 'devel'),
    'css_files': ('_static/ansible.css',  # overrides to the standard theme
                  ),
}
# The style sheet to use for HTML and HTML Help pages. A file of that name
# must exist either in Sphinx' static/ path, or in one of the custom paths
# given in html_static_path.
# html_style = 'solar.css'
# The name for this set of Sphinx documents.  If None, it defaults to
# ""<project> v<release> documentation"".
html_title = 'Ansible Documentation'
# A shorter title for the navigation bar.  Default is the same as html_title.
# html_short_title = None
# The name of an image file (within the static path) to place at the top of
# the sidebar.
# html_logo =
# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
# html_favicon = 'favicon.ico'
# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named ""default.css"" will overwrite the builtin ""default.css"".
html_static_path = ['../_static']
# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
html_last_updated_fmt = '%b %d, %Y'
# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
# html_use_smartypants = True
# Custom sidebar templates, maps document names to template names.
# html_sidebars = {}
# Additional templates that should be rendered to pages, maps page names to
# template names.
# html_additional_pages = {}
# If false, no module index is generated.
# html_use_modindex = True
# If false, no index is generated.
# html_use_index = True
# If true, the index is split into individual pages for each letter.
# html_split_index = False
# If true, the reST sources are included in the HTML build as _sources/<name>.
html_copy_source = False
# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
# html_use_opensearch = 'https://docs.ansible.com/ansible/latest'
# If nonempty, this is the file name suffix for HTML files (e.g. "".xhtml"").
# html_file_suffix = ''
# Output file base name for HTML help builder.
htmlhelp_basename = 'Poseidodoc'
# Configuration for sphinx-notfound-pages
# with no 'notfound_template' and no 'notfound_context' set,
# the extension builds 404.rst into a location-agnostic 404 page
#
# default is `en` - using this for the sub-site:
notfound_default_language = ""ansible""
# default is `latest`:
# setting explicitly - docsite serves up /ansible/latest/404.html
# so keep this set to `latest` even on the `devel` branch
# then no maintenance is needed when we branch a new stable_x.x
notfound_default_version = ""latest""
# makes default setting explicit:
notfound_no_urls_prefix = False
# Options for LaTeX output
# ------------------------
# The paper size ('letter' or 'a4').
# latex_paper_size = 'letter'
# The font size ('10pt', '11pt' or '12pt').
# latex_font_size = '10pt'
# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, document class
# [howto/manual]).
latex_documents = [
    ('index', 'ansible.tex', 'Ansible 2.2 Documentation', AUTHOR, 'manual'),
]
# The name of an image file (relative to this directory) to place at the top of
# the title page.
# latex_logo = None
# For ""manual"" documents, if this is true, then toplevel headings are parts,
# not chapters.
# latex_use_parts = False
# Additional stuff for the LaTeX preamble.
# latex_preamble = ''
# Documents to append as an appendix to all manuals.
# latex_appendices = []
# If false, no module index is generated.
# latex_use_modindex = True
autoclass_content = 'both'
# Note:  Our strategy for intersphinx mappings is to have the upstream build location as the
# canonical source and then cached copies of the mapping stored locally in case someone is building
# when disconnected from the internet.  We then have a script to update the cached copies.
#
# Because of that, each entry in this mapping should have this format:
#   name: ('http://UPSTREAM_URL', (None, 'path/to/local/cache.inv'))
#
# The update script depends on this format so deviating from this (for instance, adding a third
# location for the mappning to live) will confuse it.
intersphinx_mapping = {'python': ('https://docs.python.org/2/', (None, '../python2.inv')),
                       'python3': ('https://docs.python.org/3/', (None, '../python3.inv')),
                       'jinja2': ('http://jinja.palletsprojects.com/', (None, '../jinja2.inv')),
                       'ansible_2_10': ('https://docs.ansible.com/ansible/2.10/', (None, '../ansible_2_10.inv')),
                       'ansible_2_9': ('https://docs.ansible.com/ansible/2.9/', (None, '../ansible_2_9.inv')),
                       'ansible_2_8': ('https://docs.ansible.com/ansible/2.8/', (None, '../ansible_2_8.inv')),
                       'ansible_2_7': ('https://docs.ansible.com/ansible/2.7/', (None, '../ansible_2_7.inv')),
                       'ansible_2_6': ('https://docs.ansible.com/ansible/2.6/', (None, '../ansible_2_6.inv')),
                       'ansible_2_5': ('https://docs.ansible.com/ansible/2.5/', (None, '../ansible_2_5.inv')),
                       }
# linckchecker settings
linkcheck_ignore = [
    r'http://irc\.freenode\.net',
]
linkcheck_workers = 25
# linkcheck_anchors = False
"
-------------------------------------------------------------------------
"from __future__ import (absolute_import, division, print_function)
__metaclass__ = type
import sys
import os

sys.path.insert(0, os.path.join('ansible', 'lib'))
sys.path.append(os.path.abspath(os.path.join('..', '_extensions')))

sys.path.insert(0, os.path.abspath(os.path.join('..', '..', '..', 'lib')))
VERSION = '2.10'
AUTHOR = 'Ansible, Inc'

extensions = ['sphinx.ext.autodoc', 'sphinx.ext.intersphinx', 'pygments_lexer', 'notfound.extension']

templates_path = ['.templates']

source_suffix = '.rst'

master_doc = 'index'

project = 'Ansible'
copyright = ""2021 Red Hat, Inc.""

version = VERSION
release = VERSION

today_fmt = '%B %d, %Y'

exclude_patterns = [
    'ansible_index.rst',
    'porting_guides',
    'roadmap/ansible_roadmap_index.rst',
    'roadmap/old_roadmap_index.rst',
    'roadmap/ROADMAP_2_5.rst',
    'roadmap/ROADMAP_2_6.rst',
    'roadmap/ROADMAP_2_7.rst',
    'roadmap/ROADMAP_2_8.rst',
    'porting_guides/core_porting_guides.rst',
    'porting_guides/porting_guide_2*',
    'porting_guides/porting_guide_3*',
]

pygments_style = 'sphinx'
highlight_language = 'YAML+Jinja'

rst_epilog = """"""
.. |br| raw:: html
   <br>
.. |_| unicode:: 0xA0
    :trim:
""""""

html_theme_path = ['../_themes']
html_theme = 'sphinx_rtd_theme'
html_short_title = 'Ansible Documentation'
html_show_sphinx = False

html_theme_options = {
    'canonical_url': ""https://docs.ansible.com/ansible/latest/"",
    'vcs_pageview_mode': 'edit'
}

html_context = {
    'display_github': 'True',
    'github_user': 'ansible',
    'github_repo': 'ansible',
    'github_version': 'devel/docs/docsite/rst/',
    'github_module_version': 'devel/lib/ansible/modules/',
    'github_root_dir': 'devel/lib/ansible',
    'github_cli_version': 'devel/lib/ansible/cli/',
    'current_version': version,
    'latest_version': '3',
    'available_versions': ('latest', '2.10', '2.9', '2.9_ja', '2.8', 'devel'),
    'css_files': ('_static/ansible.css',),
}

html_title = 'Ansible Documentation'

html_static_path = ['../_static']

html_last_updated_fmt = '%b %d, %Y'

html_copy_source = False

htmlhelp_basename = 'Poseidodoc'

notfound_default_language = ""ansible""

notfound_default_version = ""latest""

notfound_no_urls_prefix = False

latex_documents = [
    ('index', 'ansible.tex', 'Ansible 2.2 Documentation', AUTHOR, 'manual'),
]

autoclass_content = 'both'

intersphinx_mapping = {'python': ('https://docs.python.org/2/', (None, '../python2.inv')),
                       'python3': ('https://docs.python.org/3/', (None, '../python3.inv')),
                       'jinja2': ('http://jinja.palletsprojects.com/', (None, '../jinja2.inv')),
                       'ansible_2_10': ('https://docs.ansible.com/ansible/2.10/', (None, '../ansible_2_10.inv')),
                       'ansible_2_9': ('https://docs.ansible.com/ansible/2.9/', (None, '../ansible_2_9.inv')),
                       'ansible_2_8': ('https://docs.ansible.com/ansible/2.8/', (None, '../ansible_2_8.inv')),
                       'ansible_2_7': ('https://docs.ansible.com/ansible/2.7/', (None, '../ansible_2_7.inv')),
                       'ansible_2_6': ('https://docs.ansible.com/ansible/2.6/', (None, '../ansible_2_6.inv')),
                       'ansible_2_5': ('https://docs.ansible.com/ansible/2.5/', (None, '../ansible_2_5.inv')),
}

linkcheck_ignore = [
    r'http://irc\.freenode\.net',
]
linkcheck_workers = 25"
-------------------------------------------------------------------------
"# -*- coding: utf-8 -*-
#
# documentation build configuration file, created by
# sphinx-quickstart on Sat Sep 27 13:23:22 2008-2009.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# The contents of this file are pickled, so don't put values in the namespace
# that aren't pickleable (module imports are okay, they're removed
# automatically).
#
# All configuration values have a default value; values that are commented out
# serve to show the default value.
from __future__ import (absolute_import, division, print_function)
__metaclass__ = type
import sys
import os
# pip install sphinx_rtd_theme
# import sphinx_rtd_theme
# html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]
# If your extensions are in another directory, add it here. If the directory
# is relative to the documentation root, use os.path.abspath to make it
# absolute, like shown here.
# sys.path.append(os.path.abspath('some/directory'))
#
sys.path.insert(0, os.path.join('ansible', 'lib'))
sys.path.append(os.path.abspath(os.path.join('..', '_extensions')))
# We want sphinx to document the ansible modules contained in this repository,
# not those that may happen to be installed in the version
# of Python used to run sphinx.  When sphinx loads in order to document,
# the repository version needs to be the one that is loaded:
sys.path.insert(0, os.path.abspath(os.path.join('..', '..', '..', 'lib')))
VERSION = '3'
AUTHOR = 'Ansible, Inc'
# General configuration
# ---------------------
# Add any Sphinx extension module names here, as strings.
# They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
# TEST: 'sphinxcontrib.fulltoc'
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.intersphinx', 'pygments_lexer', 'notfound.extension']
# Later on, add 'sphinx.ext.viewcode' to the list if you want to have
# colorized code generated too for references.
# Add any paths that contain templates here, relative to this directory.
templates_path = ['.templates']
# The suffix of source filenames.
source_suffix = '.rst'
# The master toctree document.
master_doc = 'index'
# General substitutions.
project = 'Ansible'
copyright = ""2021 Red Hat, Inc.""
# The default replacements for |version| and |release|, also used in various
# other places throughout the built documents.
#
# The short X.Y version.
version = VERSION
# The full version, including alpha/beta/rc tags.
release = VERSION
# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
# today = ''
# Else, today_fmt is used as the format for a strftime call.
today_fmt = '%B %d, %Y'
# List of documents that shouldn't be included in the build.
# unused_docs = []
# List of directories, relative to source directories, that shouldn't be
# searched for source files.
# exclude_dirs = []
# A list of glob-style patterns that should be excluded when looking
# for source files.
exclude_patterns = [
    '2.10_index.rst',
    'ansible_index.rst',
    'core_index.rst',
    'porting_guides/core_porting_guides.rst',
    'porting_guides/porting_guide_base_2.10.rst',
    'porting_guides/porting_guide_core_2.11.rst',
    'roadmap/index.rst',
    'roadmap/ansible_base_roadmap_index.rst',
    'roadmap/ROADMAP_2_10.rst',
    'roadmap/ROADMAP_2_11.rst'
]
# The reST default role (used for this markup: `text`) to use for all
# documents.
# default_role = None
# If true, '()' will be appended to :func: etc. cross-reference text.
# add_function_parentheses = True
# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
# add_module_names = True
# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
# show_authors = False
# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'
highlight_language = 'YAMLJinja'
# Substitutions, variables, entities, & shortcuts for text which do not need to link to anything.
# For titles which should be a link, use the intersphinx anchors set at the index, chapter, and section levels, such as  qi_start_:
# |br| is useful for formatting fields inside of tables
# |_| is a nonbreaking space; similarly useful inside of tables
rst_epilog = """"""
.. |br| raw:: html
   <br>
.. |_| unicode:: 0xA0
    :trim:
""""""
# Options for HTML output
# -----------------------
html_theme_path = ['../_themes']
html_theme = 'sphinx_rtd_theme'
html_short_title = 'Ansible Documentation'
html_show_sphinx = False
html_theme_options = {
    'canonical_url': ""https://docs.ansible.com/ansible/latest/"",
    'vcs_pageview_mode': 'edit'
}
html_context = {
    'display_github': 'True',
    'github_user': 'ansible',
    'github_repo': 'ansible',
    'github_version': 'devel/docs/docsite/rst/',
    'github_module_version': 'devel/lib/ansible/modules/',
    'github_root_dir': 'devel/lib/ansible',
    'github_cli_version': 'devel/lib/ansible/cli/',
    'current_version': version,
    'latest_version': '3',
    # list specifically out of order to make latest work
    'available_versions': ('latest', '2.10', '2.9', '2.9_ja', '2.8', 'devel'),
    'css_files': ('_static/ansible.css',  # overrides to the standard theme
                  ),
}
# The style sheet to use for HTML and HTML Help pages. A file of that name
# must exist either in Sphinx' static/ path, or in one of the custom paths
# given in html_static_path.
# html_style = 'solar.css'
# The name for this set of Sphinx documents.  If None, it defaults to
# ""<project> v<release> documentation"".
html_title = 'Ansible Documentation'
# A shorter title for the navigation bar.  Default is the same as html_title.
# html_short_title = None
# The name of an image file (within the static path) to place at the top of
# the sidebar.
# html_logo =
# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
# html_favicon = 'favicon.ico'
# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named ""default.css"" will overwrite the builtin ""default.css"".
html_static_path = ['../_static']
# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
html_last_updated_fmt = '%b %d, %Y'
# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
# html_use_smartypants = True
# Custom sidebar templates, maps document names to template names.
# html_sidebars = {}
# Additional templates that should be rendered to pages, maps page names to
# template names.
# html_additional_pages = {}
# If false, no module index is generated.
# html_use_modindex = True
# If false, no index is generated.
# html_use_index = True
# If true, the index is split into individual pages for each letter.
# html_split_index = False
# If true, the reST sources are included in the HTML build as _sources/<name>.
html_copy_source = False
# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
# html_use_opensearch = 'https://docs.ansible.com/ansible/latest'
# If nonempty, this is the file name suffix for HTML files (e.g. "".xhtml"").
# html_file_suffix = ''
# Output file base name for HTML help builder.
htmlhelp_basename = 'Poseidodoc'
# Configuration for sphinx-notfound-pages
# with no 'notfound_template' and no 'notfound_context' set,
# the extension builds 404.rst into a location-agnostic 404 page
#
# default is `en` - using this for the sub-site:
notfound_default_language = ""ansible""
# default is `latest`:
# setting explicitly - docsite serves up /ansible/latest/404.html
# so keep this set to `latest` even on the `devel` branch
# then no maintenance is needed when we branch a new stable_x.x
notfound_default_version = ""latest""
# makes default setting explicit:
notfound_no_urls_prefix = False
# Options for LaTeX output
# ------------------------
# The paper size ('letter' or 'a4').
# latex_paper_size = 'letter'
# The font size ('10pt', '11pt' or '12pt').
# latex_font_size = '10pt'
# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, document class
# [howto/manual]).
latex_documents = [
    ('index', 'ansible.tex', 'Ansible 2.2 Documentation', AUTHOR, 'manual'),
]
# The name of an image file (relative to this directory) to place at the top of
# the title page.
# latex_logo = None
# For ""manual"" documents, if this is true, then toplevel headings are parts,
# not chapters.
# latex_use_parts = False
# Additional stuff for the LaTeX preamble.
# latex_preamble = ''
# Documents to append as an appendix to all manuals.
# latex_appendices = []
# If false, no module index is generated.
# latex_use_modindex = True
autoclass_content = 'both'
# Note:  Our strategy for intersphinx mappings is to have the upstream build location as the
# canonical source and then cached copies of the mapping stored locally in case someone is building
# when disconnected from the internet.  We then have a script to update the cached copies.
#
# Because of that, each entry in this mapping should have this format:
#   name: ('http://UPSTREAM_URL', (None, 'path/to/local/cache.inv'))
#
# The update script depends on this format so deviating from this (for instance, adding a third
# location for the mappning to live) will confuse it.
intersphinx_mapping = {'python': ('https://docs.python.org/2/', (None, '../python2.inv')),
                       'python3': ('https://docs.python.org/3/', (None, '../python3.inv')),
                       'jinja2': ('http://jinja.palletsprojects.com/', (None, '../jinja2.inv')),
                       'ansible_2_10': ('https://docs.ansible.com/ansible/2.10/', (None, '../ansible_2_10.inv')),
                       'ansible_2_9': ('https://docs.ansible.com/ansible/2.9/', (None, '../ansible_2_9.inv')),
                       'ansible_2_8': ('https://docs.ansible.com/ansible/2.8/', (None, '../ansible_2_8.inv')),
                       'ansible_2_7': ('https://docs.ansible.com/ansible/2.7/', (None, '../ansible_2_7.inv')),
                       'ansible_2_6': ('https://docs.ansible.com/ansible/2.6/', (None, '../ansible_2_6.inv')),
                       'ansible_2_5': ('https://docs.ansible.com/ansible/2.5/', (None, '../ansible_2_5.inv')),
                       }
# linckchecker settings
linkcheck_ignore = [
    r'http://irc\.freenode\.net',
]
linkcheck_workers = 25
# linkcheck_anchors = False
"
-------------------------------------------------------------------------
"Recom
PRs: 73616, 73637"
-------------------------------------------------------------------------
=========================================================================
"if 'BHYVE' in out:
    guest_tech.add('bhyve')
    if not found_virt:
        virtual_facts['virtualization_type'] = 'bhyve'
        virtual_facts['virtualization_role'] = 'guest'
        found_virt = True
"
-------------------------------------------------------------------------
"if 'BHYVE' in out:
    guest_tech.add('bhyve')
    if not found_virt:
        virtual_facts['virtualization_type'] = 'bhyve'
        virtual_facts['virtualization_role'] = 'guest'
        found_virt = True"
-------------------------------------------------------------------------
"if 'BHYVE' in out:
    virtual_facts['virtualization_type'] = 'bhyve'
    virtual_facts['virtualization_role'] = 'guest'
    return virtual_facts
"
-------------------------------------------------------------------------
"Recom
PRs: 73204, 73234"
-------------------------------------------------------------------------
=========================================================================
"# -*- coding: utf-8 -*-
# Copyright (c) 2020 Ansible Project
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
from __future__ import absolute_import, division, print_function
__metaclass__ = type
from ansible.module_utils.facts.virtual import linux
def test_get_virtual_facts_bhyve(mocker):
    mocker.patch('os.path.exists', return_value=False)
    mocker.patch('ansible.module_utils.facts.virtual.linux.get_file_content', return_value='')
    mocker.patch('ansible.module_utils.facts.virtual.linux.get_file_lines', return_value=[])
    module = mocker.Mock()
    module.run_command.return_value = (0, 'BHYVE\n', '')
    inst = linux.LinuxVirtual(module)
    facts = inst.get_virtual_facts()
    expected = {
        'virtualization_role': 'guest',
        'virtualization_tech_host': set(),
        'virtualization_type': 'bhyve',
        'virtualization_tech_guest': set(['bhyve']),
    }
    assert facts == expected
"
-------------------------------------------------------------------------
"from ansible.module_utils.facts.virtual import linux
def test_get_virtual_facts_bhyve(mocker):
    mocker.patch('os.path.exists', return_value=False)
    mocker.patch('ansible.module_utils.facts.virtual.linux.get_file_content', return_value='')
    mocker.patch('ansible.module_utils.facts.virtual.linux.get_file_lines', return_value=[])
    module = mocker.Mock()
    module.run_command.return_value = (0, 'BHYVE\n', '')
    inst = linux.LinuxVirtual(module)
    facts = inst.get_virtual_facts()
    expected = {
        'virtualization_role': 'guest',
        'virtualization_type': 'bhyve',
    }
    assert facts == expected"
-------------------------------------------------------------------------
"# -*- coding: utf-8 -*-
# Copyright (c) 2020 Ansible Project
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
from __future__ import absolute_import, division, print_function
__metaclass__ = type
from ansible.module_utils.facts.virtual import linux
def test_get_virtual_facts_bhyve(mocker):
    mocker.patch('os.path.exists', return_value=False)
    mocker.patch('ansible.module_utils.facts.virtual.linux.get_file_content', return_value='')
    mocker.patch('ansible.module_utils.facts.virtual.linux.get_file_lines', return_value=[])
    module = mocker.Mock()
    module.run_command.return_value = (0, 'BHYVE\n', '')
    inst = linux.LinuxVirtual(module)
    facts = inst.get_virtual_facts()
    expected = {
        'virtualization_role': 'guest',
        'virtualization_type': 'bhyve',
    }
    assert facts == expected
"
-------------------------------------------------------------------------
"Recom
PRs: 73204, 73234"
-------------------------------------------------------------------------
=========================================================================
"if 'BHYVE' in out:
    guest_tech.add('bhyve')
    if not found_virt:
        virtual_facts['virtualization_type'] = 'bhyve'
        virtual_facts['virtualization_role'] = 'guest'
        found_virt = True
"
-------------------------------------------------------------------------
"if 'BHYVE' in out:
    guest_tech.add('bhyve')
    if not found_virt:
        virtual_facts['virtualization_type'] = 'bhyve'
        virtual_facts['virtualization_role'] = 'guest'
        found_virt = True"
-------------------------------------------------------------------------
"if 'BHYVE' in out:
    virtual_facts['virtualization_type'] = 'bhyve'
    virtual_facts['virtualization_role'] = 'guest'
    return virtual_facts
"
-------------------------------------------------------------------------
"Recom
PRs: 73204, 73233"
-------------------------------------------------------------------------
=========================================================================
"# -*- coding: utf-8 -*-
# Copyright (c) 2020 Ansible Project
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
from __future__ import absolute_import, division, print_function
__metaclass__ = type
from ansible.module_utils.facts.virtual import linux
def test_get_virtual_facts_bhyve(mocker):
    mocker.patch('os.path.exists', return_value=False)
    mocker.patch('ansible.module_utils.facts.virtual.linux.get_file_content', return_value='')
    mocker.patch('ansible.module_utils.facts.virtual.linux.get_file_lines', return_value=[])
    module = mocker.Mock()
    module.run_command.return_value = (0, 'BHYVE\n', '')
    inst = linux.LinuxVirtual(module)
    facts = inst.get_virtual_facts()
    expected = {
        'virtualization_role': 'guest',
        'virtualization_tech_host': set(),
        'virtualization_type': 'bhyve',
        'virtualization_tech_guest': set(['bhyve']),
    }
    assert facts == expected
"
-------------------------------------------------------------------------
"def test_get_virtual_facts_bhyve(mocker):
    mocker.patch('os.path.exists', return_value=False)
    mocker.patch('ansible.module_utils.facts.virtual.linux.get_file_content', return_value='')
    mocker.patch('ansible.module_utils.facts.virtual.linux.get_file_lines', return_value=[])

    module = mocker.Mock()
    module.run_command.return_value = (0, 'BHYVE\n', '')
    inst = linux.LinuxVirtual(module)

    facts = inst.get_virtual_facts()
    expected = {
        'virtualization_role': 'guest',
        'virtualization_type': 'bhyve',
    }

    assert facts == expected"
-------------------------------------------------------------------------
"# -*- coding: utf-8 -*-
# Copyright (c) 2020 Ansible Project
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
from __future__ import absolute_import, division, print_function
__metaclass__ = type
from ansible.module_utils.facts.virtual import linux
def test_get_virtual_facts_bhyve(mocker):
    mocker.patch('os.path.exists', return_value=False)
    mocker.patch('ansible.module_utils.facts.virtual.linux.get_file_content', return_value='')
    mocker.patch('ansible.module_utils.facts.virtual.linux.get_file_lines', return_value=[])
    module = mocker.Mock()
    module.run_command.return_value = (0, 'BHYVE\n', '')
    inst = linux.LinuxVirtual(module)
    facts = inst.get_virtual_facts()
    expected = {
        'virtualization_role': 'guest',
        'virtualization_type': 'bhyve',
    }
    assert facts == expected
"
-------------------------------------------------------------------------
"Recom
PRs: 73204, 73233"
-------------------------------------------------------------------------
=========================================================================
"import sys
"
-------------------------------------------------------------------------
import sys
-------------------------------------------------------------------------
"import sys
import time
"
-------------------------------------------------------------------------
"Recom
PRs: 72604, 72610"
-------------------------------------------------------------------------
=========================================================================
"import sys
"
-------------------------------------------------------------------------
"import ansible.plugins.callback
import ansible.executor.task_result
import ansible.errors"
-------------------------------------------------------------------------
"import sys
import time
"
-------------------------------------------------------------------------
"Recom
PRs: 72604, 72609"
-------------------------------------------------------------------------
=========================================================================
"        # Workaround for https://github.com/ansible/ansible/issues/71528
        elif err and rc == 1 and 'Failed to parse bus message' in err:
            result['status'] = parse_systemctl_show(to_native(out).split('\n'))
            (rc, out, err) = module.run_command(""{systemctl} list-units '{unit}*'"".format(systemctl=systemctl, unit=unit))
            is_systemd = unit in out
            (rc, out, err) = module.run_command(""{systemctl} is-active '{unit}'"".format(systemctl=systemctl, unit=unit))
            result['status']['ActiveState'] = out.rstrip('\n')
"
-------------------------------------------------------------------------
"# Workaround for https://github.com/ansible/ansible/issues/71528
        elif err and rc == 1 and 'Failed to parse bus message' in err:
            result['status'] = parse_systemctl_show(to_native(out).split('\n'))
            (rc, out, err) = module.run_command(""{systemctl} list-units '{unit}*'"".format(systemctl=systemctl, unit=unit))
            is_systemd = unit in out
            (rc, out, err) = module.run_command(""{systemctl} is-active '{unit}'"".format(systemctl=systemctl, unit=unit))
            result['status']['ActiveState'] = out.rstrip('\n')"
-------------------------------------------------------------------------
"        # Workaround for https://github.com/ansible/ansible/issues/71528
        elif err and rc == 1 and 'Failed to parse bus message' in err:
            result['status'] = parse_systemctl_show(to_native(out).split('\n'))
            unit, sep, suffix = unit.partition('@')
            unit_search = '{unit}{sep}*'.format(unit=unit, sep=sep)
            (rc, out, err) = module.run_command(""{systemctl} list-unit-files '{unit_search}'"".format(systemctl=systemctl, unit_search=unit_search))
            is_systemd = unit in out
            (rc, out, err) = module.run_command(""{systemctl} is-active '{unit}'"".format(systemctl=systemctl, unit=unit))
            result['status']['ActiveState'] = out.rstrip('\n')
"
-------------------------------------------------------------------------
"Recom
PRs: 72337, 72348"
-------------------------------------------------------------------------
=========================================================================
"        # Workaround for https://github.com/ansible/ansible/issues/71528
        elif err and rc == 1 and 'Failed to parse bus message' in err:
            result['status'] = parse_systemctl_show(to_native(out).split('\n'))
            (rc, out, err) = module.run_command(""{systemctl} list-units '{unit}*'"".format(systemctl=systemctl, unit=unit))
            is_systemd = unit in out
            (rc, out, err) = module.run_command(""{systemctl} is-active '{unit}'"".format(systemctl=systemctl, unit=unit))
            result['status']['ActiveState'] = out.rstrip('\n')
"
-------------------------------------------------------------------------
"# Workaround for https://github.com/ansible/ansible/issues/71528
        elif err and rc == 1 and 'Failed to parse bus message' in err:
            result['status'] = parse_systemctl_show(to_native(out).split('\n'))
            (rc, out, err) = module.run_command(""{systemctl} list-units '{unit}*'"".format(systemctl=systemctl, unit=unit))
            is_systemd = unit in out
            (rc, out, err) = module.run_command(""{systemctl} is-active '{unit}'"".format(systemctl=systemctl, unit=unit))
            if 'ActiveState' in result['status']:
                result['status']['ActiveState'] = out.rstrip('\n')"
-------------------------------------------------------------------------
"        # Workaround for https://github.com/ansible/ansible/issues/71528
        elif err and rc == 1 and 'Failed to parse bus message' in err:
            result['status'] = parse_systemctl_show(to_native(out).split('\n'))
            unit, sep, suffix = unit.partition('@')
            unit_search = '{unit}{sep}*'.format(unit=unit, sep=sep)
            (rc, out, err) = module.run_command(""{systemctl} list-unit-files '{unit_search}'"".format(systemctl=systemctl, unit_search=unit_search))
            is_systemd = unit in out
            (rc, out, err) = module.run_command(""{systemctl} is-active '{unit}'"".format(systemctl=systemctl, unit=unit))
            result['status']['ActiveState'] = out.rstrip('\n')
"
-------------------------------------------------------------------------
"Recom
PRs: 72337, 72347"
-------------------------------------------------------------------------
=========================================================================
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
                self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
                fail = True
        else:  # fatal error
            fail = True
        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg)
"
-------------------------------------------------------------------------
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres = self.base.verify_gpg_signature(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
                self.base.retrieve_gpg_key(package)
            except dnf.exceptions.Error as e:
                fail = True
        else:  # fatal error
            fail = True
        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg)"
-------------------------------------------------------------------------
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
                self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
                fail = True
        else:  # fatal error
            fail = True
        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg=msg)
"
-------------------------------------------------------------------------
"Recom
PRs: 71537, 71541"
-------------------------------------------------------------------------
=========================================================================
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
                self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
                fail = True
        else:  # fatal error
            fail = True
        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg)
"
-------------------------------------------------------------------------
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
                self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
                fail = True
        else:  # fatal error
            fail = True
        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            module.fail_json(msg)"
-------------------------------------------------------------------------
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
                self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
                fail = True
        else:  # fatal error
            fail = True
        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg=msg)
"
-------------------------------------------------------------------------
"Recom
PRs: 71537, 71540"
-------------------------------------------------------------------------
=========================================================================
"- module: ansible.builtin.blockinfile
- module: ansible.builtin.copy
- module: ansible.builtin.file
- module: ansible.builtin.replace
- module: ansible.builtin.template
- module: ansible.windows.win_lineinfile
"
-------------------------------------------------------------------------
"- module: ansible.builtin.blockinfile
    - module: ansible.builtin.copy
    - module: ansible.builtin.file
    - module: ansible.builtin.replace
    - module: ansible.builtin.template
    - module: ansible.windows.win_lineinfile"
-------------------------------------------------------------------------
"- module: ansible.builtin.blockinfile
- module: ansible.builtin.copy
- module: ansible.builtin.file
- module: ansible.builtin.replace
- module: ansible.builtin.template
- module: community.windows.win_lineinfile
"
-------------------------------------------------------------------------
"Recom
PRs: 70530, 71380"
-------------------------------------------------------------------------
=========================================================================
"- module: ansible.builtin.authorized_key
- module: ansible.builtin.group
- module: ansible.windows.win_user
"
-------------------------------------------------------------------------
"- module: ansible.module_utils.six.authorized_key
- module: ansible.module_utils.basic.group
- module: ansible.windows.win_user"
-------------------------------------------------------------------------
"- module: ansible.posix.authorized_key
- module: ansible.builtin.group
- module: ansible.windows.win_user
"
-------------------------------------------------------------------------
"Recom
PRs: 70530, 71380"
-------------------------------------------------------------------------
=========================================================================
"- module: ansible.builtin.wait_for
- module: ansible.windows.win_wait_for
- module: ansible.windows.win_wait_for_process
"
-------------------------------------------------------------------------
"- module: ansible.builtin.wait_for
- module: ansible.windows.win_wait_for
- module: ansible.windows.win_wait_for_process"
-------------------------------------------------------------------------
"- module: ansible.builtin.wait_for
- module: ansible.windows.win_wait_for
- module: community.windows.win_wait_for_process
"
-------------------------------------------------------------------------
"Recom
PRs: 70530, 71380"
-------------------------------------------------------------------------
=========================================================================
"- If you wish to update an existing repository definition use M(ansible.builtin.ini_file) instead.
"
-------------------------------------------------------------------------
"if command in arguments:
            msg = ""Consider using the ansible.builtin.ini_file module with {subcmd} rather than running '{cmd}'.  "" + disable_suffix
            substitutions['subcmd'] = arguments[command]
            module.warn(msg.format(**substitutions))

        if command in commands:
            msg = ""Consider using the ansible.builtin.ini_file module rather than running '{cmd}'.  "" + disable_suffix
            module.warn(msg.format(**substitutions))"
-------------------------------------------------------------------------
"- If you wish to update an existing repository definition use M(community.general.ini_file) instead.
"
-------------------------------------------------------------------------
"Recom
PRs: 70530, 71380"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils.common.collections import is_sequence, Mapping
def _fail_on_undefined(data):
    """"""Recursively find an undefined value in a nested data structure
    and properly raise the undefined exception.
    """"""
    if isinstance(data, Mapping):
        for value in data.values():
            _fail_on_undefined(value)
    elif is_sequence(data):
        for item in data:
            _fail_on_undefined(item)
    else:
        if isinstance(data, StrictUndefined):
            # To actually raise the undefined exception we need to
            # access the undefined object otherwise the exception would
            # be raised on the next access which might not be properly
            # handled.
            # See https://github.com/ansible/ansible/issues/52158
            # and StrictUndefined implementation in upstream Jinja2.
            str(data)
    return data
    https://github.com/pallets/jinja/blob/master/src/jinja2/nativetypes.py
    """"""
        out = _fail_on_undefined(head[0])
        out = u''.join([to_text(_fail_on_undefined(v)) for v in nodes])
"
-------------------------------------------------------------------------
"_out = _fail_on_undefined(head[0])
_out = u''.join([to_text(_fail_on_undefined(v)) for v in nodes])"
-------------------------------------------------------------------------
"from ansible.module_utils.common.collections import is_sequence, Mapping
"
-------------------------------------------------------------------------
"Recom
PRs: 68432, 71105"
-------------------------------------------------------------------------
=========================================================================
"# `distutils` must be imported after `setuptools` or it will cause explosions
# with `setuptools >=48.0.0, <49.1`.
# Refs:
# * https://github.com/ansible/ansible/issues/70456
# * https://github.com/pypa/setuptools/issues/2230
# * https://github.com/pypa/setuptools/commit/bd110264
from distutils.command.build_scripts import build_scripts as BuildScripts
from distutils.command.sdist import sdist as SDist
"
-------------------------------------------------------------------------
"from setuptools.command.build_scripts import build_scripts as BuildScripts
from setuptools.command.sdist import sdist as SDist"
-------------------------------------------------------------------------
"# `distutils` must be imported after `setuptools` or it will cause explosions
# with `setuptools >=48.0.0, <49.1`.
# Refs:
# * https://github.com/ansible/ansible/issues/70456
# * https://github.com/pypa/setuptools/issues/2230
# * https://github.com/pypa/setuptools/commit/bd110264
from distutils.command.build_scripts import build_scripts as BuildScripts
from distutils.command.sdist import sdist as SDist
def find_package_info(*file_paths):
    try:
        with open(os.path.join(*file_paths), 'r') as f:
            info_file = f.read()
    except Exception:
        raise RuntimeError(""Unable to find package info."")
    # The version line must have the form
    # __version__ = 'ver'
    version_match = re.search(r""^__version__ = ['\""]([^'\""]*)['\""]"",
                              info_file, re.M)
    author_match = re.search(r""^__author__ = ['\""]([^'\""]*)['\""]"",
                             info_file, re.M)
    if version_match and author_match:
        return version_match.group(1), author_match.group(1)
    raise RuntimeError(""Unable to find package info."")
def _validate_install_ansible_base():
    """"""Validate that we can install ansible-base. Currently this only
    cares about upgrading to ansible-base from ansible<2.10
    """"""
    if os.getenv('ANSIBLE_SKIP_CONFLICT_CHECK', '') not in ('', '0'):
        return
    # Save these for later restoring things to pre invocation
    sys_modules = sys.modules.copy()
    sys_modules_keys = set(sys_modules)
    # Make sure `lib` isn't in `sys.path` that could confuse this
    sys_path = sys.path[:]
    abspath = os.path.abspath
    sys.path[:] = [p for p in sys.path if abspath(p) != abspath('lib')]
    try:
        from ansible.release import __version__
    except ImportError:
        pass
    else:
        version_tuple = tuple(int(v) for v in __version__.split('.')[:2])
        if version_tuple < (2, 10):
            stars = '*' * 76
            raise RuntimeError(
                '''
    %s
    Cannot install ansible-base with a pre-existing ansible==%s
    installation.
    Installing ansible-base with ansible-2.9 or older currently installed with
    pip is known to cause problems. Please uninstall ansible and install the new
    version:
        pip uninstall ansible
        pip install ansible-base
    If you want to skip the conflict checks and manually resolve any issues
    afterwards, set the ANSIBLE_SKIP_CONFLICT_CHECK environment variable:
        ANSIBLE_SKIP_CONFLICT_CHECK=1 pip install ansible-base
    %s
                ''' % (stars, __version__, stars)
            )
    finally:
        sys.path[:] = sys_path
        for key in sys_modules_keys.symmetric_difference(sys.modules):
            sys.modules.pop(key, None)
        sys.modules.update(sys_modules)
_validate_install_ansible_base()
"
-------------------------------------------------------------------------
"Recom
PRs: 70525, 70760"
-------------------------------------------------------------------------
=========================================================================
"# Write config; make sure it has permissions 0x600
content = json.dumps(self._config, indent=4, sort_keys=True).encode('utf-8')
f = os.open(self._config_path, os.O_WRONLY | os.O_CREAT | os.O_TRUNC, 0o600)
try:
    os.write(f, content)
finally:
    os.close(f)
"
-------------------------------------------------------------------------
"content = json.dumps(config, indent=4, sort_keys=True).encode('utf-8')
f = os.open(path, os.O_WRONLY | os.O_CREAT | os.O_TRUNC, 0o600)
try:
    os.write(f, content)
finally:
    os.close(f)"
-------------------------------------------------------------------------
"# Write config; make sure it has permissions 0x600
content = json.dumps(config, indent=5, sort_keys=True).encode('utf-8')
f = os.open(path, os.O_WRONLY | os.O_CREAT | os.O_TRUNC, 0o600)
try:
    os.write(f, content)
finally:
    os.close(f)
"
-------------------------------------------------------------------------
"Recom
PRs: 67353, 67441"
-------------------------------------------------------------------------
=========================================================================
"'CREATE ROLE', 'DROP ROLE', 'APPLICATION_PASSWORD_ADMIN',
'AUDIT_ADMIN', 'BACKUP_ADMIN', 'BINLOG_ADMIN',
'BINLOG_ENCRYPTION_ADMIN', 'CLONE_ADMIN', 'CONNECTION_ADMIN',
'ENCRYPTION_KEY_ADMIN', 'FIREWALL_ADMIN', 'FIREWALL_USER',
'GROUP_REPLICATION_ADMIN', 'INNODB_REDO_LOG_ARCHIVE',
'NDB_STORED_USER', 'PERSIST_RO_VARIABLES_ADMIN',
'REPLICATION_APPLIER', 'REPLICATION_SLAVE_ADMIN',
'RESOURCE_GROUP_ADMIN', 'RESOURCE_GROUP_USER',
'ROLE_ADMIN', 'SESSION_VARIABLES_ADMIN', 'SET_USER_ID',
'SYSTEM_USER', 'SYSTEM_VARIABLES_ADMIN', 'SYSTEM_USER',
'TABLE_ENCRYPTION_ADMIN', 'VERSION_TOKEN_ADMIN',
'XA_RECOVER_ADMIN', 'LOAD FROM S3', 'SELECT INTO S3'))
"
-------------------------------------------------------------------------
"VALID_PRIVS = frozenset(('CREATE', 'DROP', 'GRANT', 'GRANT OPTION',
                         'LOCK TABLES', 'REFERENCES', 'EVENT', 'ALTER',
                         'DELETE', 'INDEX', 'INSERT', 'SELECT', 'UPDATE',
                         'CREATE TEMPORARY TABLES', 'TRIGGER', 'CREATE VIEW',
                         'SHOW VIEW', 'ALTER ROUTINE', 'CREATE ROUTINE',
                         'EXECUTE', 'FILE', 'CREATE TABLESPACE', 'CREATE USER',
                         'PROCESS', 'PROXY', 'RELOAD', 'REPLICATION CLIENT',
                         'REPLICATION SLAVE', 'SHOW DATABASES', 'SHUTDOWN',
                         'SUPER', 'ALL', 'ALL PRIVILEGES', 'USAGE', 'REQUIRESSL',
                         'CREATE ROLE', 'DROP ROLE', 'APPLICATION_PASSWORD_ADMIN',
                         'AUDIT_ADMIN', 'BACKUP_ADMIN', 'BINLOG_ADMIN',
                         'BINLOG_ENCRYPTION_ADMIN', 'CLONE_ADMIN', 'CONNECTION_ADMIN',
                         'ENCRYPTION_KEY_ADMIN', 'FIREWALL_ADMIN', 'FIREWALL_USER',
                         'GROUP_REPLICATION_ADMIN', 'INNODB_REDO_LOG_ARCHIVE',
                         'NDB_STORED_USER', 'PERSIST_RO_VARIABLES_ADMIN',
                         'REPLICATION_APPLIER', 'REPLICATION_SLAVE_ADMIN',
                         'RESOURCE_GROUP_ADMIN', 'RESOURCE_GROUP_USER',
                         'ROLE_ADMIN', 'SESSION_VARIABLES_ADMIN', 'SET_USER_ID',
                         'SYSTEM_USER', 'SYSTEM_VARIABLES_ADMIN', 'SYSTEM_USER',
                         'TABLE_ENCRYPTION_ADMIN', 'VERSION_TOKEN_ADMIN',
                         'XA_RECOVER_ADMIN', 'LOAD FROM S3', 'SELECT INTO S3'))"
-------------------------------------------------------------------------
"'CREATE ROLE', 'DROP ROLE', 'APPLICATION_PASSWORD_ADMIN',
'AUDIT_ADMIN', 'BACKUP_ADMIN', 'BINLOG_ADMIN',
'BINLOG_ENCRYPTION_ADMIN', 'CONNECTION_ADMIN',
'ENCRYPTION_KEY_ADMIN', 'FIREWALL_ADMIN', 'FIREWALL_USER',
'GROUP_REPLICATION_ADMIN', 'PERSIST_RO_VARIABLES_ADMIN',
'REPLICATION_SLAVE_ADMIN', 'RESOURCE_GROUP_ADMIN', 'RESOURCE_GROUP_USER',
'ROLE_ADMIN', 'SESSION_VARIABLES_ADMIN', 'SET_USER_ID',
'SYSTEM_VARIABLES_ADMIN', 'VERSION_TOKEN_ADMIN', 'XA_RECOVER_ADMIN'))
"
-------------------------------------------------------------------------
"Recom
PRs: 66995, 66999"
-------------------------------------------------------------------------
=========================================================================
"if not container.exists or container.removing:
    if container.removing:
        self.log('Found container in removal phase')
    else:
        self.log('No container found')
    if container.removing:
        # Wait for container to be removed before trying to create it
        self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"container = self.get_container(name=self.name)
        if not container or container['State']['Status'] == 'removing':
            if container and container['State']['Status'] == 'removing':
                self.log('Found container in removal phase')
            else:
                self.log('No container found')
            if container and container['State']['Status'] == 'removing':
                # Wait for container to be removed before trying to create it
                self.wait_for_state(container['Id'], wait_states=['removing'], accept_removal=True)"
-------------------------------------------------------------------------
"if not container.exists or container.removing:
    if container.removing:
        self.log('Found container in removal phase')
    else:
        self.log('No container found')
    if container.removing and not self.check_mode:
        # Wait for container to be removed before trying to create it
        self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"Recom
PRs: 65854, 66118"
-------------------------------------------------------------------------
=========================================================================
"if not container.exists or container.removing:
    if container.removing:
        self.log('Found container in removal phase')
    else:
        self.log('No container found')
    if container.removing:
        # Wait for container to be removed before trying to create it
        self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"if not client.get_container(name=container_id) or client.get_container(name=container_id).get('State', {}).get('Status') == 'removing':
    if client.get_container(name=container_id).get('State', {}).get('Status') == 'removing':
        self.log('Found container in removal phase')
    else:
        self.log('No container found')
    if client.get_container(name=container_id).get('State', {}).get('Status') == 'removing':
        # Wait for container to be removed before trying to create it
        client.wait_for_state(container_id, wait_states=['removing'], accept_removal=True)"
-------------------------------------------------------------------------
"if not container.exists or container.removing:
    if container.removing:
        self.log('Found container in removal phase')
    else:
        self.log('No container found')
    if container.removing and not self.check_mode:
        # Wait for container to be removed before trying to create it
        self.wait_for_state(container.Id, wait_states=['removing'], accept_removal=True)
"
-------------------------------------------------------------------------
"Recom
PRs: 65854, 66117"
-------------------------------------------------------------------------
=========================================================================
"e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"# Adapted code
e, m, _ = my.pkgSack.matchPackageNames([pkgspec])
pkgs.extend(my.returnPackagesByDep(pkgspec))"
-------------------------------------------------------------------------
"e, m, _ = self.yum_base.rpmdb.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnInstalledPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"pkgs = self.yum_base.returnPackagesByDep(req_spec)  \
    self.yum_base.returnInstalledPackagesByDep(req_spec)
"
-------------------------------------------------------------------------
pkgs = self.yum_base().returnPackagesByDep(req_spec) + self.yum_base().returnInstalledPackagesByDep(req_spec)
-------------------------------------------------------------------------
"pkgs = self.yum_base.returnPackagesByDep(pkgspec)  \
    self.yum_base.returnInstalledPackagesByDep(pkgspec)
    e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
updates = self.yum_base.doPackageLists(pkgnarrow='updates').updates
"
-------------------------------------------------------------------------
"Recom
PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"elif current_condition['Field'] == condition['Field'] and current_condition['Values'] == condition['Values']:
"
-------------------------------------------------------------------------
if current_condition['Field'] == condition['Field'] and current_condition['Values'][0] == condition['Values'][0]:
-------------------------------------------------------------------------
"elif current_condition['Field'] == condition['Field'] and sorted(current_condition['Values']) == sorted(condition['Values']):
"
-------------------------------------------------------------------------
"Recom
PRs: 65021, 65212"
-------------------------------------------------------------------------
=========================================================================
"""WHERE indexrelname = %(name)s ""
""AND schemaname = %(schema)s"")
exec_sql(self, query, query_params={'name': self.name, 'schema': self.schema},
         add_to_executed=False)
"
-------------------------------------------------------------------------
"exec_sql(obj, query, add_to_executed=False, query_params={'name': obj.name, 'schema': obj.schema})"
-------------------------------------------------------------------------
"""WHERE i.indexname = %(name)s"")
c_sql(self, query, query_params={'name': self.name}, add_to_executed=False)
"
-------------------------------------------------------------------------
"Recom
PRs: 64661, 65034"
-------------------------------------------------------------------------
=========================================================================
"feed_ca_cert:
      The ca_cert alias will be removed in Ansible 2.14.
  aliases: [ importer_ssl_ca_cert, ca_cert ]
feed_client_cert:
  version_added: ""2.10""
"
-------------------------------------------------------------------------
"feed_ca_cert = Tuple(elts=[Call(func=Name(id='dict', ctx=Load()), args=[], keywords=[keyword(arg='aliases', value=List(elts=[Constant(value='importer_ssl_ca_cert'), Constant(value='ca_cert')], ctx=Load())), 
keyword(arg='deprecated_aliases', value=List(elts=[Call(func=Name(id='dict', ctx=Load()), args=[], keywords=[keyword(arg='name', value=Constant(value='ca_cert')), keyword(arg='version', value=Constant(value='2.14'))])], ctx=Load()))]), 
ctx=Store())
feed_client_cert = IfExp(test=Compare(left=Subscript(value=Attribute(value=Name(id='module', ctx=Load()), attr='params', ctx=Load()), slice=Constant(value='client_cert'), ctx=Load()), ops=[Is()], comparators=[Constant(value=None)]), 
body=Assign(targets=[Name(id='importer_ssl_client_cert', ctx=Store())], value=Subscript(value=Attribute(value=Name(id='module', ctx=Load()), attr='params', ctx=Load()), slice=Constant(value='client_cert'), ctx=Load())), 
orelse=Call(func=Attribute(value=Name(id='module', ctx=Load()), attr='deprecate', ctx=Load()), 
args=[Constant(value='In Ansible 2.10 `feed_client_cert` option was added. Until 2.14 the default value will come from client_cert option')], 
keywords=[keyword(arg='version', value=Constant(value='2.14'))]), ctx=Store())"
-------------------------------------------------------------------------
"feed_ca_cert:
      The ca_cert alias will be removed in Ansible 2.14.
  aliases: [ importer_ssl_ca_cert, ca_cert ]
feed_client_cert:
  version_added: ""2.9.2""
"
-------------------------------------------------------------------------
"Recom
PRs: 59522, 65014"
-------------------------------------------------------------------------
=========================================================================
"- If not specified the default value will come from client_cert. Which will
  change in Ansible 2.14.
_client_key:
rsion_added: ""2.10""
- If not specified the default value will come from client_key. Which will
  change in Ansible 2.14.
"
-------------------------------------------------------------------------
"+ Expr(value=Call(func=Attribute(value=Name(id='module', ctx=Load()), attr='deprecate', ctx=Load()), args=[Constant(value='If not specified, the default value will come from client_cert, which will change in Ansible 2.14')], keywords=[keyword(arg='version', value=Constant(value='2.14'))])
+ Expr(value=Call(func=Attribute(value=Name(id='module', ctx=Load()), attr='deprecate', ctx=Load()), args=[Constant(value='If not specified the default value will come from client_key. Which will change in Ansible 2.14.')], keywords=[keyword(arg='version', value=Constant(value='2.14'))])"
-------------------------------------------------------------------------
"- If not specified the default value will come from client_cert. Which will
  change in Ansible 2.14.
_client_key:
rsion_added: ""2.9.2""
- If not specified the default value will come from client_key. Which will
  change in Ansible 2.14.
"
-------------------------------------------------------------------------
"Recom
PRs: 59522, 65014"
-------------------------------------------------------------------------
=========================================================================
"importer_ssl_ca_cert = module.params['feed_ca_cert']
importer_ssl_client_cert = module.params['feed_client_cert']
if importer_ssl_client_cert is None and module.params['client_cert'] is not None:
    importer_ssl_client_cert = module.params['client_cert']
    module.deprecate((""To specify client certificates to be used with the repo to sync, and not for communication with pulp.io, use the new options ""
                      ""`feed_client_cert` and `feed_client_key` (available since Ansible 2.10). Until Ansible 2.14, the default value for ""
                      ""`feed_client_cert` will be taken from `client_cert` if only the latter is specified""), version=""2.14"")
importer_ssl_client_key = module.params['feed_client_key']
if importer_ssl_client_key is None and module.params['client_key'] is not None:
    importer_ssl_client_key = module.params['client_key']
    module.deprecate(""In Ansible 2.10 `feed_client_key` option was added. Until 2.14 the default value will come from client_key option"", version=""2.14"")
"
-------------------------------------------------------------------------
"importer_ssl_ca_cert = module.params['feed_ca_cert']
importer_ssl_client_cert = module.params['feed_client_cert']
if importer_ssl_client_cert is None and module.params['client_cert'] is not None:
    importer_ssl_client_cert = module.params['client_cert']
    module.deprecate((""To specify client certificates to be used with the repo to sync, and not for communication with pulp.io, use the new options ""
                      ""`feed_client_cert` and `feed_client_key` (available since Ansible 2.10). Until Ansible 2.14, the default value for ""
                      ""`feed_client_cert` will be taken from `client_cert` if only the latter is specified""), version=""2.14"")
importer_ssl_client_key = module.params['feed_client_key']
if importer_ssl_client_key is None and module.params['client_key'] is not None:
    importer_ssl_client_key = module.params['client_key']
    module.deprecate(""In Ansible 2.10 `feed_client_key` option was added. Until 2.14 the default value will come from client_key option"", version=""2.14"")"
-------------------------------------------------------------------------
"importer_ssl_ca_cert = module.params['feed_ca_cert']
importer_ssl_client_cert = module.params['feed_client_cert']
if importer_ssl_client_cert is None and module.params['client_cert'] is not None:
    importer_ssl_client_cert = module.params['client_cert']
    module.deprecate(""To specify client certificates to be used with the repo to sync, and not for communication with the ""
                     ""Pulp instance, use the new options `feed_client_cert` and `feed_client_key` (available since ""
                     ""Ansible 2.9.2). Until Ansible 2.14, the default value for `feed_client_cert` will be taken from ""
                     ""`client_cert` if only the latter is specified"", version=""2.14"")
importer_ssl_client_key = module.params['feed_client_key']
if importer_ssl_client_key is None and module.params['client_key'] is not None:
    importer_ssl_client_key = module.params['client_key']
    module.deprecate(""In Ansible 2.9.2 `feed_client_key` option was added. Until 2.14 the default value will come from client_key option"", version=""2.14"")
"
-------------------------------------------------------------------------
"Recom
PRs: 59522, 65014"
-------------------------------------------------------------------------
=========================================================================
"rc=rc,
out=out, err=err,  # Deprecated
stdout=out, stderr=err)
"
-------------------------------------------------------------------------
"module.exit_json(
                    changed=True,
                    stack_spec_diff=json_diff(before_stack_services,
                                              after_stack_services,
                                              dump=True),
                    stdout=out, 
                    stderr=err
                )"
-------------------------------------------------------------------------
"rc=rc,
out=out, err=err,
stdout=out, stderr=err)
"
-------------------------------------------------------------------------
"Recom
PRs: 63467, 64120"
-------------------------------------------------------------------------
=========================================================================
"short_description: Gathers information for virtual machines running on Citrix Hypervisor/XenServer host or pool
"
-------------------------------------------------------------------------
"def get_xenserver_version(self):
        """"""Returns Citrix Hypervisor/XenServer version.

        Returns:
            list: Element [0] is major version. Element [1] is minor version.
            Element [2] is update number.
        """"""
        host_ref = self.xapi_session.xenapi.session.get_this_host(self.xapi_session._session)

        try:
            xenserver_version = [int(version_number) for version_number in self.xapi_session.xenapi.host.get_software_version(host_ref)['product_version'].split('.')]
        except ValueError:
            xenserver_version = [0, 0, 0]

        return xenserver_version"
-------------------------------------------------------------------------
"short_description: Gathers facts for virtual machines running on Citrix Hypervisor/XenServer host or pool
"
-------------------------------------------------------------------------
"Recom
PRs: 63728, 63816"
-------------------------------------------------------------------------
=========================================================================
"- ""The only allowed value according to L(RFC 2986,https://tools.ietf.org/html/rfc2986#section-4.1)
   is 1.""
- This option will no longer accept unsupported values from Ansible 2.14 on.
"
-------------------------------------------------------------------------
"if self.version != 1:
            raise ValueError(""The 'version' option only allows the value 1 according to RFC 2986."")"
-------------------------------------------------------------------------
"- ""The only allowed value according to L(RFC 2986,https://tools.ietf.org/html/rfc2986#section-4.1)
   is 1.""
"
-------------------------------------------------------------------------
"Recom
PRs: 63432, 63675"
-------------------------------------------------------------------------
=========================================================================
"- ""The only allowed value according to L(RFC 2986,https://tools.ietf.org/html/rfc2986#section-4.1)
   is 1.""
- This option will no longer accept unsupported values from Ansible 2.14 on.
"
-------------------------------------------------------------------------
"raise CertificateSigningRequestError('Invalid value for the version of the certificate signing request, only 1 is allowed according to RFC 2986: https://tools.ietf.org/html/rfc2986#section-4.1')"
-------------------------------------------------------------------------
"- ""The only allowed value according to L(RFC 2986,https://tools.ietf.org/html/rfc2986#section-4.1)
   is 1.""
"
-------------------------------------------------------------------------
"Recom
PRs: 63432, 63674"
-------------------------------------------------------------------------
=========================================================================
"- If not set, the value will be remain the same if container exists and will be inherited
  from the host machine if it is (re-)created.
Specification for mounts to be added to the container. More powerful alternative to I(volumes).
"
-------------------------------------------------------------------------
"volume_options=dict(type=dict, options=None),
        volumes=dict(type=dict, options=None)

        mount_points=kwargs.pop('mount_points', None)
        if mount_points:
            volume_config=[]
            for mount_point in mount_points:
                volume_config.append({'Type': mount_point['type'], 'Source': mount_point.get('source'),
                                      'Target': mount_point['target'], 'ReadOnly': mount_point.get('read_only', False)
                                      'VolumeOptions': mount_point.get('volume_options', volume_options),
                                      'Volumes': mount_point.get('volumes', volumes)})"
-------------------------------------------------------------------------
"- If not set, the value will be remain the same if container exists and will be inherited
  from the host machine if it is (re-)created.
"
-------------------------------------------------------------------------
"Recom
PRs: 63165, 63301"
-------------------------------------------------------------------------
=========================================================================
"n_url = self.api_server
if self.api_server == 'https://galaxy.ansible.com' or self.api_server == 'https://galaxy.ansible.com/':
    n_url = 'https://galaxy.ansible.com/api/'
try:
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
except (AnsibleError, GalaxyError, ValueError, KeyError):
    # Either the URL doesnt exist, or other error. Or the URL exists, but isn't a galaxy API
    # root (not JSON, no 'available_versions') so try appending '/api/'
    n_url = _urljoin(n_url, '/api/')
    # let exceptions here bubble up
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
    if 'available_versions' not in data:
        raise AnsibleError(""Tried to find galaxy API root at %s but no 'available_versions' are available on %s""
                           % (n_url, self.api_server))
available_versions = data.get('available_versions', {u'v1': u'v1/'})
    available_versions[u'v2'] = u'v2/'
"
-------------------------------------------------------------------------
"if self.api_server == 'https://galaxy.ansible.com' or self.api_server == 'https://galaxy.ansible.com/':
    if self.api_server == 'https://galaxy.ansible.com':
        n_url = 'https://galaxy.ansible.com/api/'
    else:
        n_url = 'https://galaxy.ansible.com/api/'
    try:
        data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
    except (AnsibleError, GalaxyError, ValueError, KeyError):
        # Either the URL doesnt exist, or other error. Or the URL exists, but isn't a galaxy API
        # root (not JSON, no 'available_versions') so try appending '/api/'
        n_url = _urljoin(n_url, '/api/')
        # let exceptions here bubble up
        data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
        if 'available_versions' not in data:
            raise AnsibleError(""Tried to find galaxy API root at %s but no 'available_versions' are available on %s"" % (n_url, self.api_server))
    available_versions = data.get('available_versions', {u'v1': u'v1/', u'v2': u'v2/'})"
-------------------------------------------------------------------------
"n_url = self.api_server
if self.api_server == 'https://galaxy.ansible.com' or self.api_server == 'https://galaxy.ansible.com/':
    n_url = 'https://galaxy.ansible.com/api/'
try:
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
except (AnsibleError, GalaxyError, ValueError, KeyError):
    # Either the URL doesnt exist, or other error. Or the URL exists, but isn't a galaxy API
    # root (not JSON, no 'available_versions') so try appending '/api/'
    n_url = _urljoin(n_url, '/api/')
    # let exceptions here bubble up
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
    if 'available_versions' not in data:
        raise AnsibleError(""Tried to find galaxy API root at %s but no 'available_versions' are available on %s""
                           % (n_url, self.api_server))
    # Update api_server to point to the ""real"" API root, which in this case
    # was the configured url  '/api/' appended.
    self.api_server = n_url
available_versions = data.get('available_versions', {u'v1': u'v1/'})
    available_versions[u'v2'] = u'v2/'
"
-------------------------------------------------------------------------
"Recom
PRs: 63238, 63293"
-------------------------------------------------------------------------
=========================================================================
"cron_cmd = self.module.get_bin_path('crontab', required=True)
        return ""su %s -c '%s -l'"" % (shlex_quote(self.user), shlex_quote(cron_cmd))
        return ""%s -l %s"" % (shlex_quote(cron_cmd), shlex_quote(self.user))
        return ""%s %s %s"" % (cron_cmd, '-l', shlex_quote(self.user))
return ""%s %s %s"" % (cron_cmd, user, '-l')
cron_cmd = self.module.get_bin_path('crontab', required=True)
        return ""chown %s %s ; su '%s' -c '%s %s'"" % (shlex_quote(self.user), shlex_quote(path), shlex_quote(self.user), cron_cmd, shlex_quote(path))
return ""%s %s %s"" % (cron_cmd, user, shlex_quote(path))
"
-------------------------------------------------------------------------
"cron_cmd = self.module.get_bin_path('crontab', required=True)
        return ""su %s -c '%s -l'"" % (pipes.quote(self.user), pipes.quote(cron_cmd))
        return ""%s -l %s"" % (pipes.quote(cron_cmd), pipes.quote(self.user))
        return ""%s %s %s"" % (cron_cmd, '-l', pipes.quote(self.user))
return ""%s %s %s"" % (cron_cmd, user, '-l')
cron_cmd = self.module.get_bin_path('crontab', required=True)
        return ""chown %s %s ; su '%s' -c '%s %s'"" % (pipes.quote(self.user), pipes.quote(path), pipes.quote(self.user), cron_cmd, pipes.quote(path))
return ""%s %s %s"" % (cron_cmd, user, pipes.quote(path))"
-------------------------------------------------------------------------
"self.cron_cmd = self.module.get_bin_path('crontab', required=True)
"
-------------------------------------------------------------------------
"Recom
PRs: 59765, 62546"
-------------------------------------------------------------------------
=========================================================================
"cron_cmd = self.module.get_bin_path('crontab', required=True)
        return ""su %s -c '%s -l'"" % (shlex_quote(self.user), shlex_quote(cron_cmd))
        return ""%s -l %s"" % (shlex_quote(cron_cmd), shlex_quote(self.user))
        return ""%s %s %s"" % (cron_cmd, '-l', shlex_quote(self.user))
return ""%s %s %s"" % (cron_cmd, user, '-l')
cron_cmd = self.module.get_bin_path('crontab', required=True)
        return ""chown %s %s ; su '%s' -c '%s %s'"" % (shlex_quote(self.user), shlex_quote(path), shlex_quote(self.user), cron_cmd, shlex_quote(path))
return ""%s %s %s"" % (cron_cmd, user, shlex_quote(path))
"
-------------------------------------------------------------------------
"cron_cmd = self.module.get_bin_path('crontab', required=True)
        return ""su %s -c '%s -l'"" % (shlex.quote(self.user), shlex.quote(cron_cmd))
        return ""%s -l %s"" % (shlex.quote(cron_cmd), shlex.quote(self.user))
        return ""%s %s %s"" % (cron_cmd, '-l', shlex.quote(self.user))
return ""%s %s %s"" % (cron_cmd, user, '-l')
cron_cmd = self.module.get_bin_path('crontab', required=True)
        return ""chown %s %s ; su '%s' -c '%s %s'"" % (shlex.quote(self.user), shlex.quote(path), shlex.quote(self.user), cron_cmd, shlex.quote(path))
return ""%s %s %s"" % (cron_cmd, user, shlex.quote(path))"
-------------------------------------------------------------------------
"self.cron_cmd = self.module.get_bin_path('cronvar', required=True)
"
-------------------------------------------------------------------------
"Recom
PRs: 59765, 62546"
-------------------------------------------------------------------------
=========================================================================
"# Ansible module to manage CheckPoint Firewall (c) 2019
"
-------------------------------------------------------------------------
"from __future__ import absolute_import, division, print_function
__metaclass__ = type

import pytest
from ansible.module_utils import basic
from units.modules.utils import set_module_args, exit_json, fail_json, AnsibleExitJson

from ansible.module_utils import basic
from ansible.modules.network.check_point import cp_mgmt_address_range

OBJECT = {
    ""name"": ""New Address Range 1"",
    ""ip_address_first"": ""192.0.2.1"",
    ""ip_address_last"": ""192.0.2.10""
}

CREATE_PAYLOAD = {
    ""name"": ""New Address Range 1"",
    ""ip_address_first"": ""192.0.2.1"",
    ""ip_address_last"": ""192.0.2.10""
}

UPDATE_PAYLOAD = {
    ""name"": ""New Address Range 1"",
    ""color"": ""blue"",
    ""ip_address_first"": ""192.0.2.1"",
    ""ip_address_last"": ""192.0.2.1""
}

OBJECT_AFTER_UPDATE = UPDATE_PAYLOAD

DELETE_PAYLOAD = {
    ""name"": ""New Address Range 1"",
    ""state"": ""absent""
}

function_path = 'ansible.modules.network.check_point.cp_mgmt_address_range.api_call'
api_call_object = 'address-range'


class TestCheckpointAddressRange(object):
    module = cp_mgmt_address_range

    @pytest.fixture(autouse=True)
    def module_mock(self, mocker):
        return mocker.patch.multiple(basic.AnsibleModule, exit_json=exit_json, fail_json=fail_json)

    @pytest.fixture
    def connection_mock(self, mocker):
        connection_class_mock = mocker.patch('ansible.module_utils.network.checkpoint.checkpoint.Connection')
        return connection_class_mock.return_value

    def test_create(self, mocker, connection_mock):
        mock_function = mocker.patch(function_path)
        mock_function.return_value = {'changed': True, api_call_object: OBJECT}
        result = self._run_module(CREATE_PAYLOAD)

        assert result['changed']
        assert OBJECT.items() == result[api_call_object].items()

    def test_create_idempotent(self, mocker, connection_mock):
        mock_function = mocker.patch(function_path)
        mock_function.return_value = {'changed': False, api_call_object: OBJECT}
        result = self._run_module(CREATE_PAYLOAD)

        assert not result['changed']

    def test_update(self, mocker, connection_mock):
        mock_function = mocker.patch(function_path)
        mock_function.return_value = {'changed': True, api_call_object: OBJECT_AFTER_UPDATE}
        result = self._run_module(UPDATE_PAYLOAD)

        assert result['changed']
        assert OBJECT_AFTER_UPDATE.items() == result[api_call_object].items()

    def test_update_idempotent(self, mocker, connection_mock):
        mock_function = mocker.patch(function_path)
        mock_function.return_value = {'changed': False, api_call_object: OBJECT_AFTER_UPDATE}
        result = self._run_module(UPDATE_PAYLOAD)

        assert not result['changed']

    def test_delete(self, mocker, connection_mock):
        mock_function = mocker.patch(function_path)
        mock_function.return_value = {'changed': True}
        result = self._run_module(DELETE_PAYLOAD)

        assert result['changed']

    def test_delete_idempotent(self, mocker, connection_mock):
        mock_function = mocker.patch(function_path)
        mock_function.return_value = {'changed': False}
        result = self._run_module(DELETE_PAYLOAD)

        assert not result['changed']

    def _run_module(self, module_args):
        set_module_args(module_args)
        with pytest.raises(AnsibleExitJson) as ex:
            self.module.main()
        return ex.value.args[0]"
-------------------------------------------------------------------------
"# Ansible module to manage CheckPoint Firewall (c) 2019
#
# Ansible is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Ansible is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
#
from __future__ import absolute_import, division, print_function
__metaclass__ = type
import pytest
from units.modules.utils import set_module_args, exit_json, fail_json, AnsibleExitJson
from ansible.module_utils import basic
from ansible.modules.network.check_point import cp_mgmt_address_range
OBJECT = {
    ""name"": ""New Address Range 1"",
    ""ip_address_first"": ""192.0.2.1"",
    ""ip_address_last"": ""192.0.2.10""
}
CREATE_PAYLOAD = {
    ""name"": ""New Address Range 1"",
    ""ip_address_first"": ""192.0.2.1"",
    ""ip_address_last"": ""192.0.2.10""
}
UPDATE_PAYLOAD = {
    ""name"": ""New Address Range 1"",
    ""color"": ""blue"",
    ""ip_address_first"": ""192.0.2.1"",
    ""ip_address_last"": ""192.0.2.1""
}
OBJECT_AFTER_UPDATE = UPDATE_PAYLOAD
DELETE_PAYLOAD = {
    ""name"": ""New Address Range 1"",
    ""state"": ""absent""
}
function_path = 'ansible.modules.network.check_point.cp_mgmt_address_range.api_call'
api_call_object = 'address-range'
class TestCheckpointAddressRange(object):
    module = cp_mgmt_address_range
    @pytest.fixture(autouse=True)
    def module_mock(self, mocker):
        return mocker.patch.multiple(basic.AnsibleModule, exit_json=exit_json, fail_json=fail_json)
    @pytest.fixture
    def connection_mock(self, mocker):
        connection_class_mock = mocker.patch('ansible.module_utils.network.checkpoint.checkpoint.Connection')
        return connection_class_mock.return_value
    def test_create(self, mocker, connection_mock):
        mock_function = mocker.patch(function_path)
        mock_function.return_value = {'changed': True, api_call_object: OBJECT}
        result = self._run_module(CREATE_PAYLOAD)
        assert result['changed']
        assert OBJECT.items() == result[api_call_object].items()
    def test_create_idempotent(self, mocker, connection_mock):
        mock_function = mocker.patch(function_path)
        mock_function.return_value = {'changed': False, api_call_object: OBJECT}
        result = self._run_module(CREATE_PAYLOAD)
        assert not result['changed']
    def test_update(self, mocker, connection_mock):
        mock_function = mocker.patch(function_path)
        mock_function.return_value = {'changed': True, api_call_object: OBJECT_AFTER_UPDATE}
        result = self._run_module(UPDATE_PAYLOAD)
        assert result['changed']
        assert OBJECT_AFTER_UPDATE.items() == result[api_call_object].items()
    def test_update_idempotent(self, mocker, connection_mock):
        mock_function = mocker.patch(function_path)
        mock_function.return_value = {'changed': False, api_call_object: OBJECT_AFTER_UPDATE}
        result = self._run_module(UPDATE_PAYLOAD)
        assert not result['changed']
    def test_delete(self, mocker, connection_mock):
        mock_function = mocker.patch(function_path)
        mock_function.return_value = {'changed': True}
        result = self._run_module(DELETE_PAYLOAD)
        assert result['changed']
    def test_delete_idempotent(self, mocker, connection_mock):
        mock_function = mocker.patch(function_path)
        mock_function.return_value = {'changed': False}
        result = self._run_module(DELETE_PAYLOAD)
        assert not result['changed']
    def _run_module(self, module_args):
        set_module_args(module_args)
        with pytest.raises(AnsibleExitJson) as ex:
            self.module.main()
        return ex.value.args[0]
"
-------------------------------------------------------------------------
"Recom
PRs: 62338, 62390"
-------------------------------------------------------------------------
=========================================================================
"# This is a helper class to sort the changes in a valid order
# ""Greater than"" means a change has to happen after another one.
# As an example, let's say self is daily (key == 1) and other is weekly (key == 2)
class ChangeHelper:
    def __init__(self, old, new):
        self.key = new.key
        self.old = old
        self.new = new
    def __gt__(self, other):
        if self.key < other.key:
            # You cannot disable daily if weekly is enabled, so later
            if self.new.enabled < other.old.enabled:
                return True
            # Enabling daily is OK if weekly is disabled
            elif self.new.enabled > other.old.enabled:
                return False
            # Otherwise, decreasing the daily level below the current weekly level has to be done later
            else:
                return self.new.level < other.old.level
        else:
            return not (self.old > self.new)
"
-------------------------------------------------------------------------
"class ChangeHelper:
    def __init__(self, module, old, new):
        self.key = new.key
        self.old = old
        self.new = new
    def __gt__(self, other):
        if self.key < other.key:
            # You cannot disable daily if weekly is enabled, so later
            if self.new.enabled < other.old.enabled:
                return True
            # Enabling daily is OK if weekly is disabled
            elif self.new.enabled > other.old.enabled:
                return False
            # Otherwise, decreasing the daily level below the current weekly level has to be done later
            else:
                return self.new.level < other.old.level
        else:
            return not (self.old > self.new)"
-------------------------------------------------------------------------
"# This is a helper class to sort the changes in a valid order
# ""Greater than"" means a change has to happen after another one.
# As an example, let's say self is daily (key == 1) and other is weekly (key == 2)
class ChangeHelper:
    def __init__(self, old, new):
        self.key = new.key
        self.old = old
        self.new = new
    def __eq__(self, other):
        return ((self.key, self.new.enabled, self.new.level) ==
                (other.key, other.new.enabled, other.new.level))
    def __gt__(self, other):
        if self.key < other.key:
            # You cannot disable daily if weekly is enabled, so later
            if self.new.enabled < other.old.enabled:
                return True
            # Enabling daily is OK if weekly is disabled
            elif self.new.enabled > other.old.enabled:
                return False
            # Otherwise, decreasing the daily level below the current weekly level has to be done later
            else:
                return self.new.level < other.old.level
        else:
            return not (other > self)
    def __ge__(self, other):
        return (self > other) or (self == other)
    def __lt__(self, other):
        return not (self >= other)
    def __le__(self, other):
        return not (self > other)
"
-------------------------------------------------------------------------
"Recom
PRs: 61345, 62088"
-------------------------------------------------------------------------
=========================================================================
"if self._cache is not None:
"
-------------------------------------------------------------------------
if self._cache:
-------------------------------------------------------------------------
"if self._cache is not None:
# Store the cache to avoid running pkg_cache() for each item in the comprehension, which is very slow
cache = self.pkg_cache
return [pk for pk in cache.keys() if cache[pk].is_installed]
"
-------------------------------------------------------------------------
"Recom
PRs: 60511, 60574"
-------------------------------------------------------------------------
=========================================================================
"pass_through = getattr(entity.pass_through.mode, 'name', None)
    self._get_network_filter_id() == getattr(entity.network_filter, 'id', None) and
    self._get_qos_id() == getattr(entity.qos, 'id', None) and
    equal(self.param('pass_through'), pass_through.lower() if pass_through else None) and
"
-------------------------------------------------------------------------
"self._get_qos_id() == getattr(entity.qos, 'id', None) and
equal(self.param('pass_through'), entity.pass_through.mode.name.lower() if hasattr(entity, 'pass_through') and hasattr(entity.pass_through, 'mode') else None) and"
-------------------------------------------------------------------------
"pass_through = getattr(entity.pass_through.mode, 'name', None)
    # The reason why we can't use equal method, is we get None from _get_network_filter_id or _get_qos_id method, when passing empty string.
    # And when first param of equal method is None it retruns true.
    self._get_network_filter_id() == getattr(entity.network_filter, 'id', None) and
    self._get_qos_id() == getattr(entity.qos, 'id', None) and
    equal(self.param('pass_through'), pass_through.lower() if pass_through else None) and
"
-------------------------------------------------------------------------
"Recom
PRs: 59727, 60198"
-------------------------------------------------------------------------
=========================================================================
"if module.params['api']:
        user_token['user_api'] = array.create_api_token(module.params['name'])['api_token']
"
-------------------------------------------------------------------------
"if module.params['api_token']:
        user_token['api_token'] = array.create_api_token(module.params['name'])['api_token']"
-------------------------------------------------------------------------
"if module.params['api']:
        user_token['user_api'] = array.create_api_token(module.params['name'])['api_token']
        # Added for 2.8.2: Not breaking user's playbooks in minor releases.
        user_token['api_token'] = user_token['user_api']
"
-------------------------------------------------------------------------
"Recom
PRs: 57588, 58544"
-------------------------------------------------------------------------
=========================================================================
"if module.params['api']:
        user_token['user_api'] = array.create_api_token(module.params['name'])['api_token']
"
-------------------------------------------------------------------------
"if module.params['api_token']:
        user_token['api_token'] = array.create_api_token(module.params['name'])['api_token']"
-------------------------------------------------------------------------
"if module.params['api']:
        user_token['user_api'] = array.create_api_token(module.params['name'])['api_token']
        # Added for 2.8.2: Not breaking user's playbooks in minor releases.
        user_token['api_token'] = user_token['user_api']
"
-------------------------------------------------------------------------
"Recom
PRs: 57588, 58544"
-------------------------------------------------------------------------
=========================================================================
"#
# (c) 2019 Red Hat Inc.
#
# This file is part of Ansible
#
# Ansible is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Ansible is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
#
from __future__ import (absolute_import, division, print_function)
__metaclass__ = type
from os import path
import json
from mock import MagicMock, call
from units.compat import unittest
from ansible.plugins.cliconf import ios
FIXTURE_DIR = b'%s/fixtures/ios' % (
    path.dirname(path.abspath(__file__)).encode('utf-8')
)
def _connection_side_effect(*args, **kwargs):
    try:
        if args:
            value = args[0]
        else:
            value = kwargs.get('command')
        fixture_path = path.abspath(
            b'%s/%s' % (FIXTURE_DIR, b'_'.join(value.split(b' ')))
        )
        with open(fixture_path, 'rb') as file_desc:
            return file_desc.read()
    except (OSError, IOError):
        if args:
            value = args[0]
            return value
        elif kwargs.get('command'):
            value = kwargs.get('command')
            return value
        return 'Nope'
class TestPluginCLIConfIOS(unittest.TestCase):
    """""" Test class for IOS CLI Conf Methods
    """"""
    def setUp(self):
        self._mock_connection = MagicMock()
        self._mock_connection.send.side_effect = _connection_side_effect
        self._cliconf = ios.Cliconf(self._mock_connection)
        self.maxDiff = None
    def tearDown(self):
        pass
    def test_get_device_info(self):
        """""" Test get_device_info
        """"""
        device_info = self._cliconf.get_device_info()
        mock_device_info = {'network_os': 'ios',
                            'network_os_model': 'CSR1000V',
                            'network_os_version': '16.06.01',
                            'network_os_hostname': 'an-csr-01',
                            'network_os_image': 'bootflash:packages.conf'
                            }
        self.assertEqual(device_info, mock_device_info)
    def test_get_capabilities(self):
        """""" Test get_capabilities
        """"""
        capabilities = json.loads(self._cliconf.get_capabilities())
        mock_capabilities = {
            'network_api': 'cliconf',
            'rpc': [
                'get_config',
                'edit_config',
                'get_capabilities',
                'get',
                'enable_response_logging',
                'disable_response_logging',
                'edit_banner',
                'get_diff',
                'run_commands',
                'get_defaults_flag'
            ],
            'device_operations': {
                'supports_diff_replace': True,
                'supports_commit': False,
                'supports_rollback': False,
                'supports_defaults': True,
                'supports_onbox_diff': False,
                'supports_commit_comment': False,
                'supports_multiline_delimiter': True,
                'supports_diff_match': True,
                'supports_diff_ignore_lines': True,
                'supports_generate_diff': True,
                'supports_replace': False
            },
            'device_info': {
                'network_os_hostname': 'an-csr-01',
                'network_os_image': 'bootflash:packages.conf',
                'network_os_model': 'CSR1000V',
                'network_os_version': '16.06.01',
                'network_os': 'ios'
            },
            'format': ['text'],
            'diff_match': ['line', 'strict', 'exact', 'none'],
            'diff_replace': ['line', 'block'],
            'output': []
        }
        self.assertEqual(
            mock_capabilities,
            capabilities
        )
"
-------------------------------------------------------------------------
"# (c) 2019 Red Hat Inc.
#
# This file is part of Ansible
#
# Ansible is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Ansible is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
#
from __future__ import (absolute_import, division, print_function)
__metaclass__ = type
from os import path
import json
from mock import MagicMock, call
from units.compat import unittest
from ansible.plugins.cliconf.ios import Cliconf

FIXTURE_DIR = b'%s/fixtures/ios' % (
    path.dirname(path.abspath(__file__)).encode('utf-8')
)

def _connection_side_effect(*args, **kwargs):
    try:
        if args:
            value = args[0]
        else:
            value = kwargs.get('command')
        fixture_path = path.abspath(
            b'%s/%s' % (FIXTURE_DIR, b'_'.join(value.split(b' ')))
        )
        with open(fixture_path, 'rb') as file_desc:
            return file_desc.read()
    except (OSError, IOError):
        if args:
            value = args[0]
            return value
        elif kwargs.get('command'):
            value = kwargs.get('command')
            return value
        return 'Nope'

class TestPluginCLIConfIOS(unittest.TestCase):
    """""" Test class for IOS CLI Conf Methods
    """"""
    
    def setUp(self):
        self._mock_connection = MagicMock()
        self._mock_connection.send.side_effect = _connection_side_effect
        self._cliconf = Cliconf(self._mock_connection)
        self.maxDiff = None

    def tearDown(self):
        pass

    def test_get_device_info(self):
        """""" Test get_device_info
        """"""
        device_info = self._cliconf.get_device_info()
        mock_device_info = {
            'network_os': 'ios',
            'network_os_model': 'CSR1000V',
            'network_os_version': '16.06.01',
            'network_os_hostname': 'an-csr-01',
            'network_os_image': 'bootflash:packages.conf'
        }
        self.assertEqual(device_info, mock_device_info)

    def test_get_capabilities(self):
        """""" Test get_capabilities
        """"""
        capabilities = json.loads(self._cliconf.get_capabilities())
        mock_capabilities = {
            'network_api': 'cliconf',
            'rpc': [
                'get_config',
                'edit_config',
                'get_capabilities',
                'get',
                'enable_response_logging',
                'disable_response_logging',
                'edit_banner',
                'get_diff',
                'run_commands',
                'get_defaults_flag'
            ],
            'device_operations': {
                'supports_diff_replace': True,
                'supports_commit': False,
                'supports_rollback': False,
                'supports_defaults': True,
                'supports_onbox_diff': False,
                'supports_commit_comment': False,
                'supports_multiline_delimiter': True,
                'supports_diff_match': True,
                'supports_diff_ignore_lines': True,
                'supports_generate_diff': True,
                'supports_replace': False
            },
            'device_info': {
                'network_os_hostname': 'an-csr-01',
                'network_os_image': 'bootflash:packages.conf',
                'network_os_model': 'CSR1000V',
                'network_os_version': '16.06.01',
                'network_os': 'ios'
            },
            'format': ['text'],
            'diff_match': ['line', 'strict', 'exact', 'none'],
            'diff_replace': ['line', 'block'],
            'output': []
        }
        self.assertEqual(mock_capabilities, capabilities)"
-------------------------------------------------------------------------
"#
# (c) 2019 Red Hat Inc.
#
# This file is part of Ansible
#
# Ansible is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Ansible is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
#
from __future__ import (absolute_import, division, print_function)
__metaclass__ = type
from os import path
import json
from mock import MagicMock, call
from units.compat import unittest
from ansible.plugins.cliconf import ios
from ansible.module_utils._text import to_bytes
b_FIXTURE_DIR = b'%s/fixtures/ios' % (
    to_bytes(path.dirname(path.abspath(__file__)), errors='surrogate_or_strict')
)
def _connection_side_effect(*args, **kwargs):
    try:
        if args:
            value = args[0]
        else:
            value = kwargs.get('command')
        fixture_path = path.abspath(
            b'%s/%s' % (b_FIXTURE_DIR, b'_'.join(value.split(b' ')))
        )
        with open(fixture_path, 'rb') as file_desc:
            return file_desc.read()
    except (OSError, IOError):
        if args:
            value = args[0]
            return value
        elif kwargs.get('command'):
            value = kwargs.get('command')
            return value
        return 'Nope'
class TestPluginCLIConfIOS(unittest.TestCase):
    """""" Test class for IOS CLI Conf Methods
    """"""
    def setUp(self):
        self._mock_connection = MagicMock()
        self._mock_connection.send.side_effect = _connection_side_effect
        self._cliconf = ios.Cliconf(self._mock_connection)
        self.maxDiff = None
    def tearDown(self):
        pass
    def test_get_device_info(self):
        """""" Test get_device_info
        """"""
        device_info = self._cliconf.get_device_info()
        mock_device_info = {'network_os': 'ios',
                            'network_os_model': 'CSR1000V',
                            'network_os_version': '16.06.01',
                            'network_os_hostname': 'an-csr-01',
                            'network_os_image': 'bootflash:packages.conf'
                            }
        self.assertEqual(device_info, mock_device_info)
    def test_get_capabilities(self):
        """""" Test get_capabilities
        """"""
        capabilities = json.loads(self._cliconf.get_capabilities())
        mock_capabilities = {
            'network_api': 'cliconf',
            'rpc': [
                'get_config',
                'edit_config',
                'get_capabilities',
                'get',
                'enable_response_logging',
                'disable_response_logging',
                'edit_banner',
                'get_diff',
                'run_commands',
                'get_defaults_flag'
            ],
            'device_operations': {
                'supports_diff_replace': True,
                'supports_commit': False,
                'supports_rollback': False,
                'supports_defaults': True,
                'supports_onbox_diff': False,
                'supports_commit_comment': False,
                'supports_multiline_delimiter': True,
                'supports_diff_match': True,
                'supports_diff_ignore_lines': True,
                'supports_generate_diff': True,
                'supports_replace': False
            },
            'device_info': {
                'network_os_hostname': 'an-csr-01',
                'network_os_image': 'bootflash:packages.conf',
                'network_os_model': 'CSR1000V',
                'network_os_version': '16.06.01',
                'network_os': 'ios'
            },
            'format': ['text'],
            'diff_match': ['line', 'strict', 'exact', 'none'],
            'diff_replace': ['line', 'block'],
            'output': []
        }
        self.assertEqual(
            mock_capabilities,
            capabilities
        )
"
-------------------------------------------------------------------------
"Recom
PRs: 58159, 58174"
-------------------------------------------------------------------------
=========================================================================
"def ensure_required_libs(module):
    if not HAS_PSYCOPG2:
        module.fail_json(msg=missing_required_lib('psycopg2'))
    if module.params.get('ca_cert') and LooseVersion(psycopg2.__version__) < LooseVersion('2.4.3'):
        module.fail_json(msg='psycopg2 must be at least 2.4.3 in order to use the ca_cert parameter')
def connect_to_db(module, autocommit=False, fail_on_conn=True, warn_db_default=True):
    ensure_required_libs(module)
    # To use defaults values, keyword arguments must be absent, so
    # check which values are empty and don't include in the **kw
    # dictionary
    params_map = {
        ""login_host"": ""host"",
        ""login_user"": ""user"",
        ""login_password"": ""password"",
        ""port"": ""port"",
        ""ssl_mode"": ""sslmode"",
        ""ca_cert"": ""sslrootcert""
    }
    # Might be different in the modules:
    if module.params.get('db'):
        params_map['db'] = 'database'
    elif module.params.get('database'):
        params_map['database'] = 'database'
    elif module.params.get('login_db'):
        params_map['login_db'] = 'database'
    else:
        if warn_db_default:
            module.warn('Database name has not been passed, '
                        'used default database to connect to.')
    kw = dict((params_map[k], v) for (k, v) in iteritems(module.params)
              if k in params_map and v != '' and v is not None)
    # If a login_unix_socket is specified, incorporate it here.
    is_localhost = ""host"" not in kw or kw[""host""] is None or kw[""host""] == ""localhost""
    if is_localhost and module.params[""login_unix_socket""] != """":
        kw[""host""] = module.params[""login_unix_socket""]
"
-------------------------------------------------------------------------
"def ensure_libs(sslrootcert=None):
    if not HAS_PSYCOPG2:
        raise LibraryError('psycopg2 is not installed. we need psycopg2.')
    if sslrootcert and LooseVersion(psycopg2.__version__) < LooseVersion('2.4.3'):
        raise LibraryError('psycopg2 must be at least 2.4.3 in order to use the ca_cert parameter')


def connect_to_db(module, autocommit=False):
    ensure_libs()
    # To use defaults values, keyword arguments must be absent, so
    # check which values are empty and don't include in the **kw
    # dictionary
    kw = {
        ""host"": module.params[""login_host""],
        ""user"": module.params[""login_user""],
        ""password"": module.params[""login_password""],
        ""port"": module.params[""port""],
        ""sslmode"": module.params[""ssl_mode""],
        ""sslrootcert"": module.params.get(""ca_cert"")
    }

    if module.params.get('db'):
        kw['database'] = module.params['db']
    elif module.params.get('database'):
        kw['database'] = module.params['database']
    elif module.params.get('login_db'):
        kw['database'] = module.params['login_db']
    else:
        if warn_db_default:
            module.warn('Database name has not been passed, '
                        'used default database to connect to.')

    if ""host"" not in kw or kw[""host""] is None or kw[""host""] == ""localhost"":
        if module.params.get(""login_unix_socket"") != """":
            kw[""host""] = module.params[""login_unix_socket""]"
-------------------------------------------------------------------------
"def ensure_required_libs(module):
    if not HAS_PSYCOPG2:
        module.fail_json(msg=missing_required_lib('psycopg2'))
    if module.params.get('ca_cert') and LooseVersion(psycopg2.__version__) < LooseVersion('2.4.3'):
        module.fail_json(msg='psycopg2 must be at least 2.4.3 in order to use the ca_cert parameter')
def connect_to_db(module, conn_params, autocommit=False, fail_on_conn=True):
    """"""Connect to a PostgreSQL database.
    Return psycopg2 connection object.
    Args:
        module (AnsibleModule) -- object of ansible.module_utils.basic.AnsibleModule class
        conn_params (dict) -- dictionary with connection parameters
    Kwargs:
        autocommit (bool) -- commit automatically (default False)
        fail_on_conn (bool) -- fail if connection failed or just warn and return None (default True)
    """"""
    ensure_required_libs(module)
        db_connection = psycopg2.connect(**conn_params)
        # Switch role, if specified:
        cursor = db_connection.cursor(cursor_factory=DictCursor)
        if module.params.get('session_role'):
            try:
                cursor.execute('SET ROLE %s' % module.params['session_role'])
            except Exception as e:
                module.fail_json(msg=""Could not switch role: %s"" % to_native(e))
        cursor.close()
        if fail_on_conn:
            module.fail_json(msg=""unable to connect to database: %s"" % to_native(e))
        else:
            module.warn(""PostgreSQL server is unavailable: %s"" % to_native(e))
            db_connection = None
        if fail_on_conn:
            module.fail_json(msg=""unable to connect to database: %s"" % to_native(e))
        else:
            module.warn(""PostgreSQL server is unavailable: %s"" % to_native(e))
            db_connection = None
def get_conn_params(module, params_dict, warn_db_default=True):
    """"""Get connection parameters from the passed dictionary.
    Return a dictionary with parameters to connect to PostgreSQL server.
    Args:
        module (AnsibleModule) -- object of ansible.module_utils.basic.AnsibleModule class
        params_dict (dict) -- dictionary with variables
    Kwargs:
        warn_db_default (bool) -- warn that the default DB is used (default True)
    """"""
    # To use defaults values, keyword arguments must be absent, so
    # check which values are empty and don't include in the return dictionary
    params_map = {
        ""login_host"": ""host"",
        ""login_user"": ""user"",
        ""login_password"": ""password"",
        ""port"": ""port"",
        ""ssl_mode"": ""sslmode"",
        ""ca_cert"": ""sslrootcert""
    }
    # Might be different in the modules:
    if params_dict.get('db'):
        params_map['db'] = 'database'
    elif params_dict.get('database'):
        params_map['database'] = 'database'
    elif params_dict.get('login_db'):
        params_map['login_db'] = 'database'
    else:
        if warn_db_default:
            module.warn('Database name has not been passed, '
                        'used default database to connect to.')
    kw = dict((params_map[k], v) for (k, v) in iteritems(params_dict)
              if k in params_map and v != '' and v is not None)
    # If a login_unix_socket is specified, incorporate it here.
    is_localhost = ""host"" not in kw or kw[""host""] is None or kw[""host""] == ""localhost""
    if is_localhost and params_dict[""login_unix_socket""] != """":
        kw[""host""] = params_dict[""login_unix_socket""]
    return kw
"
-------------------------------------------------------------------------
"Recom
PRs: 55799, 57473"
-------------------------------------------------------------------------
=========================================================================
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
"
-------------------------------------------------------------------------
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass

from ansible.module_utils.basic import AnsibleModule"
-------------------------------------------------------------------------
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
 ansible.module_utils.postgres import (
connect_to_db,
get_conn_params,
postgres_common_argument_spec,
"
-------------------------------------------------------------------------
"Recom
PRs: 55799, 57473"
-------------------------------------------------------------------------
=========================================================================
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
"
-------------------------------------------------------------------------
"# psycopg2 is checked by connect_to_db() from ansible.module_utils.postgres
from ansible.module_utils.postgres import connect_to_db
from ansible.module_utils.basic import AnsibleModule
from psycopg2.extras import DictCursor"
-------------------------------------------------------------------------
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
 ansible.module_utils.postgres import connect_to_db, get_conn_params, postgres_common_argument_spec
"
-------------------------------------------------------------------------
"Recom
PRs: 55799, 57473"
-------------------------------------------------------------------------
=========================================================================
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.postgres import connect_to_db, postgres_common_argument_spec
"
-------------------------------------------------------------------------
"from ansible.module_utils.postgres import connect_to_db

from psycopg2.extras import DictCursor

# psycopg2 is checked by connect_to_db() from ansible.module_utils.postgres
from ansible.module_utils.postgres import connect_to_db, postgres_common_argument_spec"
-------------------------------------------------------------------------
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.postgres import connect_to_db, get_conn_params, postgres_common_argument_spec
"
-------------------------------------------------------------------------
"Recom
PRs: 55799, 57473"
-------------------------------------------------------------------------
=========================================================================
"def __init__(self, module):
    self.session_role = self.module.params.get('session_role')
        self.db_conn = connect_to_db(self.module, warn_db_default=False)
        self.cursor = self.db_conn.cursor(cursor_factory=DictCursor)
"
-------------------------------------------------------------------------
"def __init__(self, module):
    self.session_role = self.module.params.get('session_role')
    db_connection = connect_to_db(self.module, warn_db_default=False)
    self.cursor = db_connection.cursor(cursor_factory=psycopg2.extras.DictCursor)"
-------------------------------------------------------------------------
"def __init__(self, module):
    self.session_role = self.module.params.get('session_role')
    conn_params = get_conn_params(self.module, self.module.params, warn_db_default=False)
    self.db_conn = connect_to_db(self.module, conn_params)
    return self.db_conn.cursor(cursor_factory=DictCursor)
    self.module.params['database'] = dbname
"
-------------------------------------------------------------------------
"Recom
PRs: 55799, 57473"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils.basic import AnsibleModule
"
-------------------------------------------------------------------------
"from ansible.module_utils.basic import AnsibleModule, missing_required_lib"
-------------------------------------------------------------------------
"from ansible.module_utils.basic import AnsibleModule
from ansible.module_utils.postgres import (
    connect_to_db,
    get_conn_params,
    postgres_common_argument_spec,
)
"
-------------------------------------------------------------------------
"Recom
PRs: 55799, 57473"
-------------------------------------------------------------------------
=========================================================================
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
"
-------------------------------------------------------------------------
"from ansible.module_utils.postgres import psycopg2
from ansible.module_utils.basic import AnsibleModule"
-------------------------------------------------------------------------
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
 ansible.module_utils.postgres import connect_to_db, get_conn_params, postgres_common_argument_spec
"
-------------------------------------------------------------------------
"Recom
PRs: 55799, 57473"
-------------------------------------------------------------------------
=========================================================================
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
""""""
If you want to add handling of a new type of database objects:
1. Add a specific method for this like self.__set_db_owner(), etc.
2. Add a condition with a check of ownership for new type objects to self.__is_owner()
3. Add a condition with invocation of the specific method to self.set_owner()
4. Add the information to the module documentation
That's all.
""""""
"
-------------------------------------------------------------------------
"from ansible.module_utils.basic import AnsibleModule
from psycopg2.extras import DictCursor

""""""
If you want to add handling of a new type of database objects:
1. Add a specific method for this like self.__set_db_owner(), etc.
2. Add a condition with a check of ownership for new type objects to self.__is_owner()
3. Add a condition with invocation of the specific method to self.set_owner()
4. Add the information to the module documentation
That's all.
"""""""
-------------------------------------------------------------------------
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
 ansible.module_utils.postgres import connect_to_db, get_conn_params, postgres_common_argument_spec
""""""
If you want to add handling of a new type of database objects:
1. Add a specific method for this like self.__set_db_owner(), etc.
2. Add a condition with a check of ownership for new type objects to self.__is_owner()
3. Add a condition with invocation of the specific method to self.set_owner()
4. Add the information to the module documentation
That's all.
""""""
"
-------------------------------------------------------------------------
"Recom
PRs: 55799, 57473"
-------------------------------------------------------------------------
=========================================================================
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.postgres import connect_to_db, postgres_common_argument_spec
"
-------------------------------------------------------------------------
"from ansible.module_utils.postgres import connect_to_db, postgres_common_argument_spec

# psycopg2 is checked by connect_to_db()
from ansible.module_utils.postgres import DictCursor"
-------------------------------------------------------------------------
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.postgres import connect_to_db, get_conn_params, postgres_common_argument_spec
"
-------------------------------------------------------------------------
"Recom
PRs: 55799, 57473"
-------------------------------------------------------------------------
=========================================================================
"from psycopg2 import ProgrammingError as Psycopg2ProgrammingError
from psycopg2.extras import DictCursor
# it is needed for checking 'no result to fetch' in main(),
# psycopg2 availability will be checked by connect_to_db() into
# ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
"
-------------------------------------------------------------------------
"from ansible.module_utils.basic import AnsibleModule
from ansible.module_utils.postgres import connect_to_db, psycopg2
from psycopg2 import ProgrammingError as psycopg2ProgrammingError
from psycopg2.extras import DictCursor"
-------------------------------------------------------------------------
"from psycopg2 import ProgrammingError as Psycopg2ProgrammingError
from psycopg2.extras import DictCursor
# it is needed for checking 'no result to fetch' in main(),
# psycopg2 availability will be checked by connect_to_db() into
# ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
 ansible.module_utils.postgres import connect_to_db, get_conn_params, postgres_common_argument_spec
"
-------------------------------------------------------------------------
"Recom
PRs: 55799, 57473"
-------------------------------------------------------------------------
=========================================================================
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
"
-------------------------------------------------------------------------
"from ansible.module_utils.postgres import connect_to_db
from psycopg2.extras import DictCursor
from ansible.module_utils.basic import AnsibleModule"
-------------------------------------------------------------------------
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
 ansible.module_utils.postgres import (
connect_to_db,
get_conn_params,
postgres_common_argument_spec,
"
-------------------------------------------------------------------------
"Recom
PRs: 55799, 57473"
-------------------------------------------------------------------------
=========================================================================
"try:
    from psycopg2.extras import DictCursor
except Exception:
    # psycopg2 is checked by connect_to_db()
    # from ansible.module_utils.postgres
    pass
from ansible.module_utils.basic import AnsibleModule
from ansible.module_utils.postgres import connect_to_db, postgres_common_argument_spec
PG_REQ_VER = 90400
"
-------------------------------------------------------------------------
"try:
    from psycopg2.extras import DictCursor
except ImportError:
    # psycopg2 is checked by connect_to_db()
    # from ansible.module_utils.postgres
    pass"
-------------------------------------------------------------------------
"try:
    from psycopg2.extras import DictCursor
except Exception:
    # psycopg2 is checked by connect_to_db()
    # from ansible.module_utils.postgres
    pass
from ansible.module_utils.basic import AnsibleModule
from ansible.module_utils.postgres import connect_to_db, get_conn_params, postgres_common_argument_spec
PG_REQ_VER = 90400
"
-------------------------------------------------------------------------
"Recom
PRs: 55799, 57473"
-------------------------------------------------------------------------
=========================================================================
"db_connection = connect_to_db(module, autocommit=True)
cursor = db_connection.cursor(cursor_factory=DictCursor)
"
-------------------------------------------------------------------------
"db_connection = connect_to_db(module, kw, autocommit=False)
cursor = db_connection.cursor(cursor_factory=psycopg2.extras.DictCursor)"
-------------------------------------------------------------------------
"db_connection = connect_to_db(module, conn_params, autocommit=True)
cursor = db_connection.cursor(cursor_factory=DictCursor)
"
-------------------------------------------------------------------------
"Recom
PRs: 55799, 57473"
-------------------------------------------------------------------------
=========================================================================
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
 ansible.module_utils.postgres import connect_to_db, postgres_common_argument_spec
"
-------------------------------------------------------------------------
"from psycopg2.extras import DictCursor
from ansible.module_utils.basic import AnsibleModule
from ansible.module_utils.postgres import connect_to_db, postgres_common_argument_spec"
-------------------------------------------------------------------------
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
 ansible.module_utils.postgres import connect_to_db, get_conn_params, postgres_common_argument_spec
"
-------------------------------------------------------------------------
"Recom
PRs: 55799, 57473"
-------------------------------------------------------------------------
=========================================================================
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
"
-------------------------------------------------------------------------
"from ansible.module_utils.postgres import pg_quote_identifier
from ansible.module_utils.basic import AnsibleModule, missing_required_lib, six, database, to_native
import psycopg2
from psycopg2.extras import DictCursor"
-------------------------------------------------------------------------
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
 ansible.module_utils.postgres import connect_to_db, get_conn_params, postgres_common_argument_spec
"
-------------------------------------------------------------------------
"Recom
PRs: 55799, 57473"
-------------------------------------------------------------------------
=========================================================================
"from psycopg2 import __version__ as PSYCOPG2_VERSION
from psycopg2.extras import DictCursor
from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT as AUTOCOMMIT
from psycopg2.extensions import ISOLATION_LEVEL_READ_COMMITTED as READ_COMMITTED
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
"
-------------------------------------------------------------------------
"from ansible.module_utils.postgres import psycopg2
from ansible.module_utils.postgres import psycopg2.extras.DictCursor
from ansible.module_utils.postgres import psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT as AUTOCOMMIT
from ansible.module_utils.postgres import psycopg2.extensions.ISOLATION_LEVEL_READ_COMMITTED as READ_COMMITTED
from ansible.module_utils.basic import AnsibleModule"
-------------------------------------------------------------------------
"from psycopg2 import __version__ as PSYCOPG2_VERSION
from psycopg2.extras import DictCursor
from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT as AUTOCOMMIT
from psycopg2.extensions import ISOLATION_LEVEL_READ_COMMITTED as READ_COMMITTED
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
 ansible.module_utils.postgres import connect_to_db, get_conn_params, postgres_common_argument_spec
"
-------------------------------------------------------------------------
"Recom
PRs: 55799, 57473"
-------------------------------------------------------------------------
=========================================================================
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
 ansible.module_utils.postgres import connect_to_db, postgres_common_argument_spec
"
-------------------------------------------------------------------------
"from ansible.module_utils.postgres import connect_to_db, psycopg2
from ansible.module_utils.basic import AnsibleModule
from ansible.module_utils.database import SQLParseError, missing_required_lib
from ansible.module_utils.postgres import postgres_common_argument_spec
from ansible.module_utils._text import to_native
from ansible.module_utils.six import iteritems"
-------------------------------------------------------------------------
"from psycopg2.extras import DictCursor
# psycopg2 is checked by connect_to_db()
# from ansible.module_utils.postgres
pass
 ansible.module_utils.basic import AnsibleModule
 ansible.module_utils.postgres import (
connect_to_db,
get_conn_params,
postgres_common_argument_spec,
"
-------------------------------------------------------------------------
"Recom
PRs: 55799, 57473"
-------------------------------------------------------------------------
=========================================================================
"if module.params['db'] == '' and module.params[""priv""] is not None:
privs = parse_privs(module.params[""priv""], module.params[""db""])
db_connection = connect_to_db(module, warn_db_default=False)
cursor = db_connection.cursor(cursor_factory=DictCursor)
"
-------------------------------------------------------------------------
"if module.params['db'] == '' and module.params[""priv""] is not None:
    privs = parse_privs(module.params[""priv""], module.params[""db""])
    db_connection = connect_to_db(module, warn_db_default=False)
    cursor = db_connection.cursor(cursor_factory=psycopg2.extras.DictCursor)"
-------------------------------------------------------------------------
"if module.params['db'] == '' and module.params[""priv""] is not None:
privs = parse_privs(module.params[""priv""], module.params[""db""])
conn_params = get_conn_params(module, module.params, warn_db_default=False)
db_connection = connect_to_db(module, conn_params)
cursor = db_connection.cursor(cursor_factory=DictCursor)
"
-------------------------------------------------------------------------
"Recom
PRs: 55799, 57473"
-------------------------------------------------------------------------
=========================================================================
"if client.module.params['build'].get(build_option, default_value) != default_value:
"
-------------------------------------------------------------------------
"if self.client.module.params['build'].get(build_option, None) != None:"
-------------------------------------------------------------------------
"if client.module.params['build'].get(build_option, default_value) != default_value:
client.fail('If ""source"" is set to ""build"", the ""build.path"" option must be specified.')
"
-------------------------------------------------------------------------
"Recom
PRs: 56610, 57085"
-------------------------------------------------------------------------
=========================================================================
"if to_text(out, errors='surrogate_then_replace').strip().endswith('#'):
"
-------------------------------------------------------------------------
"if to_text(out, errors='surrogate_then_replace').strip().endswith('#'):"
-------------------------------------------------------------------------
"        if to_text(out, errors='surrogate_then_replace').strip().endswith('#'):
            conn.send_command('exit discard')
"
-------------------------------------------------------------------------
"Recom
PRs: 56389, 56401"
-------------------------------------------------------------------------
=========================================================================
"if to_text(out, errors='surrogate_then_replace').strip().endswith('#'):
"
-------------------------------------------------------------------------
"if to_text(out, errors='surrogate_then_replace').strip().endswith(')#'):"
-------------------------------------------------------------------------
"if to_text(out, errors='surrogate_then_replace').strip().endswith('#'):
    conn.send_command('exit discard')
"
-------------------------------------------------------------------------
"Recom
PRs: 56389, 56399"
-------------------------------------------------------------------------
=========================================================================
"p = subprocess.Popen(
    local_cmd,
    stdin=subprocess.PIPE,
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
)
if self.become and self.become.expect_prompt() and sudoable:
    display.debug(""handling privilege escalation"")
    fcntl.fcntl(p.stdout, fcntl.F_SETFL, fcntl.fcntl(p.stdout, fcntl.F_GETFL) | os.O_NONBLOCK)
    fcntl.fcntl(p.stderr, fcntl.F_SETFL, fcntl.fcntl(p.stderr, fcntl.F_GETFL) | os.O_NONBLOCK)
    selector = selectors.DefaultSelector()
    selector.register(p.stdout, selectors.EVENT_READ)
    selector.register(p.stderr, selectors.EVENT_READ)
    become_output = b''
    try:
        while not self.become.check_success(become_output) and not self.become.check_password_prompt(become_output):
            events = selector.select(self._play_context.timeout)
            if not events:
                stdout, stderr = p.communicate()
                raise AnsibleError('timeout waiting for privilege escalation password prompt:\n'  to_native(become_output))
            for key, event in events:
                if key.fileobj == p.stdout:
                    chunk = p.stdout.read()
                    break
                elif key.fileobj == p.stderr:
                    chunk = p.stderr.read()
            if not chunk:
                stdout, stderr = p.communicate()
                raise AnsibleError('privilege output closed while waiting for password prompt:\n'  to_native(become_output))
            become_output = chunk
    finally:
        selector.close()
    if not self.become.check_success(become_output):
        p.stdin.write(to_bytes(self._play_context.become_pass, errors='surrogate_or_strict')  b'\n')
    fcntl.fcntl(p.stdout, fcntl.F_SETFL, fcntl.fcntl(p.stdout, fcntl.F_GETFL) & ~os.O_NONBLOCK)
    fcntl.fcntl(p.stderr, fcntl.F_SETFL, fcntl.fcntl(p.stderr, fcntl.F_GETFL) & ~os.O_NONBLOCK)
display.debug(""getting output with communicate()"")
display.debug(""done communicating"")
display.debug(""done with docker.exec_command()"")
"
-------------------------------------------------------------------------
"p = subprocess.Popen(
    local_cmd,
    stdin=subprocess.PIPE,
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
)"
-------------------------------------------------------------------------
"p = subprocess.Popen(
    local_cmd,
    stdin=subprocess.PIPE,
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
)
if self._play_context.prompt and sudoable:
    fcntl.fcntl(p.stdout, fcntl.F_SETFL, fcntl.fcntl(p.stdout, fcntl.F_GETFL) | os.O_NONBLOCK)
    fcntl.fcntl(p.stderr, fcntl.F_SETFL, fcntl.fcntl(p.stderr, fcntl.F_GETFL) | os.O_NONBLOCK)
    selector = selectors.DefaultSelector()
    selector.register(p.stdout, selectors.EVENT_READ)
    selector.register(p.stderr, selectors.EVENT_READ)
    become_output = b''
    try:
        while not self.check_become_success(become_output) and not self.check_password_prompt(become_output):
            events = selector.select(self._play_context.timeout)
            if not events:
                stdout, stderr = p.communicate()
                raise AnsibleError('timeout waiting for privilege escalation password prompt:\n'  to_native(become_output))
            for key, event in events:
                if key.fileobj == p.stdout:
                    chunk = p.stdout.read()
                elif key.fileobj == p.stderr:
                    chunk = p.stderr.read()
            if not chunk:
                stdout, stderr = p.communicate()
                raise AnsibleError('privilege output closed while waiting for password prompt:\n'  to_native(become_output))
            become_output = chunk
    finally:
        selector.close()
    if not self.check_become_success(become_output):
        p.stdin.write(to_bytes(self._play_context.become_pass, errors='surrogate_or_strict')  b'\n')
    fcntl.fcntl(p.stdout, fcntl.F_SETFL, fcntl.fcntl(p.stdout, fcntl.F_GETFL) & ~os.O_NONBLOCK)
    fcntl.fcntl(p.stderr, fcntl.F_SETFL, fcntl.fcntl(p.stderr, fcntl.F_GETFL) & ~os.O_NONBLOCK)
display.debug(""getting output with communicate()"")
display.debug(""done communicating"")
display.debug(""done with docker.exec_command()"")
"
-------------------------------------------------------------------------
"Recom
PRs: 55816, 56278"
-------------------------------------------------------------------------
=========================================================================
"- Seconds to wait before reboot. Passed as a parameter to the reboot command.
- Seconds to wait after the reboot command was successful before attempting to validate the system rebooted successfully.
- This timeout is evaluated separately for both reboot verification and test command success so the
"
-------------------------------------------------------------------------
"pre_reboot_delay:
    description:
      - Seconds for shutdown to wait before requesting reboot.
      - On Linux, macOS, and OpenBSD this is converted to minutes and rounded down. If less than 60, it will be set to 0.
      - On Solaris and FreeBSD this will be seconds.
    default: 0
    type: int
  post_reboot_delay:
    description:
      - Seconds to wait after the reboot was successful and the connection was re-established.
      - This is useful if you want wait for something to settle despite your connection already working.
    default: 0
    type: int"
-------------------------------------------------------------------------
"- Seconds to wait before reboot. Passed as a parameter to the reboot command.
- On Linux, macOS and OpenBSD, this is converted to minutes and rounded down. If less than 60, it will be set to 0.
- On Solaris and FreeBSD, this will be seconds.
- Seconds to wait after the reboot command was successful before attempting to validate the system rebooted successfully.
- This timeout is evaluated separately for both reboot verification and test command success so the
"
-------------------------------------------------------------------------
"Recom
PRs: 55934, 55959"
-------------------------------------------------------------------------
=========================================================================
"- Seconds to wait before reboot. Passed as a parameter to the reboot command.
- Seconds to wait after the reboot command was successful before attempting to validate the system rebooted successfully.
"
-------------------------------------------------------------------------
"pre_reboot_delay:
    description:
    - Seconds for shutdown to wait before requesting reboot
    type: int
    default: 2
    aliases: [ pre_reboot_delay_sec ]
    
    post_reboot_delay:
    description:
    - Seconds to wait after the reboot was successful and the connection was re-established
    - This is useful if you want wait for something to settle despite your connection already working
    type: int
    default: 0
    version_added: '2.4'
    aliases: [ post_reboot_delay_sec ]"
-------------------------------------------------------------------------
"- Seconds to wait before reboot. Passed as a parameter to the reboot command.
- Seconds to wait after the reboot command was successful before attempting to validate the system rebooted successfully.
- This is useful if you want wait for something to settle despite your connection already working.
"
-------------------------------------------------------------------------
"Recom
PRs: 55934, 55959"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils._text import to_native
from ansible.module_utils.basic import missing_required_lib
    HAS_NCCLIENT = True
    NCCLIENT_IMP_ERR = None
except (ImportError, AttributeError) as err:  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
    HAS_NCCLIENT = False
    NCCLIENT_IMP_ERR = err
"
-------------------------------------------------------------------------
"from ansible.module_utils.basic import missing_required_lib, HAS_NCCLIENT, NCCLIENT_IMP_ERR
from ansible.errors import AnsibleError

try:
    from ncclient.operations import RPCError
    from ncclient.xml_ import to_xml, to_ele
except ImportError as err:
    HAS_NCCLIENT = False
    NCCLIENT_IMP_ERR = err
    raise AnsibleError(""ncclient is not installed"")"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_native
    HAS_NCCLIENT = True
    NCCLIENT_IMP_ERR = None
except (ImportError, AttributeError) as err:  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
    HAS_NCCLIENT = False
    NCCLIENT_IMP_ERR = err
"
-------------------------------------------------------------------------
"Recom
PRs: 55384, 55648"
-------------------------------------------------------------------------
=========================================================================
"def ensure_ncclient(func):
    @wraps(func)
    def wrapped(self, *args, **kwargs):
        if not HAS_NCCLIENT:
            raise AnsibleError(""%s: %s"" % (missing_required_lib('ncclient'), to_native(NCCLIENT_IMP_ERR)))
        return func(self, *args, **kwargs)
    return wrapped
"
-------------------------------------------------------------------------
"def ensure_ncclient(func):
    @wraps(func)
    def wrapped(self, *args, **kwargs):
        if not self._connection._connected:
            self._connection._connect()
        return func(self, *args, **kwargs)
    return wrapped"
-------------------------------------------------------------------------
"def ensure_ncclient(func):
    @wraps(func)
    def wrapped(self, *args, **kwargs):
        if not HAS_NCCLIENT:
            raise AnsibleError(""Package ncclient is not installed: %s. Please install it with `pip install ncclient`"" % to_native(NCCLIENT_IMP_ERR))
        return func(self, *args, **kwargs)
    return wrapped
"
-------------------------------------------------------------------------
"Recom
PRs: 55384, 55648"
-------------------------------------------------------------------------
=========================================================================
"from ansible.errors import AnsibleConnectionFailure
from ansible.plugins.netconf import ensure_connected, ensure_ncclient
    HAS_NCCLIENT = True
except (ImportError, AttributeError):  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
    HAS_NCCLIENT = False
    @ensure_ncclient
    @ensure_ncclient
"
-------------------------------------------------------------------------
"from ansible.errors import AnsibleError
from ansible.plugins import AnsiblePlugin
from ncclient.xml_ import to_xml, to_ele

try:
    from ncclient.operations import RPCError
except ImportError:
    raise AnsibleError(""ncclient is not installed"")

@wraps
@wraps"
-------------------------------------------------------------------------
"from ansible.errors import AnsibleConnectionFailure
from ansible.plugins.netconf import ensure_connected, ensure_ncclient
    HAS_NCCLIENT = True
except (ImportError, AttributeError):  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
    HAS_NCCLIENT = False
"
-------------------------------------------------------------------------
"Recom
PRs: 55384, 55648"
-------------------------------------------------------------------------
=========================================================================
"@ensure_ncclient
"
-------------------------------------------------------------------------
"@ensure_connected
def get_text(self, ele, tag):
    try:
        return ansible.module_utils._text.to_text(ele.find(tag).text, errors='surrogate_then_replace').strip()
    except AttributeError:
        pass"
-------------------------------------------------------------------------
"@ensure_ncclient
@ensure_ncclient
"
-------------------------------------------------------------------------
"Recom
PRs: 55384, 55648"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils._text import to_text, to_native
from ansible.errors import AnsibleConnectionFailure
from ansible.plugins.netconf import ensure_connected, ensure_ncclient
    HAS_NCCLIENT = True
except (ImportError, AttributeError):  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
    HAS_NCCLIENT = False
    @ensure_ncclient
"
-------------------------------------------------------------------------
"if kwargs.get('config'):
            kwargs['config'] = to_bytes(kwargs['config'], errors='surrogate_or_strict')
            if kwargs.get('format', 'xml') == 'xml':
                kwargs['config'] = ncclient.xml_.to_ele(kwargs['config'])

        try:
            return self.m.load_configuration(*args, **kwargs).data_xml
        except ncclient.operations.RPCError as exc:
            raise Exception(ncclient.xml_.to_xml(exc.xml))"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_text
from ansible.errors import AnsibleConnectionFailure
from ansible.plugins.netconf import ensure_connected, ensure_ncclient
    HAS_NCCLIENT = True
except (ImportError, AttributeError):  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
    HAS_NCCLIENT = False
    @ensure_ncclient
"
-------------------------------------------------------------------------
"Recom
PRs: 55384, 55648"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils._text import to_text, to_native
from ansible.errors import AnsibleConnectionFailure
from ansible.plugins.netconf import ensure_ncclient
    from ncclient.xml_ import to_ele
    HAS_NCCLIENT = True
except (ImportError, AttributeError):  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
    HAS_NCCLIENT = False
"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_text, to_bytes
from ansible.errors import AnsibleConnectionFailure
from ansible.plugins.netconf import ensure_connected
from ncclient.xml_ import to_ele

HAS_NCCLIENT = True
try:
    from ncclient import manager
    HAS_NCCLIENT = True
except ImportError:
    HAS_NCCLIENT = False
    raise AnsibleError(""ncclient is not installed"")"
-------------------------------------------------------------------------
"from ansible.module_utils._text import to_text
from ansible.errors import AnsibleConnectionFailure
from ansible.plugins.netconf import ensure_ncclient
    from ncclient.xml_ import to_ele
    HAS_NCCLIENT = True
except (ImportError, AttributeError):  # paramiko and gssapi are incompatible and raise AttributeError not ImportError
    HAS_NCCLIENT = False
"
-------------------------------------------------------------------------
"Recom
PRs: 55384, 55648"
-------------------------------------------------------------------------
=========================================================================
"'uid': secret_data['File'].get('UID'),
'gid': secret_data['File'].get('GID'),
"
-------------------------------------------------------------------------
"'uid': secret_data['File'].get('uid'),
'gid': secret_data['File'].get('gid'),"
-------------------------------------------------------------------------
"'uid': config_data['File'].get('UID'),
'gid': config_data['File'].get('GID'),
"
-------------------------------------------------------------------------
"Recom
PRs: 55591, 55617"
-------------------------------------------------------------------------
=========================================================================
"if params['direction'] not in ['outgoing', 'incoming', 'routed', None]:
    module.fail_json(msg='For default, direction must be one of ""outgoing"", ""incoming"" and ""routed"", or direction must not be specified.')
"
-------------------------------------------------------------------------
"if params['direction'] not in ['out', 'in', 'routed', None]:
    module.fail_json(msg='For default, direction must be one of ""outgoing"", ""incoming"" and ""routed"", or direction must not be specified.')"
-------------------------------------------------------------------------
"if params['direction'] not in ['outgoing', 'incoming', 'routed', None]:
    module.fail_json(msg='For default, direction must be one of ""outgoing"", ""incoming"" and ""routed"", or direction must not be specified.')
    module.fail_json(msg='For rules, direction must be one of ""in"" and ""out"", or direction must not be specified.')
"
-------------------------------------------------------------------------
"Recom
PRs: 54799, 54987"
-------------------------------------------------------------------------
=========================================================================
"- Backreferences can be used ambiguously like C(\1), or explicitly like C(\g<1>).
- If specified, only content after this match will be replaced/removed.
- Uses DOTALL, which means the C(.) special character I(can match newlines).
- If specified, only content before this match will be replaced/removed.
- Uses DOTALL, which means the C(.) special character I(can match newlines).
"
-------------------------------------------------------------------------
"# Backreferences can be used ambiguously like '\1', or explicitly like '\g<1>'.
# If specified, only content after this match will be replaced/removed.
# Uses DOTALL, which means the '.' special character can match newlines.
# If specified, only content before this match will be replaced/removed.
# Uses DOTALL, which means the '.' special character can match newlines."
-------------------------------------------------------------------------
"- Backreferences can be used ambiguously like C(\1), or explicitly like C(\g<1>).
pe: str
- If specified, only content after this match will be replaced/removed.
- Can be used in combination with C(before).
- Uses Python regular expressions; see
- Uses DOTALL, which means the C(.) special character I(can match newlines).
pe: str
- If specified, only content before this match will be replaced/removed.
- Can be used in combination with C(after).
- Uses Python regular expressions; see
- Uses DOTALL, which means the C(.) special character I(can match newlines).
pe: str
"
-------------------------------------------------------------------------
"Recom
PRs: 31452, 54408"
-------------------------------------------------------------------------
=========================================================================
"- As of Ansible 2.7.10, the combined use of I(before) and I(after) works properly. If you were relying on the
  previous incorrect behavior, you may be need to adjust your tasks.
  See U(https://github.com/ansible/ansible/issues/31354) for details.
name: Before Ansible 2.3, option 'dest', 'destfile' or 'name' was used instead of 'path'
replace:
  path: /etc/apache2/sites-available/default.conf
  after: 'NameVirtualHost [*]'
  regexp: '^(.)$'
  replace: '# \1'
  path: /etc/apache2/sites-available/default.conf
  before: '# live site config'
  regexp: '^(.)$'
  replace: '# \1'
Prior to Ansible 2.7.10, using before and after in combination did the opposite of what was intended.
see https://github.com/ansible/ansible/issues/31354 for details.
  after: '<VirtualHost [*]>'
  before: '</VirtualHost>'
  regexp: '^(.)$'
  replace: '# \1'
name: Supports common file attributes
replace:
name: Supports a validate command
replace:
replace: path=/etc/hosts regexp='\\b(localhost)(\\d*)\\b' replace='\\1\\2.localdomain\\2 \\1\\2'
  path: /etc/hosts
name: Explicitly specifying positional matched groups in replacement
replace:
  path: /etc/ssh/sshd_config
  regexp: '^(ListenAddress[ ])[^\n]$'
  replace: '\g<1>0.0.0.0'
name: Explicitly specifying named matched groups
replace:
  path: /etc/ssh/sshd_config
  regexp: '^(?P<dctv>ListenAddress[ ])(?P<host>[^\n])$'
  replace: '#\g<dctv>\g<host>\n\g<dctv>0.0.0.0'
"
-------------------------------------------------------------------------
"# Before 2.3, option 'dest', 'destfile' or 'name' was used instead of 'path'
- replace:
    path: /etc/apache2/sites-available/default.conf
    regexp: '^(.)$'
    replace: '# \1'
    after: 'NameVirtualHost [*]'
    backup: yes

- replace:
    path: /etc/apache2/sites-available/default.conf
    regexp: '^(.)$'
    replace: '# \1'
    before: '# live site config'
    backup: yes

# Prior to Ansible 2.7.10, using before and after in combination did the opposite of what was intended.
# see https://github.com/ansible/ansible/issues/31354 for details.
- replace:
    path: /etc/apache2/sites-available/default.conf
    regexp: '^(.)$'
    replace: '# \1'
    after: '<VirtualHost [*]>'
    before: '</VirtualHost>'
    backup: yes

- replace:
    path: /etc/hosts
    regexp: '\\b(localhost)(\\d*)\\b'
    replace: '\\1\\2.localdomain\\2 \\1\\2'
    backup: yes

- replace:
    path: /etc/ssh/sshd_config
    regexp: '^(ListenAddress[ ])[^\n]$'
    replace: '\\g<1>0.0.0.0'
    backup: yes

- replace:
    path: /etc/ssh/sshd_config
    regexp: '^(?P<dctv>ListenAddress[ ])(?P<host>[^\n])$'
    replace: '#\\g<dctv>\\g<host>\\n\\g<dctv>0.0.0.0'
    backup: yes"
-------------------------------------------------------------------------
"- As of Ansible 2.7.10, the combined use of I(before) and I(after) works properly. If you were relying on the
  previous incorrect behavior, you may be need to adjust your tasks.
  See U(https://github.com/ansible/ansible/issues/31354) for details.
'
AMPLES = r'''
name: Before Ansible 2.3, option 'dest', 'destfile' or 'name' was used instead of 'path'
replace:
name: Replace after the expression till the end of the file (requires Ansible >= 2.4)
replace:
  path: /etc/apache2/sites-available/default.conf
  after: 'NameVirtualHost [*]'
  regexp: '^(.)$'
  replace: '# \1'
name: Replace before the expression till the begin of the file (requires Ansible >= 2.4)
replace:
  path: /etc/apache2/sites-available/default.conf
  before: '# live site config'
  regexp: '^(.)$'
  replace: '# \1'
Prior to Ansible 2.7.10, using before and after in combination did the opposite of what was intended.
see https://github.com/ansible/ansible/issues/31354 for details.
  after: '<VirtualHost [*]>'
  before: '</VirtualHost>'
  regexp: '^(.)$'
  replace: '# \1'
name: Supports common file attributes
replace:
name: Supports a validate command
replace:
name: Short form task (in ansible 2) necessitates backslash-escaped sequences
replace: path=/etc/hosts regexp='\\b(localhost)(\\d*)\\b' replace='\\1\\2.localdomain\\2 \\1\\2'
  path: /etc/hosts
name: Explicitly specifying positional matched groups in replacement
replace:
  path: /etc/ssh/sshd_config
  regexp: '^(ListenAddress[ ])[^\n]$'
  replace: '\g<1>0.0.0.0'
name: Explicitly specifying named matched groups
replace:
  path: /etc/ssh/sshd_config
  regexp: '^(?P<dctv>ListenAddress[ ])(?P<host>[^\n])$'
  replace: '#\g<dctv>\g<host>\n\g<dctv>0.0.0.0'
'
"
-------------------------------------------------------------------------
"Recom
PRs: 31452, 54408"
-------------------------------------------------------------------------
=========================================================================
"crypto_utils.write_file(
    module,
    self.pkcs12.export(self.passphrase, self.iter_size, self.maciter_size),
    0o600
)
"
-------------------------------------------------------------------------
"os.chmod(self.path, 0o600)"
-------------------------------------------------------------------------
"crypto_utils.write_file(
    module,
    self.pkcs12.export(self.passphrase, self.iter_size, self.maciter_size),
    0o600
)
    with open(self.src, 'rb') as pkcs12_fh:
        pkcs12_content = pkcs12_fh.read()
    p12 = crypto.load_pkcs12(pkcs12_content,
    crypto_utils.write_file(module, b'%s%s' % (pkey, crt))
"
-------------------------------------------------------------------------
"Recom
PRs: 54085, 54354"
-------------------------------------------------------------------------
=========================================================================
"# -*- coding: utf-8 -*-
# Copyright (c) 2019 Ansible Project
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
from __future__ import absolute_import, division, print_function
__metaclass__ = type
from units.compat.mock import Mock
from ansible.module_utils.facts.system.distribution import DistributionFiles
def mock_module():
    mock_module = Mock()
    mock_module.params = {'gather_subset': ['all'],
                          'gather_timeout': 5,
                          'filter': '*'}
    mock_module.get_bin_path = Mock(return_value=None)
    return mock_module
def test_parse_distribution_file_clear_linux():
    test_input = {
        'name': 'Clearlinux',
        'data': 'NAME=""Clear Linux OS""\nVERSION=1\nID=clear-linux-os\nID_LIKE=clear-linux-os\nVERSION_ID=28120\nPRETTY_NAME=""Clear Linux OS""\nANSI_COLOR=""1;35""'
                '\nHOME_URL=""https://clearlinux.org""\nSUPPORT_URL=""https://clearlinux.org""\nBUG_REPORT_URL=""mailto:dev@lists.clearlinux.org""',
        'path': '/usr/lib/os-release',
        'collected_facts': None,
    }
    result = (
        True,
        {
            'distribution': 'Clear Linux OS',
            'distribution_major_version': '28120',
            'distribution_release': 'clear-linux-os',
            'distribution_version': '28120'
        }
    )
    distribution = DistributionFiles(module=mock_module())
    assert result == distribution.parse_distribution_file_ClearLinux(**test_input)
def test_parse_distribution_file_clear_linux_no_match():
    # Test against data from Linux Mint and CoreOS to ensure we do not get a reported
    # match from parse_distribution_file_ClearLinux()
    scenarios = [
        {
            # CoreOS
            'case': {
                'name': 'Clearlinux',
                'data': 'NAME=""Container Linux by CoreOS""\nID=coreos\nVERSION=1911.5.0\nVERSION_ID=1911.5.0\nBUILD_ID=2018-12-15-2317\nPRETTY_NAME=""Container L'
                        'inux by CoreOS 1911.5.0 (Rhyolite)""\nANSI_COLOR=""38;5;75""\nHOME_URL=""https://coreos.com/""\nBUG_REPORT_URL=""https://issues.coreos.com""'
                        '\nCOREOS_BOARD=""amd64-usr""',
                'path': '/usr/lib/os-release',
                'collected_facts': None,
            },
            'result': (False, {}),
        },
        {
            # Linux Mint
            'case': {
                'name': 'Clearlinux',
                'data': 'NAME=""Linux Mint""\nVERSION=""19.1 (Tessa)""\nID=linuxmint\nID_LIKE=ubuntu\nPRETTY_NAME=""Linux Mint 19.1""\nVERSION_ID=""19.1""\nHOME_URL=""h'
                        'ttps://www.linuxmint.com/""\nSUPPORT_URL=""https://forums.ubuntu.com/""\nBUG_REPORT_URL=""http://linuxmint-troubleshooting-guide.readthedo'
                        'cs.io/en/latest/""\nPRIVACY_POLICY_URL=""https://www.linuxmint.com/""\nVERSION_CODENAME=tessa\nUBUNTU_CODENAME=bionic',
                'path': '/usr/lib/os-release',
                'collected_facts': None,
            },
            'result': (False, {}),
        },
    ]
    distribution = DistributionFiles(module=mock_module())
    for scenario in scenarios:
        assert scenario['result'] == distribution.parse_distribution_file_ClearLinux(**scenario['case'])
"
-------------------------------------------------------------------------
"# -*- coding: utf-8 -*-
# Copyright (c) 2019 Ansible Project
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
from __future__ import absolute_import, division, print_function
__metaclass__ = type
from unittest.mock import Mock
from ansible.module_utils.facts.system.distribution import DistributionFiles

def mock_module():
    mock_module = Mock()
    mock_module.params = {'gather_subset': ['all'],
                          'gather_timeout': 5,
                          'filter': '*'}
    mock_module.get_bin_path = Mock(return_value=None)
    return mock_module

def test_parse_distribution_file_clear_linux():
    test_input = {
        'name': 'Clearlinux',
        'data': 'NAME=""Clear Linux OS""\nVERSION=1\nID=clear-linux-os\nID_LIKE=clear-linux-os\nVERSION_ID=28120\nPRETTY_NAME=""Clear Linux OS""\nANSI_COLOR=""1;35""'
                '\nHOME_URL=""https://clearlinux.org""\nSUPPORT_URL=""https://clearlinux.org""\nBUG_REPORT_URL=""mailto:dev@lists.clearlinux.org""',
        'path': '/usr/lib/os-release',
        'collected_facts': None,
    }
    result = (
        True,
        {
            'distribution': 'Clear Linux OS',
            'distribution_major_version': '28120',
            'distribution_release': 'clear-linux-os',
            'distribution_version': '28120'
        }
    )
    distribution = DistributionFiles(module=mock_module())
    assert result == distribution.parse_distribution_file_ClearLinux(**test_input)

def test_parse_distribution_file_clear_linux_no_match():
    # Test against data from Linux Mint and CoreOS to ensure we do not get a reported
    # match from parse_distribution_file_ClearLinux()
    scenarios = [
        {
            # CoreOS
            'case': {
                'name': 'Clearlinux',
                'data': 'NAME=""Container Linux by CoreOS""\nID=coreos\nVERSION=1911.5.0\nVERSION_ID=1911.5.0\nBUILD_ID=2018-12-15-2317\nPRETTY_NAME=""Container L'
                        'inux by CoreOS 1911.5.0 (Rhyolite)""\nANSI_COLOR=""38;5;75""\nHOME_URL=""https://coreos.com/""\nBUG_REPORT_URL=""https://issues.coreos.com""'
                        '\nCOREOS_BOARD=""amd64-usr""',
                'path': '/usr/lib/os-release',
                'collected_facts': None,
            },
            'result': (False, {}),
        },
        {
            # Linux Mint
            'case': {
                'name': 'Clearlinux',
                'data': 'NAME=""Linux Mint""\nVERSION=""19.1 (Tessa)""\nID=linuxmint\nID_LIKE=ubuntu\nPRETTY_NAME=""Linux Mint 19.1""\nVERSION_ID=""19.1""\nHOME_URL=""h'
                        'ttps://www.linuxmint.com/""\nSUPPORT_URL=""https://forums.ubuntu.com/""\nBUG_REPORT_URL=""http://linuxmint-troubleshooting-guide.readthedo'
                        'cs.io/en/latest/""\nPRIVACY_POLICY_URL=""https://www.linuxmint.com/""\nVERSION_CODENAME=tessa\nUBUNTU_CODENAME=bionic',
                'path': '/usr/lib/os-release',
                'collected_facts': None,
            },
            'result': (False, {}),
        },
    ]
    distribution = DistributionFiles(module=mock_module())
    for scenario in scenarios:
        assert scenario['result'] == distribution.parse_distribution_file_ClearLinux(**scenario['case'])"
-------------------------------------------------------------------------
"# -*- coding: utf-8 -*-
# Copyright (c) 2019 Ansible Project
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
from __future__ import absolute_import, division, print_function
__metaclass__ = type
from ansible.compat.tests.mock import Mock
from ansible.module_utils.facts.system.distribution import DistributionFiles
def mock_module():
    mock_module = Mock()
    mock_module.params = {'gather_subset': ['all'],
                          'gather_timeout': 5,
                          'filter': '*'}
    mock_module.get_bin_path = Mock(return_value=None)
    return mock_module
def test_parse_distribution_file_clear_linux():
    test_input = {
        'name': 'Clearlinux',
        'data': 'NAME=""Clear Linux OS""\nVERSION=1\nID=clear-linux-os\nID_LIKE=clear-linux-os\nVERSION_ID=28120\nPRETTY_NAME=""Clear Linux OS""\nANSI_COLOR=""1;35""'
                '\nHOME_URL=""https://clearlinux.org""\nSUPPORT_URL=""https://clearlinux.org""\nBUG_REPORT_URL=""mailto:dev@lists.clearlinux.org""',
        'path': '/usr/lib/os-release',
        'collected_facts': None,
    }
    result = (
        True,
        {
            'distribution': 'Clear Linux OS',
            'distribution_major_version': '28120',
            'distribution_release': 'clear-linux-os',
            'distribution_version': '28120'
        }
    )
    distribution = DistributionFiles(module=mock_module())
    assert result == distribution.parse_distribution_file_ClearLinux(**test_input)
def test_parse_distribution_file_clear_linux_no_match():
    # Test against data from Linux Mint and CoreOS to ensure we do not get a reported
    # match from parse_distribution_file_ClearLinux()
    scenarios = [
        {
            # CoreOS
            'case': {
                'name': 'Clearlinux',
                'data': 'NAME=""Container Linux by CoreOS""\nID=coreos\nVERSION=1911.5.0\nVERSION_ID=1911.5.0\nBUILD_ID=2018-12-15-2317\nPRETTY_NAME=""Container L'
                        'inux by CoreOS 1911.5.0 (Rhyolite)""\nANSI_COLOR=""38;5;75""\nHOME_URL=""https://coreos.com/""\nBUG_REPORT_URL=""https://issues.coreos.com""'
                        '\nCOREOS_BOARD=""amd64-usr""',
                'path': '/usr/lib/os-release',
                'collected_facts': None,
            },
            'result': (False, {}),
        },
        {
            # Linux Mint
            'case': {
                'name': 'Clearlinux',
                'data': 'NAME=""Linux Mint""\nVERSION=""19.1 (Tessa)""\nID=linuxmint\nID_LIKE=ubuntu\nPRETTY_NAME=""Linux Mint 19.1""\nVERSION_ID=""19.1""\nHOME_URL=""h'
                        'ttps://www.linuxmint.com/""\nSUPPORT_URL=""https://forums.ubuntu.com/""\nBUG_REPORT_URL=""http://linuxmint-troubleshooting-guide.readthedo'
                        'cs.io/en/latest/""\nPRIVACY_POLICY_URL=""https://www.linuxmint.com/""\nVERSION_CODENAME=tessa\nUBUNTU_CODENAME=bionic',
                'path': '/usr/lib/os-release',
                'collected_facts': None,
            },
            'result': (False, {}),
        },
    ]
    distribution = DistributionFiles(module=mock_module())
    for scenario in scenarios:
        assert scenario['result'] == distribution.parse_distribution_file_ClearLinux(**scenario['case'])
"
-------------------------------------------------------------------------
"Recom
PRs: 53298, 53541"
-------------------------------------------------------------------------
=========================================================================
"kind: ssh
"
-------------------------------------------------------------------------
"if mod_params.pop('kind') == 'ssh':
        if mod_params.get('vault_password'):
            arguments['kind'] = 'vault'
        else:
            arguments['kind'] = 'ssh'"
-------------------------------------------------------------------------
"kind: ssh
me: Create a valid SCM credential from a private_key file
wer_credential:
name: SCM Credential
organization: Default
state: present
kind: scm
username: joe
password: secret
ssh_key_data: ""{{ lookup('file', '/tmp/id_rsa') }}""
ssh_key_unlock: ""passphrase""
me: Add Credential Into Tower
wer_credential:
name: Workshop Credential
ssh_key_data: ""/home/{{ansible_user}}/.ssh/aws-private.pem""
kind: ssh
organization: Default
tower_username: admin
tower_password: ansible
tower_host: https://localhost
n_once: true
legate_to: localhost
"
-------------------------------------------------------------------------
"Recom
PRs: 47224, 53411"
-------------------------------------------------------------------------
=========================================================================
"- This is only used by the C(selfsigned) provider.
"
-------------------------------------------------------------------------
"def _validate_privatekey(self):
        if self.privatekey_path:
            ctx = OpenSSL.SSL.Context(OpenSSL.SSL.TLSv1_2_METHOD)
            ctx.use_privatekey(self.privatekey)
            ctx.use_certificate(self.cert)
            try:
                ctx.check_privatekey()
                return True
            except OpenSSL.SSL.Error:
                return False"
-------------------------------------------------------------------------
"- This is only used by the C(assertonly) provider.
- This is only used by the C(assertonly) provider.
"
-------------------------------------------------------------------------
"Recom
PRs: 53208, 53283"
-------------------------------------------------------------------------
=========================================================================
"- This is only used by the C(selfsigned) provider.
"
-------------------------------------------------------------------------
"self.notBefore = module.params.get('selfsigned_not_before')
        self.notAfter = module.params.get('selfsigned_not_after')
        self.digest = module.params.get('selfsigned_digest')
        self.version = module.params.get('selfsigned_version')"
-------------------------------------------------------------------------
"- This is only used by the C(assertonly) provider.
- This is only used by the C(assertonly) provider.
"
-------------------------------------------------------------------------
"Recom
PRs: 53208, 53283"
-------------------------------------------------------------------------
=========================================================================
"- This is only used by the C(selfsigned) provider.
"
-------------------------------------------------------------------------
"self.registry_path = module.params['registry_path']

        if provider == 'selfsigned':
            certificate = SelfSignedCertificate(module)
            certificate.registry_path = self.registry_path

""Target method"" :        
   if provider == 'selfsigned':
        self.registry_path = module.params['registry_path']
        certificate = SelfSignedCertificate(module)
        certificate.registry_path = self.registry_path"
-------------------------------------------------------------------------
"- This is only used by the C(assertonly) provider.
- This is only used by the C(assertonly) provider.
"
-------------------------------------------------------------------------
"Recom
PRs: 53208, 53283"
-------------------------------------------------------------------------
=========================================================================
"- This is only used by the C(selfsigned) provider.
"
-------------------------------------------------------------------------
"csr = crypto_utils.load_certificate_request(self.csr_path) if self.provider == 'selfsigned' else None

        if 'privatekey_path' in module.params:
            privatekey_path = module.params['privatekey_path'] if self.provider == 'selfsigned' else None

        if 'privatekey_passphrase' in module.params:
            privatekey_passphrase = module.params['privatekey_passphrase'] if self.provider == 'selfsigned' else None"
-------------------------------------------------------------------------
"- This is only used by the C(assertonly) provider.
"
-------------------------------------------------------------------------
"Recom
PRs: 53208, 53283"
-------------------------------------------------------------------------
=========================================================================
"- This is only used by the C(ownca) provider.
- This is only used by the C(ownca) provider.
- This is only used by the C(ownca) provider.
- This is only used by the C(ownca) provider.
"
-------------------------------------------------------------------------
"ownca_digest = module.params['ownca_digest'] # This is only used by the C(ownca) provider.
        ownca_version = module.params['ownca_version'] # This is only used by the C(ownca) provider.
        ownca_not_before = module.params['ownca_not_before'] # This is only used by the C(ownca) provider.
        ownca_not_after = module.params['ownca_not_after'] # This is only used by the C(ownca) provider."
-------------------------------------------------------------------------
"- This is only used by the C(assertonly) provider.
- This is only used by the C(assertonly) provider.
"
-------------------------------------------------------------------------
"Recom
PRs: 53208, 53283"
-------------------------------------------------------------------------
=========================================================================
"if module.check_mode:
    if os.path.exists(tmpsrc):
        os.remove(tmpsrc)
    result['changed'] = ('checksum_dest' not in result or
                         result['checksum_src'] != result['checksum_dest'])
    module.exit_json(msg=info.get('msg', ''), **result)
"
-------------------------------------------------------------------------
"if module.check_mode:
    if os.path.exists(tmpsrc):
        os.remove(tmpsrc)
    changed = ('checksum_dest' not in res_args or res_args['checksum_src'] != res_args['checksum_dest'])
    res_args['changed'] = changed
    module.exit_json(msg=info.get('msg', ''), **res_args)"
-------------------------------------------------------------------------
"if module.check_mode:
    if os.path.exists(tmpsrc):
        os.remove(tmpsrc)
    changed = (checksum_dest is None or
               checksum_src != checksum_dest)
    res_args = dict(url=url, changed=changed, dest=dest, src=tmpsrc,
                    checksum_dest=checksum_dest, checksum_src=checksum_src,
                    msg=info.get('msg', ''))
    module.exit_json(**res_args)
"
-------------------------------------------------------------------------
"Recom
PRs: 53070, 53172"
-------------------------------------------------------------------------
=========================================================================
"- name: Add a new VLAN pool range
  aci_encap_pool_range:
    pool_allocation_mode: static
    range_name: anstest
    range_start: 20
    range_end: 40
    allocation_mode: inherit
- name: Remove a VLAN pool range
  aci_encap_pool_range:
    pool_allocation_mode: static
    range_name: anstest
    range_start: 20
    range_end: 40
  aci_encap_pool_range:
    pool_allocation_mode: static
    range_name: anstest
    range_start: 20
    range_end: 50
- name: Query a VLAN pool for ranges by range_name
  aci_encap_pool_range:
    host: apic
    username: admin
    password: SomeSecretPassword
    pool_type: vlan
    range_name: anstest
    state: query
  delegate_to: localhost
  register: query_result
- name: Query a VLAN pool for ranges by range_start
  aci_encap_pool_range:
    host: apic
    username: admin
    password: SomeSecretPassword
    pool_type: vlan
    range_start: 20
    state: query
  delegate_to: localhost
  register: query_result
- name: Query a VLAN pool for ranges by range_start and range_end
  aci_encap_pool_range:
    range_start: 20
    range_end: 40
- name: Query all VLAN pool ranges
  aci_encap_pool_range:
"
-------------------------------------------------------------------------
"- name: Add a new VLAN pool range
  aci_encap_pool_range:
    pool_allocation_mode: static
    range_name: anstest
    range_start: 20
    range_end: 40
    allocation_mode: inherit
  delegate_to: localhost

- name: Remove a VLAN pool range
  aci_encap_pool_range:
    pool_allocation_mode: static
    range_name: anstest
    range_start: 20
    range_end: 50
  delegate_to: localhost

- name: Query a VLAN pool for ranges by range_name
  aci_encap_pool_range:
    host: apic
    username: admin
    password: SomeSecretPassword
    pool_type: vlan
    range_name: anstest
    state: query
  delegate_to: localhost
  register: query_result

- name: Query a VLAN pool for ranges by range_start
  aci_encap_pool_range:
    host: apic
    username: admin
    password: SomeSecretPassword
    pool_type: vlan
    range_start: 20
    state: query
  delegate_to: localhost
  register: query_result

- name: Query a VLAN pool for ranges by range_start and range_end
  aci_encap_pool_range:
    range_start: 20
    range_end: 40
  delegate_to: localhost

- name: Query all VLAN pool ranges
  aci_encap_pool_range:"
-------------------------------------------------------------------------
"- name: Add a new VLAN pool range
  aci_encap_pool_range:
    pool_allocation_mode: static
    range_name: anstest
    range_start: 20
    range_end: 40
    allocation_mode: inherit
- name: Remove a VLAN pool range
  aci_encap_pool_range:
    pool_allocation_mode: static
    range_name: anstest
    range_start: 20
    range_end: 40
- name: Query a VLAN range
  aci_encap_pool_range:
    pool_allocation_mode: static
    range_name: anstest
    range_start: 20
    range_end: 50
- name: Query a VLAN pool for ranges by range_name
  aci_encap_pool_range:
    host: apic
    username: admin
    password: SomeSecretPassword
    pool_type: vlan
    range_name: anstest
    state: query
  delegate_to: localhost
  register: query_result
- name: Query a VLAN pool for ranges by range_start
  aci_encap_pool_range:
    host: apic
    username: admin
    password: SomeSecretPassword
    pool_type: vlan
    range_start: 20
    state: query
  delegate_to: localhost
  register: query_result
- name: Query a VLAN pool for ranges by range_start and range_end
  aci_encap_pool_range:
    range_start: 20
    range_end: 40
- name: Query all VLAN pool ranges
  aci_encap_pool_range:
"
-------------------------------------------------------------------------
"Recom
PRs: 52958, 52965"
-------------------------------------------------------------------------
=========================================================================
"- name: Add a new VLAN pool range
  aci_encap_pool_range:
    pool_allocation_mode: static
    range_name: anstest
    range_start: 20
    range_end: 40
    allocation_mode: inherit
- name: Remove a VLAN pool range
  aci_encap_pool_range:
    pool_allocation_mode: static
    range_name: anstest
    range_start: 20
    range_end: 40
  aci_encap_pool_range:
    pool_allocation_mode: static
    range_name: anstest
    range_start: 20
    range_end: 50
- name: Query a VLAN pool for ranges by range_name
  aci_encap_pool_range:
    host: apic
    username: admin
    password: SomeSecretPassword
    pool_type: vlan
    range_name: anstest
    state: query
  delegate_to: localhost
  register: query_result
- name: Query a VLAN pool for ranges by range_start
  aci_encap_pool_range:
    host: apic
    username: admin
    password: SomeSecretPassword
    pool_type: vlan
    range_start: 20
    state: query
  delegate_to: localhost
  register: query_result
- name: Query a VLAN pool for ranges by range_start and range_end
  aci_encap_pool_range:
    range_start: 20
    range_end: 40
- name: Query all VLAN pool ranges
  aci_encap_pool_range:
"
-------------------------------------------------------------------------
"- name: Add a new vlan range
  aci_encap_pool_range:
    pool_allocation_mode: static
    range_name: anstest
    range_start: 20
    range_end: 40
    pool_type: vlan
    allocation_mode: inherit
- name: Remove a vlan range
  aci_encap_pool_range:
    pool_allocation_mode: static
    range_name: anstest
    range_start: 20
    range_end: 50
    pool_type: vlan
- name: Query a vlan range
  aci_encap_pool_range:
    host: apic
    username: admin
    password: SomeSecretPassword
    pool_type: vlan
    range_name: anstest
    state: query
  delegate_to: localhost
  register: query_result
- name: Query a vlan range
  aci_encap_pool_range:
    host: apic
    username: admin
    password: SomeSecretPassword
    pool_type: vlan
    range_start: 20
    state: query
  delegate_to: localhost
  register: query_result
- name: Query a vlan range
  aci_encap_pool_range:
    range_start: 20
    range_end: 40
    pool_type: vlan
- name: Query all vlan ranges
  aci_encap_pool_range:
    pool_type: vlan"
-------------------------------------------------------------------------
"- name: Add a new VLAN pool range
  aci_encap_pool_range:
    pool_allocation_mode: static
    range_name: anstest
    range_start: 20
    range_end: 40
    allocation_mode: inherit
- name: Remove a VLAN pool range
  aci_encap_pool_range:
    pool_allocation_mode: static
    range_name: anstest
    range_start: 20
    range_end: 40
- name: Query a VLAN range
  aci_encap_pool_range:
    pool_allocation_mode: static
    range_name: anstest
    range_start: 20
    range_end: 50
- name: Query a VLAN pool for ranges by range_name
  aci_encap_pool_range:
    host: apic
    username: admin
    password: SomeSecretPassword
    pool_type: vlan
    range_name: anstest
    state: query
  delegate_to: localhost
  register: query_result
- name: Query a VLAN pool for ranges by range_start
  aci_encap_pool_range:
    host: apic
    username: admin
    password: SomeSecretPassword
    pool_type: vlan
    range_start: 20
    state: query
  delegate_to: localhost
  register: query_result
- name: Query a VLAN pool for ranges by range_start and range_end
  aci_encap_pool_range:
    range_start: 20
    range_end: 40
- name: Query all VLAN pool ranges
  aci_encap_pool_range:
"
-------------------------------------------------------------------------
"Recom
PRs: 52958, 52963"
-------------------------------------------------------------------------
=========================================================================
"'size': locale.atof(parts[1]),
"
-------------------------------------------------------------------------
"'size': int(decimal_point.match(parts[1]).group(1)),"
-------------------------------------------------------------------------
"'size': float(parts[1]),
"
-------------------------------------------------------------------------
"Recom
PRs: 36811, 52836"
-------------------------------------------------------------------------
=========================================================================
"'size': locale.atof(parts[1]),
'free': locale.atof(parts[2]),
'ext_size': locale.atof(parts[3])
"
-------------------------------------------------------------------------
"'size': float(parts[1]),
'free': float(parts[2]),
'ext_size': float(parts[3])"
-------------------------------------------------------------------------
"'size': float(parts[1]),
'free': float(parts[2]),
'ext_size': float(parts[3])
"
-------------------------------------------------------------------------
"Recom
PRs: 36811, 52836"
-------------------------------------------------------------------------
=========================================================================
"if locale.atof(size) > this_lv['size']:
elif shrink and locale.atof(size) < this_lv['size']:
    if locale.atof(size) == 0:
"
-------------------------------------------------------------------------
"if float(size) > this_lv['size']:
    elif shrink and float(size) < this_lv['size']:
        if float(size) == 0:"
-------------------------------------------------------------------------
"if float(size) > this_lv['size']:
elif shrink and float(size) < this_lv['size']:
    if float(size) == 0:
"
-------------------------------------------------------------------------
"Recom
PRs: 36811, 52836"
-------------------------------------------------------------------------
=========================================================================
"-  For rebooting systems, use the M(reboot) or M(win_reboot) module.
"
-------------------------------------------------------------------------
"from ansible.module_utils.basic import AnsibleModule

def check_command(module, commandline):
    commands = {'reboot': 'reboot or win_reboot'}
    command = os.path.basename(commandline[0]) if isinstance(commandline, list) else os.path.basename(commandline.split()[0])
    
    if command in commands:
        msg = ""Consider using the {} module rather than running {}.  "" + disable_suffix
        substitutions['mod'] = commands[command]
        module.warn(msg.format(**substitutions))"
-------------------------------------------------------------------------
"-  For rebooting systems, use the M(reboot) or M(win_reboot) module.
lso:
dule: raw
dule: script
dule: shell
dule: win_command
"
-------------------------------------------------------------------------
"Recom
PRs: 51499, 52192"
-------------------------------------------------------------------------
=========================================================================
"if params['direction'] not in ['outgoing', 'incoming', 'routed']:
    module.fail_json(msg='For default, direction must be one of ""outgoing"", ""incoming"" and ""routed"".')
"
-------------------------------------------------------------------------
"if params['direction'] not in ['outgoing', 'incoming', 'routed']:
    module.fail_json(msg='For default, direction must be one of ""outgoing"", ""incoming"" and ""routed"".')"
-------------------------------------------------------------------------
"if params['direction'] not in ['outgoing', 'incoming', 'routed']:
    module.fail_json(msg='For default, direction must be one of ""outgoing"", ""incoming"" and ""routed"".')
if params['direction'] not in ['in', 'out', None]:
    module.fail_json(msg='For rules, direction must be one of ""in"" and ""out"".')
"
-------------------------------------------------------------------------
"Recom
PRs: 50402, 52027"
-------------------------------------------------------------------------
=========================================================================
"altnames = [altname.strip() for altname in str(altnames_ext).split(',') if altname.strip()]
"
-------------------------------------------------------------------------
"altnames = [altname.strip() for altname in str(altnames_ext).split(',') if altname.strip()]"
-------------------------------------------------------------------------
"altnames = [altname.strip() for altname in str(altnames_ext).split(',') if altname.strip() if altname.strip()]
"
-------------------------------------------------------------------------
"Recom
PRs: 51473, 52024"
-------------------------------------------------------------------------
=========================================================================
"res = re.match(""""""GRANT (.) ON (.) TO (['`""]).*\\3@(['`""]).*\\4( IDENTIFIED BY PASSWORD (['`""]).\5)? ?(.*)"""""", grant[0])
if ""WITH GRANT OPTION"" in res.group(7):
if ""REQUIRE SSL"" in res.group(7):
"
-------------------------------------------------------------------------
"res = re.match(""GRANT (.+) ON (.+) TO (['`']).*\\3@(['`']).*\\4( IDENTIFIED BY PASSWORD (['`']).\\5)? ?(.*)"", grant[0])
if ""WITH GRANT OPTION"" in res.group(7):
if ""REQUIRE SSL"" in res.group(7):"
-------------------------------------------------------------------------
"res = re.match(""""""GRANT (.) ON (.) TO (['`""]).*\\3@(['`""]).*\\4( IDENTIFIED BY PASSWORD (['`""]).\\6)? ?(.*)"""""", grant[0])
if ""WITH GRANT OPTION"" in res.group(7):
if ""REQUIRE SSL"" in res.group(7):
"
-------------------------------------------------------------------------
"Recom
PRs: 40092, 51910"
-------------------------------------------------------------------------
=========================================================================
"res = re.match(""""""GRANT (.) ON (.) TO (['`""]).*\\3@(['`""]).*\\4( IDENTIFIED BY PASSWORD (['`""]).\5)? ?(.*)"""""", grant[0])
if ""WITH GRANT OPTION"" in res.group(7):
if ""REQUIRE SSL"" in res.group(7):
"
-------------------------------------------------------------------------
"# Adapted statement
res = re.match(""GRANT (.+) ON (.+) TO '.*'@'.*'( IDENTIFIED BY PASSWORD '.+')? ?(.*)"", grant[0])
if ""WITH GRANT OPTION"" in res.group(4):
if ""REQUIRE SSL"" in res.group(4):"
-------------------------------------------------------------------------
"res = re.match(""""""GRANT (.) ON (.) TO (['`""]).*\\3@(['`""]).*\\4( IDENTIFIED BY PASSWORD (['`""]).\\6)? ?(.*)"""""", grant[0])
if ""WITH GRANT OPTION"" in res.group(7):
if ""REQUIRE SSL"" in res.group(7):
"
-------------------------------------------------------------------------
"Recom
PRs: 40092, 51909"
-------------------------------------------------------------------------
=========================================================================
"from ansible.errors import (
    AnsibleAuthenticationFailure,
    AnsibleConnectionFailure,
    AnsibleError,
    AnsibleFileNotFound,
)
"
-------------------------------------------------------------------------
"from ansible.errors import AnsibleAuthenticationFailure, AnsibleError, AnsibleFileNotFound"
-------------------------------------------------------------------------
"from ansible.errors import (
    AnsibleAuthenticationFailure,
    AnsibleConnectionFailure,
    AnsibleError,
    AnsibleFileNotFound,
)
from ansible.module_utils._text import to_bytes, to_native, to_text
"
-------------------------------------------------------------------------
"Recom
PRs: 50776, 51236"
-------------------------------------------------------------------------
=========================================================================
"remaining_retries = remaining_tries - attempt - 1
_handle_error(remaining_retries, cmd[0], return_tuple, self._play_context.no_log, self.host)
= Invalid/incorrect password from sshpass
pt AnsibleAuthenticationFailure as e:
# Raising this exception, which is subclassed from AnsibleConnectionFailure, prevents further retries
raise
"
-------------------------------------------------------------------------
"try:
    remaining_retries = remaining_tries - attempt - 1
    _handle_error(remaining_retries, cmd[0], return_tuple, self._play_context.no_log, self._play_context.remote_addr)
except AnsibleAuthenticationFailure as e:
    # Raising this exception, which is subclassed from AnsibleConnectionFailure, prevents further retries
    raise"
-------------------------------------------------------------------------
"remaining_retries = remaining_tries - attempt - 1
_handle_error(remaining_retries, cmd[0], return_tuple, self._play_context.no_log, self.host)
break
= Invalid/incorrect password from sshpass
pt AnsibleAuthenticationFailure as e:
# Raising this exception, which is subclassed from AnsibleConnectionFailure, prevents further retries
raise
"
-------------------------------------------------------------------------
"Recom
PRs: 50776, 51236"
-------------------------------------------------------------------------
=========================================================================
"from ansible.errors import (
    AnsibleAuthenticationFailure,
    AnsibleConnectionFailure,
    AnsibleError,
    AnsibleFileNotFound,
)
"
-------------------------------------------------------------------------
"from ansible.errors import (
    AnsibleAuthenticationFailure,
    AnsibleError,
    AnsibleFileNotFound,
)"
-------------------------------------------------------------------------
"from ansible.errors import (
    AnsibleAuthenticationFailure,
    AnsibleConnectionFailure,
    AnsibleError,
    AnsibleFileNotFound,
)
from ansible.module_utils._text import to_bytes, to_native, to_text
"
-------------------------------------------------------------------------
"Recom
PRs: 50776, 51235"
-------------------------------------------------------------------------
=========================================================================
"if not differences.empty and self.parameters.force:
"
-------------------------------------------------------------------------
if differences and self.parameters.force:
-------------------------------------------------------------------------
"if differences and self.parameters.force:
"
-------------------------------------------------------------------------
"Recom
PRs: 50663, 50821"
-------------------------------------------------------------------------
=========================================================================
"if not differences.empty and self.parameters.force:
"
-------------------------------------------------------------------------
if differences and self.parameters.force:
-------------------------------------------------------------------------
"if differences and self.parameters.force:
"
-------------------------------------------------------------------------
"Recom
PRs: 50663, 50820"
-------------------------------------------------------------------------
=========================================================================
"# Copyright (c) 2018 Cisco and/or its affiliates.
#
# This file is part of Ansible
#
# Ansible is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Ansible is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
#
from __future__ import absolute_import
import copy
import json
import unittest
import pytest
from units.compat import mock
from ansible.module_utils.network.ftd.common import FtdServerError, HTTPMethod, ResponseParams, FtdConfigurationError
from ansible.module_utils.network.ftd.configuration import DUPLICATE_NAME_ERROR_MESSAGE, UNPROCESSABLE_ENTITY_STATUS, \
    MULTIPLE_DUPLICATES_FOUND_ERROR, BaseConfigurationResource, FtdInvalidOperationNameError, QueryParams
from ansible.module_utils.network.ftd.fdm_swagger_client import ValidationError
ADD_RESPONSE = {'status': 'Object added'}
EDIT_RESPONSE = {'status': 'Object edited'}
DELETE_RESPONSE = {'status': 'Object deleted'}
GET_BY_FILTER_RESPONSE = [{'name': 'foo', 'description': 'bar'}]
ARBITRARY_RESPONSE = {'status': 'Arbitrary request sent'}
class TestUpsertOperationUnitTests(unittest.TestCase):
    def setUp(self):
        conn = mock.MagicMock()
        self._resource = BaseConfigurationResource(conn)
    def test_get_operation_name(self):
        operation_a = mock.MagicMock()
        operation_b = mock.MagicMock()
        def checker_wrapper(expected_object):
            def checker(obj, *args, **kwargs):
                return obj == expected_object
            return checker
        operations = {
            operation_a: ""spec"",
            operation_b: ""spec""
        }
        assert operation_a == self._resource._get_operation_name(checker_wrapper(operation_a), operations)
        assert operation_b == self._resource._get_operation_name(checker_wrapper(operation_b), operations)
        self.assertRaises(
            FtdConfigurationError,
            self._resource._get_operation_name, checker_wrapper(None), operations
        )
    @mock.patch.object(BaseConfigurationResource, ""_get_operation_name"")
    @mock.patch.object(BaseConfigurationResource, ""add_object"")
    def test_add_upserted_object(self, add_object_mock, get_operation_mock):
        model_operations = mock.MagicMock()
        params = mock.MagicMock()
        add_op_name = get_operation_mock.return_value
        assert add_object_mock.return_value == self._resource._add_upserted_object(model_operations, params)
        get_operation_mock.assert_called_once_with(
            self._resource._operation_checker.is_add_operation,
            model_operations)
        add_object_mock.assert_called_once_with(add_op_name, params)
    @mock.patch.object(BaseConfigurationResource, ""_get_operation_name"")
    @mock.patch.object(BaseConfigurationResource, ""edit_object"")
    @mock.patch(""ansible.module_utils.network.ftd.configuration.copy_identity_properties"")
    @mock.patch(""ansible.module_utils.network.ftd.configuration._set_default"")
    def test_edit_upserted_object(self, _set_default_mock, copy_properties_mock, edit_object_mock, get_operation_mock):
        model_operations = mock.MagicMock()
        existing_object = mock.MagicMock()
        params = {
            'path_params': {},
            'data': {}
        }
        result = self._resource._edit_upserted_object(model_operations, existing_object, params)
        assert result == edit_object_mock.return_value
        _set_default_mock.assert_has_calls([
            mock.call(params, 'path_params', {}),
            mock.call(params, 'data', {})
        ])
        get_operation_mock.assert_called_once_with(
            self._resource._operation_checker.is_edit_operation,
            model_operations
        )
        copy_properties_mock.assert_called_once_with(
            existing_object,
            params['data']
        )
        edit_object_mock.assert_called_once_with(
            get_operation_mock.return_value,
            params
        )
    @mock.patch.object(BaseConfigurationResource, ""get_operation_specs_by_model_name"")
    @mock.patch(""ansible.module_utils.network.ftd.configuration.OperationChecker.is_upsert_operation_supported"")
    @mock.patch(""ansible.module_utils.network.ftd.configuration._extract_model_from_upsert_operation"")
    def test_is_upsert_operation_supported(self, extract_model_mock, is_upsert_supported_mock, get_operation_spec_mock):
        op_name = mock.MagicMock()
        result = self._resource.is_upsert_operation_supported(op_name)
        assert result == is_upsert_supported_mock.return_value
        extract_model_mock.assert_called_once_with(op_name)
        get_operation_spec_mock.assert_called_once_with(extract_model_mock.return_value)
        is_upsert_supported_mock.assert_called_once_with(get_operation_spec_mock.return_value)
    @mock.patch.object(BaseConfigurationResource, ""is_upsert_operation_supported"")
    @mock.patch.object(BaseConfigurationResource, ""get_operation_specs_by_model_name"")
    @mock.patch.object(BaseConfigurationResource, ""_add_upserted_object"")
    @mock.patch.object(BaseConfigurationResource, ""_edit_upserted_object"")
    @mock.patch(""ansible.module_utils.network.ftd.configuration._extract_model_from_upsert_operation"")
    def test_upsert_object_succesfully_added(self, extract_model_mock, edit_mock, add_mock, get_operation_mock,
                                             is_upsert_supported_mock):
        op_name = mock.MagicMock()
        params = mock.MagicMock()
        is_upsert_supported_mock.return_value = True
        result = self._resource.upsert_object(op_name, params)
        assert result == add_mock.return_value
        is_upsert_supported_mock.assert_called_once_with(op_name)
        extract_model_mock.assert_called_once_with(op_name)
        get_operation_mock.assert_called_once_with(extract_model_mock.return_value)
        add_mock.assert_called_once_with(get_operation_mock.return_value, params)
        edit_mock.assert_not_called()
    @mock.patch.object(BaseConfigurationResource, ""is_upsert_operation_supported"")
    @mock.patch.object(BaseConfigurationResource, ""get_operation_specs_by_model_name"")
    @mock.patch.object(BaseConfigurationResource, ""_add_upserted_object"")
    @mock.patch.object(BaseConfigurationResource, ""_edit_upserted_object"")
    @mock.patch(""ansible.module_utils.network.ftd.configuration._extract_model_from_upsert_operation"")
    def test_upsert_object_succesfully_edited(self, extract_model_mock, edit_mock, add_mock, get_operation_mock,
                                              is_upsert_supported_mock):
        op_name = mock.MagicMock()
        params = mock.MagicMock()
        is_upsert_supported_mock.return_value = True
        error = FtdConfigurationError(""Obj duplication error"")
        error.obj = mock.MagicMock()
        add_mock.side_effect = error
        result = self._resource.upsert_object(op_name, params)
        assert result == edit_mock.return_value
        is_upsert_supported_mock.assert_called_once_with(op_name)
        extract_model_mock.assert_called_once_with(op_name)
        get_operation_mock.assert_called_once_with(extract_model_mock.return_value)
        add_mock.assert_called_once_with(get_operation_mock.return_value, params)
        edit_mock.assert_called_once_with(get_operation_mock.return_value, error.obj, params)
    @mock.patch.object(BaseConfigurationResource, ""is_upsert_operation_supported"")
    @mock.patch.object(BaseConfigurationResource, ""get_operation_specs_by_model_name"")
    @mock.patch.object(BaseConfigurationResource, ""_add_upserted_object"")
    @mock.patch.object(BaseConfigurationResource, ""_edit_upserted_object"")
    @mock.patch(""ansible.module_utils.network.ftd.configuration._extract_model_from_upsert_operation"")
    def test_upsert_object_not_supported(self, extract_model_mock, edit_mock, add_mock, get_operation_mock,
                                         is_upsert_supported_mock):
        op_name = mock.MagicMock()
        params = mock.MagicMock()
        is_upsert_supported_mock.return_value = False
        self.assertRaises(
            FtdInvalidOperationNameError,
            self._resource.upsert_object, op_name, params
        )
        is_upsert_supported_mock.assert_called_once_with(op_name)
        extract_model_mock.assert_not_called()
        get_operation_mock.assert_not_called()
        add_mock.assert_not_called()
        edit_mock.assert_not_called()
    @mock.patch.object(BaseConfigurationResource, ""is_upsert_operation_supported"")
    @mock.patch.object(BaseConfigurationResource, ""get_operation_specs_by_model_name"")
    @mock.patch.object(BaseConfigurationResource, ""_add_upserted_object"")
    @mock.patch.object(BaseConfigurationResource, ""_edit_upserted_object"")
    @mock.patch(""ansible.module_utils.network.ftd.configuration._extract_model_from_upsert_operation"")
    def test_upsert_object_neither_added_nor_edited(self, extract_model_mock, edit_mock, add_mock, get_operation_mock,
                                                    is_upsert_supported_mock):
        op_name = mock.MagicMock()
        params = mock.MagicMock()
        is_upsert_supported_mock.return_value = True
        error = FtdConfigurationError(""Obj duplication error"")
        error.obj = mock.MagicMock()
        add_mock.side_effect = error
        edit_mock.side_effect = FtdConfigurationError(""Some object edit error"")
        self.assertRaises(
            FtdConfigurationError,
            self._resource.upsert_object, op_name, params
        )
        is_upsert_supported_mock.assert_called_once_with(op_name)
        extract_model_mock.assert_called_once_with(op_name)
        get_operation_mock.assert_called_once_with(extract_model_mock.return_value)
        add_mock.assert_called_once_with(get_operation_mock.return_value, params)
        edit_mock.assert_called_once_with(get_operation_mock.return_value, error.obj, params)
    @mock.patch.object(BaseConfigurationResource, ""is_upsert_operation_supported"")
    @mock.patch.object(BaseConfigurationResource, ""get_operation_specs_by_model_name"")
    @mock.patch.object(BaseConfigurationResource, ""_add_upserted_object"")
    @mock.patch.object(BaseConfigurationResource, ""_edit_upserted_object"")
    @mock.patch(""ansible.module_utils.network.ftd.configuration._extract_model_from_upsert_operation"")
    def test_upsert_object_with_fatal_error_during_add(self, extract_model_mock, edit_mock, add_mock,
                                                       get_operation_mock, is_upsert_supported_mock):
        op_name = mock.MagicMock()
        params = mock.MagicMock()
        is_upsert_supported_mock.return_value = True
        error = FtdConfigurationError(""Obj duplication error"")
        add_mock.side_effect = error
        self.assertRaises(
            FtdConfigurationError,
            self._resource.upsert_object, op_name, params
        )
        is_upsert_supported_mock.assert_called_once_with(op_name)
        extract_model_mock.assert_called_once_with(op_name)
        get_operation_mock.assert_called_once_with(extract_model_mock.return_value)
        add_mock.assert_called_once_with(get_operation_mock.return_value, params)
        edit_mock.assert_not_called()
# functional tests below
class TestUpsertOperationFunctionalTests(object):
    @pytest.fixture(autouse=True)
    def connection_mock(self, mocker):
        connection_class_mock = mocker.patch('ansible.modules.network.ftd.ftd_configuration.Connection')
        connection_instance = connection_class_mock.return_value
        connection_instance.validate_data.return_value = True, None
        connection_instance.validate_query_params.return_value = True, None
        connection_instance.validate_path_params.return_value = True, None
        return connection_instance
    def test_module_should_create_object_when_upsert_operation_and_object_does_not_exist(self, connection_mock):
        url = '/test'
        operations = {
            'getObjectList': {
                'method': HTTPMethod.GET,
                'url': url,
                'modelName': 'Object',
                'returnMultipleItems': True},
            'addObject': {
                'method': HTTPMethod.POST,
                'modelName': 'Object',
                'url': url},
            'editObject': {
                'method': HTTPMethod.PUT,
                'modelName': 'Object',
                'url': '/test/{objId}'},
            'otherObjectOperation': {
                'method': HTTPMethod.GET,
                'modelName': 'Object',
                'url': '/test/{objId}',
                'returnMultipleItems': False
            }
        }
        def get_operation_spec(name):
            return operations[name]
        connection_mock.get_operation_spec = get_operation_spec
        connection_mock.get_operation_specs_by_model_name.return_value = operations
        connection_mock.send_request.return_value = {
            ResponseParams.SUCCESS: True,
            ResponseParams.RESPONSE: ADD_RESPONSE
        }
        params = {
            'operation': 'upsertObject',
            'data': {'id': '123', 'name': 'testObject', 'type': 'object'},
            'path_params': {'objId': '123'},
            'register_as': 'test_var'
        }
        result = self._resource_execute_operation(params, connection=connection_mock)
        connection_mock.send_request.assert_called_once_with(url_path=url,
                                                             http_method=HTTPMethod.POST,
                                                             path_params=params['path_params'],
                                                             query_params={},
                                                             body_params=params['data'])
        assert ADD_RESPONSE == result
    # test when object exists but with different fields(except id)
    def test_module_should_update_object_when_upsert_operation_and_object_exists(self, connection_mock):
        url = '/test'
        obj_id = '456'
        version = 'test_version'
        url_with_id_templ = '{0}/{1}'.format(url, '{objId}')
        new_value = '0000'
        old_value = '1111'
        params = {
            'operation': 'upsertObject',
            'data': {'name': 'testObject', 'value': new_value, 'type': 'object'},
            'register_as': 'test_var'
        }
        def request_handler(url_path=None, http_method=None, body_params=None, path_params=None, query_params=None):
            if http_method == HTTPMethod.POST:
                assert url_path == url
                assert body_params == params['data']
                assert query_params == {}
                assert path_params == {}
                return {
                    ResponseParams.SUCCESS: False,
                    ResponseParams.RESPONSE: DUPLICATE_NAME_ERROR_MESSAGE,
                    ResponseParams.STATUS_CODE: UNPROCESSABLE_ENTITY_STATUS
                }
            elif http_method == HTTPMethod.GET:
                is_get_list_req = url_path == url
                is_get_req = url_path == url_with_id_templ
                assert is_get_req or is_get_list_req
                if is_get_list_req:
                    assert body_params == {}
                    assert query_params == {QueryParams.FILTER: 'name:testObject', 'limit': 10, 'offset': 0}
                    assert path_params == {}
                elif is_get_req:
                    assert body_params == {}
                    assert query_params == {}
                    assert path_params == {'objId': obj_id}
                return {
                    ResponseParams.SUCCESS: True,
                    ResponseParams.RESPONSE: {
                        'items': [
                            {'name': 'testObject', 'value': old_value, 'type': 'object', 'id': obj_id,
                             'version': version}
                        ]
                    }
                }
            elif http_method == HTTPMethod.PUT:
                assert url_path == url_with_id_templ
                return {
                    ResponseParams.SUCCESS: True,
                    ResponseParams.RESPONSE: body_params
                }
            else:
                assert False
        operations = {
            'getObjectList': {'method': HTTPMethod.GET, 'url': url, 'modelName': 'Object', 'returnMultipleItems': True},
            'addObject': {'method': HTTPMethod.POST, 'modelName': 'Object', 'url': url},
            'editObject': {'method': HTTPMethod.PUT, 'modelName': 'Object', 'url': url_with_id_templ},
            'otherObjectOperation': {
                'method': HTTPMethod.GET,
                'modelName': 'Object',
                'url': url_with_id_templ,
                'returnMultipleItems': False}
        }
        def get_operation_spec(name):
            return operations[name]
        connection_mock.get_operation_spec = get_operation_spec
        connection_mock.get_operation_specs_by_model_name.return_value = operations
        connection_mock.send_request = request_handler
        expected_val = {'name': 'testObject', 'value': new_value, 'type': 'object', 'id': obj_id, 'version': version}
        result = self._resource_execute_operation(params, connection=connection_mock)
        assert expected_val == result
    # test when object exists and all fields have the same value
    def test_module_should_not_update_object_when_upsert_operation_and_object_exists_with_the_same_fields(
            self, connection_mock):
        url = '/test'
        url_with_id_templ = '{0}/{1}'.format(url, '{objId}')
        params = {
            'operation': 'upsertObject',
            'data': {'name': 'testObject', 'value': '3333', 'type': 'object'},
            'register_as': 'test_var'
        }
        expected_val = copy.deepcopy(params['data'])
        expected_val['version'] = 'test_version'
        expected_val['id'] = 'test_id'
        def request_handler(url_path=None, http_method=None, body_params=None, path_params=None, query_params=None):
            if http_method == HTTPMethod.POST:
                assert url_path == url
                assert body_params == params['data']
                assert query_params == {}
                assert path_params == {}
                return {
                    ResponseParams.SUCCESS: False,
                    ResponseParams.RESPONSE: DUPLICATE_NAME_ERROR_MESSAGE,
                    ResponseParams.STATUS_CODE: UNPROCESSABLE_ENTITY_STATUS
                }
            elif http_method == HTTPMethod.GET:
                assert url_path == url
                assert body_params == {}
                assert query_params == {QueryParams.FILTER: 'name:testObject', 'limit': 10, 'offset': 0}
                assert path_params == {}
                return {
                    ResponseParams.SUCCESS: True,
                    ResponseParams.RESPONSE: {
                        'items': [expected_val]
                    }
                }
            else:
                assert False
        operations = {
            'getObjectList': {'method': HTTPMethod.GET, 'modelName': 'Object', 'url': url, 'returnMultipleItems': True},
            'addObject': {'method': HTTPMethod.POST, 'modelName': 'Object', 'url': url},
            'editObject': {'method': HTTPMethod.PUT, 'modelName': 'Object', 'url': url_with_id_templ},
            'otherObjectOperation': {
                'method': HTTPMethod.GET,
                'modelName': 'Object',
                'url': url_with_id_templ,
                'returnMultipleItems': False}
        }
        def get_operation_spec(name):
            return operations[name]
        connection_mock.get_operation_spec = get_operation_spec
        connection_mock.get_operation_specs_by_model_name.return_value = operations
        connection_mock.send_request = request_handler
        result = self._resource_execute_operation(params, connection=connection_mock)
        assert expected_val == result
    def test_module_should_fail_when_upsert_operation_is_not_supported(self, connection_mock):
        connection_mock.get_operation_specs_by_model_name.return_value = {
            'addObject': {'method': HTTPMethod.POST, 'modelName': 'Object', 'url': '/test'},
            'editObject': {'method': HTTPMethod.PUT, 'modelName': 'Object', 'url': '/test/{objId}'},
            'otherObjectOperation': {
                'method': HTTPMethod.GET,
                'modelName': 'Object',
                'url': '/test/{objId}',
                'returnMultipleItems': False}
        }
        operation_name = 'upsertObject'
        params = {
            'operation': operation_name,
            'data': {'id': '123', 'name': 'testObject', 'type': 'object'},
            'path_params': {'objId': '123'},
            'register_as': 'test_var'
        }
        result = self._resource_execute_operation_with_expected_failure(
            expected_exception_class=FtdInvalidOperationNameError,
            params=params, connection=connection_mock)
        connection_mock.send_request.assert_not_called()
        assert operation_name == result.operation_name
    # when create operation raised FtdConfigurationError exception without id and version
    def test_module_should_fail_when_upsert_operation_and_failed_create_without_id_and_version(self, connection_mock):
        url = '/test'
        url_with_id_templ = '{0}/{1}'.format(url, '{objId}')
        params = {
            'operation': 'upsertObject',
            'data': {'name': 'testObject', 'value': '3333', 'type': 'object'},
            'register_as': 'test_var'
        }
        def request_handler(url_path=None, http_method=None, body_params=None, path_params=None, query_params=None):
            if http_method == HTTPMethod.POST:
                assert url_path == url
                assert body_params == params['data']
                assert query_params == {}
                assert path_params == {}
                return {
                    ResponseParams.SUCCESS: False,
                    ResponseParams.RESPONSE: DUPLICATE_NAME_ERROR_MESSAGE,
                    ResponseParams.STATUS_CODE: UNPROCESSABLE_ENTITY_STATUS
                }
            elif http_method == HTTPMethod.GET:
                assert url_path == url
                assert body_params == {}
                assert query_params == {QueryParams.FILTER: 'name:testObject', 'limit': 10, 'offset': 0}
                assert path_params == {}
                return {
                    ResponseParams.SUCCESS: True,
                    ResponseParams.RESPONSE: {
                        'items': []
                    }
                }
            else:
                assert False
        operations = {
            'getObjectList': {'method': HTTPMethod.GET, 'modelName': 'Object', 'url': url, 'returnMultipleItems': True},
            'addObject': {'method': HTTPMethod.POST, 'modelName': 'Object', 'url': url},
            'editObject': {'method': HTTPMethod.PUT, 'modelName': 'Object', 'url': url_with_id_templ},
            'otherObjectOperation': {
                'method': HTTPMethod.GET,
                'modelName': 'Object',
                'url': url_with_id_templ,
                'returnMultipleItems': False}
        }
        def get_operation_spec(name):
            return operations[name]
        connection_mock.get_operation_spec = get_operation_spec
        connection_mock.get_operation_specs_by_model_name.return_value = operations
        connection_mock.send_request = request_handler
        result = self._resource_execute_operation_with_expected_failure(
            expected_exception_class=FtdServerError,
            params=params, connection=connection_mock)
        assert result.code == 422
        assert result.response == 'Validation failed due to a duplicate name'
    def test_module_should_fail_when_upsert_operation_and_failed_update_operation(self, connection_mock):
        url = '/test'
        obj_id = '456'
        version = 'test_version'
        url_with_id_templ = '{0}/{1}'.format(url, '{objId}')
        error_code = 404
        new_value = '0000'
        old_value = '1111'
        params = {
            'operation': 'upsertObject',
            'data': {'name': 'testObject', 'value': new_value, 'type': 'object'},
            'register_as': 'test_var'
        }
        error_msg = 'test error'
        def request_handler(url_path=None, http_method=None, body_params=None, path_params=None, query_params=None):
            if http_method == HTTPMethod.POST:
                assert url_path == url
                assert body_params == params['data']
                assert query_params == {}
                assert path_params == {}
                return {
                    ResponseParams.SUCCESS: False,
                    ResponseParams.RESPONSE: DUPLICATE_NAME_ERROR_MESSAGE,
                    ResponseParams.STATUS_CODE: UNPROCESSABLE_ENTITY_STATUS
                }
            elif http_method == HTTPMethod.GET:
                is_get_list_req = url_path == url
                is_get_req = url_path == url_with_id_templ
                assert is_get_req or is_get_list_req
                if is_get_list_req:
                    assert body_params == {}
                    assert query_params == {QueryParams.FILTER: 'name:testObject', 'limit': 10, 'offset': 0}
                elif is_get_req:
                    assert body_params == {}
                    assert query_params == {}
                    assert path_params == {'objId': obj_id}
                return {
                    ResponseParams.SUCCESS: True,
                    ResponseParams.RESPONSE: {
                        'items': [
                            {'name': 'testObject', 'value': old_value, 'type': 'object', 'id': obj_id,
                             'version': version}
                        ]
                    }
                }
            elif http_method == HTTPMethod.PUT:
                assert url_path == url_with_id_templ
                raise FtdServerError(error_msg, error_code)
            else:
                assert False
        operations = {
            'getObjectList': {'method': HTTPMethod.GET, 'modelName': 'Object', 'url': url, 'returnMultipleItems': True},
            'addObject': {'method': HTTPMethod.POST, 'modelName': 'Object', 'url': url},
            'editObject': {'method': HTTPMethod.PUT, 'modelName': 'Object', 'url': url_with_id_templ},
            'otherObjectOperation': {
                'method': HTTPMethod.GET,
                'modelName': 'Object',
                'url': url_with_id_templ,
                'returnMultipleItems': False}
        }
        def get_operation_spec(name):
            return operations[name]
        connection_mock.get_operation_spec = get_operation_spec
        connection_mock.get_operation_specs_by_model_name.return_value = operations
        connection_mock.send_request = request_handler
        result = self._resource_execute_operation_with_expected_failure(
            expected_exception_class=FtdServerError,
            params=params, connection=connection_mock)
        assert result.code == error_code
        assert result.response == error_msg
    def test_module_should_fail_when_upsert_operation_and_invalid_data_for_create_operation(self, connection_mock):
        new_value = '0000'
        params = {
            'operation': 'upsertObject',
            'data': {'name': 'testObject', 'value': new_value, 'type': 'object'},
            'register_as': 'test_var'
        }
        connection_mock.send_request.assert_not_called()
        operations = {
            'getObjectList': {
                'method': HTTPMethod.GET,
                'modelName': 'Object',
                'url': 'sd',
                'returnMultipleItems': True},
            'addObject': {'method': HTTPMethod.POST, 'modelName': 'Object', 'url': 'sdf'},
            'editObject': {'method': HTTPMethod.PUT, 'modelName': 'Object', 'url': 'sadf'},
            'otherObjectOperation': {
                'method': HTTPMethod.GET,
                'modelName': 'Object',
                'url': 'sdfs',
                'returnMultipleItems': False}
        }
        def get_operation_spec(name):
            return operations[name]
        connection_mock.get_operation_spec = get_operation_spec
        connection_mock.get_operation_specs_by_model_name.return_value = operations
        report = {
            'required': ['objects[0].type'],
            'invalid_type': [
                {
                    'path': 'objects[3].id',
                    'expected_type': 'string',
                    'actually_value': 1
                }
            ]
        }
        connection_mock.validate_data.return_value = (False, json.dumps(report, sort_keys=True, indent=4))
        key = 'Invalid data provided'
        result = self._resource_execute_operation_with_expected_failure(
            expected_exception_class=ValidationError,
            params=params, connection=connection_mock)
        assert len(result.args) == 1
        assert key in result.args[0]
        assert json.loads(result.args[0][key]) == {
            'invalid_type': [{'actually_value': 1, 'expected_type': 'string', 'path': 'objects[3].id'}],
            'required': ['objects[0].type']
        }
    def test_module_should_fail_when_upsert_operation_and_few_objects_found_by_filter(self, connection_mock):
        url = '/test'
        url_with_id_templ = '{0}/{1}'.format(url, '{objId}')
        sample_obj = {'name': 'testObject', 'value': '3333', 'type': 'object'}
        params = {
            'operation': 'upsertObject',
            'data': sample_obj,
            'register_as': 'test_var'
        }
        def request_handler(url_path=None, http_method=None, body_params=None, path_params=None, query_params=None):
            if http_method == HTTPMethod.POST:
                assert url_path == url
                assert body_params == params['data']
                assert query_params == {}
                assert path_params == {}
                return {
                    ResponseParams.SUCCESS: False,
                    ResponseParams.RESPONSE: DUPLICATE_NAME_ERROR_MESSAGE,
                    ResponseParams.STATUS_CODE: UNPROCESSABLE_ENTITY_STATUS
                }
            elif http_method == HTTPMethod.GET:
                assert url_path == url
                assert body_params == {}
                assert query_params == {QueryParams.FILTER: 'name:testObject', 'limit': 10, 'offset': 0}
                assert path_params == {}
                return {
                    ResponseParams.SUCCESS: True,
                    ResponseParams.RESPONSE: {
                        'items': [sample_obj, sample_obj]
                    }
                }
            else:
                assert False
        operations = {
            'getObjectList': {'method': HTTPMethod.GET, 'modelName': 'Object', 'url': url, 'returnMultipleItems': True},
            'addObject': {'method': HTTPMethod.POST, 'modelName': 'Object', 'url': url},
            'editObject': {'method': HTTPMethod.PUT, 'modelName': 'Object', 'url': url_with_id_templ},
            'otherObjectOperation': {
                'method': HTTPMethod.GET,
                'modelName': 'Object',
                'url': url_with_id_templ,
                'returnMultipleItems': False}
        }
        def get_operation_spec(name):
            return operations[name]
        connection_mock.get_operation_spec = get_operation_spec
        connection_mock.get_operation_specs_by_model_name.return_value = operations
        connection_mock.send_request = request_handler
        result = self._resource_execute_operation_with_expected_failure(
            expected_exception_class=FtdConfigurationError,
            params=params, connection=connection_mock)
        assert result.msg is MULTIPLE_DUPLICATES_FOUND_ERROR
        assert result.obj is None
    @staticmethod
    def _resource_execute_operation(params, connection):
        resource = BaseConfigurationResource(connection)
        op_name = params['operation']
        resp = resource.execute_operation(op_name, params)
        return resp
    def _resource_execute_operation_with_expected_failure(self, expected_exception_class, params, connection):
        with pytest.raises(expected_exception_class) as ex:
            self._resource_execute_operation(params, connection)
        # 'ex' here is the instance of '_pytest._code.code.ExceptionInfo' but not <expected_exception_class>
        # actual instance of <expected_exception_class> is in the value attribute of 'ex'. That's why we should return
        # 'ex.value' here, so it can be checked in a test later.
        return ex.value
"
-------------------------------------------------------------------------
"# test when object exists but with different fields(except id)
    def test_module_should_update_object_when_upsert_operation_and_object_exists(self, connection_mock):
        url = '/test'
        obj_id = '456'
        version = 'test_version'
        url_with_id_templ = '{0}/{1}'.format(url, '{objId}')
        new_value = '0000'
        old_value = '1111'
        params = {
            'operation': 'upsertObject',
            'data': {'name': 'testObject', 'value': new_value, 'type': 'object'},
            'register_as': 'test_var'
        }
        def response_handler(url_path=None, http_method=None, body_params=None, path_params=None, query_params=None):
            if http_method == HTTPMethod.GET:
                is_get_list_req = url_path == url
                is_get_req = url_path == url_with_id_templ
                assert is_get_req or is_get_list_req
                if is_get_list_req:
                    assert body_params == {}
                    assert query_params == {QueryParams.FILTER: 'name:testObject', 'limit': 10, 'offset': 0}
                elif is_get_req:
                    assert body_params == {}
                    assert query_params == {}
                    assert path_params == {'objId': obj_id}
                return {
                    ResponseParams.SUCCESS: True,
                    ResponseParams.RESPONSE: {
                        'items': [
                            {'name': 'testObject', 'value': old_value, 'type': 'object', 'id': obj_id,
                             'version': version}
                        ]
                    }
                }
            elif http_method == HTTPMethod.PUT:
                assert url_path == url_with_id_templ
                return {
                    ResponseParams.SUCCESS: True,
                    ResponseParams.RESPONSE: body_params
                }
        # Existing operations not included for simplicity
        connection_mock.send_request = response_handler
        expected_val = {'name': 'testObject', 'value': new_value, 'type': 'object', 'id': obj_id, 'version': version}
        result = self._resource_execute_operation(params, connection=connection_mock)
        assert expected_val == result"
-------------------------------------------------------------------------
"# Copyright (c) 2018 Cisco and/or its affiliates.
#
# This file is part of Ansible
#
# Ansible is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Ansible is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.
#
from __future__ import absolute_import
import copy
import json
import unittest
import pytest
from ansible.compat.tests import mock
from ansible.module_utils.network.ftd.common import FtdServerError, HTTPMethod, ResponseParams, FtdConfigurationError
from ansible.module_utils.network.ftd.configuration import DUPLICATE_NAME_ERROR_MESSAGE, UNPROCESSABLE_ENTITY_STATUS, \
    MULTIPLE_DUPLICATES_FOUND_ERROR, BaseConfigurationResource, FtdInvalidOperationNameError, QueryParams
from ansible.module_utils.network.ftd.fdm_swagger_client import ValidationError
ADD_RESPONSE = {'status': 'Object added'}
EDIT_RESPONSE = {'status': 'Object edited'}
DELETE_RESPONSE = {'status': 'Object deleted'}
GET_BY_FILTER_RESPONSE = [{'name': 'foo', 'description': 'bar'}]
ARBITRARY_RESPONSE = {'status': 'Arbitrary request sent'}
class TestUpsertOperationUnitTests(unittest.TestCase):
    def setUp(self):
        conn = mock.MagicMock()
        self._resource = BaseConfigurationResource(conn)
    def test_get_operation_name(self):
        operation_a = mock.MagicMock()
        operation_b = mock.MagicMock()
        def checker_wrapper(expected_object):
            def checker(obj, *args, **kwargs):
                return obj == expected_object
            return checker
        operations = {
            operation_a: ""spec"",
            operation_b: ""spec""
        }
        assert operation_a == self._resource._get_operation_name(checker_wrapper(operation_a), operations)
        assert operation_b == self._resource._get_operation_name(checker_wrapper(operation_b), operations)
        self.assertRaises(
            FtdConfigurationError,
            self._resource._get_operation_name, checker_wrapper(None), operations
        )
    @mock.patch.object(BaseConfigurationResource, ""_get_operation_name"")
    @mock.patch.object(BaseConfigurationResource, ""add_object"")
    def test_add_upserted_object(self, add_object_mock, get_operation_mock):
        model_operations = mock.MagicMock()
        params = mock.MagicMock()
        add_op_name = get_operation_mock.return_value
        assert add_object_mock.return_value == self._resource._add_upserted_object(model_operations, params)
        get_operation_mock.assert_called_once_with(
            self._resource._operation_checker.is_add_operation,
            model_operations)
        add_object_mock.assert_called_once_with(add_op_name, params)
    @mock.patch.object(BaseConfigurationResource, ""_get_operation_name"")
    @mock.patch.object(BaseConfigurationResource, ""edit_object"")
    @mock.patch(""ansible.module_utils.network.ftd.configuration.copy_identity_properties"")
    @mock.patch(""ansible.module_utils.network.ftd.configuration._set_default"")
    def test_edit_upserted_object(self, _set_default_mock, copy_properties_mock, edit_object_mock, get_operation_mock):
        model_operations = mock.MagicMock()
        existing_object = mock.MagicMock()
        params = {
            'path_params': {},
            'data': {}
        }
        result = self._resource._edit_upserted_object(model_operations, existing_object, params)
        assert result == edit_object_mock.return_value
        _set_default_mock.assert_has_calls([
            mock.call(params, 'path_params', {}),
            mock.call(params, 'data', {})
        ])
        get_operation_mock.assert_called_once_with(
            self._resource._operation_checker.is_edit_operation,
            model_operations
        )
        copy_properties_mock.assert_called_once_with(
            existing_object,
            params['data']
        )
        edit_object_mock.assert_called_once_with(
            get_operation_mock.return_value,
            params
        )
    @mock.patch.object(BaseConfigurationResource, ""get_operation_specs_by_model_name"")
    @mock.patch(""ansible.module_utils.network.ftd.configuration.OperationChecker.is_upsert_operation_supported"")
    @mock.patch(""ansible.module_utils.network.ftd.configuration._extract_model_from_upsert_operation"")
    def test_is_upsert_operation_supported(self, extract_model_mock, is_upsert_supported_mock, get_operation_spec_mock):
        op_name = mock.MagicMock()
        result = self._resource.is_upsert_operation_supported(op_name)
        assert result == is_upsert_supported_mock.return_value
        extract_model_mock.assert_called_once_with(op_name)
        get_operation_spec_mock.assert_called_once_with(extract_model_mock.return_value)
        is_upsert_supported_mock.assert_called_once_with(get_operation_spec_mock.return_value)
    @mock.patch.object(BaseConfigurationResource, ""is_upsert_operation_supported"")
    @mock.patch.object(BaseConfigurationResource, ""get_operation_specs_by_model_name"")
    @mock.patch.object(BaseConfigurationResource, ""_add_upserted_object"")
    @mock.patch.object(BaseConfigurationResource, ""_edit_upserted_object"")
    @mock.patch(""ansible.module_utils.network.ftd.configuration._extract_model_from_upsert_operation"")
    def test_upsert_object_succesfully_added(self, extract_model_mock, edit_mock, add_mock, get_operation_mock,
                                             is_upsert_supported_mock):
        op_name = mock.MagicMock()
        params = mock.MagicMock()
        is_upsert_supported_mock.return_value = True
        result = self._resource.upsert_object(op_name, params)
        assert result == add_mock.return_value
        is_upsert_supported_mock.assert_called_once_with(op_name)
        extract_model_mock.assert_called_once_with(op_name)
        get_operation_mock.assert_called_once_with(extract_model_mock.return_value)
        add_mock.assert_called_once_with(get_operation_mock.return_value, params)
        edit_mock.assert_not_called()
    @mock.patch.object(BaseConfigurationResource, ""is_upsert_operation_supported"")
    @mock.patch.object(BaseConfigurationResource, ""get_operation_specs_by_model_name"")
    @mock.patch.object(BaseConfigurationResource, ""_add_upserted_object"")
    @mock.patch.object(BaseConfigurationResource, ""_edit_upserted_object"")
    @mock.patch(""ansible.module_utils.network.ftd.configuration._extract_model_from_upsert_operation"")
    def test_upsert_object_succesfully_edited(self, extract_model_mock, edit_mock, add_mock, get_operation_mock,
                                              is_upsert_supported_mock):
        op_name = mock.MagicMock()
        params = mock.MagicMock()
        is_upsert_supported_mock.return_value = True
        error = FtdConfigurationError(""Obj duplication error"")
        error.obj = mock.MagicMock()
        add_mock.side_effect = error
        result = self._resource.upsert_object(op_name, params)
        assert result == edit_mock.return_value
        is_upsert_supported_mock.assert_called_once_with(op_name)
        extract_model_mock.assert_called_once_with(op_name)
        get_operation_mock.assert_called_once_with(extract_model_mock.return_value)
        add_mock.assert_called_once_with(get_operation_mock.return_value, params)
        edit_mock.assert_called_once_with(get_operation_mock.return_value, error.obj, params)
    @mock.patch.object(BaseConfigurationResource, ""is_upsert_operation_supported"")
    @mock.patch.object(BaseConfigurationResource, ""get_operation_specs_by_model_name"")
    @mock.patch.object(BaseConfigurationResource, ""_add_upserted_object"")
    @mock.patch.object(BaseConfigurationResource, ""_edit_upserted_object"")
    @mock.patch(""ansible.module_utils.network.ftd.configuration._extract_model_from_upsert_operation"")
    def test_upsert_object_not_supported(self, extract_model_mock, edit_mock, add_mock, get_operation_mock,
                                         is_upsert_supported_mock):
        op_name = mock.MagicMock()
        params = mock.MagicMock()
        is_upsert_supported_mock.return_value = False
        self.assertRaises(
            FtdInvalidOperationNameError,
            self._resource.upsert_object, op_name, params
        )
        is_upsert_supported_mock.assert_called_once_with(op_name)
        extract_model_mock.assert_not_called()
        get_operation_mock.assert_not_called()
        add_mock.assert_not_called()
        edit_mock.assert_not_called()
    @mock.patch.object(BaseConfigurationResource, ""is_upsert_operation_supported"")
    @mock.patch.object(BaseConfigurationResource, ""get_operation_specs_by_model_name"")
    @mock.patch.object(BaseConfigurationResource, ""_add_upserted_object"")
    @mock.patch.object(BaseConfigurationResource, ""_edit_upserted_object"")
    @mock.patch(""ansible.module_utils.network.ftd.configuration._extract_model_from_upsert_operation"")
    def test_upsert_object_neither_added_nor_edited(self, extract_model_mock, edit_mock, add_mock, get_operation_mock,
                                                    is_upsert_supported_mock):
        op_name = mock.MagicMock()
        params = mock.MagicMock()
        is_upsert_supported_mock.return_value = True
        error = FtdConfigurationError(""Obj duplication error"")
        error.obj = mock.MagicMock()
        add_mock.side_effect = error
        edit_mock.side_effect = FtdConfigurationError(""Some object edit error"")
        self.assertRaises(
            FtdConfigurationError,
            self._resource.upsert_object, op_name, params
        )
        is_upsert_supported_mock.assert_called_once_with(op_name)
        extract_model_mock.assert_called_once_with(op_name)
        get_operation_mock.assert_called_once_with(extract_model_mock.return_value)
        add_mock.assert_called_once_with(get_operation_mock.return_value, params)
        edit_mock.assert_called_once_with(get_operation_mock.return_value, error.obj, params)
    @mock.patch.object(BaseConfigurationResource, ""is_upsert_operation_supported"")
    @mock.patch.object(BaseConfigurationResource, ""get_operation_specs_by_model_name"")
    @mock.patch.object(BaseConfigurationResource, ""_add_upserted_object"")
    @mock.patch.object(BaseConfigurationResource, ""_edit_upserted_object"")
    @mock.patch(""ansible.module_utils.network.ftd.configuration._extract_model_from_upsert_operation"")
    def test_upsert_object_with_fatal_error_during_add(self, extract_model_mock, edit_mock, add_mock,
                                                       get_operation_mock, is_upsert_supported_mock):
        op_name = mock.MagicMock()
        params = mock.MagicMock()
        is_upsert_supported_mock.return_value = True
        error = FtdConfigurationError(""Obj duplication error"")
        add_mock.side_effect = error
        self.assertRaises(
            FtdConfigurationError,
            self._resource.upsert_object, op_name, params
        )
        is_upsert_supported_mock.assert_called_once_with(op_name)
        extract_model_mock.assert_called_once_with(op_name)
        get_operation_mock.assert_called_once_with(extract_model_mock.return_value)
        add_mock.assert_called_once_with(get_operation_mock.return_value, params)
        edit_mock.assert_not_called()
# functional tests below
class TestUpsertOperationFunctionalTests(object):
    @pytest.fixture(autouse=True)
    def connection_mock(self, mocker):
        connection_class_mock = mocker.patch('ansible.modules.network.ftd.ftd_configuration.Connection')
        connection_instance = connection_class_mock.return_value
        connection_instance.validate_data.return_value = True, None
        connection_instance.validate_query_params.return_value = True, None
        connection_instance.validate_path_params.return_value = True, None
        return connection_instance
    def test_module_should_create_object_when_upsert_operation_and_object_does_not_exist(self, connection_mock):
        url = '/test'
        operations = {
            'getObjectList': {
                'method': HTTPMethod.GET,
                'url': url,
                'modelName': 'Object',
                'returnMultipleItems': True},
            'addObject': {
                'method': HTTPMethod.POST,
                'modelName': 'Object',
                'url': url},
            'editObject': {
                'method': HTTPMethod.PUT,
                'modelName': 'Object',
                'url': '/test/{objId}'},
            'otherObjectOperation': {
                'method': HTTPMethod.GET,
                'modelName': 'Object',
                'url': '/test/{objId}',
                'returnMultipleItems': False
            }
        }
        def get_operation_spec(name):
            return operations[name]
        connection_mock.get_operation_spec = get_operation_spec
        connection_mock.get_operation_specs_by_model_name.return_value = operations
        connection_mock.send_request.return_value = {
            ResponseParams.SUCCESS: True,
            ResponseParams.RESPONSE: ADD_RESPONSE
        }
        params = {
            'operation': 'upsertObject',
            'data': {'id': '123', 'name': 'testObject', 'type': 'object'},
            'path_params': {'objId': '123'},
            'register_as': 'test_var'
        }
        result = self._resource_execute_operation(params, connection=connection_mock)
        connection_mock.send_request.assert_called_once_with(url_path=url,
                                                             http_method=HTTPMethod.POST,
                                                             path_params=params['path_params'],
                                                             query_params={},
                                                             body_params=params['data'])
        assert ADD_RESPONSE == result
    # test when object exists but with different fields(except id)
    def test_module_should_update_object_when_upsert_operation_and_object_exists(self, connection_mock):
        url = '/test'
        obj_id = '456'
        version = 'test_version'
        url_with_id_templ = '{0}/{1}'.format(url, '{objId}')
        new_value = '0000'
        old_value = '1111'
        params = {
            'operation': 'upsertObject',
            'data': {'name': 'testObject', 'value': new_value, 'type': 'object'},
            'register_as': 'test_var'
        }
        def request_handler(url_path=None, http_method=None, body_params=None, path_params=None, query_params=None):
            if http_method == HTTPMethod.POST:
                assert url_path == url
                assert body_params == params['data']
                assert query_params == {}
                assert path_params == {}
                return {
                    ResponseParams.SUCCESS: False,
                    ResponseParams.RESPONSE: DUPLICATE_NAME_ERROR_MESSAGE,
                    ResponseParams.STATUS_CODE: UNPROCESSABLE_ENTITY_STATUS
                }
            elif http_method == HTTPMethod.GET:
                is_get_list_req = url_path == url
                is_get_req = url_path == url_with_id_templ
                assert is_get_req or is_get_list_req
                if is_get_list_req:
                    assert body_params == {}
                    assert query_params == {QueryParams.FILTER: 'name:testObject', 'limit': 10, 'offset': 0}
                    assert path_params == {}
                elif is_get_req:
                    assert body_params == {}
                    assert query_params == {}
                    assert path_params == {'objId': obj_id}
                return {
                    ResponseParams.SUCCESS: True,
                    ResponseParams.RESPONSE: {
                        'items': [
                            {'name': 'testObject', 'value': old_value, 'type': 'object', 'id': obj_id,
                             'version': version}
                        ]
                    }
                }
            elif http_method == HTTPMethod.PUT:
                assert url_path == url_with_id_templ
                return {
                    ResponseParams.SUCCESS: True,
                    ResponseParams.RESPONSE: body_params
                }
            else:
                assert False
        operations = {
            'getObjectList': {'method': HTTPMethod.GET, 'url': url, 'modelName': 'Object', 'returnMultipleItems': True},
            'addObject': {'method': HTTPMethod.POST, 'modelName': 'Object', 'url': url},
            'editObject': {'method': HTTPMethod.PUT, 'modelName': 'Object', 'url': url_with_id_templ},
            'otherObjectOperation': {
                'method': HTTPMethod.GET,
                'modelName': 'Object',
                'url': url_with_id_templ,
                'returnMultipleItems': False}
        }
        def get_operation_spec(name):
            return operations[name]
        connection_mock.get_operation_spec = get_operation_spec
        connection_mock.get_operation_specs_by_model_name.return_value = operations
        connection_mock.send_request = request_handler
        expected_val = {'name': 'testObject', 'value': new_value, 'type': 'object', 'id': obj_id, 'version': version}
        result = self._resource_execute_operation(params, connection=connection_mock)
        assert expected_val == result
    # test when object exists and all fields have the same value
    def test_module_should_not_update_object_when_upsert_operation_and_object_exists_with_the_same_fields(
            self, connection_mock):
        url = '/test'
        url_with_id_templ = '{0}/{1}'.format(url, '{objId}')
        params = {
            'operation': 'upsertObject',
            'data': {'name': 'testObject', 'value': '3333', 'type': 'object'},
            'register_as': 'test_var'
        }
        expected_val = copy.deepcopy(params['data'])
        expected_val['version'] = 'test_version'
        expected_val['id'] = 'test_id'
        def request_handler(url_path=None, http_method=None, body_params=None, path_params=None, query_params=None):
            if http_method == HTTPMethod.POST:
                assert url_path == url
                assert body_params == params['data']
                assert query_params == {}
                assert path_params == {}
                return {
                    ResponseParams.SUCCESS: False,
                    ResponseParams.RESPONSE: DUPLICATE_NAME_ERROR_MESSAGE,
                    ResponseParams.STATUS_CODE: UNPROCESSABLE_ENTITY_STATUS
                }
            elif http_method == HTTPMethod.GET:
                assert url_path == url
                assert body_params == {}
                assert query_params == {QueryParams.FILTER: 'name:testObject', 'limit': 10, 'offset': 0}
                assert path_params == {}
                return {
                    ResponseParams.SUCCESS: True,
                    ResponseParams.RESPONSE: {
                        'items': [expected_val]
                    }
                }
            else:
                assert False
        operations = {
            'getObjectList': {'method': HTTPMethod.GET, 'modelName': 'Object', 'url': url, 'returnMultipleItems': True},
            'addObject': {'method': HTTPMethod.POST, 'modelName': 'Object', 'url': url},
            'editObject': {'method': HTTPMethod.PUT, 'modelName': 'Object', 'url': url_with_id_templ},
            'otherObjectOperation': {
                'method': HTTPMethod.GET,
                'modelName': 'Object',
                'url': url_with_id_templ,
                'returnMultipleItems': False}
        }
        def get_operation_spec(name):
            return operations[name]
        connection_mock.get_operation_spec = get_operation_spec
        connection_mock.get_operation_specs_by_model_name.return_value = operations
        connection_mock.send_request = request_handler
        result = self._resource_execute_operation(params, connection=connection_mock)
        assert expected_val == result
    def test_module_should_fail_when_upsert_operation_is_not_supported(self, connection_mock):
        connection_mock.get_operation_specs_by_model_name.return_value = {
            'addObject': {'method': HTTPMethod.POST, 'modelName': 'Object', 'url': '/test'},
            'editObject': {'method': HTTPMethod.PUT, 'modelName': 'Object', 'url': '/test/{objId}'},
            'otherObjectOperation': {
                'method': HTTPMethod.GET,
                'modelName': 'Object',
                'url': '/test/{objId}',
                'returnMultipleItems': False}
        }
        operation_name = 'upsertObject'
        params = {
            'operation': operation_name,
            'data': {'id': '123', 'name': 'testObject', 'type': 'object'},
            'path_params': {'objId': '123'},
            'register_as': 'test_var'
        }
        result = self._resource_execute_operation_with_expected_failure(
            expected_exception_class=FtdInvalidOperationNameError,
            params=params, connection=connection_mock)
        connection_mock.send_request.assert_not_called()
        assert operation_name == result.operation_name
    # when create operation raised FtdConfigurationError exception without id and version
    def test_module_should_fail_when_upsert_operation_and_failed_create_without_id_and_version(self, connection_mock):
        url = '/test'
        url_with_id_templ = '{0}/{1}'.format(url, '{objId}')
        params = {
            'operation': 'upsertObject',
            'data': {'name': 'testObject', 'value': '3333', 'type': 'object'},
            'register_as': 'test_var'
        }
        def request_handler(url_path=None, http_method=None, body_params=None, path_params=None, query_params=None):
            if http_method == HTTPMethod.POST:
                assert url_path == url
                assert body_params == params['data']
                assert query_params == {}
                assert path_params == {}
                return {
                    ResponseParams.SUCCESS: False,
                    ResponseParams.RESPONSE: DUPLICATE_NAME_ERROR_MESSAGE,
                    ResponseParams.STATUS_CODE: UNPROCESSABLE_ENTITY_STATUS
                }
            elif http_method == HTTPMethod.GET:
                assert url_path == url
                assert body_params == {}
                assert query_params == {QueryParams.FILTER: 'name:testObject', 'limit': 10, 'offset': 0}
                assert path_params == {}
                return {
                    ResponseParams.SUCCESS: True,
                    ResponseParams.RESPONSE: {
                        'items': []
                    }
                }
            else:
                assert False
        operations = {
            'getObjectList': {'method': HTTPMethod.GET, 'modelName': 'Object', 'url': url, 'returnMultipleItems': True},
            'addObject': {'method': HTTPMethod.POST, 'modelName': 'Object', 'url': url},
            'editObject': {'method': HTTPMethod.PUT, 'modelName': 'Object', 'url': url_with_id_templ},
            'otherObjectOperation': {
                'method': HTTPMethod.GET,
                'modelName': 'Object',
                'url': url_with_id_templ,
                'returnMultipleItems': False}
        }
        def get_operation_spec(name):
            return operations[name]
        connection_mock.get_operation_spec = get_operation_spec
        connection_mock.get_operation_specs_by_model_name.return_value = operations
        connection_mock.send_request = request_handler
        result = self._resource_execute_operation_with_expected_failure(
            expected_exception_class=FtdServerError,
            params=params, connection=connection_mock)
        assert result.code == 422
        assert result.response == 'Validation failed due to a duplicate name'
    def test_module_should_fail_when_upsert_operation_and_failed_update_operation(self, connection_mock):
        url = '/test'
        obj_id = '456'
        version = 'test_version'
        url_with_id_templ = '{0}/{1}'.format(url, '{objId}')
        error_code = 404
        new_value = '0000'
        old_value = '1111'
        params = {
            'operation': 'upsertObject',
            'data': {'name': 'testObject', 'value': new_value, 'type': 'object'},
            'register_as': 'test_var'
        }
        error_msg = 'test error'
        def request_handler(url_path=None, http_method=None, body_params=None, path_params=None, query_params=None):
            if http_method == HTTPMethod.POST:
                assert url_path == url
                assert body_params == params['data']
                assert query_params == {}
                assert path_params == {}
                return {
                    ResponseParams.SUCCESS: False,
                    ResponseParams.RESPONSE: DUPLICATE_NAME_ERROR_MESSAGE,
                    ResponseParams.STATUS_CODE: UNPROCESSABLE_ENTITY_STATUS
                }
            elif http_method == HTTPMethod.GET:
                is_get_list_req = url_path == url
                is_get_req = url_path == url_with_id_templ
                assert is_get_req or is_get_list_req
                if is_get_list_req:
                    assert body_params == {}
                    assert query_params == {QueryParams.FILTER: 'name:testObject', 'limit': 10, 'offset': 0}
                elif is_get_req:
                    assert body_params == {}
                    assert query_params == {}
                    assert path_params == {'objId': obj_id}
                return {
                    ResponseParams.SUCCESS: True,
                    ResponseParams.RESPONSE: {
                        'items': [
                            {'name': 'testObject', 'value': old_value, 'type': 'object', 'id': obj_id,
                             'version': version}
                        ]
                    }
                }
            elif http_method == HTTPMethod.PUT:
                assert url_path == url_with_id_templ
                raise FtdServerError(error_msg, error_code)
            else:
                assert False
        operations = {
            'getObjectList': {'method': HTTPMethod.GET, 'modelName': 'Object', 'url': url, 'returnMultipleItems': True},
            'addObject': {'method': HTTPMethod.POST, 'modelName': 'Object', 'url': url},
            'editObject': {'method': HTTPMethod.PUT, 'modelName': 'Object', 'url': url_with_id_templ},
            'otherObjectOperation': {
                'method': HTTPMethod.GET,
                'modelName': 'Object',
                'url': url_with_id_templ,
                'returnMultipleItems': False}
        }
        def get_operation_spec(name):
            return operations[name]
        connection_mock.get_operation_spec = get_operation_spec
        connection_mock.get_operation_specs_by_model_name.return_value = operations
        connection_mock.send_request = request_handler
        result = self._resource_execute_operation_with_expected_failure(
            expected_exception_class=FtdServerError,
            params=params, connection=connection_mock)
        assert result.code == error_code
        assert result.response == error_msg
    def test_module_should_fail_when_upsert_operation_and_invalid_data_for_create_operation(self, connection_mock):
        new_value = '0000'
        params = {
            'operation': 'upsertObject',
            'data': {'name': 'testObject', 'value': new_value, 'type': 'object'},
            'register_as': 'test_var'
        }
        connection_mock.send_request.assert_not_called()
        operations = {
            'getObjectList': {
                'method': HTTPMethod.GET,
                'modelName': 'Object',
                'url': 'sd',
                'returnMultipleItems': True},
            'addObject': {'method': HTTPMethod.POST, 'modelName': 'Object', 'url': 'sdf'},
            'editObject': {'method': HTTPMethod.PUT, 'modelName': 'Object', 'url': 'sadf'},
            'otherObjectOperation': {
                'method': HTTPMethod.GET,
                'modelName': 'Object',
                'url': 'sdfs',
                'returnMultipleItems': False}
        }
        def get_operation_spec(name):
            return operations[name]
        connection_mock.get_operation_spec = get_operation_spec
        connection_mock.get_operation_specs_by_model_name.return_value = operations
        report = {
            'required': ['objects[0].type'],
            'invalid_type': [
                {
                    'path': 'objects[3].id',
                    'expected_type': 'string',
                    'actually_value': 1
                }
            ]
        }
        connection_mock.validate_data.return_value = (False, json.dumps(report, sort_keys=True, indent=4))
        key = 'Invalid data provided'
        result = self._resource_execute_operation_with_expected_failure(
            expected_exception_class=ValidationError,
            params=params, connection=connection_mock)
        assert len(result.args) == 1
        assert key in result.args[0]
        assert json.loads(result.args[0][key]) == {
            'invalid_type': [{'actually_value': 1, 'expected_type': 'string', 'path': 'objects[3].id'}],
            'required': ['objects[0].type']
        }
    def test_module_should_fail_when_upsert_operation_and_few_objects_found_by_filter(self, connection_mock):
        url = '/test'
        url_with_id_templ = '{0}/{1}'.format(url, '{objId}')
        sample_obj = {'name': 'testObject', 'value': '3333', 'type': 'object'}
        params = {
            'operation': 'upsertObject',
            'data': sample_obj,
            'register_as': 'test_var'
        }
        def request_handler(url_path=None, http_method=None, body_params=None, path_params=None, query_params=None):
            if http_method == HTTPMethod.POST:
                assert url_path == url
                assert body_params == params['data']
                assert query_params == {}
                assert path_params == {}
                return {
                    ResponseParams.SUCCESS: False,
                    ResponseParams.RESPONSE: DUPLICATE_NAME_ERROR_MESSAGE,
                    ResponseParams.STATUS_CODE: UNPROCESSABLE_ENTITY_STATUS
                }
            elif http_method == HTTPMethod.GET:
                assert url_path == url
                assert body_params == {}
                assert query_params == {QueryParams.FILTER: 'name:testObject', 'limit': 10, 'offset': 0}
                assert path_params == {}
                return {
                    ResponseParams.SUCCESS: True,
                    ResponseParams.RESPONSE: {
                        'items': [sample_obj, sample_obj]
                    }
                }
            else:
                assert False
        operations = {
            'getObjectList': {'method': HTTPMethod.GET, 'modelName': 'Object', 'url': url, 'returnMultipleItems': True},
            'addObject': {'method': HTTPMethod.POST, 'modelName': 'Object', 'url': url},
            'editObject': {'method': HTTPMethod.PUT, 'modelName': 'Object', 'url': url_with_id_templ},
            'otherObjectOperation': {
                'method': HTTPMethod.GET,
                'modelName': 'Object',
                'url': url_with_id_templ,
                'returnMultipleItems': False}
        }
        def get_operation_spec(name):
            return operations[name]
        connection_mock.get_operation_spec = get_operation_spec
        connection_mock.get_operation_specs_by_model_name.return_value = operations
        connection_mock.send_request = request_handler
        result = self._resource_execute_operation_with_expected_failure(
            expected_exception_class=FtdConfigurationError,
            params=params, connection=connection_mock)
        assert result.msg is MULTIPLE_DUPLICATES_FOUND_ERROR
        assert result.obj is None
    @staticmethod
    def _resource_execute_operation(params, connection):
        resource = BaseConfigurationResource(connection)
        op_name = params['operation']
        resp = resource.execute_operation(op_name, params)
        return resp
    def _resource_execute_operation_with_expected_failure(self, expected_exception_class, params, connection):
        with pytest.raises(expected_exception_class) as ex:
            self._resource_execute_operation(params, connection)
        # 'ex' here is the instance of '_pytest._code.code.ExceptionInfo' but not <expected_exception_class>
        # actual instance of <expected_exception_class> is in the value attribute of 'ex'. That's why we should return
        # 'ex.value' here, so it can be checked in a test later.
        return ex.value
"
-------------------------------------------------------------------------
"Recom
PRs: 47747, 48982"
-------------------------------------------------------------------------
=========================================================================
"new_args = parse_module_arguments(new_args)
changes = 0
    rule_changed = False
        if(current_rule.rule_type != new_type):
            rule_changed = True
            current_rule.rule_type = new_type
        if(current_rule.rule_control != new_control):
            rule_changed = True
            current_rule.rule_control = new_control
        if(current_rule.rule_path != new_path):
            rule_changed = True
            current_rule.rule_path = new_path
        if(current_rule.rule_args != new_args):
            rule_changed = True
            current_rule.rule_args = new_args
    if rule_changed:
        changes = 1
return changes
changes = 0
"
-------------------------------------------------------------------------
"new_args = parse_module_arguments(new_args)
changes = 0
rule_changed = False
if (current_rule.rule_type != new_type):
    rule_changed = True
    current_rule.rule_type = new_type
if (current_rule.rule_control != new_control):
    rule_changed = True
    current_rule.rule_control = new_control
if (current_rule.rule_path != new_path):
    rule_changed = True
    current_rule.rule_path = new_path
if (current_rule.rule_args != new_args):
    rule_changed = True
    current_rule.rule_args = new_args
if rule_changed:
    changes = 1
return changes"
-------------------------------------------------------------------------
"self._args = parse_module_arguments(args)
"
-------------------------------------------------------------------------
"Recom
PRs: 47695, 48307"
-------------------------------------------------------------------------
=========================================================================
"changes = 1
"
-------------------------------------------------------------------------
changes = changes
-------------------------------------------------------------------------
"changes = 1
hanges
= 0
"
-------------------------------------------------------------------------
"Recom
PRs: 47695, 48307"
-------------------------------------------------------------------------
=========================================================================
"changes = 1
hanges
= 0
"
-------------------------------------------------------------------------
"changes = 1
changes = 0"
-------------------------------------------------------------------------
"changes = 1
"
-------------------------------------------------------------------------
"Recom
PRs: 47695, 48307"
-------------------------------------------------------------------------
=========================================================================
"changes = 1
"
-------------------------------------------------------------------------
changes = 1
-------------------------------------------------------------------------
"changes = 1
hanges
add = parse_module_arguments(args_to_add)
= 0
_changed = False
eate some structures to evaluate the situation
le_new_args = set()
value_new_args = dict()
arg in args_to_add:
if arg.startswith(""[""):
    continue
elif ""="" in arg:
    key, value = arg.split(""="")
    key_value_new_args[key] = value
else:
    simple_new_args.add(arg)
value_new_args_set = set(key_value_new_args)
le_current_args = set()
value_current_args = dict()
arg in current_rule.rule_args:
if arg.startswith(""[""):
    continue
elif ""="" in arg:
    key, value = arg.split(""="")
    key_value_current_args[key] = value
else:
    simple_current_args.add(arg)
value_current_args_set = set(key_value_current_args)
args_to_add = list()
ndle new simple arguments
imple_new_args.difference(simple_current_args):
for arg in simple_new_args.difference(simple_current_args):
    new_args_to_add.append(arg)
ndle new key value arguments
ey_value_new_args_set.difference(key_value_current_args_set):
for key in key_value_new_args_set.difference(key_value_current_args_set):
    new_args_to_add.append(key  '='  key_value_new_args[key])
ew_args_to_add:
current_rule.rule_args = new_args_to_add
rule_changed = True
ndle existing key value arguments when value is not equal
ey_value_new_args_set.intersection(key_value_current_args_set):
for key in key_value_new_args_set.intersection(key_value_current_args_set):
    if key_value_current_args[key] != key_value_new_args[key]:
        arg_index = current_rule.rule_args.index(key  '='  key_value_current_args[key])
        current_rule.rule_args[arg_index] = str(key  '='  key_value_new_args[key])
        rule_changed = True
ule_changed:
changes = 1
hanges
remove = parse_module_arguments(args_to_remove)
= 0
"
-------------------------------------------------------------------------
"Recom
PRs: 47695, 48307"
-------------------------------------------------------------------------
=========================================================================
"changes = 1
hanges
add = parse_module_arguments(args_to_add)
= 0
_changed = False
eate some structures to evaluate the situation
le_new_args = set()
value_new_args = dict()
arg in args_to_add:
if arg.startswith(""[""):
    continue
elif ""="" in arg:
    key, value = arg.split(""="")
    key_value_new_args[key] = value
else:
    simple_new_args.add(arg)
value_new_args_set = set(key_value_new_args)
le_current_args = set()
value_current_args = dict()
arg in current_rule.rule_args:
if arg.startswith(""[""):
    continue
elif ""="" in arg:
    key, value = arg.split(""="")
    key_value_current_args[key] = value
else:
    simple_current_args.add(arg)
value_current_args_set = set(key_value_current_args)
args_to_add = list()
ndle new simple arguments
imple_new_args.difference(simple_current_args):
for arg in simple_new_args.difference(simple_current_args):
    new_args_to_add.append(arg)
ndle new key value arguments
ey_value_new_args_set.difference(key_value_current_args_set):
for key in key_value_new_args_set.difference(key_value_current_args_set):
    new_args_to_add.append(key  '='  key_value_new_args[key])
ew_args_to_add:
current_rule.rule_args = new_args_to_add
rule_changed = True
ndle existing key value arguments when value is not equal
ey_value_new_args_set.intersection(key_value_current_args_set):
for key in key_value_new_args_set.intersection(key_value_current_args_set):
    if key_value_current_args[key] != key_value_new_args[key]:
        arg_index = current_rule.rule_args.index(key  '='  key_value_current_args[key])
        current_rule.rule_args[arg_index] = str(key  '='  key_value_new_args[key])
        rule_changed = True
ule_changed:
changes = 1
hanges
remove = parse_module_arguments(args_to_remove)
= 0
"
-------------------------------------------------------------------------
"changes = 1
add = parse_module_arguments(args_to_add)
_changed = False

# Create some structures to evaluate the situation
new_args_set = set()
value_new_args = dict()

for arg in args_to_add:
    if arg.startswith(""[""):
        continue
    elif ""="" in arg:
        key, value = arg.split(""="")
        value_new_args[key] = value
    else:
        new_args_set.add(arg)

value_new_args_set = set(value_new_args.keys())

current_args_set = set()
value_current_args = dict()

for arg in current_rule.rule_args:
    if arg.startswith(""[""):
        continue
    elif ""="" in arg:
        key, value = arg.split(""="")
        value_current_args[key] = value
    else:
        current_args_set.add(arg)

value_current_args_set = set(value_current_args.keys())

args_to_add = list()

# Handle new simple arguments
for arg in new_args_set.difference(current_args_set):
    args_to_add.append(arg)

# Handle new key-value arguments
for key in value_new_args_set.difference(value_current_args_set):
    args_to_add.append(f""{key}={value_new_args[key]}"")

# Update rule with the new arguments
if args_to_add:
    current_rule.rule_args = args_to_add
    rule_changed = True

# Handle existing key-value arguments when value is not equal
if value_new_args_set.intersection(value_current_args):
    for key in value_new_args_set.intersection(value_current_args_set):
        if value_current_args[key] != value_new_args[key]:
            arg_index = current_rule.rule_args.index(f""{key}={value_current_args[key]}"")
            current_rule.rule_args[arg_index] = str(f""{key}={value_new_args[key]}"")
            rule_changed = True

if rule_changed:
    changes = 1
remove = parse_module_arguments(args_to_remove)
_changed = False"
-------------------------------------------------------------------------
"changes = 1
rn changes
"
-------------------------------------------------------------------------
"Recom
PRs: 47695, 48307"
-------------------------------------------------------------------------
=========================================================================
"changes = 1
rn changes
"
-------------------------------------------------------------------------
"changed += 1
return changed"
-------------------------------------------------------------------------
"changes = 1
"
-------------------------------------------------------------------------
"Recom
PRs: 47695, 48307"
-------------------------------------------------------------------------
=========================================================================
"changes = 0
"
-------------------------------------------------------------------------
changes = changed
-------------------------------------------------------------------------
"changes = 1
"
-------------------------------------------------------------------------
"Recom
PRs: 47695, 48307"
-------------------------------------------------------------------------
=========================================================================
"result = dict(
    changed=(changes > 0),
    change_count=changes,
    backupdest='',
)
if not module.check_mode and result['changed']:
        result['backupdest'] = module.backup_local(fname)
"
-------------------------------------------------------------------------
"result = {
    'changed': (changes > 0),
    'change_count': changes,
    'backupdest': '',
}

if not module.check_mode and result['changed']:
    result['backupdest'] = module.backup_local(fname)"
-------------------------------------------------------------------------
"result = dict(
    changed=(changes > 0),
    change_count=changes,
    backupdest='',
    action=action,
)
if not module.check_mode and result['changed']:
        result['backupdest'] = module.backup_local(fname)
"
-------------------------------------------------------------------------
"Recom
PRs: 47695, 48307"
-------------------------------------------------------------------------
=========================================================================
"init='init',
uts_mode='uts',
runtime='runtime',
auto_remove='auto_remove',
device_read_bps='device_read_bps',
device_write_bps='device_write_bps',
device_read_iops='device_read_iops',
device_write_iops='device_write_iops',
elf.client.docker_py_version >= LooseVersion('1.9') and self.client.docker_api_version >= LooseVersion('1.22'):
# blkio_weight can always be updated, but can only be set on creation
# when docker-py and docker API are new enough
elf.client.docker_py_version >= LooseVersion('3.0'):
    if self.client.option_minimal_versions[value]['supported']:
        params[key] = getattr(self, value)
"
-------------------------------------------------------------------------
"init='init',
uts_mode='uts',
runtime='runtime',
auto_remove='auto_remove',
device_read_bps='device_read_bps',
device_write_bps='device_write_bps',
device_read_iops='device_read_iops',
device_write_iops='device_write_iops',
elf.client.docker_py_version >= LooseVersion('1.9') and self.client.docker_api_version >= LooseVersion('1.22'):
# blkio_weight can always be updated, but can only be set on creation
# when docker-py and docker API are new enough
elf.client.docker_py_version >= LooseVersion('3.0'):
    if self.client.option_minimal_versions[value]['supported']:
        params[key] = getattr(self, value)"
-------------------------------------------------------------------------
"init='init',
uts_mode='uts',
auto_remove='auto_remove',
elf.client.docker_py_version >= LooseVersion('1.9') and self.client.docker_api_version >= LooseVersion('1.22'):
# blkio_weight can always be updated, but can only be set on creation
# when docker-py and docker API are new enough
elf.client.docker_py_version >= LooseVersion('3.0'):
    if self.client.option_minimal_versions[value]['supported']:
        params[key] = getattr(self, value)
"
-------------------------------------------------------------------------
"Recom
PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"volume_driver=host_config.get('VolumeDriver'),
"
-------------------------------------------------------------------------
volume_driver = host_config.get('VolumeDriver')
-------------------------------------------------------------------------
"volume_driver=host_config.get('VolumeDriver'),
tions which don't make sense without their accompanying option
elf.parameters.client.option_minimal_versions['auto_remove']['supported']:
# auto_remove is only supported in docker>=2; unfortunately it has a default
# value, that's why we have to jump through the hoops here
elf.parameters.client.docker_api_version < LooseVersion('1.22'):
# For docker API < 1.22, update_container() is not supported. Thus
# we need to handle all limits which are usually handled by
# update_container() as configuration changes which require a container
# restart.
config_mapping.update(dict(
    blkio_weight=host_config.get('BlkioWeight'),
    cpu_period=host_config.get('CpuPeriod'),
    cpu_quota=host_config.get('CpuQuota'),
    cpu_shares=host_config.get('CpuShares'),
    cpuset_cpus=host_config.get('CpusetCpus'),
    cpuset_mems=host_config.get('CpusetMems'),
    kernel_memory=host_config.get(""KernelMemory""),
    memory=host_config.get('Memory'),
    memory_reservation=host_config.get('MemoryReservation'),
    memory_swap=host_config.get('MemorySwap'),
))
"
-------------------------------------------------------------------------
"Recom
PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"if self.client.docker_py_version >= LooseVersion('3.0'):
"
-------------------------------------------------------------------------
if self._client._api_version_supported('3.0'):
-------------------------------------------------------------------------
"if self.client.docker_py_version < LooseVersion('3.0'):
    # cpu_shares and volume_driver moved to create_host_config in > 3
"
-------------------------------------------------------------------------
"Recom
PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"- On Linux, macOS and OpenBSD, this is converted to minutes and rounded down. If less than 60, it will be set to 0.
"
-------------------------------------------------------------------------
"On Linux, macOS, and OpenBSD, the variable `pre_reboot_delay` is converted to minutes and rounded down. If the value is less than 60, it will be set to 0."
-------------------------------------------------------------------------
"- On Linux, macOS, and OpenBSD this is converted to minutes and rounded down. If less than 60, it will be set to 0.
- On Solaris and FreeBSD this will be seconds.
"
-------------------------------------------------------------------------
"Recom
PRs: 46147, 46289"
-------------------------------------------------------------------------
=========================================================================
"if vpc_id:
    vpc_wins = dict((group['GroupName'], group) for group in all_groups if group['VpcId'] == vpc_id)
    groups.update(vpc_wins)
"
-------------------------------------------------------------------------
"if vpc_id:
    vpc_wins = dict((group['GroupName'], group) for group in all_groups if group.get('VpcId') == vpc_id)
    groups.update(vpc_wins)"
-------------------------------------------------------------------------
"if vpc_id:
    vpc_wins = dict((group['GroupName'], group) for group in all_groups if group.get('VpcId') and group['VpcId'] == vpc_id)
    groups.update(vpc_wins)
"
-------------------------------------------------------------------------
"Recom
PRs: 45787, 45815"
-------------------------------------------------------------------------
=========================================================================
"stdout = ''
stderr = ''
"
-------------------------------------------------------------------------
"stdout = ''
stderr = ''"
-------------------------------------------------------------------------
"stdout = u''
stderr = u''
"
-------------------------------------------------------------------------
"Recom
PRs: 45607, 45791"
-------------------------------------------------------------------------
=========================================================================
"type: boolean
"
-------------------------------------------------------------------------
"become:
    default: False"
-------------------------------------------------------------------------
"type: boolean
type: boolean
"
-------------------------------------------------------------------------
"Recom
PRs: 45736, 45738"
-------------------------------------------------------------------------
=========================================================================
"if checksum != destination_checksum:
    checksum_mismatch = True
t forcing redownload, unless checksum does not match
ot force and not checksum_mismatch:
# Not forcing redownload, unless checksum does not match
# allow file attribute changes
module.params['path'] = dest
file_args = module.load_file_common_arguments(module.params)
file_args['path'] = dest
result['changed'] = module.set_fs_attributes_if_different(file_args, False)
if result['changed']:
    module.exit_json(msg=""file already exists but file attributes changed"", **result)
module.exit_json(msg=""file already exists"", **result)
"
-------------------------------------------------------------------------
"if checksum != destination_checksum:
    force = True
elif not force and not checksum_mismatch:
    # Not forcing redownload, unless checksum does not match
    # allow file attribute changes
    module.params['path'] = dest
    file_args = module.load_file_common_arguments(module.params)
    file_args['path'] = dest
    changed = module.set_fs_attributes_if_different(file_args, False)
    if changed:
        module.exit_json(msg=""file already exists but file attributes changed"", dest=dest, url=url, changed=changed)
    module.exit_json(msg=""file already exists"", dest=dest, url=url, changed=changed)"
-------------------------------------------------------------------------
"if checksum != destination_checksum:
    checksum_mismatch = True
t forcing redownload, unless checksum does not match
ot force and not checksum_mismatch:
# allow file attribute changes
module.params['path'] = dest
file_args = module.load_file_common_arguments(module.params)
file_args['path'] = dest
changed = module.set_fs_attributes_if_different(file_args, False)
if changed:
    module.exit_json(msg=""file already exists but file attributes changed"", dest=dest, url=url, changed=changed)
module.exit_json(msg=""file already exists"", dest=dest, url=url, changed=changed)
"
-------------------------------------------------------------------------
"Recom
PRs: 45495, 45567"
-------------------------------------------------------------------------
=========================================================================
"if checksum != destination_checksum:
    checksum_mismatch = True
t forcing redownload, unless checksum does not match
ot force and not checksum_mismatch:
# Not forcing redownload, unless checksum does not match
# allow file attribute changes
module.params['path'] = dest
file_args = module.load_file_common_arguments(module.params)
file_args['path'] = dest
result['changed'] = module.set_fs_attributes_if_different(file_args, False)
if result['changed']:
    module.exit_json(msg=""file already exists but file attributes changed"", **result)
module.exit_json(msg=""file already exists"", **result)
"
-------------------------------------------------------------------------
"if force and checksum != destination_checksum:
    os.remove(dest)
    module.fail_json(msg=""The checksum for %s did not match %s; it was %s."" % (dest, checksum, destination_checksum)

if not force and not checksum_mismatch:
    # Not forcing redownload, unless checksum does not match
    # allow file attribute changes
    module.params['path'] = dest
    file_args = module.load_file_common_arguments(module.params)
    file_args['path'] = dest
    changed = module.set_fs_attributes_if_different(file_args, False)
    if changed:
        module.exit_json(msg=""file already exists but file attributes changed"", dest=dest, url=url, changed=changed)
    module.exit_json(msg=""file already exists"", dest=dest, url=url, changed=changed)"
-------------------------------------------------------------------------
"if checksum != destination_checksum:
    checksum_mismatch = True
t forcing redownload, unless checksum does not match
ot force and not checksum_mismatch:
# Not forcing redownload, unless checksum does not match
# allow file attribute changes
module.params['path'] = dest
file_args = module.load_file_common_arguments(module.params)
file_args['path'] = dest
changed = module.set_fs_attributes_if_different(file_args, False)
if changed:
    module.exit_json(msg=""file already exists but file attributes changed"", dest=dest, url=url, changed=changed)
module.exit_json(msg=""file already exists"", dest=dest, url=url, changed=changed)
"
-------------------------------------------------------------------------
"Recom
PRs: 45495, 45565"
-------------------------------------------------------------------------
=========================================================================
"- The C(backup) argument will backup the current device's active
  in the playbook root directory or role root directory if the
  playbook is part of an ansible role. If the directory does not
  exist, it is created.
"
-------------------------------------------------------------------------
"- name: Backup the current active configuration
    edgeos_command:
      commands: backup"
-------------------------------------------------------------------------
"- The C(backup) argument will backup the current device's active
  in the playbook root directory or role root directory if the
  playbook is part of an ansible role. If the directory does not
  exist, it is created.
pe: bool
fault: 'no'
"
-------------------------------------------------------------------------
"Recom
PRs: 39530, 40548"
-------------------------------------------------------------------------
=========================================================================
"- ""To use this module, it has to be executed twice. Either as two
   different tasks in the same run or during two runs. Note that the output
   of the first run needs to be recorded and passed to the second run as the
   module argument C(data).""
   U(https://tools.ietf.org/html/draft-ietf-acme-acme-09#section-8).
   Also, consider the examples provided for this module.""
"
-------------------------------------------------------------------------
"# First run: start challenges / start new order
    client.start_challenges()"
-------------------------------------------------------------------------
"- ""To use this module, it has to be executed twice. Either as two
   different tasks in the same run or during two runs. Note that the output
   of the first run needs to be recorded and passed to the second run as the
   module argument C(data).""
"
-------------------------------------------------------------------------
"Recom
PRs: 38135, 38160"
-------------------------------------------------------------------------
=========================================================================
"# Copyright (c) 2018 Matt Martz <matt@sivel.net>
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
# -*- coding: utf-8 -*-
from __future__ import (absolute_import, division, print_function)
__metaclass__ = type
import pytest
from ansible.executor.module_common import modify_module
from ansible.module_utils.six import PY2
from test_module_common import templar
FAKE_OLD_MODULE = b'''#!/usr/bin/python
import sys
print('{""result"": ""%s""}' % sys.executable)
'''
@pytest.fixture
def fake_old_module_open(mocker):
    m = mocker.mock_open(read_data=FAKE_OLD_MODULE)
    if PY2:
        mocker.patch('__builtin__.open', m)
    else:
        mocker.patch('builtins.open', m)
def test_shebang(fake_old_module_open):
    (data, style, shebang) = modify_module('fake_module', 'fake_path', {})
    assert shebang == '#!/usr/bin/python'
def test_shebang_task_vars(fake_old_module_open, templar):
    task_vars = {
        'ansible_python_interpreter': '/usr/bin/python3'
    }
    (data, style, shebang) = modify_module('fake_module', 'fake_path', {}, task_vars=task_vars, templar=templar)
    assert shebang == '#!/usr/bin/python3'
"
-------------------------------------------------------------------------
"def fake_old_module_open(mocker):
    m = mocker.mock_open(read_data=FAKE_OLD_MODULE)
    if PY2:
        mocker.patch('ansible.executor.module_common.open', m)
    else:
        mocker.patch('builtins.open', m)

def test_shebang(fake_old_module_open):
    (data, style, shebang) = modify_module('fake_module', 'fake_path', {})
    assert shebang == '#!/usr/bin/python'

def test_shebang_task_vars(fake_old_module_open):
    task_vars = {
        'ansible_python_interpreter': '/usr/bin/python3'
    }

    (data, style, shebang) = modify_module('fake_module', 'fake_path', {}, task_vars=task_vars)
    assert shebang == '#!/usr/bin/python3'"
-------------------------------------------------------------------------
"# Copyright (c) 2018 Matt Martz <matt@sivel.net>
# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
# -*- coding: utf-8 -*-
from __future__ import (absolute_import, division, print_function)
__metaclass__ = type
import pytest
from ansible.executor.module_common import modify_module
from ansible.module_utils.six import PY2
FAKE_OLD_MODULE = b'''#!/usr/bin/python
import sys
print('{""result"": ""%s""}' % sys.executable)
'''
@pytest.fixture
def fake_old_module_open(mocker):
    m = mocker.mock_open(read_data=FAKE_OLD_MODULE)
    if PY2:
        mocker.patch('__builtin__.open', m)
    else:
        mocker.patch('builtins.open', m)
def test_shebang(fake_old_module_open):
    (data, style, shebang) = modify_module('fake_module', 'fake_path', {})
    assert shebang == '#!/usr/bin/python'
def test_shebang_task_vars(fake_old_module_open):
    task_vars = {
        'ansible_python_interpreter': '/usr/bin/python3'
    }
    (data, style, shebang) = modify_module('fake_module', 'fake_path', {}, task_vars=task_vars)
    assert shebang == '#!/usr/bin/python3'
"
-------------------------------------------------------------------------
"Recom
PRs: 36602, 36607"
-------------------------------------------------------------------------
=========================================================================
"new_ir = self._copy_included_file(included_file)
new_blocks, handler_blocks = new_ir.get_block_list(
"
-------------------------------------------------------------------------
"new_included_result = self._load_included_file(included_file, iterator)
new_blocks, handler_blocks = new_included_result.get_block_list("
-------------------------------------------------------------------------
"new_ir = self._copy_included_file(included_file)
"
-------------------------------------------------------------------------
"Recom
PRs: 36470, 36526"
-------------------------------------------------------------------------
=========================================================================
