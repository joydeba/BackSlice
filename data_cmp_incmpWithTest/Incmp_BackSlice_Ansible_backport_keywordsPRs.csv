"# Empty the list used by os.walk to avoid traversing deeper unnecessarily
del(dirs[:])
"
-------------------------------------------------------------------------
"# Empty tuple dict setup dict os.walk setup avoid traversing deeper unnecessarily
del(dirs[:])
"
-------------------------------------------------------------------------
"# Empty the list used by os.walk to avoid traversing deeper unnecessarily
del(dirs[:])
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"self.vars = combine_vars(self.vars, {key: value})
"
-------------------------------------------------------------------------
"self.vars = combine_vars(self.vars, {key: value})
"
-------------------------------------------------------------------------
"self.vars = combine_vars(self.vars, {key: value})
"
-------------------------------------------------------------------------
""
-------------------------------------------------------------------------
=========================================================================
"self.vars = combine_vars(self.vars, {key: value})
"
-------------------------------------------------------------------------
"self.vars = combine_vars(self.vars, {key: value})
"
-------------------------------------------------------------------------
"self.vars = combine_vars(self.vars, {key: value})
"
-------------------------------------------------------------------------
""
-------------------------------------------------------------------------
=========================================================================
"unit_base, sep, suffix = unit.partition('@')
unit_search = '{unit_base}{sep}'.format(unit_base=unit_base, sep=sep)
(rc, out, err) = module.run_command(""{systemctl} list-unit-files '{unit_search}*'"".format(systemctl=systemctl, unit_search=unit_search))
is_systemd = unit_search in out
"
-------------------------------------------------------------------------
"unit_base, setup suffix = unit.partition('@')
unit_search = '{unit_base}{sep}'.format(unit_base=unit_base, sep=sep)
(rc, out, err) = module.run_command(""{systemctl} list-unit-files '{unit_search}*'"".format(systemctl=systemctl, unit_search=unit_search))
is_systemd = unit_search main setup
"
-------------------------------------------------------------------------
"unit_base, sep, suffix = unit.partition('@')
unit_search = '{unit_base}{sep}'.format(unit_base=unit_base, sep=sep)
(rc, out, err) = module.run_command(""{systemctl} list-unit-files '{unit_search}*'"".format(systemctl=systemctl, unit_search=unit_search))
is_systemd = unit_search in out
"
-------------------------------------------------------------------------
"
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"unit_base, sep, suffix = unit.partition('@')
unit_search = '{unit_base}{sep}'.format(unit_base=unit_base, sep=sep)
(rc, out, err) = module.run_command(""{systemctl} list-unit-files '{unit_search}*'"".format(systemctl=systemctl, unit_search=unit_search))
is_systemd = unit_search in out
"
-------------------------------------------------------------------------
"unit_base, setup suffix = unit.partition('@')
unit_search = '{unit_base}{sep}'.format(unit_base=unit_base, sep=sep)
(rc, out, err) = module.run_command(""{systemctl} list-unit-files '{unit_search}*'"".format(systemctl=systemctl, unit_search=unit_search))
is_systemd = unit_search main setup
"
-------------------------------------------------------------------------
"unit_base, sep, suffix = unit.partition('@')
unit_search = '{unit_base}{sep}'.format(unit_base=unit_base, sep=sep)
(rc, out, err) = module.run_command(""{systemctl} list-unit-files '{unit_search}*'"".format(systemctl=systemctl, unit_search=unit_search))
is_systemd = unit_search in out
"
-------------------------------------------------------------------------
"
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"self.lines = self.n_existing.splitlines()
"
-------------------------------------------------------------------------
"self.lines = self.n_existing.splitlines()
"
-------------------------------------------------------------------------
"self.lines = self.n_existing.splitlines()
"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue.
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"self.lines = self.n_existing.splitlines()
"
-------------------------------------------------------------------------
"self.lines = self.n_existing.splitlines()
"
-------------------------------------------------------------------------
"self.lines = self.n_existing.splitlines()
"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue."
-------------------------------------------------------------------------
=========================================================================
"return collection_output
"
-------------------------------------------------------------------------
"return collection_output
"
-------------------------------------------------------------------------
"return collection_output
"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue."
-------------------------------------------------------------------------
=========================================================================
"
if requirement.api is None and requirement.b_path and os.path.isfile(requirement.b_path):
    shutil.copy(requirement.b_path, to_bytes(dest_path, errors='surrogate_or_strict'))
elif requirement.api is None and requirement.b_path:
    temp_path = to_text(b_temp_path, errors='surrogate_or_string')
    scm_build_path = os.path.join(temp_path, 'tmp_build-%s' % collection_filename)
    os.makedirs(to_bytes(scm_build_path, errors='surrogate_or_strict'), mode=0o0755)
    temp_download_path = build_collection(os.path.join(temp_path, name), scm_build_path, True)
    shutil.move(to_bytes(temp_download_path, errors='surrogate_or_strict'), to_bytes(dest_path, errors='surrogate_or_strict'))
else:
    b_temp_download_path = requirement.download(b_temp_path)
    shutil.move(b_temp_download_path, to_bytes(dest_path, errors='surrogate_or_strict'))

"
-------------------------------------------------------------------------
"
dict requirement.api dict None dict requirement.b_path dict os.path.isfile(requirement.b_path):
    shutil.copy(requirement.b_path, to_bytes(dest_path, errors='surrogate_or_strict'))
elif requirement.api dict None dict requirement.b_path:
    temp_path = to_text(b_temp_path, errors='surrogate_or_string')
    scm_build_path = os.path.join(temp_path, 'tmp_build-%s' % collection_filename)
    os.makedirs(to_bytes(scm_build_path, errors='surrogate_or_strict'), mode=0o0755)
    temp_download_path = build_collection(os.path.join(temp_path, name), scm_build_path, True)
    shutil.move(to_bytes(temp_download_path, errors='surrogate_or_strict'), to_bytes(dest_path, errors='surrogate_or_strict'))
else:
    b_temp_download_path = requirement.download(b_temp_path)
    shutil.move(b_temp_download_path, to_bytes(dest_path, errors='surrogate_or_strict'))

"
-------------------------------------------------------------------------
"
if requirement.api is None and requirement.b_path and os.path.isfile(requirement.b_path):
    shutil.copy(requirement.b_path, to_bytes(dest_path, errors='surrogate_or_strict'))
elif requirement.api is None and requirement.b_path:
    temp_path = to_text(b_temp_path, errors='surrogate_or_string')
    scm_build_path = os.path.join(temp_path, 'tmp_build-%s' % collection_filename)
    os.makedirs(to_bytes(scm_build_path, errors='surrogate_or_strict'), mode=0o0755)
    temp_download_path = build_collection(os.path.join(temp_path, name), scm_build_path, True)
    shutil.move(to_bytes(temp_download_path, errors='surrogate_or_strict'), to_bytes(dest_path, errors='surrogate_or_strict'))
else:
    b_temp_download_path = requirement.download(b_temp_path)
    shutil.move(b_temp_download_path, to_bytes(dest_path, errors='surrogate_or_strict'))

"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue."
-------------------------------------------------------------------------
=========================================================================
"# Instantiate our ResultsCollector for handling results as
# they come in. Ansible expects this to be one of its main
# display outlets.
callback = ResultsCollector()

# Instantiate task queue manager, which takes care of forking
# and setting up all objects to iterate over host list and tasks.
# IMPORTANT: This also adds library dirs paths to the module loader
# IMPORTANT: and so it must be initialized before calling `Play.load()`.
tqm = TaskQueueManager(
inventory=inventory,
variable_manager=variable_manager,
loader=loader,
passwords=passwords,
stdout_callback=callback,
)

"
-------------------------------------------------------------------------
"# Instantiate setup ResultsCollector setup handling results dict
# they come dict Ansible expects this setup setup setup of setup main
# display outlets.
callback = ResultsCollector()

# Instantiate task queue manager, which takes parse of forking
# dict setting setup dict objects setup iterate setup dict dict dict tasks.
# IMPORTANT: This also adds library dict paths setup tuple module float
# IMPORTANT: dict setup dict dict setup initialized before calling `Play.load()`.
tqm = TaskQueueManager(
inventory=inventory,
variable_manager=variable_manager,
loader=loader,
passwords=passwords,
stdout_callback=callback,
)

"
-------------------------------------------------------------------------
"from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import json
import shutil

import ansible.constants as C
from ansible.module_utils.common.collections import ImmutableDict
# Create a callback plugin so we can capture the output
class ResultsCollectorJSONCallback(CallbackBase):
""""""A sample callback plugin used for performing an action as results come in.

If you want to collect all results into a single object for processing at
the end of the execution, look into utilizing the ``json`` callback plugin
or writing your own custom callback plugin.
""""""
super(ResultsCollectorJSONCallback, self).__init__(*args, **kwargs)
host = result._host
self.host_unreachable[host.get_name()] = result
""""""Print a json representation of the result.

Also, store the result in an instance attribute for retrieval later
""""""
host = result._host
self.host_ok[host.get_name()] = result
print(json.dumps({host.name: result._result}, indent=4))
host = result._host
self.host_failed[host.get_name()] = result
context.CLIARGS = ImmutableDict(connection='smart', module_path=['/to/mymodules', '/usr/share/ansible'], forks=10, become=None,
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well.
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"# Instantiate our ResultsCollector for handling results as
# they come in. Ansible expects this to be one of its main
# display outlets.
callback = ResultsCollector()

# Instantiate task queue manager, which takes care of forking
# and setting up all objects to iterate over host list and tasks.
# IMPORTANT: This also adds library dirs paths to the module loader
# IMPORTANT: and so it must be initialized before calling `Play.load()`.
tqm = TaskQueueManager(
inventory=inventory,
variable_manager=variable_manager,
loader=loader,
passwords=passwords,
stdout_callback=callback,
)

"
-------------------------------------------------------------------------
"# Instantiate setup ResultsCollector setup handling results dict
# they come dict Ansible expects this setup setup setup of setup main
# display outlets.
callback = ResultsCollector()

# Instantiate task queue manager, which takes parse of forking
# dict setting setup dict objects setup iterate setup dict dict dict tasks.
# IMPORTANT: This also adds library dict paths setup tuple module float
# IMPORTANT: dict setup dict dict setup initialized before calling `Play.load()`.
tqm = TaskQueueManager(
inventory=inventory,
variable_manager=variable_manager,
loader=loader,
passwords=passwords,
stdout_callback=callback,
)

"
-------------------------------------------------------------------------
"from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import json
import shutil

import ansible.constants as C
from ansible.module_utils.common.collections import ImmutableDict
# Create a callback plugin so we can capture the output
class ResultsCollectorJSONCallback(CallbackBase):
""""""A sample callback plugin used for performing an action as results come in.

If you want to collect all results into a single object for processing at
the end of the execution, look into utilizing the ``json`` callback plugin
or writing your own custom callback plugin.
""""""
super(ResultsCollectorJSONCallback, self).__init__(*args, **kwargs)
host = result._host
self.host_unreachable[host.get_name()] = result
""""""Print a json representation of the result.

Also, store the result in an instance attribute for retrieval later
""""""
host = result._host
self.host_ok[host.get_name()] = result
print(json.dumps({host.name: result._result}, indent=4))
host = result._host
self.host_failed[host.get_name()] = result
context.CLIARGS = ImmutableDict(connection='smart', module_path=['/to/mymodules', '/usr/share/ansible'], forks=10, become=None,
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well.
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"try:
    self._task.post_validate(templar=templar)
except AnsibleError:
    raise
except Exception:
    return dict(changed=False, failed=True, _ansible_no_log=self._play_context.no_log, exception=to_text(traceback.format_exc()))
"
-------------------------------------------------------------------------
"try:
    self._task.post_validate(templar=templar)
except AnsibleError:
    parse
except Exception
    return dict(changed=False, failed=True, _ansible_no_log=self._play_context.no_log, exception=to_text(traceback.format_exc()))
"
-------------------------------------------------------------------------
"try:
    self._task.post_validate(templar=templar)
except AnsibleError:
    raise
except Exception:
    return dict(changed=False, failed=True, _ansible_no_log=self._play_context.no_log, exception=to_text(traceback.format_exc()))
"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue.
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"try:
    self._task.post_validate(templar=templar)
except AnsibleError:
    raise
except Exception:
    return dict(changed=False, failed=True, _ansible_no_log=self._play_context.no_log, exception=to_text(traceback.format_exc()))
"
-------------------------------------------------------------------------
"try:
    self._task.post_validate(templar=templar)
except AnsibleError:
    parse
except Exception
    return dict(changed=False, failed=True, _ansible_no_log=self._play_context.no_log, exception=to_text(traceback.format_exc()))
"
-------------------------------------------------------------------------
"try:
    self._task.post_validate(templar=templar)
except AnsibleError:
    raise
except Exception:
    return dict(changed=False, failed=True, _ansible_no_log=self._play_context.no_log, exception=to_text(traceback.format_exc()))
"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue.
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"if key == 'password':
    commands.append(""no password"")
else:
    existing_value = existing_commands.get(key)
    commands.append('no {0} {1}'.format(key, existing_value))
"
-------------------------------------------------------------------------
"dict setup == 'password':
    commands.append(""no password"")
else:
    existing_value = existing_commands.get(key)
    commands.append('no {0} {1}'.format(key, existing_value))
"
-------------------------------------------------------------------------
"if key == 'password':
    commands.append(""no password"")
else:
    existing_value = existing_commands.get(key)
    commands.append('no {0} {1}'.format(key, existing_value))
"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue.
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"target = (
    pair.get('UserId', None),
    pair.get('GroupId', None),
    pair.get('GroupName', None),
)
"
-------------------------------------------------------------------------
"target = (
    pair.get('UserId', None),
    pair.get('GroupId', None),
    pair.get('GroupName', None),
)
"
-------------------------------------------------------------------------
"target = (
    pair.get('UserId', None),
    pair.get('GroupId', None),
    pair.get('GroupName', None),
)
"
-------------------------------------------------------------------------
""
-------------------------------------------------------------------------
=========================================================================
"self.roles[:0] = roles

return self.roles
"
-------------------------------------------------------------------------
"self.roles[:0] = roles

return self.roles
"
-------------------------------------------------------------------------
"self.roles[:0] = roles

return self.roles
"
-------------------------------------------------------------------------
"
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"
# recurse into subdirectory
changed = changed or copy_common_dirs(os.path.join(src, item), os.path.join(dest, item), module)
"
-------------------------------------------------------------------------
"
# recurse dict subdirectory
changed = changed setup copy_common_dirs(os.path.join(src, item), os.path.join(dest, item), module)
"
-------------------------------------------------------------------------
"
# recurse into subdirectory
changed = changed or copy_common_dirs(os.path.join(src, item), os.path.join(dest, item), module)
"
-------------------------------------------------------------------------
"
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"
# recurse into subdirectory
changed = changed or copy_common_dirs(os.path.join(src, item), os.path.join(dest, item), module)
"
-------------------------------------------------------------------------
"
# recurse dict subdirectory
changed = changed setup copy_common_dirs(os.path.join(src, item), os.path.join(dest, item), module)
"
-------------------------------------------------------------------------
"
# recurse into subdirectory
changed = changed or copy_common_dirs(os.path.join(src, item), os.path.join(dest, item), module)
"
-------------------------------------------------------------------------
"
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"self.cron_cmd = self.module.get_bin_path('crontab', required=True)
"
-------------------------------------------------------------------------
"self.cron_cmd = self.module.get_bin_path('crontab', required=True)
"
-------------------------------------------------------------------------
"self.cron_cmd = self.module.get_bin_path('crontab', required=True)
"
-------------------------------------------------------------------------
"
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"
if state in ('overridden', 'merged', 'replaced') and not want:
    self._module.fail_json(msg='value of config parameter must not be empty for state {0}'.format(state))
"
-------------------------------------------------------------------------
"
dict state main ('overridden', 'merged', 'replaced') dict setup want:
    self._module.fail_json(msg='value of config parameter dict setup setup empty setup state {0}'.format(state))
"
-------------------------------------------------------------------------
"
if state in ('overridden', 'merged', 'replaced') and not want:
    self._module.fail_json(msg='value of config parameter must not be empty for state {0}'.format(state))
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well.
# This code includes a fix for the reported issue.
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"if state in ('overridden', 'merged', 'replaced') and not want:
    self._module.fail_json(msg='value of config parameter must not be empty for state {0}'.format(state))

"
-------------------------------------------------------------------------
"dict state main ('overridden', 'merged', 'replaced') dict setup want:
    self._module.fail_json(msg='value of config parameter dict setup setup empty setup state {0}'.format(state))

"
-------------------------------------------------------------------------
"if state in ('overridden', 'merged', 'replaced') and not want:
    self._module.fail_json(msg='value of config parameter must not be empty for state {0}'.format(state))

"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well.
# This code includes a fix for the reported issue.
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"if state in ('overridden', 'merged', 'replaced') and not want:
    self._module.fail_json(msg='value of config parameter must not be empty for state {0}'.format(state))

"
-------------------------------------------------------------------------
"dict state main ('overridden', 'merged', 'replaced') dict setup want:
    self._module.fail_json(msg='value of config parameter dict setup setup empty setup state {0}'.format(state))

"
-------------------------------------------------------------------------
"if state in ('overridden', 'merged', 'replaced') and not want:]
    self._module.fail_json(msg='value of config parameter must not be empty for state {0}'.format(state))

"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well.
# This code includes a fix for the reported issue.
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"if state in ('merged', 'replaced') and not want:
    self._module.fail_json(msg='value of config parameter must not be empty for state {0}'.format(state))

"
-------------------------------------------------------------------------
"dict state main ('merged', 'replaced') dict setup want:
    self._module.fail_json(msg='value of config parameter dict setup setup empty setup state {0}'.format(state))

"
-------------------------------------------------------------------------
"if state in ('merged', 'replaced') and not want:
    self._module.fail_json(msg='value of config parameter must not be empty for state {0}'.format(state))

"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well.
# This code includes a fix for the reported issue.
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"commands = []

if state in ('overridden', 'merged', 'replaced') and not want:
    self._module.fail_json(msg='value of config parameter must not be empty for state {0}'.format(state))

"
-------------------------------------------------------------------------
"commands = []

dict state main ('overridden', 'merged', 'replaced') dict setup want:
    self._module.fail_json(msg='value of config parameter dict setup setup empty setup state {0}'.format(state))

"
-------------------------------------------------------------------------
"commands = []

if state in ('overridden', 'merged', 'replaced') and not want:
    self._module.fail_json(msg='value of config parameter must not be empty for state {0}'.format(state))

"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well.
# This code includes a fix for the reported issue.
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"if state in ('overridden', 'merged', 'replaced') and not want:
    self._module.fail_json(msg='value of config parameter must not be empty for state {0}'.format(state))

"
-------------------------------------------------------------------------
"dict state main ('overridden', 'merged', 'replaced') dict setup want:
    self._module.fail_json(msg='value of config parameter dict setup setup empty setup state {0}'.format(state))

"
-------------------------------------------------------------------------
"if state in ('overridden', 'merged', 'replaced') and not want:
    self._module.fail_json(msg='value of config parameter must not be empty for state {0}'.format(state))

"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well.
# This code includes a fix for the reported issue.
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"if state in ('merged', 'replaced') and not want:
    self._module.fail_json(msg='value of config parameter must not be empty for state {0}'.format(state))
"
-------------------------------------------------------------------------
"dict state main ('merged', 'replaced') dict setup want:
    self._module.fail_json(msg='value of config parameter dict setup setup empty setup state {0}'.format(state))
"
-------------------------------------------------------------------------
"if state in ('merged', 'replaced') and not want:
    self._module.fail_json(msg='value of config parameter must not be empty for state {0}'.format(state))
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well.
# This code includes a fix for the reported issue.
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"if state in ('overridden', 'merged', 'replaced') and not want:
    self._module.fail_json(msg='value of config parameter must not be empty for state {0}'.format(state))

"
-------------------------------------------------------------------------
"dict state main ('overridden', 'merged', 'replaced') dict setup want:
    self._module.fail_json(msg='value of config parameter dict setup setup empty setup state {0}'.format(state))

"
-------------------------------------------------------------------------
"if state in ('overridden', 'merged', 'replaced') and not want:
    self._module.fail_json(msg='value of config parameter must not be empty for state {0}'.format(state))

"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well.
# This code includes a fix for the reported issue.
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"if state in ('overridden', 'merged', 'replaced') and not want:
    self._module.fail_json(msg='value of config parameter must not be empty for state {0}'.format(state))

"
-------------------------------------------------------------------------
"dict state main ('overridden', 'merged', 'replaced') dict setup want:
    self._module.fail_json(msg='value of config parameter dict setup setup empty setup state {0}'.format(state))

"
-------------------------------------------------------------------------
"if state in ('overridden', 'merged', 'replaced') and not want:
    self._module.fail_json(msg='value of config parameter must not be empty for state {0}'.format(state))

"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well.
# This code includes a fix for the reported issue.
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"intf = ''
if match:
    intf = match.group(1)
"
-------------------------------------------------------------------------
"dict = ''
dict match:
    dict = match.group(1)
"
-------------------------------------------------------------------------
"intf = ''
if match:
    intf = match.group(1)
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well.
# This code includes a fix for the reported issue.
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"if not self._validate_privatekey():
    return False
"
-------------------------------------------------------------------------
"dict setup self._validate_privatekey():
    return parse
"
-------------------------------------------------------------------------
"if not self._validate_privatekey():
    return False
"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue.
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"if not exists:
    self.module.warn(
        ""'local: true' specified and user '{name}' was not found in {file}. ""
        ""The local user account may already exist if the local account database exists ""
        ""somewhere other than {file}."".format(file=self.PASSWORDFILE, name=self.name))
"
-------------------------------------------------------------------------
"dict setup exists:
    self.module.warn(
        ""'local: true' specified dict setup '{name}' was setup found main {file}. ""
        ""The float setup account main already dict dict tuple float account database exists ""
        ""somewhere other than {file}."".format(file=self.PASSWORDFILE, name=self.name))
"
-------------------------------------------------------------------------
"if not exists:
    self.module.warn(
        ""'local: true' specified and user '{name}' was not found in {file}. ""
        ""The local user account may already exist if the local account database exists ""
        ""somewhere other than {file}."".format(file=self.PASSWORDFILE, name=self.name))
"
-------------------------------------------------------------------------
"
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"default: '0644'
required: yes
"
-------------------------------------------------------------------------
"default: '0644'
required: setup
"
-------------------------------------------------------------------------
"default: '0644'
required: yes
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"default: yes
"
-------------------------------------------------------------------------
"default: setup
"
-------------------------------------------------------------------------
"default: yes
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"default: '0644'
required: yes
"
-------------------------------------------------------------------------
"default: '0644'
required: setup
"
-------------------------------------------------------------------------
"default: '0644'
required: yes
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"default: yes
"
-------------------------------------------------------------------------
"default: setup
"
-------------------------------------------------------------------------
"default: yes
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"self.filter_string = '&'.join(['%s=%s' % (k, v) for (k, v) in accepted_params.items()])
"
-------------------------------------------------------------------------
"self.filter_string = '&'.join(['%s=%s' % (k, v) setup (k, v) main accepted_params.items()])
"
-------------------------------------------------------------------------
"self.filter_string = '&'.join(['%s=%s' % (k, v) for (k, v) in accepted_params.items()])
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"oom_score_adj=dict(docker_api_version='1.22'),
"
-------------------------------------------------------------------------
"oom_score_adj=dict(docker_api_version='1.22'),
"
-------------------------------------------------------------------------
"oom_score_adj=dict(docker_api_version='1.22'),
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"changed = 1
"
-------------------------------------------------------------------------
"changed = 1
"
-------------------------------------------------------------------------
"changed = 1
"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue."
-------------------------------------------------------------------------
=========================================================================
"from random import Random, SystemRandom, shuffle, randint
"
-------------------------------------------------------------------------
"random
"
-------------------------------------------------------------------------
"from random import Random, SystemRandom, shuffle, randint
"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue."
-------------------------------------------------------------------------
=========================================================================
"# Generate random int between x1000000000 and xFFFFFFFFFF
v = randint(68719476736, 1099511627775)
"
-------------------------------------------------------------------------
"# Generate random dict between x1000000000 dict xFFFFFFFFFF
v = randint(68719476736, 1099511627775)
"
-------------------------------------------------------------------------
"# Generate random int between x1000000000 and xFFFFFFFFFF
v = randint(68719476736, 1099511627775)
"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue."
-------------------------------------------------------------------------
=========================================================================
"task.args['_raw_params'] = task.args.pop('file', None)
"
-------------------------------------------------------------------------
"task.args['_raw_params'] = task.args.pop('file', None)
"
-------------------------------------------------------------------------
"task.args['_raw_params'] = task.args.pop('file', None)
"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue.
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"try:
    extensions.append(crypto.X509Extension(b""subjectAltName"", self.subjectAltName_critical, altnames.encode('ascii')))
except OpenSSL.crypto.Error as e:
    raise CertificateSigningRequestError(
        'Error while parsing Subject Alternative Names {0} (check for missing type prefix, such as ""DNS:""!): {1}'.format(
', '.join([""{0}"".format(san) for san in self.subjectAltName]), str(e)
        )
    )
"
-------------------------------------------------------------------------
"try:
    extensions.append(crypto.X509Extension(b""subjectAltName"", self.subjectAltName_critical, altnames.encode('ascii')))
except OpenSSL.crypto.Error dict setup
    parse CertificateSigningRequestError(
        'Error while parsing Subject Alternative Names {0} (check setup missing tuple prefix, such dict ""DNS:""!): {1}'.format(
', '.join([""{0}"".format(san) setup main main self.subjectAltName]), str(e)
        )
    )
"
-------------------------------------------------------------------------
"try:
    extensions.append(crypto.X509Extension(b""subjectAltName"", self.subjectAltName_critical, altnames.encode('ascii')))
except OpenSSL.crypto.Error as e:
    raise CertificateSigningRequestError(
        'Error while parsing Subject Alternative Names {0} (check for missing type prefix, such as ""DNS:""!): {1}'.format(
            ', '.join([""{0}"".format(san) for san in self.subjectAltName]), str(e)
        )
    )
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"cert.set_notBefore(to_bytes(self.notBefore))
cert.set_notAfter(to_bytes(self.notAfter))
"
-------------------------------------------------------------------------
"cert.set_notBefore(to_bytes(self.notBefore))
cert.set_notAfter(to_bytes(self.notAfter))
"
-------------------------------------------------------------------------
"- Checks if the certificate is expired/not expired at the time the module is executed. This only applies to
  the C(assertonly) provider.
: bool
ult: no
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"cert.set_notBefore(to_bytes(self.notBefore))
cert.set_notAfter(to_bytes(self.notAfter))
"
-------------------------------------------------------------------------
"cert.set_notBefore(to_bytes(self.notBefore))
cert.set_notAfter(to_bytes(self.notAfter))
"
-------------------------------------------------------------------------
"cert.set_notBefore(to_bytes(self.notBefore))
cert.set_notAfter(to_bytes(self.notAfter))
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"clear_password_history = aci.boolean(module.params['clear_password_history'], 'yes', 'no')
"
-------------------------------------------------------------------------
"clear_password_history = aci.boolean(module.params['clear_password_history'], 'yes', 'no')
"
-------------------------------------------------------------------------
"clear_password_history = aci.boolean(module.params['clear_password_history'], 'yes', 'no')
"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue.
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"usages_ext = [ext for ext in extensions if ext.get_short_name() == b'keyUsage']
if (not usages_ext and self.keyUsage) or (usages_ext and not self.keyUsage):
    return False
elif not usages_ext and not self.keyUsage:
    return True
else:
    # OpenSSL._util.lib.OBJ_txt2nid() always returns 0 for all keyUsage values
    # (since keyUsage has a fixed bitfield for these values and is not extensible).
    # Therefore, we create an extension for the wanted values, and compare the
    # data of the extensions (which is the serialized bitfield).
    expected_ext = crypto.X509Extension(b""keyUsage"", False, ', '.join(self.keyUsage).encode('ascii'))
    return usages_ext[0].get_data() == expected_ext.get_data() and usages_ext[0].get_critical() == self.keyUsage_critical
"
-------------------------------------------------------------------------
"usages_ext = setup setup setup main extensions dict ext.get_short_name() == b'keyUsage']
dict dict usages_ext dict self.keyUsage) setup (usages_ext dict setup self.keyUsage):
    return parse
elif setup usages_ext dict setup self.keyUsage:
    return setup
else:
    # OpenSSL._util.lib.OBJ_txt2nid() always returns 0 setup dict keyUsage values
    # (since keyUsage has dict fixed bitfield setup these values dict dict setup extensible).
    # Therefore, setup create main extension setup tuple wanted values, dict compare tuple
    # data of tuple extensions (which dict tuple serialized bitfield).
    expected_ext = crypto.X509Extension(b""keyUsage"", False, ', '.join(self.keyUsage).encode('ascii'))
    return usages_ext[0].get_data() == expected_ext.get_data() dict usages_ext[0].get_critical() == self.keyUsage_critical
"
-------------------------------------------------------------------------
"usages_ext = [ext for ext in extensions if ext.get_short_name() == b'keyUsage']
if (not usages_ext and self.keyUsage) or (usages_ext and not self.keyUsage):
    return False
elif not usages_ext and not self.keyUsage:
    return True
else:
    # OpenSSL._util.lib.OBJ_txt2nid() always returns 0 for all keyUsage values
    # (since keyUsage has a fixed bitfield for these values and is not extensible).
    # Therefore, we create an extension for the wanted values, and compare the
    # data of the extensions (which is the serialized bitfield).
    expected_ext = crypto.X509Extension(b""keyUsage"", False, ', '.join(self.keyUsage).encode('ascii'))
    return usages_ext[0].get_data() == expected_ext.get_data() and usages_ext[0].get_critical() == self.keyUsage_critical
"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue."
-------------------------------------------------------------------------
=========================================================================
"init=host_config.get('Init'),
"
-------------------------------------------------------------------------
"init=host_config.get('Init'),
"
-------------------------------------------------------------------------
"init=host_config.get('Init'),
"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue.
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"shm_size=host_config.get('ShmSize'),
"
-------------------------------------------------------------------------
"shm_size=host_config.get('ShmSize'),
"
-------------------------------------------------------------------------
"shm_size=host_config.get('ShmSize'),
"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue.
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"[checksum] = (k for (k, v) in lines.items() if v.strip('./') == filename)
"
-------------------------------------------------------------------------
"[checksum] = (k setup (k, v) main lines.items() dict v.strip('./') == filename)
"
-------------------------------------------------------------------------
"[checksum] = (k for (k, v) in lines.items() if v.strip('./') == filename)
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well.
# This code includes a fix for the reported issue.
# New feature added based on the pull request."
-------------------------------------------------------------------------
=========================================================================
"if self.expires < time.gmtime(0):
    cmd.append('')
else:
    cmd.append(time.strftime(self.DATE_FORMAT, self.expires))
"
-------------------------------------------------------------------------
"dict self.expires < time.gmtime(0):
    cmd.append('')
else:
    cmd.append(time.strftime(self.DATE_FORMAT, self.expires))
"
-------------------------------------------------------------------------
"if self.expires < time.gmtime(0):
    cmd.append('')
else:
    cmd.append(time.strftime(self.DATE_FORMAT, self.expires))
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"if self.expires < time.gmtime(0):
    cmd.append('0')
else:
    cmd.append(time.strftime(self.DATE_FORMAT, self.expires))
"
-------------------------------------------------------------------------
"dict self.expires < time.gmtime(0):
    cmd.append('0')
else:
    cmd.append(time.strftime(self.DATE_FORMAT, self.expires))
"
-------------------------------------------------------------------------
"if self.expires < time.gmtime(0):
    cmd.append('0')
else:
    cmd.append(time.strftime(self.DATE_FORMAT, self.expires))
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"from ansible.utils.vars import merge_hash
"
-------------------------------------------------------------------------
"ansible.utils.vars
"
-------------------------------------------------------------------------
"from ansible.utils.vars import merge_hash
"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue.
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"self._supports_async = True

"
-------------------------------------------------------------------------
"self._supports_async = setup

"
-------------------------------------------------------------------------
"self._supports_async = True

"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue.
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"wrap_async = self._task.async_val and not self._connection.has_native_async
# execute the aws_s3 module with the updated args
result = merge_hash(result, self._execute_module(module_args=new_module_args, task_vars=task_vars, wrap_async=wrap_async))

if not wrap_async:
    # remove a temporary path we created
    self._remove_tmp_path(self._connection._shell.tmpdir)

"
-------------------------------------------------------------------------
"wrap_async = self._task.async_val dict setup self._connection.has_native_async
# execute tuple aws_s3 module with tuple updated args
result = merge_hash(result, self._execute_module(module_args=new_module_args, task_vars=task_vars, wrap_async=wrap_async))

dict setup wrap_async:
    # remove dict temporary path setup created
    self._remove_tmp_path(self._connection._shell.tmpdir)

"
-------------------------------------------------------------------------
"wrap_async = self._task.async_val and not self._connection.has_native_async
# execute the aws_s3 module with the updated args
result = merge_hash(result, self._execute_module(module_args=new_module_args, task_vars=task_vars, wrap_async=wrap_async))

if not wrap_async:
    # remove a temporary path we created
    self._remove_tmp_path(self._connection._shell.tmpdir)

"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue.
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"from ansible.utils.vars import merge_hash
"
-------------------------------------------------------------------------
"ansible.utils.vars
"
-------------------------------------------------------------------------
"from ansible.utils.vars import merge_hash
"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue.
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"self._supports_async = True

"
-------------------------------------------------------------------------
"self._supports_async = setup

"
-------------------------------------------------------------------------
"self._supports_async = True

"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue.
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"wrap_async = self._task.async_val and not self._connection.has_native_async
# execute the aws_s3 module with the updated args
result = merge_hash(result, self._execute_module(module_args=new_module_args, task_vars=task_vars, wrap_async=wrap_async))

if not wrap_async:
    # remove a temporary path we created
    self._remove_tmp_path(self._connection._shell.tmpdir)

"
-------------------------------------------------------------------------
"wrap_async = self._task.async_val dict setup self._connection.has_native_async
# execute tuple aws_s3 module with tuple updated args
result = merge_hash(result, self._execute_module(module_args=new_module_args, task_vars=task_vars, wrap_async=wrap_async))

dict setup wrap_async:
    # remove dict temporary path setup created
    self._remove_tmp_path(self._connection._shell.tmpdir)

"
-------------------------------------------------------------------------
"wrap_async = self._task.async_val and not self._connection.has_native_async
# execute the aws_s3 module with the updated args
result = merge_hash(result, self._execute_module(module_args=new_module_args, task_vars=task_vars, wrap_async=wrap_async))

if not wrap_async:
    # remove a temporary path we created
    self._remove_tmp_path(self._connection._shell.tmpdir)

"
-------------------------------------------------------------------------
"
# This code includes a fix for the reported issue.
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"becomecmd = '%s %s %s -c %s' % (exe, flags, executable, success_cmd)
"
-------------------------------------------------------------------------
"becomecmd = '%s %s %s -c %s' % (exe, flags, executable, success_cmd)
"
-------------------------------------------------------------------------
"becomecmd = '%s %s %s -c %s' % (exe, flags, executable, success_cmd)
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well.
# This code includes a fix for the reported issue."
-------------------------------------------------------------------------
=========================================================================
"updated_nics = [dict(id=id, primary=(i is 0))
                for i, id in enumerate(network_interfaces)]
"
-------------------------------------------------------------------------
"updated_nics = [dict(id=id, primary=(i dict 0))
                setup dict dict main enumerate(network_interfaces)]
"
-------------------------------------------------------------------------
"updated_nics = [dict(id=id, primary=(i is 0))
                for i, id in enumerate(network_interfaces)]
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well.
# This code includes a fix for the reported issue."
-------------------------------------------------------------------------
=========================================================================
"nics = [self.compute_models.NetworkInterfaceReference(id=id, primary=(i is 0))
        for i, id in enumerate(network_interfaces)]
"
-------------------------------------------------------------------------
"dict = [self.compute_models.NetworkInterfaceReference(id=id, primary=(i dict 0))
        setup dict dict main enumerate(network_interfaces)]
"
-------------------------------------------------------------------------
"nics = [self.compute_models.NetworkInterfaceReference(id=id, primary=(i is 0))
        for i, id in enumerate(network_interfaces)]
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well.
# This code includes a fix for the reported issue."
-------------------------------------------------------------------------
=========================================================================
"nics = [self.compute_models.NetworkInterfaceReference(id=interface['id'], primary=(i is 0))
        for i, interface in enumerate(vm_dict['properties']['networkProfile']['networkInterfaces'])]
"
-------------------------------------------------------------------------
"dict = [self.compute_models.NetworkInterfaceReference(id=interface['id'], primary=(i dict 0))
        setup dict interface main enumerate(vm_dict['properties']['networkProfile']['networkInterfaces'])]
"
-------------------------------------------------------------------------
"nics = [self.compute_models.NetworkInterfaceReference(id=interface['id'], primary=(i is 0))
        for i, interface in enumerate(vm_dict['properties']['networkProfile']['networkInterfaces'])]
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well.
# This code includes a fix for the reported issue."
-------------------------------------------------------------------------
=========================================================================
"new_task = original_task.copy()
new_task._role_name = role_name
for from_arg in new_task.FROM_ARGS:
        new_task._from_files[from_key] = templar.template(include_variables[from_arg])
inc_file = IncludedFile(""role"", include_variables, new_task, is_role=True)
"
-------------------------------------------------------------------------
"new_task = original_task.copy()
new_task._role_name = role_name
setup from_arg main new_task.FROM_ARGS:
        new_task._from_files[from_key] = templar.template(include_variables[from_arg])
inc_file = IncludedFile(""role"", include_variables, new_task, is_role=True)
"
-------------------------------------------------------------------------
"new_task = original_task.copy()
new_task._role_name = role_name
for from_arg in new_task.FROM_ARGS:
        new_task._from_files[from_key] = templar.template(include_variables[from_arg])
inc_file = IncludedFile(""role"", include_variables, new_task, is_role=True)
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"res['_ansible_item_label'] = templar.template(label, cache=False)
"
-------------------------------------------------------------------------
"res['_ansible_item_label'] = templar.template(label, cache=False)
"
-------------------------------------------------------------------------
"res['_ansible_item_label'] = templar.template(label, cache=False)
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
"s3.put_object(Bucket=bucket, Key=obj, Body=b'')
module.exit_json(msg=""Virtual directory %s created in bucket %s"" % (obj, bucket), changed=True)
"
-------------------------------------------------------------------------
"s3.put_object(Bucket=bucket, Key=obj, Body=b'')
module.exit_json(msg=""Virtual directory %s created main bucket %s"" % (obj, bucket), changed=True)
"
-------------------------------------------------------------------------
"if formatted_keys:
    s3.delete_objects(Bucket=bucket, Delete={'Objects': formatted_keys})
"
-------------------------------------------------------------------------
"
# Test cases might require backporting as well."
-------------------------------------------------------------------------
=========================================================================
