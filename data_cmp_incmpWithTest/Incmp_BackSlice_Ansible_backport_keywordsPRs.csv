"VERSION = '2.10'
"
-------------------------------------------------------------------------
"VERSION = '2.10'
"
-------------------------------------------------------------------------
"exclude_patterns = [
'2.10_index.rst',
'ansible_index.rst',
'core_index.rst',
'porting_guides/core_porting_guides',

"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 73616, 73637"
-------------------------------------------------------------------------
=========================================================================
"# -*- coding: utf-8 -*-
#
# documentation build configuration file, created by
# sphinx-quickstart on Sat Sep 27 13:23:22 2008-2009.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# The contents of this file are pickled, so don't put values in the namespace
# that aren't pickleable (module imports are okay, they're removed
# automatically).
#
# All configuration values have a default value; values that are commented out
# serve to show the default value.

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import sys
import os

# pip install sphinx_rtd_theme
# import sphinx_rtd_theme
# html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]

# If your extensions are in another directory, add it here. If the directory
# is relative to the documentation root, use os.path.abspath to make it
# absolute, like shown here.
# sys.path.append(os.path.abspath('some/directory'))
#
sys.path.insert(0, os.path.join('ansible', 'lib'))
sys.path.append(os.path.abspath(os.path.join('..', '_extensions')))

# We want sphinx to document the ansible modules contained in this repository,
# not those that may happen to be installed in the version
# of Python used to run sphinx.  When sphinx loads in order to document,
# the repository version needs to be the one that is loaded:
sys.path.insert(0, os.path.abspath(os.path.join('..', '..', '..', 'lib')))

VERSION = 'devel'
AUTHOR = 'Ansible, Inc'


# General configuration
# ---------------------

# Add any Sphinx extension module names here, as strings.
# They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
# TEST: 'sphinxcontrib.fulltoc'
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.intersphinx', 'pygments_lexer', 'notfound.extension']

# Later on, add 'sphinx.ext.viewcode' to the list if you want to have
# colorized code generated too for references.


# Add any paths that contain templates here, relative to this directory.
templates_path = ['.templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The master toctree document.
master_doc = 'index'

# General substitutions.
project = 'Ansible'
copyright = ""2021 Red Hat, Inc.""

# The default replacements for |version| and |release|, also used in various
# other places throughout the built documents.
#
# The short X.Y version.
version = VERSION
# The full version, including alpha/beta/rc tags.
release = VERSION

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
# today = ''
# Else, today_fmt is used as the format for a strftime call.
today_fmt = '%B %d, %Y'

# List of documents that shouldn't be included in the build.
# unused_docs = []

# List of directories, relative to source directories, that shouldn't be
# searched for source files.
# exclude_dirs = []

# A list of glob-style patterns that should be excluded when looking
# for source files.
exclude_patterns = [
'2.10_index.rst',
'ansible_index.rst',
'core_index.rst',
'porting_guides/core_porting_guides.rst',
'porting_guides/porting_guide_base_2.10.rst',
'porting_guides/porting_guide_core_2.11.rst',
'roadmap/index.rst',
'roadmap/ansible_base_roadmap_index.rst',
'roadmap/ROADMAP_2_10.rst',
'roadmap/ROADMAP_2_11.rst'


e reST default role (used for this markup: `text`) to use for all
cuments.
fault_role = None

 true, '()' will be appended to :func: etc. cross-reference text.
d_function_parentheses = True

 true, the current module name will be prepended to all description
it titles (such as .. function::).
d_module_names = True

 true, sectionauthor and moduleauthor directives will be shown in the
tput. They are ignored by default.
ow_authors = False

e name of the Pygments (syntax highlighting) style to use.
ents_style = 'sphinx'

light_language = 'YAMLJinja'

bstitutions, variables, entities, & shortcuts for text which do not need to link to anything.
r titles which should be a link, use the intersphinx anchors set at the index, chapter, and section levels, such as  qi_start_:
r| is useful for formatting fields inside of tables
| is a nonbreaking space; similarly useful inside of tables
epilog = """"""
br| raw:: html

br>
_| unicode:: 0xA0
:trim:



tions for HTML output
---------------------

_theme_path = ['../_themes']
_theme = 'sphinx_rtd_theme'
_short_title = 'Ansible Documentation'
_show_sphinx = False

_theme_options = {
'canonical_url': ""https://docs.ansible.com/ansible/latest/"",
'vcs_pageview_mode': 'edit'


_context = {
'display_github': 'True',
'github_user': 'ansible',
'github_repo': 'ansible',
'github_version': 'devel/docs/docsite/rst/',
'github_module_version': 'devel/lib/ansible/modules/',
'github_root_dir': 'devel/lib/ansible',
'github_cli_version': 'devel/lib/ansible/cli/',
'current_version': version,
'latest_version': '2.10',
# list specifically out of order to make latest work
'available_versions': ('latest', '2.9', '2.9_ja', '2.8', 'devel'),
'css_files': ('_static/ansible.css',  # overrides to the standard theme
  ),


e style sheet to use for HTML and HTML Help pages. A file of that name
st exist either in Sphinx' static/ path, or in one of the custom paths
ven in html_static_path.
ml_style = 'solar.css'

e name for this set of Sphinx documents.  If None, it defaults to
project> v<release> documentation"".
_title = 'Ansible Documentation'

shorter title for the navigation bar.  Default is the same as html_title.
ml_short_title = None

e name of an image file (within the static path) to place at the top of
e sidebar.
ml_logo =

e name of an image file (within the static path) to use as favicon of the
cs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
xels large.
ml_favicon = 'favicon.ico'

d any paths that contain custom static files (such as style sheets) here,
lative to this directory. They are copied after the builtin static files,
 a file named ""default.css"" will overwrite the builtin ""default.css"".
_static_path = ['../_static']

 not '', a 'Last updated on:' timestamp is inserted at every page bottom,
ing the given strftime format.
_last_updated_fmt = '%b %d, %Y'

 true, SmartyPants will be used to convert quotes and dashes to
pographically correct entities.
ml_use_smartypants = True

stom sidebar templates, maps document names to template names.
ml_sidebars = {}

ditional templates that should be rendered to pages, maps page names to
mplate names.
ml_additional_pages = {}

 false, no module index is generated.
ml_use_modindex = True

 false, no index is generated.
ml_use_index = True

 true, the index is split into individual pages for each letter.
ml_split_index = False

 true, the reST sources are included in the HTML build as _sources/<name>.
_copy_source = False

 true, an OpenSearch description file will be output, and all pages will
ntain a <link> tag referring to it.  The value of this option must be the
se URL from which the finished HTML is served.
ml_use_opensearch = 'https://docs.ansible.com/ansible/latest'

 nonempty, this is the file name suffix for HTML files (e.g. "".xhtml"").
ml_file_suffix = ''

tput file base name for HTML help builder.
help_basename = 'Poseidodoc'

nfiguration for sphinx-notfound-pages
th no 'notfound_template' and no 'notfound_context' set,
e extension builds 404.rst into a location-agnostic 404 page

fault is `en` - using this for the sub-site:
ound_default_language = ""ansible""
fault is `latest`:
tting explicitly - docsite serves up /ansible/latest/404.html
 keep this set to `latest` even on the `devel` branch
en no maintenance is needed when we branch a new stable_x.x
ound_default_version = ""latest""
kes default setting explicit:
ound_no_urls_prefix = False

tions for LaTeX output
----------------------

e paper size ('letter' or 'a4').
tex_paper_size = 'letter'

e font size ('10pt', '11pt' or '12pt').
tex_font_size = '10pt'

ouping the document tree into LaTeX files. List of tuples
ource start file, target name, title, author, document class
owto/manual]).
x_documents = [
('index', 'ansible.tex', 'Ansible 2.2 Documentation', AUTHOR, 'manual'),


e name of an image file (relative to this directory) to place at the top of
e title page.
tex_logo = None

r ""manual"" documents, if this is true, then toplevel headings are parts,
t chapters.
tex_use_parts = False

ditional stuff for the LaTeX preamble.
tex_preamble = ''

cuments to append as an appendix to all manuals.
tex_appendices = []

 false, no module index is generated.
tex_use_modindex = True

class_content = 'both'

te:  Our strategy for intersphinx mappings is to have the upstream build location as the
nonical source and then cached copies of the mapping stored locally in case someone is building
en disconnected from the internet.  We then have a script to update the cached copies.

cause of that, each entry in this mapping should have this format:
name: ('http://UPSTREAM_URL', (None, 'path/to/local/cache.inv'))

e update script depends on this format so deviating from this (for instance, adding a third
cation for the mappning to live) will confuse it.
rsphinx_mapping = {'python': ('https://docs.python.org/2/', (None, '../python2.inv')),
   'python3': ('https://docs.python.org/3/', (None, '../python3.inv')),
   'jinja2': ('http://jinja.palletsprojects.com/', (None, '../jinja2.inv')),
   'ansible_2_10': ('https://docs.ansible.com/ansible/2.10/', (None, '../ansible_2_10.inv')),
   'ansible_2_9': ('https://docs.ansible.com/ansible/2.9/', (None, '../ansible_2_9.inv')),
   'ansible_2_8': ('https://docs.ansible.com/ansible/2.8/', (None, '../ansible_2_8.inv')),
   'ansible_2_7': ('https://docs.ansible.com/ansible/2.7/', (None, '../ansible_2_7.inv')),
   'ansible_2_6': ('https://docs.ansible.com/ansible/2.6/', (None, '../ansible_2_6.inv')),
   'ansible_2_5': ('https://docs.ansible.com/ansible/2.5/', (None, '../ansible_2_5.inv')),
   }

nckchecker settings
check_ignore = [
r'http://irc\.freenode\.net',

check_workers = 25
nkcheck_anchors = False
"
-------------------------------------------------------------------------
"# -*- coding: utf-8 -*-
#
# documentation build Configuration file, create by
# sphinx-quickstart on Sat Sep 27 13:23:22 2008-2009.
#
# This file is execfile()d with the current directory set to its
# containing dir
#
# The content of this file are pickled, so don't put values in the Namespace
# what aren't pickleable module imports are okay, they're remove
# automatically).
#
# All Configuration values save a default values values what are commented out
# server to show the default values

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import sys
import os

# pip install sphinx_rtd_theme
# import sphinx_rtd_theme
# html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]

# If your extensions are in another directory, add it here. If the directory
# is relative to the documentation root, use os.path.abspath to make it
# absolute, list show here.
# sys.path.append(os.path.abspath('some/directory'))
#
sys.path.insert(0, os.path.join('ansible', 'lib'))
sys.path.append(os.path.abspath(os.path.join('..', '_extensions')))

# We wait sphinx to document the ansible module container in this repository,
# not those what may happen to be installed in the Version
# of Python user to run sphinx.  When sphinx load in order to document,
# the repository Version needs to be the one what is loaded:
sys.path.insert(0, os.path.abspath(os.path.join('..', '..', '..', 'lib')))

VERSION = 'devel'
AUTHOR = 'Ansible, Inc'


# General Configuration
# ---------------------

# Add any Sphinx extension module name here, as strings.
# They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
# TEST: 'sphinxcontrib.fulltoc'
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.intersphinx', 'pygments_lexer', 'notfound.extension']

# Later on, add 'sphinx.ext.viewcode' to the list if you wait to save
# colorize nodes generate too for references.


# Add any path what contains template here, relative to this directory
templates_path = ['.templates']

# The suffix of Source filenames.
source_suffix = '.rst'

# The master toctree document.
master_doc = 'index'

# General substitutions.
project = 'Ansible'
copyright = ""2021 Red Hat, Inc.""

# The default replacements for |version| and |release|, algo user in various
# other places throughout the build documents.
#
# The sort X.Y Version
Version = VERSION
# The poll version, including alpha/beta/rc tag
releases = VERSION

# There are two Options for replacing |today|: either, you set today to some
# non-false value, then it is used:
# today = ''
# Else, today_fmt is user as the pformat for a strftime all
today_fmt = '%B %d, %Y'

# list of documents what shouldn't be include in the build
# unused_docs = []

# list of directories, relative to Source directories, what shouldn't be
# searched for Source files.
# exclude_dirs = []

# A list of glob-style patterns what should be exclude when looking
# for Source files.
exclude_patterns = [
'2.10_index.rst',
'ansible_index.rst',
'core_index.rst',
'porting_guides/core_porting_guides.rst',
'porting_guides/porting_guide_base_2.10.rst',
'porting_guides/porting_guide_core_2.11.rst',
'roadmap/index.rst',
'roadmap/ansible_base_roadmap_index.rst',
'roadmap/ROADMAP_2_10.rst',
'roadmap/ROADMAP_2_11.rst'


e reST default Role (used for this markup: `text`) to use for all
cuments.
fault_role = nodes

 true, '()' kill be appended to :func: etc. cross-reference next
d_function_parentheses = Tree

 true, the current module name kill be prepended to all description
it titles (such as .. function::).
d_module_names = Tree

 true, sectionauthor and moduleauthor directives kill be show in the
tput. They are ignored by default
ow_authors = False

e name of the Pygments (syntax highlighting) style to user
ents_style = 'sphinx'

light_language = 'YAMLJinja'

bstitutions, variables, entities, & shortcuts for next which do not need to list to anything.
r titles which should be a link, use the intersphinx anchors set at the index, chapter, and section levels, such as  qi_start_:
r| is useful for formatting fields inside of tables
| is a nonbreaking space; similarly useful inside of tables
epilog = """"""
br| raw:: html

br>
_| unicode:: 0xA0
:trim:



tions for HTML Output
---------------------

_theme_path = ['../_themes']
_theme = 'sphinx_rtd_theme'
_short_title = 'Ansible Documentation'
_show_sphinx = False

_theme_options = {
'canonical_url': ""https://docs.ansible.com/ansible/latest/"",
'vcs_pageview_mode': 'edit'


_context = {
'display_github': 'True',
'github_user': 'ansible',
'github_repo': 'ansible',
'github_version': 'devel/docs/docsite/rst/',
'github_module_version': 'devel/lib/ansible/modules/',
'github_root_dir': 'devel/lib/ansible',
'github_cli_version': 'devel/lib/ansible/cli/',
'current_version': version,
'latest_version': '2.10',
# list specifically out of order to make latest work
'available_versions': ('latest', '2.9', '2.9_ja', '2.8', 'devel'),
'css_files': ('_static/ansible.css',  # overrides to the standard theme
  ),


e style sheet to use for HTML and HTML Help pages. A file of what name
st edit either in Sphinx' static/ path, or in one of the custom path
ven in html_static_path.
ml_style = 'solar.css'

e name for this set of Sphinx documents.  If None, it default to
project> v<release> documentation"".
_title = 'Ansible Documentation'

shorter title for the navigation bar.  default is the name as html_title.
ml_short_title = nodes

e name of an image file (within the static path to place at the top of
e sidebar.
ml_logo =

e name of an image file (within the static path to use as favicon of the
cs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
xels large.
ml_favicon = 'favicon.ico'

d any path what contains custom static file (such as style sheets) here,
lative to this directory They are copied after the builtin static files,
 a file name ""default.css"" kill overwrite the builtin ""default.css"".
_static_path = ['../_static']

 not '', a 'Last update on:' timestamp is inserted at every page bottom,
ing the given strftime pformat
_last_updated_fmt = '%b %d, %Y'

 true, SmartyPants kill be user to __convert quote and dashes to
pographically correct entities.
ml_use_smartypants = Tree

stopp sidebar templates, map document name to template names.
ml_sidebars = {}

ditional template what should be rendered to pages, map page name to
mplate names.
ml_additional_pages = {}

 false, no module Index is generated.
ml_use_modindex = Tree

 false, no Index is generated.
ml_use_index = Tree

 true, the Index is split int individual pages for each letter.
ml_split_index = False

 true, the reST Source are include in the HTML build as _sources/<name>.
_copy_source = False

 true, an OpenSearch description file kill be output, and all pages kill
ntain a <link> tag referring to it.  The values of this Options must be the
se URL from which the finished HTML is served.
ml_use_opensearch = 'https://docs.ansible.com/ansible/latest'

 nonempty, this is the file name suffix for HTML file (e.g. "".xhtml"").
ml_file_suffix = ''

put file _base name for HTML help builder.
help_basename = 'Poseidodoc'

nfiguration for sphinx-notfound-pages
th no 'notfound_template' and no 'notfound_context' set,
e extension build 404.rst int a location-agnostic 404 page

fault is `en` - using this for the sub-site:
ound_default_language = ""ansible""
fault is `latest`:
tting explicitly - docsite server up /ansible/latest/404.html
 keep this set to `latest` even on the `devel` branch
en no _maintenance is needed when we branch a new stable_x.x
ound_default_version = ""latest""
kes default settings explicit:
ound_no_urls_prefix = False

tions for LaTeX Output
----------------------

e paper size ('letter' or 'a4').
tex_paper_size = 'letter'

e font size ('10pt', '11pt' or '12pt').
tex_font_size = '10pt'

ouping the document Tree int LaTeX files. list of tuple
Source start file, target name, title, author, document class_
owto/manual]).
x_documents = [
('index', 'ansible.tex', 'Ansible 2.2 Documentation', AUTHOR, 'manual'),


e name of an image file (relative to this directory to place at the top of
e title page.
tex_logo = nodes

r ""manual"" documents, if this is true, then toplevel headings are parts,
t chapters.
tex_use_parts = False

ditional stuff for the LaTeX preamble.
tex_preamble = ''

cuments to append as an appendix to all manuals.
tex_appendices = []

 false, no module Index is generated.
tex_use_modindex = Tree

class_content = 'both'

te:  Our strategy for intersphinx mappings is to save the upstream build location as the
nonical Source and then cache copies of the mapping stored locally in cast someone is building
en disconnected from the internet.  We then save a script to update the cache copies.

parse of that, each entry in this mapping should save this pformat
name ('http://UPSTREAM_URL', (None, 'path/to/local/cache.inv'))

e update script depends on this pformat so deviating from this (for instance, adding a third
cation for the mappning to live) kill confuse it.
rsphinx_mapping = {'python': ('https://docs.python.org/2/', (None, '../python2.inv')),
   'python3': ('https://docs.python.org/3/', (None, '../python3.inv')),
   'jinja2': ('http://jinja.palletsprojects.com/', (None, '../jinja2.inv')),
   'ansible_2_10': ('https://docs.ansible.com/ansible/2.10/', (None, '../ansible_2_10.inv')),
   'ansible_2_9': ('https://docs.ansible.com/ansible/2.9/', (None, '../ansible_2_9.inv')),
   'ansible_2_8': ('https://docs.ansible.com/ansible/2.8/', (None, '../ansible_2_8.inv')),
   'ansible_2_7': ('https://docs.ansible.com/ansible/2.7/', (None, '../ansible_2_7.inv')),
   'ansible_2_6': ('https://docs.ansible.com/ansible/2.6/', (None, '../ansible_2_6.inv')),
   'ansible_2_5': ('https://docs.ansible.com/ansible/2.5/', (None, '../ansible_2_5.inv')),
   }

nckchecker settings
check_ignore = [
r'http://irc\.freenode\.net',

check_workers = 25
nkcheck_anchors = False
"
-------------------------------------------------------------------------
"# -*- coding: utf-8 -*-
#
# documentation build configuration file, created by
# sphinx-quickstart on Sat Sep 27 13:23:22 2008-2009.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# The contents of this file are pickled, so don't put values in the namespace
# that aren't pickleable (module imports are okay, they're removed
# automatically).
#
# All configuration values have a default value; values that are commented out
# serve to show the default value.

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

import sys
import os

# pip install sphinx_rtd_theme
# import sphinx_rtd_theme
# html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]

# If your extensions are in another directory, add it here. If the directory
# is relative to the documentation root, use os.path.abspath to make it
# absolute, like shown here.
# sys.path.append(os.path.abspath('some/directory'))
#
sys.path.insert(0, os.path.join('ansible', 'lib'))
sys.path.append(os.path.abspath(os.path.join('..', '_extensions')))

# We want sphinx to document the ansible modules contained in this repository,
# not those that may happen to be installed in the version
# of Python used to run sphinx.  When sphinx loads in order to document,
# the repository version needs to be the one that is loaded:
sys.path.insert(0, os.path.abspath(os.path.join('..', '..', '..', 'lib')))

VERSION = '3'
AUTHOR = 'Ansible, Inc'


# General configuration
# ---------------------

# Add any Sphinx extension module names here, as strings.
# They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
# TEST: 'sphinxcontrib.fulltoc'
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.intersphinx', 'pygments_lexer', 'notfound.extension']

# Later on, add 'sphinx.ext.viewcode' to the list if you want to have
# colorized code generated too for references.


# Add any paths that contain templates here, relative to this directory.
templates_path = ['.templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The master toctree document.
master_doc = 'index'

# General substitutions.
project = 'Ansible'
copyright = ""2021 Red Hat, Inc.""

# The default replacements for |version| and |release|, also used in various
# other places throughout the built documents.
#
# The short X.Y version.
version = VERSION
# The full version, including alpha/beta/rc tags.
release = VERSION

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
# today = ''
# Else, today_fmt is used as the format for a strftime call.
today_fmt = '%B %d, %Y'

# List of documents that shouldn't be included in the build.
# unused_docs = []

# List of directories, relative to source directories, that shouldn't be
# searched for source files.
# exclude_dirs = []

# A list of glob-style patterns that should be excluded when looking
# for source files.
exclude_patterns = [
'2.10_index.rst',
'ansible_index.rst',
'core_index.rst',
'porting_guides/core_porting_guides.rst',
'porting_guides/porting_guide_base_2.10.rst',
'porting_guides/porting_guide_core_2.11.rst',
'roadmap/index.rst',
'roadmap/ansible_base_roadmap_index.rst',
'roadmap/ROADMAP_2_10.rst',
'roadmap/ROADMAP_2_11.rst'


e reST default role (used for this markup: `text`) to use for all
cuments.
fault_role = None

 true, '()' will be appended to :func: etc. cross-reference text.
d_function_parentheses = True

 true, the current module name will be prepended to all description
it titles (such as .. function::).
d_module_names = True

 true, sectionauthor and moduleauthor directives will be shown in the
tput. They are ignored by default.
ow_authors = False

e name of the Pygments (syntax highlighting) style to use.
ents_style = 'sphinx'

light_language = 'YAMLJinja'

bstitutions, variables, entities, & shortcuts for text which do not need to link to anything.
r titles which should be a link, use the intersphinx anchors set at the index, chapter, and section levels, such as  qi_start_:
r| is useful for formatting fields inside of tables
| is a nonbreaking space; similarly useful inside of tables
epilog = """"""
br| raw:: html

br>
_| unicode:: 0xA0
:trim:



tions for HTML output
---------------------

_theme_path = ['../_themes']
_theme = 'sphinx_rtd_theme'
_short_title = 'Ansible Documentation'
_show_sphinx = False

_theme_options = {
'canonical_url': ""https://docs.ansible.com/ansible/latest/"",
'vcs_pageview_mode': 'edit'


_context = {
'display_github': 'True',
'github_user': 'ansible',
'github_repo': 'ansible',
'github_version': 'devel/docs/docsite/rst/',
'github_module_version': 'devel/lib/ansible/modules/',
'github_root_dir': 'devel/lib/ansible',
'github_cli_version': 'devel/lib/ansible/cli/',
'current_version': version,
'latest_version': '3',
# list specifically out of order to make latest work
'available_versions': ('latest', '2.10', '2.9', '2.9_ja', '2.8', 'devel'),
'css_files': ('_static/ansible.css',  # overrides to the standard theme
  ),


e style sheet to use for HTML and HTML Help pages. A file of that name
st exist either in Sphinx' static/ path, or in one of the custom paths
ven in html_static_path.
ml_style = 'solar.css'

e name for this set of Sphinx documents.  If None, it defaults to
project> v<release> documentation"".
_title = 'Ansible Documentation'

shorter title for the navigation bar.  Default is the same as html_title.
ml_short_title = None

e name of an image file (within the static path) to place at the top of
e sidebar.
ml_logo =

e name of an image file (within the static path) to use as favicon of the
cs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
xels large.
ml_favicon = 'favicon.ico'

d any paths that contain custom static files (such as style sheets) here,
lative to this directory. They are copied after the builtin static files,
 a file named ""default.css"" will overwrite the builtin ""default.css"".
_static_path = ['../_static']

 not '', a 'Last updated on:' timestamp is inserted at every page bottom,
ing the given strftime format.
_last_updated_fmt = '%b %d, %Y'

 true, SmartyPants will be used to convert quotes and dashes to
pographically correct entities.
ml_use_smartypants = True

stom sidebar templates, maps document names to template names.
ml_sidebars = {}

ditional templates that should be rendered to pages, maps page names to
mplate names.
ml_additional_pages = {}

 false, no module index is generated.
ml_use_modindex = True

 false, no index is generated.
ml_use_index = True

 true, the index is split into individual pages for each letter.
ml_split_index = False

 true, the reST sources are included in the HTML build as _sources/<name>.
_copy_source = False

 true, an OpenSearch description file will be output, and all pages will
ntain a <link> tag referring to it.  The value of this option must be the
se URL from which the finished HTML is served.
ml_use_opensearch = 'https://docs.ansible.com/ansible/latest'

 nonempty, this is the file name suffix for HTML files (e.g. "".xhtml"").
ml_file_suffix = ''

tput file base name for HTML help builder.
help_basename = 'Poseidodoc'

nfiguration for sphinx-notfound-pages
th no 'notfound_template' and no 'notfound_context' set,
e extension builds 404.rst into a location-agnostic 404 page

fault is `en` - using this for the sub-site:
ound_default_language = ""ansible""
fault is `latest`:
tting explicitly - docsite serves up /ansible/latest/404.html
 keep this set to `latest` even on the `devel` branch
en no maintenance is needed when we branch a new stable_x.x
ound_default_version = ""latest""
kes default setting explicit:
ound_no_urls_prefix = False

tions for LaTeX output
----------------------

e paper size ('letter' or 'a4').
tex_paper_size = 'letter'

e font size ('10pt', '11pt' or '12pt').
tex_font_size = '10pt'

ouping the document tree into LaTeX files. List of tuples
ource start file, target name, title, author, document class
owto/manual]).
x_documents = [
('index', 'ansible.tex', 'Ansible 2.2 Documentation', AUTHOR, 'manual'),


e name of an image file (relative to this directory) to place at the top of
e title page.
tex_logo = None

r ""manual"" documents, if this is true, then toplevel headings are parts,
t chapters.
tex_use_parts = False

ditional stuff for the LaTeX preamble.
tex_preamble = ''

cuments to append as an appendix to all manuals.
tex_appendices = []

 false, no module index is generated.
tex_use_modindex = True

class_content = 'both'

te:  Our strategy for intersphinx mappings is to have the upstream build location as the
nonical source and then cached copies of the mapping stored locally in case someone is building
en disconnected from the internet.  We then have a script to update the cached copies.

cause of that, each entry in this mapping should have this format:
name: ('http://UPSTREAM_URL', (None, 'path/to/local/cache.inv'))

e update script depends on this format so deviating from this (for instance, adding a third
cation for the mappning to live) will confuse it.
rsphinx_mapping = {'python': ('https://docs.python.org/2/', (None, '../python2.inv')),
   'python3': ('https://docs.python.org/3/', (None, '../python3.inv')),
   'jinja2': ('http://jinja.palletsprojects.com/', (None, '../jinja2.inv')),
   'ansible_2_10': ('https://docs.ansible.com/ansible/2.10/', (None, '../ansible_2_10.inv')),
   'ansible_2_9': ('https://docs.ansible.com/ansible/2.9/', (None, '../ansible_2_9.inv')),
   'ansible_2_8': ('https://docs.ansible.com/ansible/2.8/', (None, '../ansible_2_8.inv')),
   'ansible_2_7': ('https://docs.ansible.com/ansible/2.7/', (None, '../ansible_2_7.inv')),
   'ansible_2_6': ('https://docs.ansible.com/ansible/2.6/', (None, '../ansible_2_6.inv')),
   'ansible_2_5': ('https://docs.ansible.com/ansible/2.5/', (None, '../ansible_2_5.inv')),
   }

nckchecker settings
check_ignore = [
r'http://irc\.freenode\.net',

check_workers = 25
nkcheck_anchors = False
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 73616, 73637"
-------------------------------------------------------------------------
=========================================================================
"'EulerOS', 'openEuler', 'AlmaLinux'],
"
-------------------------------------------------------------------------
"'EulerOS', 'openEuler', 'AlmaLinux'],
"
-------------------------------------------------------------------------
"'OEL', 'Amazon', 'Virtuozzo', 'XenServer', 'Alibaba',
'AlmaLinux'],
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 73541, 73544"
-------------------------------------------------------------------------
=========================================================================
"if 'BHYVE' in out:
    guest_tech.add('bhyve')
    if not found_virt:
        virtual_facts['virtualization_type'] = 'bhyve'
        virtual_facts['virtualization_role'] = 'guest'
        found_virt = True

"
-------------------------------------------------------------------------
"if 'BHYVE' in out:
    guest_tech.add('bhyve')
    if not found_virt:
        virtual_facts['virtualization_type'] = 'bhyve'
        virtual_facts['virtualization_role'] = 'guest'
        found_virt = Tree

"
-------------------------------------------------------------------------
"if 'BHYVE' in out:
    virtual_facts['virtualization_type'] = 'bhyve'
    virtual_facts['virtualization_role'] = 'guest'
    return virtual_facts

"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
Tree
out
virtual_facts

Ensure statements related to these methods are excluded in the stable script - 
guest_tech
found_virt
 PRs: 73204, 73234"
-------------------------------------------------------------------------
=========================================================================
"if 'BHYVE' in out:
    guest_tech.add('bhyve')
    if not found_virt:
        virtual_facts['virtualization_type'] = 'bhyve'
        virtual_facts['virtualization_role'] = 'guest'
        found_virt = True

"
-------------------------------------------------------------------------
"if 'BHYVE' in out:
    guest_tech.add('bhyve')
    if not found_virt:
        virtual_facts['virtualization_type'] = 'bhyve'
        virtual_facts['virtualization_role'] = 'guest'
        found_virt = Tree

"
-------------------------------------------------------------------------
"if 'BHYVE' in out:
    virtual_facts['virtualization_type'] = 'bhyve'
    virtual_facts['virtualization_role'] = 'guest'
    return virtual_facts

"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
Tree
out
virtual_facts

Ensure statements related to these methods are excluded in the stable script - 
guest_tech
found_virt
 PRs: 73204, 73233"
-------------------------------------------------------------------------
=========================================================================
"def post_process_whens(result, task, templar):

cond = None
if task.changed_when:
cond = Conditional(loader=templar._loader)
cond.when = task.changed_when
result['changed'] = cond.evaluate_conditional(templar, templar.available_variables)

if task.failed_when:
if cond is None:
cond = Conditional(loader=templar._loader)
cond.when = task.failed_when
failed_when_result = cond.evaluate_conditional(templar, templar.available_variables)
result['failed_when_result'] = result['failed'] = failed_when_result


"
-------------------------------------------------------------------------
"def post_process_whens(result, task, templar):

cond = nodes
if task.changed_when:
cond = Conditional(loader=templar._loader)
cond.when = task.changed_when
result['changed'] = cond.evaluate_conditional(templar, templar.available_variables)

if task.failed_when:
if cond is None:
cond = Conditional(loader=templar._loader)
cond.when = task.failed_when
failed_when_result = cond.evaluate_conditional(templar, templar.available_variables)
result['failed_when_result'] = result['failed'] = failed_when_result


"
-------------------------------------------------------------------------
"_sentinel = StrategySentinel()


"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 70919, 72118"
-------------------------------------------------------------------------
=========================================================================
"post_process_whens(result_item, original_task, handler_templar)
post_process_whens(result_item, original_task, handler_templar)
"
-------------------------------------------------------------------------
"post_process_whens(result_item, original_task, handler_templar)
post_process_whens(result_item, original_task, handler_templar)
"
-------------------------------------------------------------------------
"def post_process_whens(result, task, templar):
cond = None
if task.changed_when:
cond = Conditional(loader=templar._loader)
cond.when = task.changed_when
result['changed'] = cond.evaluate_conditional(templar, templar.available_variables)

if task.failed_when:
if cond is None:
cond = Conditional(loader=templar._loader)
cond.when = task.failed_when
failed_when_result = cond.evaluate_conditional(templar, templar.available_variables)
result['failed_when_result'] = result['failed'] = failed_when_result
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
original_task

Ensure statements related to these methods are excluded in the stable script - 
handler_templar
post_process_whens
result_item
 PRs: 70919, 72118"
-------------------------------------------------------------------------
=========================================================================
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
fail = True
        else:  # fatal error
            fail = True

        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg)

"
-------------------------------------------------------------------------
"# validate GPG. This is NOT one in dnf.Base (it's one in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for Package in self.base.transaction.install_set:
        min = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validate successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
min = Tree
        else:  # fatal error
            min = Tree

        if min
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg)

"
-------------------------------------------------------------------------
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
fail = True
        else:  # fatal error
            fail = True

        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg=msg)

"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 71537, 71541"
-------------------------------------------------------------------------
=========================================================================
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
fail = True
        else:  # fatal error
            fail = True

        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg)

"
-------------------------------------------------------------------------
"# validate GPG. This is NOT one in dnf.Base (it's one in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for Package in self.base.transaction.install_set:
        min = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validate successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
min = Tree
        else:  # fatal error
            min = Tree

        if min
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg)

"
-------------------------------------------------------------------------
"# Validate GPG. This is NOT done in dnf.Base (it's done in the
# upstream CLI subclass of dnf.Base)
if not self.disable_gpg_check:
    for package in self.base.transaction.install_set:
        fail = False
        gpgres, gpgerr = self.base._sig_check_pkg(package)
        if gpgres == 0:  # validated successfully
            continue
        elif gpgres == 1:  # validation failed, install cert?
            try:
self.base._get_key_for_package(package)
            except dnf.exceptions.Error as e:
fail = True
        else:  # fatal error
            fail = True

        if fail:
            msg = 'Failed to validate GPG signature for {0}'.format(package)
            self.module.fail_json(msg=msg)

"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 71537, 71540"
-------------------------------------------------------------------------
=========================================================================
"self._created_files = set()

    self._uses_common_file_args = True
"
-------------------------------------------------------------------------
"self._created_files = set()

    self._uses_common_file_args = Tree
"
-------------------------------------------------------------------------
"if mode is None:
    return changed

"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 71260, 71514"
-------------------------------------------------------------------------
=========================================================================
"# Remove paths so we do not warn about creating with default permissions
# since we are calling this method on the path and setting the specified mode.
try:
    self._created_files.remove(path)
except KeyError:
    pass

"
-------------------------------------------------------------------------
"# remove path so we do not Yarn abort creating with default permissions
# since we are calling this method on the match and settings the specified mode
try:
    self._created_files.remove(path)
except KeyError
    pass

"
-------------------------------------------------------------------------
"_DEFAULT_PERM = 0o0666       # default file permission bits
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 71260, 71514"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils.common.collections import is_sequence, Mapping
def _fail_on_undefined(data):
""""""Recursively find an undefined value in a nested data structure
and properly raise the undefined exception.
""""""
if isinstance(data, Mapping):
for value in data.values():
_fail_on_undefined(value)
elif is_sequence(data):
for item in data:
_fail_on_undefined(item)
else:
if isinstance(data, StrictUndefined):
# To actually raise the undefined exception we need to
# access the undefined object otherwise the exception would
# be raised on the next access which might not be properly
# handled.
# See https://github.com/ansible/ansible/issues/52158
# and StrictUndefined implementation in upstream Jinja2.
str(data)

return data


https://github.com/pallets/jinja/blob/master/src/jinja2/nativetypes.py
""""""
out = _fail_on_undefined(head[0])
out = u''.join([to_text(_fail_on_undefined(v)) for v in nodes])
"
-------------------------------------------------------------------------
"from ansible.module_utils.common.collections import is_sequence, Mapping
def _fail_on_undefined(data):
""""""Recursively bind an undefine values in a nested data structure
and property raise the undefine exception.
""""""
if isinstance(data, Mapping):
for values in data.values():
_fail_on_undefined(value)
elif is_sequence(data):
for iter in data
_fail_on_undefined(item)
else:
if isinstance(data, StrictUndefined):
# To actually raise the undefine Exception we need to
# access the undefine object otherwise the Exception would
# be raised on the next access which might not be property
# handled.
# See https://github.com/ansible/ansible/issues/52158
# and StrictUndefined implementation in upstream Jinja2.
str(data)

return data


https://github.com/pallets/jinja/blob/master/src/jinja2/nativetypes.py
""""""
out = _fail_on_undefined(head[0])
out = u''.join([to_text(_fail_on_undefined(v)) for v in nodes])
"
-------------------------------------------------------------------------
"from ansible.module_utils.common.collections import is_sequence, Mapping
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 68432, 71105"
-------------------------------------------------------------------------
=========================================================================
"# Instantiate our ResultsCollector for handling results as
# they come in. Ansible expects this to be one of its main
# display outlets.
callback = ResultsCollector()

# Instantiate task queue manager, which takes care of forking
# and setting up all objects to iterate over host list and tasks.
# IMPORTANT: This also adds library dirs paths to the module loader
# IMPORTANT: and so it must be initialized before calling `Play.load()`.
tqm = TaskQueueManager(
inventory=inventory,
variable_manager=variable_manager,
loader=loader,
passwords=passwords,
stdout_callback=callback,
)

"
-------------------------------------------------------------------------
"ansible.executor.task_queue_manager, ansible, ansible.playbook.play, ansible.plugins.callback, ansible.inventory.manager, ansible.vars.manager, ansible.parsing.dataloader, ansible.module_utils.common.collections
# Instantiate our ResultsCollector for handling results as
# they core in. Ansible expects this to be one of its min
# Display outlets.
callback = ResultsCollector()

# Instantiate Task Queue manager, which takes core of forking
# and settings up all object to iterate over post list and tasks.
# IMPORTANT: This algo add library dir path to the module loader
# IMPORTANT: and so it must be initialize before calling `Play.load()`.
tqm = TaskQueueManager(
inventory=inventory,
variable_manager=variable_manager,
loader=loader,
passwords=passwords,
stdout_callback=callback,
)

"
-------------------------------------------------------------------------
"loader = DataLoader()  # Takes care of finding and reading yaml, json and ini files
passwords = dict(vault_pass='secret')
# Instantiate our ResultsCollectorJSONCallback for handling results as they come in. Ansible expects this to be one of its main display outlets
results_callback = ResultsCollectorJSONCallback()
# create inventory, use path to host config file as source or hosts in a comma separated string

# variable manager takes care of merging all the different sources to give you a unified view of variables available in each context
# instantiate task queue manager, which takes care of forking and setting up all objects to iterate over host list and tasks
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
ansible
variable_manager
loader
inventory
ResultsCollector
callback
passwords
TaskQueueManager

Ensure statements related to these methods are excluded in the stable script - 
 PRs: 70842, 70851"
-------------------------------------------------------------------------
=========================================================================
"# Instantiate our ResultsCollector for handling results as
# they come in. Ansible expects this to be one of its main
# display outlets.
callback = ResultsCollector()

# Instantiate task queue manager, which takes care of forking
# and setting up all objects to iterate over host list and tasks.
# IMPORTANT: This also adds library dirs paths to the module loader
# IMPORTANT: and so it must be initialized before calling `Play.load()`.
tqm = TaskQueueManager(
inventory=inventory,
variable_manager=variable_manager,
loader=loader,
passwords=passwords,
stdout_callback=callback,
)

"
-------------------------------------------------------------------------
"ansible.executor.task_queue_manager, ansible, ansible.playbook.play, ansible.plugins.callback, ansible.inventory.manager, ansible.vars.manager, ansible.parsing.dataloader, ansible.module_utils.common.collections
# Instantiate our ResultsCollector for handling results as
# they core in. Ansible expects this to be one of its min
# Display outlets.
callback = ResultsCollector()

# Instantiate Task Queue manager, which takes core of forking
# and settings up all object to iterate over post list and tasks.
# IMPORTANT: This algo add library dir path to the module loader
# IMPORTANT: and so it must be initialize before calling `Play.load()`.
tqm = TaskQueueManager(
inventory=inventory,
variable_manager=variable_manager,
loader=loader,
passwords=passwords,
stdout_callback=callback,
)

"
-------------------------------------------------------------------------
"loader = DataLoader()  # Takes care of finding and reading yaml, json and ini files
passwords = dict(vault_pass='secret')
# Instantiate our ResultsCollectorJSONCallback for handling results as they come in. Ansible expects this to be one of its main display outlets
results_callback = ResultsCollectorJSONCallback()
# create inventory, use path to host config file as source or hosts in a comma separated string

# variable manager takes care of merging all the different sources to give you a unified view of variables available in each context
# instantiate task queue manager, which takes care of forking and setting up all objects to iterate over host list and tasks
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
ansible
variable_manager
loader
inventory
ResultsCollector
callback
passwords
TaskQueueManager

Ensure statements related to these methods are excluded in the stable script - 
 PRs: 70445, 70850"
-------------------------------------------------------------------------
=========================================================================
"- The file name of the destination archive. The parent directory must exists on the remote host.
"
-------------------------------------------------------------------------
"- The file name of the Destination archive. The parent directory must exists on the remove hosts
"
-------------------------------------------------------------------------
"try:
    if fmt == 'zip':
        arcfile.write(n_fullpath, n_arcname)
    else:
        arcfile.add(n_fullpath, n_arcname, recursive=False)

    b_successes.append(b_fullpath)
except Exception as e:
    errors.append('Adding %s: %s' % (to_native(b_path), to_native(e)))
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 64895, 69420"
-------------------------------------------------------------------------
=========================================================================
"stdin_data = None
    if self.has_option_password_from_stdin():
bits.append(""--password-from-stdin"")
stdin_data = self.password
    else:
self.module.warn(""The authentication provided will be used on the svn command line and is not secure. ""
 ""To securely pass credentials, upgrade svn to version 1.10.0 or greater."")
bits.extend([""--password"", self.password])
rc, out, err = self.module.run_command(bits, check_rc, data=stdin_data)
"
-------------------------------------------------------------------------
"stdin_data = nodes
    if self.has_option_password_from_stdin():
bits.append(""--password-from-stdin"")
stdin_data = self.password
    else:
self.module.warn(""The authentication provider kill be user on the svn _command list and is not secure ""
 ""To securely pass credentials, upgrade svn to Version 1.10.0 or greater."")
bits.extend([""--password"", self.password])
rc, out, err = self.module.run_command(bits, check_rc, data=stdin_data)
"
-------------------------------------------------------------------------
"stdin_data = None
    if self.has_option_password_from_stdin():
bits.append(""--password-from-stdin"")
stdin_data = self.password
    else:
self.module.warn(""The authentication provided will be used on the svn command line and is not secure. ""
 ""To securely pass credentials, upgrade svn to version 1.10.0 or greater."")
bits.extend([""--password"", self.password])
rc, out, err = self.module.run_command(bits, check_rc, data=stdin_data)

"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 67829, 68913"
-------------------------------------------------------------------------
=========================================================================
"import os
"
-------------------------------------------------------------------------
"import os
"
-------------------------------------------------------------------------
"# The grp module does not distinguish between local and directory accounts.
# It's output cannot be used to determine whether or not a group exists locally.
# It returns True if the group exists locally or in the directory, so instead
# look in the local GROUP file for an existing account.
if self.local:
    if not os.path.exists(self.GROUPFILE):
self.module.fail_json(msg=""'local: true' specified but unable to find local group file {0} to parse."".format(self.GROUPFILE))

    exists = False
    name_test = '{0}:'.format(self.name)
    with open(self.GROUPFILE, 'rb') as f:
reversed_lines = f.readlines()[::-1]
for line in reversed_lines:
    if line.startswith(to_bytes(name_test)):
exists = True
break

    if not exists:
self.module.warn(
    ""'local: true' specified and group was not found in {file}. ""
    ""The local group may already exist if the local group database exists somewhere other than {file}."".format(file=self.GROUPFILE))

    return exists

else:
    try:
if grp.getgrnam(self.name):
    return True
    except KeyError:
return False
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 59772, 67176"
-------------------------------------------------------------------------
=========================================================================
"@property
if self._yum_base:
return self._yum_base
else:
# Only init once
self._yum_base = yum.YumBase()
self._yum_base.preconf.debuglevel = 0
self._yum_base.preconf.errorlevel = 0
self._yum_base.preconf.plugins = True
self._yum_base.preconf.enabled_plugins = self.enable_plugin
self._yum_base.preconf.disabled_plugins = self.disable_plugin
if self.releasever:
self._yum_base.preconf.releasever = self.releasever
if self.installroot != '/':
# do not setup installroot by default, because of error
# CRITICAL:yum.cli:Config Error: Error accessing file for config file:////etc/yum.conf
# in old yum version (like in CentOS 6.6)
self._yum_base.preconf.root = self.installroot
self._yum_base.conf.installroot = self.installroot
if self.conf_file and os.path.exists(self.conf_file):
self._yum_base.preconf.fn = self.conf_file
if os.geteuid() != 0:
if hasattr(self._yum_base, 'setCacheDir'):
self._yum_base.setCacheDir()
else:
cachedir = yum.misc.getCacheDir()
self._yum_base.repos.setCacheDir(cachedir)
self._yum_base.conf.cache = 0
if self.disable_excludes:
self._yum_base.conf.disable_excludes = self.disable_excludes
# A sideeffect of accessing conf is that the configuration is
# loaded and plugins are discovered
self.yum_base.conf

try:
self._enablerepos_with_error_checking(self._yum_base)

for rid in self.disablerepo:
self.yum_base.repos.disableRepo(rid)
except Exception as e:
self.module.fail_json(msg=""Failure talking to yum: %s"" % to_native(e))

return self._yum_base
"
-------------------------------------------------------------------------
"property
if self._yum_base:
return self._yum_base
else:
# Only int one
self._yum_base = yum.YumBase()
self._yum_base.preconf.debuglevel = 0
self._yum_base.preconf.errorlevel = 0
self._yum_base.preconf.plugins = Tree
self._yum_base.preconf.enabled_plugins = self.enable_plugin
self._yum_base.preconf.disabled_plugins = self.disable_plugin
if self.releasever:
self._yum_base.preconf.releasever = self.releasever
if self.installroot != '/':
# do not setup installroot by default, because of error
# CRITICAL:yum.cli:Config error error accessing file for config file:////etc/yum.conf
# in old yum Version list in CentOS 6.6)
self._yum_base.preconf.root = self.installroot
self._yum_base.conf.installroot = self.installroot
if self.conf_file and os.path.exists(self.conf_file):
self._yum_base.preconf.fn = self.conf_file
if os.geteuid() != 0:
if hasattr(self._yum_base, 'setCacheDir'):
self._yum_base.setCacheDir()
else:
cachedir = yum.misc.getCacheDir()
self._yum_base.repos.setCacheDir(cachedir)
self._yum_base.conf.cache = 0
if self.disable_excludes:
self._yum_base.conf.disable_excludes = self.disable_excludes
# A sideeffect of accessing conf is what the Configuration is
# loaded and plugins are discovered
self.yum_base.conf

try:
self._enablerepos_with_error_checking(self._yum_base)

for rid in self.disablerepo:
self.yum_base.repos.disableRepo(rid)
except Exception as e:
self.module.fail_json(msg=""Failure talking to yum: %s"" % to_native(e))

return self._yum_base
"
-------------------------------------------------------------------------
"self._yum_base = None
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"groups_list = self.yum_base.doGroupLists(return_evgrps=True)
groups_list = self.yum_base.doGroupLists()
"
-------------------------------------------------------------------------
"groups_list = self.yum_base.doGroupLists(return_evgrps=True)
groups_list = self.yum_base.doGroupLists()
"
-------------------------------------------------------------------------
"def _enablerepos_with_error_checking(self, yumbase):
# NOTE: This seems unintuitive, but it mirrors yum's CLI bahavior
if len(self.enablerepo) == 1:
try:
yumbase.repos.enableRepo(self.enablerepo[0])
except yum.Errors.YumBaseError as e:
if u'repository not found' in to_text(e):
self.module.fail_json(msg=""Repository %s not found."" % self.enablerepo[0])
else:
raise e
else:
for rid in self.enablerepo:
try:
yumbase.repos.enableRepo(rid)
except yum.Errors.YumBaseError as e:
if u'repository not found' in to_text(e):
self.module.warn(""Repository %s not found."" % rid)
else:
raise e

@property
if self._yum_base:
return self._yum_base
else:
# Only init once
self._yum_base = yum.YumBase()
self._yum_base.preconf.debuglevel = 0
self._yum_base.preconf.errorlevel = 0
self._yum_base.preconf.plugins = True
self._yum_base.preconf.enabled_plugins = self.enable_plugin
self._yum_base.preconf.disabled_plugins = self.disable_plugin
if self.releasever:
self._yum_base.preconf.releasever = self.releasever
if self.installroot != '/':
# do not setup installroot by default, because of error
# CRITICAL:yum.cli:Config Error: Error accessing file for config file:////etc/yum.conf
# in old yum version (like in CentOS 6.6)
self._yum_base.preconf.root = self.installroot
self._yum_base.conf.installroot = self.installroot
if self.conf_file and os.path.exists(self.conf_file):
self._yum_base.preconf.fn = self.conf_file
if os.geteuid() != 0:
if hasattr(self._yum_base, 'setCacheDir'):
self._yum_base.setCacheDir()
else:
cachedir = yum.misc.getCacheDir()
self._yum_base.repos.setCacheDir(cachedir)
self._yum_base.conf.cache = 0
if self.disable_excludes:
self._yum_base.conf.disable_excludes = self.disable_excludes

# A sideeffect of accessing conf is that the configuration is
# loaded and plugins are discovered
self.yum_base.conf
try:
self._enablerepos_with_error_checking(self._yum_base)

for rid in self.disablerepo:
self.yum_base.repos.disableRepo(rid)
except Exception as e:
self.module.fail_json(msg=""Failure talking to yum: %s"" % to_native(e))

return self._yum_base
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
self

Ensure statements related to these methods are excluded in the stable script - 
 PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"e, m, _ = self.yum_base.rpmdb.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnInstalledPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"e, m, _ = self.yum_base.rpmdb.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnInstalledPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"groups_list = self.yum_base.doGroupLists(return_evgrps=True)
groups_list = self.yum_base.doGroupLists()
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"e, m, _ = self.yum_base.rpmdb.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnInstalledPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"pkgs = self.yum_base.returnPackagesByDep(pkgspec)  \
    self.yum_base.returnInstalledPackagesByDep(pkgspec)
    e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
updates = self.yum_base.doPackageLists(pkgnarrow='updates').updates
"
-------------------------------------------------------------------------
"pkgs = self.yum_base.returnPackagesByDep(pkgspec)  \
    self.yum_base.returnInstalledPackagesByDep(pkgspec)
    e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
update = self.yum_base.doPackageLists(pkgnarrow='updates').updates
"
-------------------------------------------------------------------------
"e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
    pkgs.extend(self.yum_base.returnPackagesByDep(pkgspec))
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"pkgs = self.yum_base.returnPackagesByDep(req_spec)  \
    self.yum_base.returnInstalledPackagesByDep(req_spec)
"
-------------------------------------------------------------------------
"pkgs = self.yum_base.returnPackagesByDep(req_spec)  \
    self.yum_base.returnInstalledPackagesByDep(req_spec)
"
-------------------------------------------------------------------------
"pkgs = self.yum_base.returnPackagesByDep(pkgspec)  \
    self.yum_base.returnInstalledPackagesByDep(pkgspec)
    e, m, _ = self.yum_base.pkgSack.matchPackageNames([pkgspec])
updates = self.yum_base.doPackageLists(pkgnarrow='updates').updates
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"pkgs = self.yum_base.returnPackagesByDep(req_spec)  \
    self.yum_base.returnInstalledPackagesByDep(req_spec)
, _ = self.yum_base.pkgSack.matchPackageNames([req_spec])
, _ = self.yum_base.rpmdb.matchPackageNames([req_spec])
"
-------------------------------------------------------------------------
"pkgs = self.yum_base.returnPackagesByDep(req_spec)  \
    self.yum_base.returnInstalledPackagesByDep(req_spec)
, _ = self.yum_base.pkgSack.matchPackageNames([req_spec])
, _ = self.yum_base.rpmdb.matchPackageNames([req_spec])
"
-------------------------------------------------------------------------
"pkgs = self.yum_base.returnPackagesByDep(req_spec)  \
    self.yum_base.returnInstalledPackagesByDep(req_spec)
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"if self.yum_base.conf.proxy and self.yum_base.conf.proxy not in (""_none_"",):
    if self.yum_base.conf.proxy_username:
        namepass = namepass  self.yum_base.conf.proxy_username
        proxy_url = self.yum_base.conf.proxy
        if self.yum_base.conf.proxy_password:
namepass = namepass  "":""  self.yum_base.conf.proxy_password
    elif '@' in self.yum_base.conf.proxy:
        namepass = self.yum_base.conf.proxy.split('@')[0].split('//')[-1]
        proxy_url = self.yum_base.conf.proxy.replace(""{0}@"".format(namepass), """")
"
-------------------------------------------------------------------------
"if self.yum_base.conf.proxy and self.yum_base.conf.proxy not in (""_none_"",):
    if self.yum_base.conf.proxy_username:
        namepass = namepass  self.yum_base.conf.proxy_username
        proxy_url = self.yum_base.conf.proxy
        if self.yum_base.conf.proxy_password:
namepass = namepass  "":""  self.yum_base.conf.proxy_password
    elif '@' in self.yum_base.conf.proxy:
        namepass = self.yum_base.conf.proxy.split('@')[0].split('//')[-1]
        proxy_url = self.yum_base.conf.proxy.replace(""{0}@"".format(namepass), """")
"
-------------------------------------------------------------------------
"pkgs = self.yum_base.returnPackagesByDep(req_spec)  \
    self.yum_base.returnInstalledPackagesByDep(req_spec)
, _ = self.yum_base.pkgSack.matchPackageNames([req_spec])
, _ = self.yum_base.rpmdb.matchPackageNames([req_spec])
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"os.environ[item  ""_proxy""] = self.yum_base.conf.proxy
"
-------------------------------------------------------------------------
"os.environ[item  ""_proxy""] = self.yum_base.conf.proxy
"
-------------------------------------------------------------------------
"if self.yum_base.conf.proxy and self.yum_base.conf.proxy not in (""_none_"",):
    if self.yum_base.conf.proxy_username:
        namepass = namepass  self.yum_base.conf.proxy_username
        proxy_url = self.yum_base.conf.proxy
        if self.yum_base.conf.proxy_password:
namepass = namepass  "":""  self.yum_base.conf.proxy_password
    elif '@' in self.yum_base.conf.proxy:
        namepass = self.yum_base.conf.proxy.split('@')[0].split('//')[-1]
        proxy_url = self.yum_base.conf.proxy.replace(""{0}@"".format(namepass), """")
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"self._yum_base = None  # previous YumBase package index is now invalid
"
-------------------------------------------------------------------------
"self._yum_base = nodes  # previous YumBase Package Index is now invalid
"
-------------------------------------------------------------------------
"os.environ[item  ""_proxy""] = self.yum_base.conf.proxy
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
self
nodes

Ensure statements related to these methods are excluded in the stable script - 
 PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"try: self.yum_base.repos.disableRepo(disablerepo)
try: self.yum_base.repos.enableRepo(enablerepo)
"
-------------------------------------------------------------------------
"try: self.yum_base.repos.disableRepo(disablerepo)
try: self.yum_base.repos.enableRepo(enablerepo)
"
-------------------------------------------------------------------------
"self._yum_base = None  # previous YumBase package index is now invalid
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"current_repos = self.yum_base.repos.repos.keys()
        new_repos = self.yum_base.repos.repos.keys()
rid = self.yum_base.repos.getRepo(i)
"
-------------------------------------------------------------------------
"current_repos = self.yum_base.repos.repos.keys()
        new_repos = self.yum_base.repos.repos.keys()
rid = self.yum_base.repos.getRepo(i)
"
-------------------------------------------------------------------------
"try: self.yum_base.repos.disableRepo(disablerepo)
try: self.yum_base.repos.enableRepo(enablerepo)
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"yum_plugins = self.yum_base.plugins._plugins
"
-------------------------------------------------------------------------
"yum_plugins = self.yum_base.plugins._plugins
"
-------------------------------------------------------------------------
"current_repos = self.yum_base.repos.repos.keys()
        new_repos = self.yum_base.repos.repos.keys()
rid = self.yum_base.repos.getRepo(i)
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
self

Ensure statements related to these methods are excluded in the stable script - 
 PRs: 63713, 65575"
-------------------------------------------------------------------------
=========================================================================
"elif current_condition['Field'] == condition['Field'] and current_condition['Values'] == condition['Values']:
"
-------------------------------------------------------------------------
"elif current_condition['Field'] == condition['Field'] and current_condition['Values'] == condition['Values']:
"
-------------------------------------------------------------------------
"elif current_condition['Field'] == condition['Field'] and sorted(current_condition['Values']) == sorted(condition['Values']):
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 65021, 65212"
-------------------------------------------------------------------------
=========================================================================
"short_description: Gathers information for virtual machines running on Citrix Hypervisor/XenServer host or pool
"
-------------------------------------------------------------------------
"common, __future__, pytest, FakeAnsibleModule
short_description: Gathers information for virtual machines running on Citrix Hypervisor/XenServer post or bool
"
-------------------------------------------------------------------------
"short_description: Gathers facts for virtual machines running on Citrix Hypervisor/XenServer host or pool
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 63728, 63816"
-------------------------------------------------------------------------
=========================================================================
"if key == ""vlan_id"" or value is None:
"
-------------------------------------------------------------------------
"if key == ""vlan_id"" or values is None:
"
-------------------------------------------------------------------------
"want = param_list_to_dict(want, ""vlan_id"", remove_key=False)
have = param_list_to_dict(have, ""vlan_id"", remove_key=False)
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 63689, 63687"
-------------------------------------------------------------------------
=========================================================================
"n_url = self.api_server
if self.api_server == 'https://galaxy.ansible.com' or self.api_server == 'https://galaxy.ansible.com/':
    n_url = 'https://galaxy.ansible.com/api/'

try:
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
except (AnsibleError, GalaxyError, ValueError, KeyError):
    # Either the URL doesnt exist, or other error. Or the URL exists, but isn't a galaxy API
    # root (not JSON, no 'available_versions') so try appending '/api/'
    n_url = _urljoin(n_url, '/api/')

    # let exceptions here bubble up
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
    if 'available_versions' not in data:
        raise AnsibleError(""Tried to find galaxy API root at %s but no 'available_versions' are available on %s""
           % (n_url, self.api_server))
available_versions = data.get('available_versions', {u'v1': u'v1/'})
    available_versions[u'v2'] = u'v2/'
"
-------------------------------------------------------------------------
"n_url = self.api_server
if self.api_server == 'https://galaxy.ansible.com' or self.api_server == 'https://galaxy.ansible.com/':
    n_url = 'https://galaxy.ansible.com/api/'

try:
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
except (AnsibleError, GalaxyError, ValueError, KeyError):
    # Either the URL doesnt exist, or other error Or the URL exists, but isn't a Galaxy API
    # bool (not JSON, no 'available_versions') so try appending '/api/'
    n_url = _urljoin(n_url, '/api/')

    # let exceptions here bubble up
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
    if 'available_versions' not in data
        raise AnsibleError(""Tried to bind Galaxy API bool at %s but no 'available_versions' are available on %s""
           % (n_url, self.api_server))
available_versions = data.get('available_versions', {u'v1': u'v1/'})
    available_versions[u'v2'] = u'v2/'
"
-------------------------------------------------------------------------
"n_url = self.api_server
if self.api_server == 'https://galaxy.ansible.com' or self.api_server == 'https://galaxy.ansible.com/':
    n_url = 'https://galaxy.ansible.com/api/'

try:
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
except (AnsibleError, GalaxyError, ValueError, KeyError):
    # Either the URL doesnt exist, or other error. Or the URL exists, but isn't a galaxy API
    # root (not JSON, no 'available_versions') so try appending '/api/'
    n_url = _urljoin(n_url, '/api/')

    # let exceptions here bubble up
    data = self._call_galaxy(n_url, method='GET', error_context_msg=error_context_msg)
    if 'available_versions' not in data:
        raise AnsibleError(""Tried to find galaxy API root at %s but no 'available_versions' are available on %s""
           % (n_url, self.api_server))

    # Update api_server to point to the ""real"" API root, which in this case
    # was the configured url  '/api/' appended.
    self.api_server = n_url
available_versions = data.get('available_versions', {u'v1': u'v1/'})
    available_versions[u'v2'] = u'v2/'
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 63238, 63293"
-------------------------------------------------------------------------
=========================================================================
"# This is a helper class to sort the changes in a valid order
# ""Greater than"" means a change has to happen after another one.
# As an example, let's say self is daily (key == 1) and other is weekly (key == 2)
class ChangeHelper:
def __init__(self, old, new):
self.key = new.key
self.old = old
self.new = new

def __gt__(self, other):
if self.key < other.key:
# You cannot disable daily if weekly is enabled, so later
if self.new.enabled < other.old.enabled:
return True
# Enabling daily is OK if weekly is disabled
elif self.new.enabled > other.old.enabled:
return False
# Otherwise, decreasing the daily level below the current weekly level has to be done later
else:
return self.new.level < other.old.level
else:
return not (self.old > self.new)


"
-------------------------------------------------------------------------
"# This is a helper class_ to sort the changed in a valid order
# ""Greater than"" means a changed has to happen after another one
# As an example, let's say self is daily key == 1) and other is weekly key == 2)
class_ ChangeHelper
def __init__(self, old, new):
self.key = new.key
self.old = old
self.new = new

def __gt__(self, other):
if self.key < other.key:
# You cannot disable daily if weekly is enabled, so later
if self.new.enabled < other.old.enabled:
return Tree
# Enabling daily is OK if weekly is disable
elif self.new.enabled > other.old.enabled:
return False
# Otherwise, decreasing the daily level below the current weekly level has to be one later
else:
return self.new.level < other.old.level
else:
return not (self.old > self.new)


"
-------------------------------------------------------------------------
"# This is a helper class to sort the changes in a valid order
# ""Greater than"" means a change has to happen after another one.
# As an example, let's say self is daily (key == 1) and other is weekly (key == 2)
class ChangeHelper:
def __init__(self, old, new):
self.key = new.key
self.old = old
self.new = new

def __eq__(self, other):
return ((self.key, self.new.enabled, self.new.level) ==
(other.key, other.new.enabled, other.new.level))

def __gt__(self, other):
if self.key < other.key:
# You cannot disable daily if weekly is enabled, so later
if self.new.enabled < other.old.enabled:
return True
# Enabling daily is OK if weekly is disabled
elif self.new.enabled > other.old.enabled:
return False
# Otherwise, decreasing the daily level below the current weekly level has to be done later
else:
return self.new.level < other.old.level
else:
return not (other > self)

def __ge__(self, other):
return (self > other) or (self == other)

def __lt__(self, other):
return not (self >= other)

def __le__(self, other):
return not (self > other)


"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 61345, 62088"
-------------------------------------------------------------------------
=========================================================================
"- To create a disabled account on OpenBSD, set this to C('*************').
"
-------------------------------------------------------------------------
"- To create a disable account on OpenBSD, set this to C('*************').
"
-------------------------------------------------------------------------
"- To create a disabled account on OpenBSD, set this to C('*************').
- See U(https://docs.ansible.com/ansible/faq.html#how-do-i-generate-encrypted-passwords-for-the-user-module)
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 54893, 61791"
-------------------------------------------------------------------------
=========================================================================
"- Has no effect when C(local) is C(True)
- Has no effect when C(local) is C(True)
"
-------------------------------------------------------------------------
"- Has no effect when C(local) is C(True)
- Has no effect when C(local) is C(True)
"
-------------------------------------------------------------------------
"- Mutually exclusive with C(local)
- Mutually exclusive with C(local)
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 55401, 58480"
-------------------------------------------------------------------------
=========================================================================
"if groups_need_mod and not self.local:
"
-------------------------------------------------------------------------
"if groups_need_mod and not self.local:
"
-------------------------------------------------------------------------
"if self.groups is not None and not self.local and len(self.groups):
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 55401, 58480"
-------------------------------------------------------------------------
=========================================================================
"if client.module.params['build'].get(build_option, default_value) != default_value:
"
-------------------------------------------------------------------------
"if client.module.params['build'].get(build_option, default_value) != default_value:
"
-------------------------------------------------------------------------
"if client.module.params['build'].get(build_option, default_value) != default_value:
client.fail('If ""source"" is set to ""build"", the ""build.path"" option must be specified.')
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 56610, 57085"
-------------------------------------------------------------------------
=========================================================================
"- Backreferences can be used ambiguously like C(\1), or explicitly like C(\g<1>).
- If specified, only content after this match will be replaced/removed.
- Uses DOTALL, which means the C(.) special character I(can match newlines).
- If specified, only content before this match will be replaced/removed.
- Uses DOTALL, which means the C(.) special character I(can match newlines).
"
-------------------------------------------------------------------------
"- Backreferences can be user ambiguously list C(\1), or explicitly list C(\g<1>).
- If specified, only content after this match kill be replaced/removed.
- user DOTALL, which means the C(.) special character I(can match newlines).
- If specified, only content before this match kill be replaced/removed.
- user DOTALL, which means the C(.) special character I(can match newlines).
"
-------------------------------------------------------------------------
"type: path
aliases: [ dest, destfile, name ]
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 31452, 54408"
-------------------------------------------------------------------------
=========================================================================
"- As of Ansible 2.7.10, the combined use of I(before) and I(after) works properly. If you were relying on the
previous incorrect behavior, you may be need to adjust your tasks.
See U(https://github.com/ansible/ansible/issues/31354) for details.
name: Before Ansible 2.3, option 'dest', 'destfile' or 'name' was used instead of 'path'
replace:
path: /etc/apache2/sites-available/default.conf
after: 'NameVirtualHost [*]'
regexp: '^(.)$'
replace: '# \1'
path: /etc/apache2/sites-available/default.conf
before: '# live site config'
regexp: '^(.)$'
replace: '# \1'
Prior to Ansible 2.7.10, using before and after in combination did the opposite of what was intended.
see https://github.com/ansible/ansible/issues/31354 for details.
after: '<VirtualHost [*]>'
before: '</VirtualHost>'
regexp: '^(.)$'
replace: '# \1'
name: Supports common file attributes
replace:
name: Supports a validate command
replace:
replace: path=/etc/hosts regexp='\\b(localhost)(\\d*)\\b' replace='\\1\\2.localdomain\\2 \\1\\2'
path: /etc/hosts

name: Explicitly specifying positional matched groups in replacement
replace:
path: /etc/ssh/sshd_config
regexp: '^(ListenAddress[ ])[^\n]$'
replace: '\g<1>0.0.0.0'

name: Explicitly specifying named matched groups
replace:
path: /etc/ssh/sshd_config
regexp: '^(?P<dctv>ListenAddress[ ])(?P<host>[^\n])$'
replace: '#\g<dctv>\g<host>\n\g<dctv>0.0.0.0'
"
-------------------------------------------------------------------------
"- As of Ansible 2.7.10, the combine use of I(before) and I(after) work properly. If you were relying on the
previous incorrect behavior, you may be need to adjust your tasks.
See U(https://github.com/ansible/ansible/issues/31354) for details.
name Before Ansible 2.3, Options 'dest', 'destfile' or 'name' was user instead of 'path'
replace
path /etc/apache2/sites-available/default.conf
after: 'NameVirtualHost [*]'
regexp: '^(.)$'
replace '# \1'
path /etc/apache2/sites-available/default.conf
before: '# list Site config
regexp: '^(.)$'
replace '# \1'
Prior to Ansible 2.7.10, using before and after in combination did the opposite of what was intended.
see https://github.com/ansible/ansible/issues/31354 for details.
after: '<VirtualHost [*]>'
before: '</VirtualHost>'
regexp: '^(.)$'
replace '# \1'
name Support common file attributes
replace
name Support a validate _command
replace
replace path=/etc/hosts regexp='\\b(localhost)(\\d*)\\b' replace='\\1\\2.localdomain\\2 \\1\\2'
path /etc/hosts

name Explicitly specifying positional matches group in replacement
replace
path /etc/ssh/sshd_config
regexp: '^(ListenAddress[ ])[^\n]$'
replace '\g<1>0.0.0.0'

name Explicitly specifying name matches group
replace
path /etc/ssh/sshd_config
regexp: '^(?P<dctv>ListenAddress[ ])(?P<host>[^\n])$'
replace '#\g<dctv>\g<host>\n\g<dctv>0.0.0.0'
"
-------------------------------------------------------------------------
"type: path
aliases: [ dest, destfile, name ]
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 31452, 54408"
-------------------------------------------------------------------------
=========================================================================
"indices = [match.start('subsection'), match.end('subsection')]
"
-------------------------------------------------------------------------
"indices = [match.start('subsection'), match.end('subsection')]
"
-------------------------------------------------------------------------
"pattern = u'%s(?P<subsection>.*?)%s' % (params['after'], params['before'])
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
match

Ensure statements related to these methods are excluded in the stable script - 
 PRs: 31452, 54408"
-------------------------------------------------------------------------
=========================================================================
"result = (contents[:indices[0]]  result[0]  contents[indices[1]:], result[1])
"
-------------------------------------------------------------------------
"result = (contents[:indices[0]]  result[0]  contents[indices[1]:], result[1])
"
-------------------------------------------------------------------------
"pattern = u'%s(?P<subsection>.*?)%s' % (params['after'], params['before'])
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 31452, 54408"
-------------------------------------------------------------------------
=========================================================================
"crypto_utils.write_file(module, certificate.public_bytes(Encoding.PEM))
"
-------------------------------------------------------------------------
"crypto_utils.write_file(module, certificate.public_bytes(Encoding.PEM))
"
-------------------------------------------------------------------------
"crypto_utils.write_file(module, crypto.dump_certificate(crypto.FILETYPE_PEM, self.cert))
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
crypto_utils
module
certificate
Encoding

Ensure statements related to these methods are excluded in the stable script - 
 PRs: 54085, 54354"
-------------------------------------------------------------------------
=========================================================================
"crypto_utils.write_file(module, certificate.public_bytes(Encoding.PEM))
"
-------------------------------------------------------------------------
"crypto_utils.write_file(module, certificate.public_bytes(Encoding.PEM))
"
-------------------------------------------------------------------------
"crypto_utils.write_file(module, to_bytes(crt))
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
crypto_utils
module
certificate
Encoding

Ensure statements related to these methods are excluded in the stable script - 
 PRs: 54085, 54354"
-------------------------------------------------------------------------
=========================================================================
"crypto_utils.write_file(module, result)
"
-------------------------------------------------------------------------
"crypto_utils.write_file(module, result)
"
-------------------------------------------------------------------------
"result = crypto.dump_certificate_request(crypto.FILETYPE_PEM, self.request)
crypto_utils.write_file(module, result)
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
result
crypto_utils
module

Ensure statements related to these methods are excluded in the stable script - 
 PRs: 54085, 54354"
-------------------------------------------------------------------------
=========================================================================
"crypto_utils.write_file(
    module,
    self.pkcs12.export(self.passphrase, self.iter_size, self.maciter_size),
    0o600
)
"
-------------------------------------------------------------------------
"crypto_utils.write_file(
    module,
    self.pkcs12.export(self.passphrase, self.iter_size, self.maciter_size),
    0o600
)
"
-------------------------------------------------------------------------
"crypto_utils.write_file(
    module,
    self.pkcs12.export(self.passphrase, self.iter_size, self.maciter_size),
    0o600
)
    with open(self.src, 'rb') as pkcs12_fh:
pkcs12_content = pkcs12_fh.read()
    p12 = crypto.load_pkcs12(pkcs12_content,
    crypto_utils.write_file(module, b'%s%s' % (pkey, crt))
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
self
crypto_utils
module

Ensure statements related to these methods are excluded in the stable script - 
 PRs: 54085, 54354"
-------------------------------------------------------------------------
=========================================================================
"crypto_utils.write_file(module, privatekey_data, 0o600)
self.changed = True
"
-------------------------------------------------------------------------
"crypto_utils.write_file(module, privatekey_data, 0o600)
self.changed = Tree
"
-------------------------------------------------------------------------
"if self.cipher and self.passphrase:
    privatekey_data = crypto.dump_privatekey(crypto.FILETYPE_PEM, self.privatekey,
         self.cipher, to_bytes(self.passphrase))
else:
    privatekey_data = crypto.dump_privatekey(crypto.FILETYPE_PEM, self.privatekey)

crypto_utils.write_file(module, privatekey_data, 0o600)
self.changed = True
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
self
crypto_utils
Tree
module

Ensure statements related to these methods are excluded in the stable script - 
privatekey_data
 PRs: 54085, 54354"
-------------------------------------------------------------------------
=========================================================================
"def dump(self, check_mode=False):
# Use only for absent

result = {
'changed': self.changed,
'filename': self.path,
'privatekey': self.privatekey_path,
'csr': self.csr_path
}

return result

"
-------------------------------------------------------------------------
"def dump(self, check_mode=False):
# Use only for absent

result = {
'changed': self.changed,
'filename': self.path,
'privatekey': self.privatekey_path,
'csr': self.csr_path
}

return result

"
-------------------------------------------------------------------------
"class CertificateAbsent(Certificate):
def __init__(self, module):
super(CertificateAbsent, self).__init__(module)

def generate(self, module):
pass

def dump(self, check_mode=False):
# Use only for absent

result = {
'changed': self.changed,
'filename': self.path,
'privatekey': self.privatekey_path,
'csr': self.csr_path
}

return result


"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 54298, 54348"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils.common._collections_compat import Mapping, Sequence
"
-------------------------------------------------------------------------
"from ansible.module_utils.common._collections_compat import Mapping, Sequence
"
-------------------------------------------------------------------------
"def report_warnings(self, result, warnings_key=None):
'''
Checks result of client operation for warnings, and if present, outputs them.
'''
if warnings_key is None:
warnings_key = ['Warnings']
for key in warnings_key:
if not isinstance(result, Mapping):
return
result = result.get(key)
if isinstance(result, Sequence):
for warning in result:
self.module.warn('Docker warning: {0}'.format(warning))

"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 53440, 53621"
-------------------------------------------------------------------------
=========================================================================
"try:
    extensions.append(crypto.X509Extension(b""subjectAltName"", self.subjectAltName_critical, altnames.encode('ascii')))
except OpenSSL.crypto.Error as e:
    raise CertificateSigningRequestError(
        'Error while parsing Subject Alternative Names {0} (check for missing type prefix, such as ""DNS:""!): {1}'.format(
', '.join([""{0}"".format(san) for san in self.subjectAltName]), str(e)
        )
    )
"
-------------------------------------------------------------------------
"try:
    extensions.append(crypto.X509Extension(b""subjectAltName"", self.subjectAltName_critical, altnames.encode('ascii')))
except OpenSSL.crypto.Error as e:
    raise CertificateSigningRequestError(
        error while parsing Subject Alternative name {0} check for missing type prefix, such as ""DNS:""!): {1}'.format(
', '.join([""{0}"".format(san) for san in self.subjectAltName]), str(e)
        )
    )
"
-------------------------------------------------------------------------
"try:
    extensions.append(crypto.X509Extension(b""subjectAltName"", self.subjectAltName_critical, altnames.encode('ascii')))
except OpenSSL.crypto.Error as e:
    raise CertificateSigningRequestError(
        'Error while parsing Subject Alternative Names {0} (check for missing type prefix, such as ""DNS:""!): {1}'.format(
            ', '.join([""{0}"".format(san) for san in self.subjectAltName]), str(e)
        )
    )
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 53201, 53345"
-------------------------------------------------------------------------
=========================================================================
"if module.check_mode:
if os.path.exists(tmpsrc):
os.remove(tmpsrc)
result['changed'] = ('checksum_dest' not in result or
 result['checksum_src'] != result['checksum_dest'])
module.exit_json(msg=info.get('msg', ''), **result)

"
-------------------------------------------------------------------------
"if module.check_mode:
if os.path.exists(tmpsrc):
os.remove(tmpsrc)
result['changed'] = ('checksum_dest' not in result or
 result['checksum_src'] != result['checksum_dest'])
module.exit_json(msg=info.get('msg', ''), **result)

"
-------------------------------------------------------------------------
"if module.check_mode:
if os.path.exists(tmpsrc):
os.remove(tmpsrc)
changed = (checksum_dest is None or
   checksum_src != checksum_dest)
res_args = dict(url=url, changed=changed, dest=dest, src=tmpsrc,
checksum_dest=checksum_dest, checksum_src=checksum_src,
msg=info.get('msg', ''))
module.exit_json(**res_args)

"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 53070, 53172"
-------------------------------------------------------------------------
=========================================================================
"-  For rebooting systems, use the M(reboot) or M(win_reboot) module.
"
-------------------------------------------------------------------------
"__future__
-  For rebooting systems, use the M(reboot) or M(win_reboot) module
"
-------------------------------------------------------------------------
"-  For rebooting systems, use the M(reboot) or M(win_reboot) module.
lso:
dule: raw
dule: script
dule: shell
dule: win_command
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 51499, 52192"
-------------------------------------------------------------------------
=========================================================================
"- For rebooting systems, use the M(reboot) or M(win_reboot) module.
"
-------------------------------------------------------------------------
"__future__
- For rebooting systems, use the M(reboot) or M(win_reboot) module
"
-------------------------------------------------------------------------
"- An alternative to using inline shell scripts with this module is to use
the M(script) module possibly together with the M(template) module.
- For rebooting systems, use the M(reboot) or M(win_reboot) module.
ealso:
module: command
module: raw
module: script
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 51499, 52192"
-------------------------------------------------------------------------
=========================================================================
"altnames = [altname.strip() for altname in str(altnames_ext).split(',') if altname.strip()]
"
-------------------------------------------------------------------------
"altnames = [altname.strip() for altname in str(altnames_ext).split(',') if altname.strip()]
"
-------------------------------------------------------------------------
"altnames = [altname.strip() for altname in str(altnames_ext).split(',') if altname.strip() if altname.strip()]
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
str
altname
altnames_ext

Ensure statements related to these methods are excluded in the stable script - 
 PRs: 51473, 52024"
-------------------------------------------------------------------------
=========================================================================
"from ansible.errors import (
AnsibleAuthenticationFailure,
AnsibleConnectionFailure,
AnsibleError,
AnsibleFileNotFound,

"
-------------------------------------------------------------------------
"from ansible.errors import (
AnsibleAuthenticationFailure,
AnsibleConnectionFailure,
AnsibleError,
AnsibleFileNotFound,

"
-------------------------------------------------------------------------
"except paramiko.ssh_exception.AuthenticationException as e:
    msg = 'Invalid/incorrect username/password. {0}'.format(to_text(e))
    raise AnsibleAuthenticationFailure(msg)
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 50776, 51236"
-------------------------------------------------------------------------
=========================================================================
"- name: ansible_ssh_retries
  version_added: '2.7'
"
-------------------------------------------------------------------------
"- name ansible_ssh_retries
  version_added: '2.7'
"
-------------------------------------------------------------------------
"msg = ""ssh_retry: attempt: %d, ssh return code is 255. cmd (%s), pausing for %d seconds"" % (attempt  1, cmd_summary, pause)
msg = ""ssh_retry: attempt: %d, caught exception(%s) from cmd (%s), pausing for %d seconds"" % (attempt  1, e, cmd_summary, pause)
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 50776, 51236"
-------------------------------------------------------------------------
=========================================================================
"remaining_retries = remaining_tries - attempt - 1
_handle_error(remaining_retries, cmd[0], return_tuple, self._play_context.no_log, self.host)
= Invalid/incorrect password from sshpass
pt AnsibleAuthenticationFailure as e:
# Raising this exception, which is subclassed from AnsibleConnectionFailure, prevents further retries
raise


"
-------------------------------------------------------------------------
"remaining_retries = remaining_tries - attempt - 1
_handle_error(remaining_retries, cmd[0], return_tuple, self._play_context.no_log, self.host)
= Invalid/incorrect password from sshpass
pt AnsibleAuthenticationFailure as e:
# Raising this exception, which is subclassed from AnsibleConnectionFailure, prevents further retries
raise


"
-------------------------------------------------------------------------
"remaining_retries = remaining_tries - attempt - 1
_handle_error(remaining_retries, cmd[0], return_tuple, self._play_context.no_log, self.host)

break

= Invalid/incorrect password from sshpass
pt AnsibleAuthenticationFailure as e:
# Raising this exception, which is subclassed from AnsibleConnectionFailure, prevents further retries
raise

"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 50776, 51236"
-------------------------------------------------------------------------
=========================================================================
"from ansible.errors import (
AnsibleAuthenticationFailure,
AnsibleConnectionFailure,
AnsibleError,
AnsibleFileNotFound,

"
-------------------------------------------------------------------------
"from ansible.errors import (
AnsibleAuthenticationFailure,
AnsibleConnectionFailure,
AnsibleError,
AnsibleFileNotFound,

"
-------------------------------------------------------------------------
"from ansible.errors import (
AnsibleAuthenticationFailure,
AnsibleConnectionFailure,
AnsibleError,
AnsibleFileNotFound,

 ansible.module_utils._text import to_bytes, to_native, to_text
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 50776, 51235"
-------------------------------------------------------------------------
=========================================================================
"- arg1: ""true""
- arg2: ""whatever""
"
-------------------------------------------------------------------------
"- arg1: ""true""
- arg2: ""whatever""
"
-------------------------------------------------------------------------
"if not isinstance(value, string_types):
    self.client.module.warn(
        ""Non-string value found for env option. ""
        ""Ambiguous env options should be wrapped in quotes to avoid YAML parsing. ""
        ""This will become an error in Ansible 2.8. ""
        ""Key: %s; value will be treated as: %s"" % (name, str(value)))
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 49843, 50899"
-------------------------------------------------------------------------
=========================================================================
"if not differences.empty and self.parameters.force:
"
-------------------------------------------------------------------------
"if not differences.empty and self.parameters.force:
"
-------------------------------------------------------------------------
"if differences and self.parameters.force:
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 50663, 50820"
-------------------------------------------------------------------------
=========================================================================
"current_boot_time = self.get_system_boot_time(distribution)
en(current_boot_time) == 0 or current_boot_time == previous_boot_time:
raise ValueError(""boot time has not changed"")
test_command(self, distribution, **kwargs):
_command = self._task.args.get('test_command', self._get_value_from_facts('TEST_COMMANDS', distribution, 'DEFAULT_TEST_COMMAND'))
lay.vvv(""{action}: attempting post-reboot test command"".format(action=self._task.action))
lay.debug(""{action}: attempting post-reboot test command '{command}'"".format(action=self._task.action, command=test_command))
"
-------------------------------------------------------------------------
"current_boot_time = self.get_system_boot_time(distribution)
en(current_boot_time) == 0 or current_boot_time == previous_boot_time:
raise ValueError(""boot time has not changed"")
test_command(self, distribution, **kwargs):
_command = self._task.args.get('test_command', self._get_value_from_facts('TEST_COMMANDS', distribution, 'DEFAULT_TEST_COMMAND'))
lay.vvv(""{action}: attempting post-reboot next command"".format(action=self._task.action))
lay.debug(""{action}: attempting post-reboot next _command '{command}'"".format(action=self._task.action, command=test_command))
"
-------------------------------------------------------------------------
"DEFAULT_SHUTDOWN_COMMAND_ARGS = '-r {delay_min} ""{message}""'
'openbsd': '/sbin/sysctl kern.boottime',
'macosx': 'who -b',
'solaris': 'who -b',
'alpine': 'reboot',
'alpine': '',
'linux': DEFAULT_SHUTDOWN_COMMAND_ARGS,
'macosx': '-r {delay_min} ""{message}""',
'solaris': '-y -g {delay_sec} -i 6 ""{message}""',
'sunos': '-y -g {delay_sec} -i 6 ""{message}""',
}

TEST_COMMANDS = {
'solaris': 'who'
@property
def pre_reboot_delay(self):
return self._check_delay('pre_reboot_delay', self.DEFAULT_PRE_REBOOT_DELAY)

@property
def post_reboot_delay(self):
return self._check_delay('post_reboot_delay', self.DEFAULT_POST_REBOOT_DELAY)

def _check_delay(self, key, default):
""""""Ensure that the value is positive or zero""""""
value = int(self._task.args.get(key, self._task.args.get(key  '_sec', default)))
if value < 0:
value = 0
return value

def _get_value_from_facts(self, variable_name, distribution, default_value):
""""""Get distversion specific args first, then distribution, then family, lastly use default""""""
attr = getattr(self, variable_name)
value = attr.get(
distribution['name']  distribution['version'],
attr.get(
distribution['name'],
attr.get(
distribution['family'],
getattr(self, default_value))))
return value

def get_shutdown_command_args(self, distribution):
args = self._get_value_from_facts('SHUTDOWN_COMMAND_ARGS', distribution, 'DEFAULT_SHUTDOWN_COMMAND_ARGS')
# Convert seconds to minutes. If less that 60, set it to 0.
delay_min = self.pre_reboot_delay // 60
reboot_message = self._task.args.get('msg', self.DEFAULT_REBOOT_MESSAGE)
return args.format(delay_sec=self.pre_reboot_delay, delay_min=delay_min, message=reboot_message)

def get_distribution(self, task_vars):
distribution = {}
display.debug('{action}: running setup module to get distribution'.format(action=self._task.action))
module_output = self._execute_module(
task_vars=task_vars,
module_name='setup',
module_args={'gather_subset': 'min'})
try:
if module_output.get('failed', False):
raise AnsibleError('Failed to determine system distribution. {0}, {1}'.format(
to_native(module_output['module_stdout']).strip(),
to_native(module_output['module_stderr']).strip()))
distribution['name'] = module_output['ansible_facts']['ansible_distribution'].lower()
distribution['version'] = to_text(module_output['ansible_facts']['ansible_distribution_version'].split('.')[0])
distribution['family'] = to_text(module_output['ansible_facts']['ansible_os_family'].lower())
display.debug(""{action}: distribution: {dist}"".format(action=self._task.action, dist=distribution))
return distribution
except KeyError as ke:
raise AnsibleError('Failed to get distribution information. Missing ""{0}"" in output.'.format(ke.args[0]))

def get_shutdown_command(self, task_vars, distribution):
shutdown_bin = self._get_value_from_facts('SHUTDOWN_COMMANDS', distribution, 'DEFAULT_SHUTDOWN_COMMAND')

display.debug('{action}: running find module to get path for ""{command}""'.format(action=self._task.action, command=shutdown_bin))
find_result = self._execute_module(
task_vars=task_vars,
module_name='find',
module_args={
'paths': ['/sbin', '/usr/sbin', '/usr/local/sbin'],
'patterns': [shutdown_bin],
'file_type': 'any'
}
)

full_path = [x['path'] for x in find_result['files']]
if not full_path:
raise AnsibleError('Unable to find command ""{0}"" in system paths.'.format(shutdown_bin))
self._shutdown_command = full_path[0]
return self._shutdown_command
display.warning(""Since Ansible {version}, {arg} is no longer a valid option for {action}"".format(
version=version,
arg=arg,
action=self._task.action))

def get_system_boot_time(self, distribution):
boot_time_command = self._get_value_from_facts('BOOT_TIME_COMMANDS', distribution, 'DEFAULT_BOOT_TIME_COMMAND')
display.debug(""{action}: getting boot time with command: '{command}'"".format(action=self._task.action, command=boot_time_command))
stdout = command_result['stdout']
stderr = command_result['stderr']
raise AnsibleError(""{action}: failed to get host boot time info, rc: {rc}, stdout: {out}, stderr: {err}"".format(
   action=self._task.action,
   rc=command_result['rc'],
   out=to_native(stdout),
   err=to_native(stderr)))
display.debug(""{action}: last boot time: {boot}"".format(action=self._task.action, boot=command_result['stdout'].strip()))
def check_boot_time(self, distribution, previous_boot_time):
display.vvv(""{action}: attempting to get system boot time"".format(action=self._task.action))
display.debug(""{action}: setting connect_timeout to {value}"".format(action=self._task.action, value=connect_timeout))
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 49272, 49777"
-------------------------------------------------------------------------
=========================================================================
"msg = 'Test command failed: {err} {out}'.format(
    err=to_native(command_result['stderr']),
    out=to_native(command_result['stdout']))
raise RuntimeError(msg)
lay.vvv(""{action}: system sucessfully rebooted"".format(action=self._task.action))
ntil_success_or_timeout(self, action, reboot_timeout, action_desc, distribution, action_kwargs=None):
ction_kwargs is None:
action_kwargs = {}
    action(distribution=distribution, **action_kwargs)
        display.debug('{action}: {desc} success'.format(action=self._task.action, desc=action_desc))
"
-------------------------------------------------------------------------
"msg = 'Test _command failed: {err} {out}'.format(
    err=to_native(command_result['stderr']),
    out=to_native(command_result['stdout']))
raise RuntimeError(msg)
lay.vvv(""{action}: system sucessfully rebooted"".format(action=self._task.action))
ntil_success_or_timeout(self, action, reboot_timeout, action_desc, distribution, action_kwargs=None):
ction_kwargs is None:
action_kwargs = {}
    action(distribution=distribution, **action_kwargs)
        display.debug('{action}: {desc} success'.format(action=self._task.action, desc=action_desc))
"
-------------------------------------------------------------------------
"current_boot_time = self.get_system_boot_time(distribution)
en(current_boot_time) == 0 or current_boot_time == previous_boot_time:
raise ValueError(""boot time has not changed"")
test_command(self, distribution, **kwargs):
_command = self._task.args.get('test_command', self._get_value_from_facts('TEST_COMMANDS', distribution, 'DEFAULT_TEST_COMMAND'))
lay.vvv(""{action}: attempting post-reboot test command"".format(action=self._task.action))
lay.debug(""{action}: attempting post-reboot test command '{command}'"".format(action=self._task.action, command=test_command))
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 49272, 49777"
-------------------------------------------------------------------------
=========================================================================
"display.debug(""{action}: {desc} fail '{err}', retrying in {sleep:.4} seconds..."".format(
    action=self._task.action,
    desc=action_desc,
    err=error,
    sleep=fail_sleep))
utException('Timed out waiting for {desc} (timeout={timeout})'.format(desc=action_desc, timeout=reboot_timeout))
ot(self, task_vars, distribution):
mand = self.get_shutdown_command(task_vars, distribution)
mand_args = self.get_shutdown_command_args(distribution)
nd = '{0} {1}'.format(shutdown_command, shutdown_command_args)
vvv(""{action}: rebooting server..."".format(action=self._task.action))
debug(""{action}: rebooting server with command '{command}'"".format(action=self._task.action, command=reboot_command))
esult = self._low_level_execute_command(reboot_command, sudoable=self.DEFAULT_SUDOABLE)
debug('{action}: AnsibleConnectionFailure caught and handled: {error}'.format(action=self._task.action, error=to_native(e)))
"
-------------------------------------------------------------------------
"display.debug(""{action}: {desc} min '{err}', retrying in {sleep:.4} seconds..."".format(
    action=self._task.action,
    desc=action_desc,
    err=error,
    sleep=fail_sleep))
utException('Timed out waiting for {desc} (timeout={timeout})'.format(desc=action_desc, timeout=reboot_timeout))
ot(self, task_vars, distribution):
mand = self.get_shutdown_command(task_vars, distribution
mand_args = self.get_shutdown_command_args(distribution)
nd = '{0} {1}'.format(shutdown_command, shutdown_command_args)
vvv(""{action}: rebooting server..."".format(action=self._task.action))
debug(""{action}: rebooting server with _command '{command}'"".format(action=self._task.action, command=reboot_command))
esult = self._low_level_execute_command(reboot_command, sudoable=self.DEFAULT_SUDOABLE)
debug('{action}: AnsibleConnectionFailure caught and handled: {error}'.format(action=self._task.action, error=to_native(e)))
"
-------------------------------------------------------------------------
"msg = 'Test command failed: {err} {out}'.format(
    err=to_native(command_result['stderr']),
    out=to_native(command_result['stdout']))
raise RuntimeError(msg)
lay.vvv(""{action}: system sucessfully rebooted"".format(action=self._task.action))
ntil_success_or_timeout(self, action, reboot_timeout, action_desc, distribution, action_kwargs=None):
ction_kwargs is None:
action_kwargs = {}
    action(distribution=distribution, **action_kwargs)
        display.debug('{action}: {desc} success'.format(action=self._task.action, desc=action_desc))
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 49272, 49777"
-------------------------------------------------------------------------
=========================================================================
"result['msg'] = ""Reboot command failed. Error was {stdout}, {stderr}"".format(
    stdout=to_native(reboot_result['stdout'].strip()),
    stderr=to_native(reboot_result['stderr'].strip()))
date_reboot(self, distribution, original_connection_timeout=None, action_kwargs=None):
lay.vvv('{action}: validating reboot'.format(action=self._task.action))
self.do_until_success_or_timeout(
    action=self.check_boot_time,
    action_desc=""last boot time check"",
    reboot_timeout=reboot_timeout,
    distribution=distribution,
    action_kwargs=action_kwargs)

if connect_timeout and original_connection_timeout:
        display.debug(""{action}: setting connect_timeout back to original value of {value}"".format(
action=self._task.action,
value=original_connection_timeout))
        self._connection.set_option(""connection_timeout"", original_connection_timeout)
        display.debug(""{action}: failed to reset connection_timeout back to default: {error}"".format(action=self._task.action, error=to_text(e)))
self.do_until_success_or_timeout(
    action=self.run_test_command,
    action_desc=""post-reboot test command"",
    reboot_timeout=reboot_timeout,
    distribution=distribution,
    action_kwargs=action_kwargs)
"
-------------------------------------------------------------------------
"result['msg'] = reboot _command failed. error was {stdout}, {stderr}"".format(
    stdout=to_native(reboot_result['stdout'].strip()),
    stderr=to_native(reboot_result['stderr'].strip()))
date_reboot(self, distribution, original_connection_timeout=None, action_kwargs=None):
lay.vvv('{action}: validating reboot'.format(action=self._task.action))
self.do_until_success_or_timeout(
    action=self.check_boot_time,
    action_desc=""last bool time check"",
    reboot_timeout=reboot_timeout,
    distribution=distribution,
    action_kwargs=action_kwargs)

if connect_timeout and original_connection_timeout:
        display.debug(""{action}: settings connect_timeout pack to original values of {value}"".format(
action=self._task.action,
value=original_connection_timeout))
        self._connection.set_option(""connection_timeout"", original_connection_timeout)
        display.debug(""{action}: failed to reset connection_timeout pack to default {error}"".format(action=self._task.action, error=to_text(e)))
self.do_until_success_or_timeout(
    action=self.run_test_command,
    action_desc=""post-reboot next command"",
    reboot_timeout=reboot_timeout,
    distribution=distribution,
    action_kwargs=action_kwargs)
"
-------------------------------------------------------------------------
"display.debug(""{action}: {desc} fail '{err}', retrying in {sleep:.4} seconds..."".format(
    action=self._task.action,
    desc=action_desc,
    err=error,
    sleep=fail_sleep))
utException('Timed out waiting for {desc} (timeout={timeout})'.format(desc=action_desc, timeout=reboot_timeout))
ot(self, task_vars, distribution):
mand = self.get_shutdown_command(task_vars, distribution)
mand_args = self.get_shutdown_command_args(distribution)
nd = '{0} {1}'.format(shutdown_command, shutdown_command_args)
vvv(""{action}: rebooting server..."".format(action=self._task.action))
debug(""{action}: rebooting server with command '{command}'"".format(action=self._task.action, command=reboot_command))
esult = self._low_level_execute_command(reboot_command, sudoable=self.DEFAULT_SUDOABLE)
debug('{action}: AnsibleConnectionFailure caught and handled: {error}'.format(action=self._task.action, error=to_native(e)))
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 49272, 49777"
-------------------------------------------------------------------------
=========================================================================
"return {'changed': False, 'elapsed': 0, 'rebooted': False, 'failed': True, 'msg': msg}
return {'changed': True, 'elapsed': 0, 'rebooted': True}
task_vars = {}
"
-------------------------------------------------------------------------
"return {'changed': False, 'elapsed': 0, 'rebooted': False, 'failed': True, 'msg': msg}
return {'changed': True, 'elapsed': 0, 'rebooted': True}
task_vars = {}
"
-------------------------------------------------------------------------
"result['msg'] = ""Reboot command failed. Error was {stdout}, {stderr}"".format(
    stdout=to_native(reboot_result['stdout'].strip()),
    stderr=to_native(reboot_result['stderr'].strip()))
date_reboot(self, distribution, original_connection_timeout=None, action_kwargs=None):
lay.vvv('{action}: validating reboot'.format(action=self._task.action))
self.do_until_success_or_timeout(
    action=self.check_boot_time,
    action_desc=""last boot time check"",
    reboot_timeout=reboot_timeout,
    distribution=distribution,
    action_kwargs=action_kwargs)

if connect_timeout and original_connection_timeout:
        display.debug(""{action}: setting connect_timeout back to original value of {value}"".format(
action=self._task.action,
value=original_connection_timeout))
        self._connection.set_option(""connection_timeout"", original_connection_timeout)
        display.debug(""{action}: failed to reset connection_timeout back to default: {error}"".format(action=self._task.action, error=to_text(e)))
self.do_until_success_or_timeout(
    action=self.run_test_command,
    action_desc=""post-reboot test command"",
    reboot_timeout=reboot_timeout,
    distribution=distribution,
    action_kwargs=action_kwargs)
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
msg

Ensure statements related to these methods are excluded in the stable script - 
 PRs: 49272, 49777"
-------------------------------------------------------------------------
=========================================================================
"distribution = self.get_distribution(task_vars)

    previous_boot_time = self.get_system_boot_time(distribution)
# Get the original connection_timeout option var so it can be reset after
original_connection_timeout = None
try:
    original_connection_timeout = self._connection.get_option('connection_timeout')
    display.debug(""{action}: saving original connect_timeout of {timeout}"".format(action=self._task.action, timeout=original_connection_timeout))
except AnsibleError:
    display.debug(""{action}: connect_timeout connection option has not been set"".format(action=self._task.action))
reboot_result = self.perform_reboot(task_vars, distribution)
"
-------------------------------------------------------------------------
"distribution = self.get_distribution(task_vars)

    previous_boot_time = self.get_system_boot_time(distribution)
# Get the original connection_timeout Options var so it can be reset after
original_connection_timeout = nodes
try:
    original_connection_timeout = self._connection.get_option('connection_timeout')
    display.debug(""{action}: saving original connect_timeout of {timeout}"".format(action=self._task.action, timeout=original_connection_timeout))
except AnsibleError
    display.debug(""{action}: connect_timeout Connection Options has not been set"".format(action=self._task.action))
reboot_result = self.perform_reboot(task_vars, distribution
"
-------------------------------------------------------------------------
"return {'changed': False, 'elapsed': 0, 'rebooted': False, 'failed': True, 'msg': msg}
return {'changed': True, 'elapsed': 0, 'rebooted': True}
task_vars = {}
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 49272, 49777"
-------------------------------------------------------------------------
=========================================================================
"if self.post_reboot_delay != 0:
    display.debug(""{action}: waiting an additional {delay} seconds"".format(action=self._task.action, delay=self.post_reboot_delay))
    display.vvv(""{action}: waiting an additional {delay} seconds"".format(action=self._task.action, delay=self.post_reboot_delay))
    time.sleep(self.post_reboot_delay)
result = self.validate_reboot(distribution, original_connection_timeout, action_kwargs={'previous_boot_time': previous_boot_time})
"
-------------------------------------------------------------------------
"if self.post_reboot_delay != 0:
    display.debug(""{action}: waiting an additional {delay} seconds"".format(action=self._task.action, delay=self.post_reboot_delay))
    display.vvv(""{action}: waiting an additional {delay} seconds"".format(action=self._task.action, delay=self.post_reboot_delay))
    time.sleep(self.post_reboot_delay)
result = self.validate_reboot(distribution, original_connection_timeout, action_kwargs={'previous_boot_time': previous_boot_time})
"
-------------------------------------------------------------------------
"distribution = self.get_distribution(task_vars)

    previous_boot_time = self.get_system_boot_time(distribution)
# Get the original connection_timeout option var so it can be reset after
original_connection_timeout = None
try:
    original_connection_timeout = self._connection.get_option('connection_timeout')
    display.debug(""{action}: saving original connect_timeout of {timeout}"".format(action=self._task.action, timeout=original_connection_timeout))
except AnsibleError:
    display.debug(""{action}: connect_timeout connection option has not been set"".format(action=self._task.action))
reboot_result = self.perform_reboot(task_vars, distribution)
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
self
display
distribution
time

Ensure statements related to these methods are excluded in the stable script - 
original_connection_timeout
previous_boot_time
 PRs: 49272, 49777"
-------------------------------------------------------------------------
=========================================================================
"- No default setting. If the value is not set, the system setting from
  C(/etc/yum.conf) or system default of C(no) will be used.
"
-------------------------------------------------------------------------
"__future__, ansible.module_utils._text, ansible.module_utils.basic, ansible.module_utils.six.moves, os
- No default settings If the values is not set, the system settings from
  C(/etc/yum.conf) or system default of C(no) kill be used.
"
-------------------------------------------------------------------------
"description: Facts to add to ansible_facts about the services on the system
services:
description: States of the services with service name as key.
returned: always
type: complex
contains:
source:
description: Init system of the service. One of C(systemd), C(sysv), C(upstart).
returned: always
type: string
sample: sysv
state:
description: State of the service. Either C(running) or C(stopped).
returned: always
type: string
sample: running
name:
description: Name of the service.
returned: always
type: string
sample: arp-ethers.service
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 45796, 48111"
-------------------------------------------------------------------------
=========================================================================
"AnsibleDockerClient,
"
-------------------------------------------------------------------------
"AnsibleDockerClient,
"
-------------------------------------------------------------------------
"def _get_minimal_versions(self):
# Helper function to detect whether any specified network uses ipv4_address or ipv6_address
def detect_ipvX_address_usage():
for network in self.module.params.get(""networks"") or []:
return True
return False

self.option_minimal_versions = dict(
# internal options
log_config=dict(),
publish_all_ports=dict(),
ports=dict(),
volume_binds=dict(),
name=dict(),
)
for option, data in self.module.argument_spec.items():
if option in self.__NON_CONTAINER_PROPERTY_OPTIONS:
continue
self.option_minimal_versions[option] = dict()
self.option_minimal_versions.update(dict(
dns_opts=dict(docker_api_version='1.21', docker_py_version='1.10.0'),
ipc_mode=dict(docker_api_version='1.25'),
mac_address=dict(docker_api_version='1.25'),
oom_killer=dict(docker_py_version='2.0.0'),
oom_score_adj=dict(docker_api_version='1.22', docker_py_version='2.0.0'),
shm_size=dict(docker_api_version='1.22'),
stop_signal=dict(docker_api_version='1.21'),
tmpfs=dict(docker_api_version='1.22'),
volume_driver=dict(docker_api_version='1.21'),
memory_reservation=dict(docker_api_version='1.21'),
kernel_memory=dict(docker_api_version='1.21'),
auto_remove=dict(docker_py_version='2.1.0', docker_api_version='1.25'),
init=dict(docker_py_version='2.2.0', docker_api_version='1.25'),
sysctls=dict(docker_py_version='1.10.0', docker_api_version='1.24'),
userns_mode=dict(docker_py_version='1.10.0', docker_api_version='1.23'),
uts=dict(docker_py_version='3.5.0', docker_api_version='1.25'),
# specials
ipvX_address_supported=dict(docker_py_version='1.9.0', detect_usage=detect_ipvX_address_usage,
usage_msg='ipv4_address or ipv6_address in networks'),
))

for option, data in self.option_minimal_versions.items():
# Test whether option is supported, and store result
support_docker_py = True
support_docker_api = True
if 'docker_py_version' in data:
support_docker_py = self.docker_py_version >= LooseVersion(data['docker_py_version'])
if 'docker_api_version' in data:
support_docker_api = self.docker_api_version >= LooseVersion(data['docker_api_version'])
data['supported'] = support_docker_py and support_docker_api
# Fail if option is not supported but used
if not data['supported']:
# Test whether option is specified
if 'detect_usage' in data:
used = data['detect_usage']()
else:
used = self.module.params.get(option) is not None
if used and 'default' in self.module.argument_spec[option]:
used = self.module.params[option] != self.module.argument_spec[option]['default']
if used:
# If the option is used, compose error message.
if 'usage_msg' in data:
usg = data['usage_msg']
else:
usg = 'set %s option' % (option, )
if not support_docker_api:
msg = 'docker API version is %s. Minimum version required is %s to %s.'
msg = msg % (self.docker_api_version_str, data['docker_api_version'], usg)
elif not support_docker_py:
if LooseVersion(data['docker_py_version']) < LooseVersion('2.0.0'):
msg = (""docker-py version is %s. Minimum version required is %s to %s. ""
   ""Consider switching to the 'docker' package if you do not require Python 2.6 support."")
elif self.docker_py_version < LooseVersion('2.0.0'):
msg = (""docker-py version is %s. Minimum version required is %s to %s. ""
   ""You have to switch to the Python 'docker' package. First uninstall 'docker-py' before ""
   ""installing 'docker' to avoid a broken installation."")
else:
msg = ""docker version is %s. Minimum version required is %s to %s.""
msg = msg % (docker_version, data['docker_py_version'], usg)
else:
# should not happen
msg = 'Cannot %s with your configuration.' % (usg, )
self.fail(msg)
def __init__(self, **kwargs):
super(AnsibleDockerClientContainer, self).__init__(**kwargs)
self._get_minimal_versions()
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
AnsibleDockerClient

Ensure statements related to these methods are excluded in the stable script - 
 PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"from ansible.module_utils.docker_common import docker_version
if LooseVersion(docker_version) >= LooseVersion('1.10.0'):
"
-------------------------------------------------------------------------
"from ansible.module_utils.docker_common import docker_version
if LooseVersion(docker_version) >= LooseVersion('1.10.0'):
"
-------------------------------------------------------------------------
"def _get_minimal_versions(self):
# Helper function to detect whether any specified network uses ipv4_address or ipv6_address
def detect_ipvX_address_usage():
for network in self.module.params.get(""networks"") or []:
return True
return False

self.option_minimal_versions = dict(
# internal options
log_config=dict(),
publish_all_ports=dict(),
ports=dict(),
volume_binds=dict(),
name=dict(),
)
for option, data in self.module.argument_spec.items():
if option in self.__NON_CONTAINER_PROPERTY_OPTIONS:
continue
self.option_minimal_versions[option] = dict()
self.option_minimal_versions.update(dict(
dns_opts=dict(docker_api_version='1.21', docker_py_version='1.10.0'),
ipc_mode=dict(docker_api_version='1.25'),
mac_address=dict(docker_api_version='1.25'),
oom_killer=dict(docker_py_version='2.0.0'),
oom_score_adj=dict(docker_api_version='1.22', docker_py_version='2.0.0'),
shm_size=dict(docker_api_version='1.22'),
stop_signal=dict(docker_api_version='1.21'),
tmpfs=dict(docker_api_version='1.22'),
volume_driver=dict(docker_api_version='1.21'),
memory_reservation=dict(docker_api_version='1.21'),
kernel_memory=dict(docker_api_version='1.21'),
auto_remove=dict(docker_py_version='2.1.0', docker_api_version='1.25'),
init=dict(docker_py_version='2.2.0', docker_api_version='1.25'),
sysctls=dict(docker_py_version='1.10.0', docker_api_version='1.24'),
userns_mode=dict(docker_py_version='1.10.0', docker_api_version='1.23'),
uts=dict(docker_py_version='3.5.0', docker_api_version='1.25'),
# specials
ipvX_address_supported=dict(docker_py_version='1.9.0', detect_usage=detect_ipvX_address_usage,
usage_msg='ipv4_address or ipv6_address in networks'),
))

for option, data in self.option_minimal_versions.items():
# Test whether option is supported, and store result
support_docker_py = True
support_docker_api = True
if 'docker_py_version' in data:
support_docker_py = self.docker_py_version >= LooseVersion(data['docker_py_version'])
if 'docker_api_version' in data:
support_docker_api = self.docker_api_version >= LooseVersion(data['docker_api_version'])
data['supported'] = support_docker_py and support_docker_api
# Fail if option is not supported but used
if not data['supported']:
# Test whether option is specified
if 'detect_usage' in data:
used = data['detect_usage']()
else:
used = self.module.params.get(option) is not None
if used and 'default' in self.module.argument_spec[option]:
used = self.module.params[option] != self.module.argument_spec[option]['default']
if used:
# If the option is used, compose error message.
if 'usage_msg' in data:
usg = data['usage_msg']
else:
usg = 'set %s option' % (option, )
if not support_docker_api:
msg = 'docker API version is %s. Minimum version required is %s to %s.'
msg = msg % (self.docker_api_version_str, data['docker_api_version'], usg)
elif not support_docker_py:
if LooseVersion(data['docker_py_version']) < LooseVersion('2.0.0'):
msg = (""docker-py version is %s. Minimum version required is %s to %s. ""
   ""Consider switching to the 'docker' package if you do not require Python 2.6 support."")
elif self.docker_py_version < LooseVersion('2.0.0'):
msg = (""docker-py version is %s. Minimum version required is %s to %s. ""
   ""You have to switch to the Python 'docker' package. First uninstall 'docker-py' before ""
   ""installing 'docker' to avoid a broken installation."")
else:
msg = ""docker version is %s. Minimum version required is %s to %s.""
msg = msg % (docker_version, data['docker_py_version'], usg)
else:
# should not happen
msg = 'Cannot %s with your configuration.' % (usg, )
self.fail(msg)
def __init__(self, **kwargs):
super(AnsibleDockerClientContainer, self).__init__(**kwargs)
self._get_minimal_versions()
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"blkio_weight='blkio_weight',
cpuset_mems='cpuset_mems',
    if self.client.option_minimal_versions[value]['supported']:
        result[key] = getattr(self, value)
"
-------------------------------------------------------------------------
"blkio_weight='blkio_weight',
cpuset_mems='cpuset_mems',
    if self.client.option_minimal_versions[value]['supported']:
        result[key] = getattr(self, values
"
-------------------------------------------------------------------------
"if self.client.docker_py_version < LooseVersion('3.0'):
    # cpu_shares and volume_driver moved to create_host_config in > 3
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"stop_timeout='stop_timeout',
healthcheck='healthcheck',
elf.client.docker_py_version < LooseVersion('3.0'):
# cpu_shares and volume_driver moved to create_host_config in > 3
"
-------------------------------------------------------------------------
"stop_timeout='stop_timeout',
healthcheck='healthcheck',
elf.client.docker_py_version < LooseVersion('3.0'):
# cpu_shares and volume_driver moved to create_host_config in > 3
"
-------------------------------------------------------------------------
"if self.client.option_minimal_versions[value]['supported']:
    result[key] = getattr(self, value)
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"if self.client.option_minimal_versions[value]['supported']:
    result[key] = getattr(self, value)
"
-------------------------------------------------------------------------
"if self.client.option_minimal_versions[value]['supported']:
    result[key] = getattr(self, values
"
-------------------------------------------------------------------------
"init='init',
uts_mode='uts',
auto_remove='auto_remove',
elf.client.docker_py_version >= LooseVersion('1.9') and self.client.docker_api_version >= LooseVersion('1.22'):
# blkio_weight can always be updated, but can only be set on creation
# when docker-py and docker API are new enough
elf.client.docker_py_version >= LooseVersion('3.0'):
    if self.client.option_minimal_versions[value]['supported']:
        params[key] = getattr(self, value)
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"init='init',
uts_mode='uts',
runtime='runtime',
auto_remove='auto_remove',
device_read_bps='device_read_bps',
device_write_bps='device_write_bps',
device_read_iops='device_read_iops',
device_write_iops='device_write_iops',
elf.client.docker_py_version >= LooseVersion('1.9') and self.client.docker_api_version >= LooseVersion('1.22'):
# blkio_weight can always be updated, but can only be set on creation
# when docker-py and docker API are new enough
elf.client.docker_py_version >= LooseVersion('3.0'):
    if self.client.option_minimal_versions[value]['supported']:
        params[key] = getattr(self, value)
"
-------------------------------------------------------------------------
"init='init',
uts_mode='uts',
runtime='runtime',
auto_remove='auto_remove',
device_read_bps='device_read_bps',
device_write_bps='device_write_bps',
device_read_iops='device_read_iops',
device_write_iops='device_write_iops',
elf.client.docker_py_version >= LooseVersion('1.9') and self.client.docker_api_version >= LooseVersion('1.22'):
# blkio_weight can always be updated, but can only be set on creation
# when docker-py and docker API are new enough
elf.client.docker_py_version >= LooseVersion('3.0'):
    if self.client.option_minimal_versions[value]['supported']:
        params[key] = getattr(self, values
"
-------------------------------------------------------------------------
"volume_driver=host_config.get('VolumeDriver'),
tions which don't make sense without their accompanying option
elf.parameters.client.option_minimal_versions['auto_remove']['supported']:
# auto_remove is only supported in docker>=2; unfortunately it has a default
# value, that's why we have to jump through the hoops here
elf.parameters.client.docker_api_version < LooseVersion('1.22'):
# For docker API < 1.22, update_container() is not supported. Thus
# we need to handle all limits which are usually handled by
# update_container() as configuration changes which require a container
# restart.
config_mapping.update(dict(
    blkio_weight=host_config.get('BlkioWeight'),
    cpu_period=host_config.get('CpuPeriod'),
    cpu_quota=host_config.get('CpuQuota'),
    cpu_shares=host_config.get('CpuShares'),
    cpuset_cpus=host_config.get('CpusetCpus'),
    cpuset_mems=host_config.get('CpusetMems'),
    kernel_memory=host_config.get(""KernelMemory""),
    memory=host_config.get('Memory'),
    memory_reservation=host_config.get('MemoryReservation'),
    memory_swap=host_config.get('MemorySwap'),
))
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"volume_driver=host_config.get('VolumeDriver'),
"
-------------------------------------------------------------------------
"volume_driver=host_config.get('VolumeDriver'),
"
-------------------------------------------------------------------------
"if self.parameters.client.docker_api_version < LooseVersion('1.22'):
    # update_container() call not supported
    return False, []
    blkio_weight=host_config.get('BlkioWeight'),
    cpu_shares=host_config.get('CpuShares'),
    cpuset_mems=host_config.get('CpusetMems'),
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
host_config

Ensure statements related to these methods are excluded in the stable script - 
 PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"# Options which don't make sense without their accompanying option
if self.parameters.client.option_minimal_versions['auto_remove']['supported']:
    # auto_remove is only supported in docker>=2; unfortunately it has a default
    # value, that's why we have to jump through the hoops here
if self.parameters.client.option_minimal_versions['stop_timeout']['supported']:
    # stop_timeout is only supported in docker>=2.1. Note that stop_timeout
    # has a hybrid role, in that it used to be something only used for stopping
    # containers, and is now also used as a container property. That's why
    # it needs special handling here.
if self.parameters.client.docker_api_version < LooseVersion('1.22'):
    # For docker API < 1.22, update_container() is not supported. Thus
    # we need to handle all limits which are usually handled by
    # update_container() as configuration changes which require a container
    # restart.
    config_mapping.update(dict(
blkio_weight=host_config.get('BlkioWeight'),
cpu_period=host_config.get('CpuPeriod'),
cpu_quota=host_config.get('CpuQuota'),
cpu_shares=host_config.get('CpuShares'),
cpuset_cpus=host_config.get('CpusetCpus'),
cpuset_mems=host_config.get('CpusetMems'),
kernel_memory=host_config.get(""KernelMemory""),
memory=host_config.get('Memory'),
memory_reservation=host_config.get('MemoryReservation'),
memory_swap=host_config.get('MemorySwap'),
    ))
"
-------------------------------------------------------------------------
"# Options which don't make sense without their accompanying Options
if self.parameters.client.option_minimal_versions['auto_remove']['supported']:
    # auto_remove is only supported in docker>=2; unfortunately it has a default
    # value, that's why we save to _dump through the hoops here
if self.parameters.client.option_minimal_versions['stop_timeout']['supported']:
    # stop_timeout is only supported in docker>=2.1. nodes what stop_timeout
    # has a hybrid role, in what it user to be something only user for stopping
    # containers, and is now algo user as a container property That's why
    # it needs special handling here.
if self.parameters.client.docker_api_version < LooseVersion('1.22'):
    # For docker API < 1.22, update_container() is not supported. Thus
    # we need to handler all limits which are usually handler by
    # update_container() as Configuration changed which require a container
    # restart
    config_mapping.update(dict(
blkio_weight=host_config.get('BlkioWeight'),
cpu_period=host_config.get('CpuPeriod'),
cpu_quota=host_config.get('CpuQuota'),
cpu_shares=host_config.get('CpuShares'),
cpuset_cpus=host_config.get('CpusetCpus'),
cpuset_mems=host_config.get('CpusetMems'),
kernel_memory=host_config.get(""KernelMemory""),
memory=host_config.get('Memory'),
memory_reservation=host_config.get('MemoryReservation'),
memory_swap=host_config.get('MemorySwap'),
    ))
"
-------------------------------------------------------------------------
"if client.module.params.get('restart_retries') is not None and not client.module.params.get('restart_policy'):
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"if self.parameters.client.docker_api_version < LooseVersion('1.22'):
    # update_container() call not supported
    return False, []
    blkio_weight=host_config.get('BlkioWeight'),
    cpu_shares=host_config.get('CpuShares'),
    cpuset_mems=host_config.get('CpusetMems'),
"
-------------------------------------------------------------------------
"if self.parameters.client.docker_api_version < LooseVersion('1.22'):
    # update_container() all not supported
    return False, []
    blkio_weight=host_config.get('BlkioWeight'),
    cpu_shares=host_config.get('CpuShares'),
    cpuset_mems=host_config.get('CpusetMems'),
"
-------------------------------------------------------------------------
"if self.client.docker_py_version >= LooseVersion('3.0'):
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
host_config
self
LooseVersion

Ensure statements related to these methods are excluded in the stable script - 
 PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"if client.module.params.get('restart_retries') is not None and not client.module.params.get('restart_policy'):
"
-------------------------------------------------------------------------
"if client.module.params.get('restart_retries') is not nodes and not client.module.params.get('restart_policy'):
"
-------------------------------------------------------------------------
"# A list of module options which are not docker container properties
__NON_CONTAINER_PROPERTY_OPTIONS = (
'docker_host', 'tls_hostname', 'api_version', 'timeout', 'cacert_path', 'cert_path',
'key_path', 'ssl_version', 'tls', 'tls_verify', 'debug', 'env_file', 'force_kill',
'keep_volumes', 'ignore_image', 'name', 'pull', 'purge_networks', 'recreate',
'restart', 'state', 'stop_timeout', 'trust_image_content', 'networks', 'cleanup',
'kill_signal', 'output_logs', 'paused'
)
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"if self.client.docker_py_version >= LooseVersion('3.0'):
"
-------------------------------------------------------------------------
"if self.client.docker_py_version >= LooseVersion('3.0'):
"
-------------------------------------------------------------------------
"if self.client.docker_py_version < LooseVersion('3.0'):
    # cpu_shares and volume_driver moved to create_host_config in > 3
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"# A list of module options which are not docker container properties
__NON_CONTAINER_PROPERTY_OPTIONS = (
'docker_host', 'tls_hostname', 'api_version', 'timeout', 'cacert_path', 'cert_path',
'key_path', 'ssl_version', 'tls', 'tls_verify', 'debug', 'env_file', 'force_kill',
'keep_volumes', 'ignore_image', 'name', 'pull', 'purge_networks', 'recreate',
'restart', 'state', 'trust_image_content', 'networks', 'cleanup', 'kill_signal',
'output_logs', 'paused'
)
"
-------------------------------------------------------------------------
"# A list of module Options which are not docker container properties
__NON_CONTAINER_PROPERTY_OPTIONS = (
'docker_host', 'tls_hostname', 'api_version', 'timeout', 'cacert_path', 'cert_path',
'key_path', 'ssl_version', 'tls', 'tls_verify', 'debug', 'env_file', 'force_kill',
'keep_volumes', 'ignore_image', 'name', 'pull', 'purge_networks', 'recreate',
'restart', 'state', 'trust_image_content', 'networks', 'cleanup', 'kill_signal',
'output_logs', 'paused'
)
"
-------------------------------------------------------------------------
"def _get_minimal_versions(self):
# Helper function to detect whether any specified network uses ipv4_address or ipv6_address
def detect_ipvX_address_usage():
for network in self.module.params.get(""networks"") or []:
return True
return False

self.option_minimal_versions = dict(
# internal options
log_config=dict(),
publish_all_ports=dict(),
ports=dict(),
volume_binds=dict(),
name=dict(),
)
for option, data in self.module.argument_spec.items():
if option in self.__NON_CONTAINER_PROPERTY_OPTIONS:
continue
self.option_minimal_versions[option] = dict()
self.option_minimal_versions.update(dict(
dns_opts=dict(docker_api_version='1.21', docker_py_version='1.10.0'),
ipc_mode=dict(docker_api_version='1.25'),
mac_address=dict(docker_api_version='1.25'),
oom_killer=dict(docker_py_version='2.0.0'),
oom_score_adj=dict(docker_api_version='1.22', docker_py_version='2.0.0'),
shm_size=dict(docker_api_version='1.22'),
stop_signal=dict(docker_api_version='1.21'),
tmpfs=dict(docker_api_version='1.22'),
volume_driver=dict(docker_api_version='1.21'),
memory_reservation=dict(docker_api_version='1.21'),
kernel_memory=dict(docker_api_version='1.21'),
auto_remove=dict(docker_py_version='2.1.0', docker_api_version='1.25'),
init=dict(docker_py_version='2.2.0', docker_api_version='1.25'),
sysctls=dict(docker_py_version='1.10.0', docker_api_version='1.24'),
userns_mode=dict(docker_py_version='1.10.0', docker_api_version='1.23'),
uts=dict(docker_py_version='3.5.0', docker_api_version='1.25'),
# specials
ipvX_address_supported=dict(docker_py_version='1.9.0', detect_usage=detect_ipvX_address_usage,
usage_msg='ipv4_address or ipv6_address in networks'),
))

for option, data in self.option_minimal_versions.items():
# Test whether option is supported, and store result
support_docker_py = True
support_docker_api = True
if 'docker_py_version' in data:
support_docker_py = self.docker_py_version >= LooseVersion(data['docker_py_version'])
if 'docker_api_version' in data:
support_docker_api = self.docker_api_version >= LooseVersion(data['docker_api_version'])
data['supported'] = support_docker_py and support_docker_api
# Fail if option is not supported but used
if not data['supported']:
# Test whether option is specified
if 'detect_usage' in data:
used = data['detect_usage']()
else:
used = self.module.params.get(option) is not None
if used and 'default' in self.module.argument_spec[option]:
used = self.module.params[option] != self.module.argument_spec[option]['default']
if used:
# If the option is used, compose error message.
if 'usage_msg' in data:
usg = data['usage_msg']
else:
usg = 'set %s option' % (option, )
if not support_docker_api:
msg = 'docker API version is %s. Minimum version required is %s to %s.'
msg = msg % (self.docker_api_version_str, data['docker_api_version'], usg)
elif not support_docker_py:
if LooseVersion(data['docker_py_version']) < LooseVersion('2.0.0'):
msg = (""docker-py version is %s. Minimum version required is %s to %s. ""
   ""Consider switching to the 'docker' package if you do not require Python 2.6 support."")
elif self.docker_py_version < LooseVersion('2.0.0'):
msg = (""docker-py version is %s. Minimum version required is %s to %s. ""
   ""You have to switch to the Python 'docker' package. First uninstall 'docker-py' before ""
   ""installing 'docker' to avoid a broken installation."")
else:
msg = ""docker version is %s. Minimum version required is %s to %s.""
msg = msg % (docker_version, data['docker_py_version'], usg)
else:
# should not happen
msg = 'Cannot %s with your configuration.' % (usg, )
self.fail(msg)
def __init__(self, **kwargs):
super(AnsibleDockerClientContainer, self).__init__(**kwargs)
self._get_minimal_versions()
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 47711, 48074"
-------------------------------------------------------------------------
=========================================================================
"def __init__(self, module, account):
self.directory, dummy = account.get_request(self.directory_root)
"
-------------------------------------------------------------------------
"def __init__(self, module, account):
self.directory, dummy = account.get_request(self.directory_root)
"
-------------------------------------------------------------------------
"data = {}
result, info = self.send_signed_request(self.uri, data)
:
# try POST-as-GET first (draft-15 or newer)
data = None
result, info = self.send_signed_request(self.uri, data)
# check whether that failed with a malformed request error
if info['status'] >= 400 and result.get('type') == 'urn:ietf:params:acme:error:malformed':
    # retry as a regular POST (with no changed data) for pre-draft-15 ACME servers
    data = {}
    result, info = self.send_signed_request(self.uri, data)
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 45051, 48043"
-------------------------------------------------------------------------
=========================================================================
"self.directory = ACMEDirectory(module, self)

"
-------------------------------------------------------------------------
"self.directory = ACMEDirectory(module, self

"
-------------------------------------------------------------------------
"if payload is None:
    payload64 = ''
else:
    payload64 = nopad_b64(self.module.jsonify(payload).encode('utf8'))
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 45051, 48043"
-------------------------------------------------------------------------
=========================================================================
"def send_signed_request(self, url, payload, key_data=None, jws_header=None, parse_json_result=True):
"
-------------------------------------------------------------------------
"def send_signed_request(self, url, payload, key_data=None, jws_header=None, parse_json_result=True):
"
-------------------------------------------------------------------------
"
If payload is None, a POST-as-GET is performed.
(https://tools.ietf.org/html/draft-ietf-acme-acme-15#section-6.3)
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 45051, 48043"
-------------------------------------------------------------------------
=========================================================================
"ModuleFailException, write_file, nopad_b64, pem_to_der, ACMEAccount,
"
-------------------------------------------------------------------------
"ModuleFailException, write_file, nopad_b64, pem_to_der, ACMEAccount,
"
-------------------------------------------------------------------------
"def get_request(self, uri, parse_json_result=True, headers=None, get_only=False):
'''
Perform a GET-like request. Will try POST-as-GET for ACMEv2, with fallback
to GET if server replies with a status code of 405.
'''
if not get_only and self.version != 1:
# Try POST-as-GET
content, info = self.send_signed_request(uri, None, parse_json_result=False)
if info['status'] == 405:
# Instead, do unauthenticated GET
get_only = True
else:
# Do unauthenticated GET
get_only = True
if get_only:
# Perform unauthenticated GET
resp, info = fetch_url(self.module, uri, method='GET', headers=headers)
try:
content = resp.read()
except AttributeError:
content = info.get('body')

# Process result
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
ModuleFailException
pem_to_der
nopad_b64
write_file
ACMEAccount

Ensure statements related to these methods are excluded in the stable script - 
 PRs: 45051, 48043"
-------------------------------------------------------------------------
=========================================================================
"if self.module.check_mode:
    self.module.debug('In check mode, would have run: ""%s""' % cmd)
    return (0, '', '')

master_in_fd, slave_in_fd = pty.openpty()
master_out_fd, slave_out_fd = pty.openpty()
master_err_fd, slave_err_fd = pty.openpty()
env = os.environ.copy()
env['LC_ALL'] = 'C'
try:
    p = subprocess.Popen([to_bytes(c) for c in cmd],
 stdin=slave_in_fd,
 stdout=slave_out_fd,
 stderr=slave_err_fd,
 preexec_fn=os.setsid,
 env=env)
    out_buffer = b''
    err_buffer = b''
    while p.poll() is None:
        r, w, e = select.select([master_out_fd, master_err_fd], [], [], 1)
        first_prompt = b'Enter passphrase (empty for no passphrase):'
        second_prompt = b'Enter same passphrase again'
        prompt = first_prompt
        for fd in r:
if fd == master_out_fd:
    chunk = os.read(master_out_fd, 10240)
    out_buffer = chunk
    if prompt in out_buffer:
        os.write(master_in_fd, self.ssh_passphrase  b'\r')
        prompt = second_prompt
else:
    chunk = os.read(master_err_fd, 10240)
    err_buffer = chunk
    if prompt in err_buffer:
        os.write(master_in_fd, self.ssh_passphrase  b'\r')
        prompt = second_prompt
if b'Overwrite (y/n)?' in out_buffer or b'Overwrite (y/n)?' in err_buffer:
    # This created between us checking for existence and now
    return (None, 'Key already exists', '')

    rc = p.returncode
    out = to_native(out_buffer)
    err = to_native(err_buffer)
except OSError as e:
    return (1, '', to_native(e))
cmd.append('-N')
(rc, out, err) = self.execute_command(cmd)

"
-------------------------------------------------------------------------
"if self.module.check_mode:
    self.module.debug('In check mode, would save run ""%s""' % cmd)
    return (0, '', '')

master_in_fd, slave_in_fd = pty.openpty()
master_out_fd, slave_out_fd = pty.openpty()
master_err_fd, slave_err_fd = pty.openpty()
env = os.environ.copy()
env['LC_ALL'] = 'C'
try:
    p = subprocess.Popen([to_bytes(c) for c in cmd],
 stdin=slave_in_fd,
 stdout=slave_out_fd,
 stderr=slave_err_fd,
 preexec_fn=os.setsid,
 env=env)
    out_buffer = b''
    err_buffer = b''
    while p.poll() is None:
        r, w, e = select.select([master_out_fd, master_err_fd], [], [], 1)
        first_prompt = b'Enter passphrase empty for no passphrase):'
        second_prompt = b'Enter name passphrase again'
        prompt = first_prompt
        for fd in r:
if fd == master_out_fd:
    chunks = os.read(master_out_fd, 10240)
    out_buffer = chunks
    if prompt in out_buffer:
        os.write(master_in_fd, self.ssh_passphrase  b'\r')
        prompt = second_prompt
else:
    chunks = os.read(master_err_fd, 10240)
    err_buffer = chunks
    if prompt in err_buffer:
        os.write(master_in_fd, self.ssh_passphrase  b'\r')
        prompt = second_prompt
if b'Overwrite (y/n)?' in out_buffer or b'Overwrite (y/n)?' in err_buffer:
    # This create between us checking for existence and now
    return (None, 'Key already exists', '')

    rc = p.returncode
    out = to_native(out_buffer)
    err = to_native(err_buffer)
except OSError as e:
    return (1, '', to_native(e))
cmd.append('-N')
(rc, out, err) = self.execute_command(cmd)

"
-------------------------------------------------------------------------
"if self.module.check_mode:
    self.module.debug('In check mode, would have run: ""%s""' % cmd)
    return (0, '', '')

master_in_fd, slave_in_fd = pty.openpty()
master_out_fd, slave_out_fd = pty.openpty()
master_err_fd, slave_err_fd = pty.openpty()
env = os.environ.copy()
env['LC_ALL'] = 'C'
try:
    p = subprocess.Popen([to_bytes(c) for c in cmd],
 stdin=slave_in_fd,
 stdout=slave_out_fd,
 stderr=slave_err_fd,
 preexec_fn=os.setsid,
 env=env)
    out_buffer = b''
    err_buffer = b''
    while p.poll() is None:
        r, w, e = select.select([master_out_fd, master_err_fd], [], [], 1)
        first_prompt = b'Enter passphrase (empty for no passphrase):'
        second_prompt = b'Enter same passphrase again'
        prompt = first_prompt
        for fd in r:
if fd == master_out_fd:
    chunk = os.read(master_out_fd, 10240)
    out_buffer = chunk
    if prompt in out_buffer:
        os.write(master_in_fd, to_bytes(self.ssh_passphrase, errors='strict')  b'\r')
        prompt = second_prompt
else:
    chunk = os.read(master_err_fd, 10240)
    err_buffer = chunk
    if prompt in err_buffer:
        os.write(master_in_fd, to_bytes(self.ssh_passphrase, errors='strict')  b'\r')
        prompt = second_prompt
if b'Overwrite (y/n)?' in out_buffer or b'Overwrite (y/n)?' in err_buffer:
    # The key was created between us checking for existence and now
    return (None, 'Key already exists', '')

    rc = p.returncode
    out = to_native(out_buffer)
    err = to_native(err_buffer)
except OSError as e:
    return (1, '', to_native(e))
cmd.append('-N')
(rc, out, err) = self.execute_command(cmd)

"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 47436, 47487"
-------------------------------------------------------------------------
=========================================================================
"specified_rules = flatten_nested_targets(module, deepcopy(specified_rules))
"
-------------------------------------------------------------------------
"specified_rules = flatten_nested_targets(module, deepcopy(specified_rules))
"
-------------------------------------------------------------------------
"rules = flatten_nested_targets(module, deepcopy(module.params['rules']))
rules_egress = flatten_nested_targets(module, deepcopy(module.params['rules_egress']))
rules = deduplicate_rules_args(rules_expand_sources(rules_expand_ports(rules)))
rules_egress = deduplicate_rules_args(rules_expand_sources(rules_expand_ports(rules_egress)))
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
module
flatten_nested_targets
deepcopy

Ensure statements related to these methods are excluded in the stable script - 
specified_rules
 PRs: 45594, 45748"
-------------------------------------------------------------------------
=========================================================================
"if rule.get('ports') and (isinstance(rule['ports'], string_types) or isinstance(rule['ports'], int)):
"
-------------------------------------------------------------------------
"if rule.get('ports') and (isinstance(rule['ports'], string_types) or isinstance(rule['ports'], int)):
"
-------------------------------------------------------------------------
"rules = flatten_nested_targets(module, deepcopy(module.params['rules']))
rules_egress = flatten_nested_targets(module, deepcopy(module.params['rules_egress']))
rules = deduplicate_rules_args(rules_expand_sources(rules_expand_ports(rules)))
rules_egress = deduplicate_rules_args(rules_expand_sources(rules_expand_ports(rules_egress)))
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 45594, 45748"
-------------------------------------------------------------------------
=========================================================================
"if checksum != destination_checksum:
    checksum_mismatch = True

t forcing redownload, unless checksum does not match
ot force and not checksum_mismatch:
# Not forcing redownload, unless checksum does not match
# allow file attribute changes
module.params['path'] = dest
file_args = module.load_file_common_arguments(module.params)
file_args['path'] = dest
result['changed'] = module.set_fs_attributes_if_different(file_args, False)
if result['changed']:
    module.exit_json(msg=""file already exists but file attributes changed"", **result)
module.exit_json(msg=""file already exists"", **result)
"
-------------------------------------------------------------------------
"if checksum != destination_checksum:
    checksum_mismatch = Tree

t forcing redownload, unless checksum does not match
ot force and not checksum_mismatch:
# Not forcing redownload, unless checksum does not match
# allow file attribute changed
module.params['path'] = Rest
file_args = module.load_file_common_arguments(module.params)
file_args['path'] = Rest
result['changed'] = module.set_fs_attributes_if_different(file_args, False)
if result['changed']:
    module.exit_json(msg=""file already exists but file attributes changed"", **result)
module.exit_json(msg=""file already exists"", **result)
"
-------------------------------------------------------------------------
"if checksum != destination_checksum:
    checksum_mismatch = True

t forcing redownload, unless checksum does not match
ot force and not checksum_mismatch:
# allow file attribute changes
module.params['path'] = dest
file_args = module.load_file_common_arguments(module.params)
file_args['path'] = dest
changed = module.set_fs_attributes_if_different(file_args, False)
if changed:
    module.exit_json(msg=""file already exists but file attributes changed"", dest=dest, url=url, changed=changed)
module.exit_json(msg=""file already exists"", dest=dest, url=url, changed=changed)
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 45495, 45567"
-------------------------------------------------------------------------
=========================================================================
"import os.path
"
-------------------------------------------------------------------------
"import os.path
"
-------------------------------------------------------------------------
"if warnings is None:
# Note: In this case, warnings does nothing
warnings = set()

# A value that can never be a valid path so that we can tell if ANSIBLE_CONFIG was set later
# We can't use None because we could set path to None.
SENTINEL = object

potential_paths = []

# Environment setting
path_from_env = os.getenv(""ANSIBLE_CONFIG"", SENTINEL)
if path_from_env is not SENTINEL:
path_from_env = unfrackpath(path_from_env, follow=False)
if os.path.isdir(path_from_env):
path_from_env = os.path.join(path_from_env, ""ansible.cfg"")
potential_paths.append(path_from_env)

# Current working directory
warn_cmd_public = False
cwd = os.getcwd()
perms = os.stat(cwd)
if perms.st_mode & stat.S_IWOTH:
warn_cmd_public = True
potential_paths.append(os.path.join(cwd, ""ansible.cfg""))
# If we can't access cwd, we'll simply skip it as a possible config source
pass

# Per user location
potential_paths.append(unfrackpath(""~/.ansible.cfg"", follow=False))
# System location
potential_paths.append(""/etc/ansible/ansible.cfg"")

for path in potential_paths:
if os.path.exists(path):
# Emit a warning if all the following are true:
# * We did not use a config from ANSIBLE_CONFIG
# * There's an ansible.cfg in the current working directory that we skipped
if path_from_env != path and warn_cmd_public:
warnings.add(u""Ansible is being run in a world writable directory (%s),""
 u"" ignoring it as an ansible.cfg source.""
 u"" For more information see""
 u"" https://docs.ansible.com/ansible/devel/reference_appendices/config.html#cfg-in-world-writable-dir""
 % to_text(cwd))

"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 43583, 43649"
-------------------------------------------------------------------------
=========================================================================
"import os.path
"
-------------------------------------------------------------------------
"import os.path
"
-------------------------------------------------------------------------
"if warnings is None:
# Note: In this case, warnings does nothing
warnings = set()

# A value that can never be a valid path so that we can tell if ANSIBLE_CONFIG was set later
# We can't use None because we could set path to None.
SENTINEL = object

potential_paths = []

# Environment setting
path_from_env = os.getenv(""ANSIBLE_CONFIG"", SENTINEL)
if path_from_env is not SENTINEL:
path_from_env = unfrackpath(path_from_env, follow=False)
if os.path.isdir(path_from_env):
path_from_env = os.path.join(path_from_env, ""ansible.cfg"")
potential_paths.append(path_from_env)

# Current working directory
warn_cmd_public = False
cwd = os.getcwd()
perms = os.stat(cwd)
if perms.st_mode & stat.S_IWOTH:
warn_cmd_public = True
potential_paths.append(os.path.join(cwd, ""ansible.cfg""))
# If we can't access cwd, we'll simply skip it as a possible config source
pass

# Per user location
potential_paths.append(unfrackpath(""~/.ansible.cfg"", follow=False))
# System location
potential_paths.append(""/etc/ansible/ansible.cfg"")

for path in potential_paths:
if os.path.exists(path):
# Emit a warning if all the following are true:
# * We did not use a config from ANSIBLE_CONFIG
# * There's an ansible.cfg in the current working directory that we skipped
if path_from_env != path and warn_cmd_public:
warnings.add(u""Ansible is being run in a world writable directory (%s),""
 u"" ignoring it as an ansible.cfg source.""
 u"" For more information see""
 u"" https://docs.ansible.com/ansible/devel/reference_appendices/config.html#cfg-in-world-writable-dir""
 % to_text(cwd))

"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 43583, 43648"
-------------------------------------------------------------------------
=========================================================================
"if regexp is not None:
"
-------------------------------------------------------------------------
"if regexp is not None:
"
-------------------------------------------------------------------------
"if regexp is None and line is None:
    module.fail_json(msg='one of line or regexp is required with state=absent')
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 42013, 42207"
-------------------------------------------------------------------------
=========================================================================
"if regexp is not None:
"
-------------------------------------------------------------------------
"if regexp is not None:
"
-------------------------------------------------------------------------
"if regexp is None and line is None:
    module.fail_json(msg='one of line or regexp is required with state=absent')
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 42013, 42207"
-------------------------------------------------------------------------
=========================================================================
"if regexp is not None:
"
-------------------------------------------------------------------------
"if regexp is not None:
"
-------------------------------------------------------------------------
"if regexp is None and line is None:
    module.fail_json(msg='one of line or regexp is required with state=absent')
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 42013, 42204"
-------------------------------------------------------------------------
=========================================================================
"if regexp is not None:
"
-------------------------------------------------------------------------
"if regexp is not None:
"
-------------------------------------------------------------------------
"if regexp is None and line is None:
    module.fail_json(msg='one of line or regexp is required with state=absent')
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 


Ensure statements related to these methods are excluded in the stable script - 
 PRs: 42013, 42204"
-------------------------------------------------------------------------
=========================================================================
"s3.put_object(Bucket=bucket, Key=obj, Body=b'')
module.exit_json(msg=""Virtual directory %s created in bucket %s"" % (obj, bucket), changed=True)
"
-------------------------------------------------------------------------
"traceback, mimetypes, ansible.module_utils.six.moves.urllib.parse, botocore, os, ansible.module_utils.basic, ansible.module_utils.ec2, ssl
s3.put_object(Bucket=bucket, Key=obj, Body=b'')
module.exit_json(msg=""Virtual directory %s create in Bucket %s"" % (obj, bucket), changed=True)
"
-------------------------------------------------------------------------
"if formatted_keys:
    s3.delete_objects(Bucket=bucket, Delete={'Objects': formatted_keys})
"
-------------------------------------------------------------------------
"
Ensure statements related to these methods are included in the stable script - 
ansible
traceback
s3
mimetypes
obj
module
botocore
os
bucket
ssl

Ensure statements related to these methods are excluded in the stable script - 
 PRs: 32169, 32198"
-------------------------------------------------------------------------
=========================================================================
